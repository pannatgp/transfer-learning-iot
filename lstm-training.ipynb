{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10602361,"sourceType":"datasetVersion","datasetId":6562823},{"sourceId":10645250,"sourceType":"datasetVersion","datasetId":6591490},{"sourceId":10645964,"sourceType":"datasetVersion","datasetId":6591941},{"sourceId":10836726,"sourceType":"datasetVersion","datasetId":6542647},{"sourceId":10954494,"sourceType":"datasetVersion","datasetId":6727332}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf_cleaned_3 = pd.read_csv('/kaggle/input/cicids2017/df_cleaned_3.csv')\ndf_cleaned_4 = pd.read_csv('/kaggle/input/cicids2017/df_cleaned_4.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:47:29.195484Z","iopub.execute_input":"2025-03-27T20:47:29.195741Z","iopub.status.idle":"2025-03-27T20:48:20.096433Z","shell.execute_reply.started":"2025-03-27T20:47:29.195717Z","shell.execute_reply":"2025-03-27T20:48:20.095215Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Separate features (X) and labels (y)\nX = df_cleaned_4.values  # Features\ny = df_cleaned_3['Encoded_Label'].values  # Encoded labels\n\n# # Normalize the features\n# from sklearn.preprocessing import StandardScaler\n# scaler = StandardScaler()\n# X = scaler.fit_transform(X)\n# Split the data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\n# Initial split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:20.097607Z","iopub.execute_input":"2025-03-27T20:48:20.097919Z","iopub.status.idle":"2025-03-27T20:48:25.862670Z","shell.execute_reply.started":"2025-03-27T20:48:20.097859Z","shell.execute_reply":"2025-03-27T20:48:25.861496Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\n# Check for extremely large values\nprint(\"Max value in X_train:\", np.max(X_train))\nprint(\"Min value in X_train:\", np.min(X_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:25.863812Z","iopub.execute_input":"2025-03-27T20:48:25.864477Z","iopub.status.idle":"2025-03-27T20:48:26.041088Z","shell.execute_reply.started":"2025-03-27T20:48:25.864434Z","shell.execute_reply":"2025-03-27T20:48:26.039194Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train: 2071000000.0\nMin value in X_train: -32212234632.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Apply SMOTE to the training set\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\nscaler = StandardScaler()\nsmote = SMOTE(random_state=42)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:26.043047Z","iopub.execute_input":"2025-03-27T20:48:26.043892Z","iopub.status.idle":"2025-03-27T20:48:26.780063Z","shell.execute_reply.started":"2025-03-27T20:48:26.043791Z","shell.execute_reply":"2025-03-27T20:48:26.778726Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import load_model, Model\n# from tensorflow.keras.layers import Dense, Input\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.layers import Flatten\n\n# # Load the pre-trained model\n# pretrained_model = load_model(\"/kaggle/input/unsw-nb15-lstm-model/unsw_nb15_lstm_model.h5\")\n\n# # Freeze all layers except the last layer\n# for layer in pretrained_model.layers[:-1]:\n#     layer.trainable = False\n\n# # Check the model summary before modification\n# print(\"Pre-trained model summary:\")\n# pretrained_model.summary()\n\n# # Number of classes in CICIDS2017 dataset\n# num_classes_cicids2017 = 15\n\n# # Assuming the original input shape was (time_steps, features) -> (1, 56)\n# input_layer = Input(shape=(1, 56))  # Add an explicit time_steps dimension\n\n# # Pass input through the model except the final Dense layer\n# x = input_layer\n# for layer in pretrained_model.layers[:-1]:  # Exclude the last output layer\n#     x = layer(x)\n\n# # Flatten the output before the new Dense layer\n# x = Flatten()(x)\n\n# # Add a new output layer\n# output_layer = Dense(num_classes_cicids2017, activation=\"softmax\")(x)\n\n# # Create the fine-tuned model\n# fine_tuned_model = Model(inputs=input_layer, outputs=output_layer)\n\n# # Compile the fine-tuned model\n# fine_tuned_model.compile(\n#     optimizer=Adam(learning_rate=1e-4),\n#     loss=\"sparse_categorical_crossentropy\",\n#     metrics=[\"accuracy\"]\n# )\n\n# # Print model summary\n# fine_tuned_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:26.781066Z","iopub.execute_input":"2025-03-27T20:48:26.781517Z","iopub.status.idle":"2025-03-27T20:48:26.786948Z","shell.execute_reply.started":"2025-03-27T20:48:26.781481Z","shell.execute_reply":"2025-03-27T20:48:26.785327Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model, Model\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\n\n\nfine_tuned_model = load_model('/kaggle/input/model-saved/checkpoint_model_lstm-4.keras')\nfine_tuned_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:26.791224Z","iopub.execute_input":"2025-03-27T20:48:26.791637Z","iopub.status.idle":"2025-03-27T20:48:42.175972Z","shell.execute_reply.started":"2025-03-27T20:48:26.791606Z","shell.execute_reply":"2025-03-27T20:48:42.174863Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m56\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m20\u001b[0m)               │           \u001b[38;5;34m6,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m20\u001b[0m)               │           \u001b[38;5;34m3,280\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m315\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,280</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,387\u001b[0m (40.58 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,387</span> (40.58 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m315\u001b[0m (1.23 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> (1.23 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,440\u001b[0m (36.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,440</span> (36.88 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m632\u001b[0m (2.47 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">632</span> (2.47 KB)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\n# Path to save the model\ncheckpoint_filepath = '/kaggle/working/checkpoint_model_lstm.keras'\n#checkpoint_filepath_weight = '/kaggle/working/checkpoint_model_gru.weights.h5'\n# checkpoint_filepath_f1 = '/kaggle/working/checkpoint_model_f1_gru.keras'\n# checkpoint_filepath_roc_auc = '/kaggle/working/checkpoint_model_roc_auc_gru.keras'\n\n# Configure ModelCheckpoint to save the full model\nmodel_checkpoint = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=False,  # Set to False to save the full model\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,  # Only save when 'val_accuracy' improves\n    verbose=1\n)\n\n# model_checkpoint_weight = ModelCheckpoint(\n#     filepath=checkpoint_filepath_weight,\n#     save_weights_only=True,  # Set to False to save the full model\n#     monitor='val_accuracy',\n#     mode='max',\n#     save_best_only=True,  # Only save when 'val_accuracy' improves\n#     verbose=1\n# )\n\n# Checkpoint to save the best model based on the highest validation F1 score\n# checkpoint_f1 = ModelCheckpoint(\n#     filepath= checkpoint_filepath_f1,\n#     save_weights_only=False,  # Set to False to save the full model\n#     monitor='val_f1_score',\n#     mode='max',\n#     save_best_only=True,\n#     verbose=1\n# )\n\n# # Checkpoint to save the best model based on the highest validation ROC-AUC score\n# checkpoint_roc_auc = ModelCheckpoint(\n#     filepath= checkpoint_filepath_roc_auc,\n#     save_weights_only=False,  # Set to False to save the full model\n#     monitor='val_roc_auc',\n#     mode='max',\n#     save_best_only=True,\n#     verbose=1\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:42.177337Z","iopub.execute_input":"2025-03-27T20:48:42.177988Z","iopub.status.idle":"2025-03-27T20:48:42.188483Z","shell.execute_reply.started":"2025-03-27T20:48:42.177959Z","shell.execute_reply":"2025-03-27T20:48:42.187286Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Get the original class distribution\nclass_counts = Counter(y_train)\nprint(\"Original class distribution:\", class_counts)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size = class_counts[min(class_counts, key=class_counts.get)]\ndesired_majority_size = minority_class_size * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy = {0: desired_majority_size, 1: minority_class_size}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\nX_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:42.189903Z","iopub.execute_input":"2025-03-27T20:48:42.190263Z","iopub.status.idle":"2025-03-27T20:48:44.449091Z","shell.execute_reply.started":"2025-03-27T20:48:42.190237Z","shell.execute_reply":"2025-03-27T20:48:44.447700Z"}},"outputs":[{"name":"stdout","text":"Original class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Apply SMOTE on the smaller subset\n\nX_train_resampled, y_train_resampled = smote.fit_resample(X_resampled, y_resampled)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:48:44.450230Z","iopub.execute_input":"2025-03-27T20:48:44.450634Z","iopub.status.idle":"2025-03-27T20:49:12.316984Z","shell.execute_reply.started":"2025-03-27T20:48:44.450604Z","shell.execute_reply":"2025-03-27T20:49:12.315852Z"}},"outputs":[{"name":"stdout","text":"Class Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"X_test = X_test.reshape(X_test.shape[0], 1, 56)  # Ensure shape matches training data\n\n# Evaluate the model\ntest_loss, test_accuracy = fine_tuned_model.evaluate(X_test, y_test, verbose=2)\n\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T20:49:12.318098Z","iopub.execute_input":"2025-03-27T20:49:12.318642Z","iopub.status.idle":"2025-03-27T20:49:48.465579Z","shell.execute_reply.started":"2025-03-27T20:49:12.318566Z","shell.execute_reply":"2025-03-27T20:49:48.464379Z"}},"outputs":[{"name":"stdout","text":"23633/23633 - 36s - 2ms/step - accuracy: 0.6277 - loss: 1.7277\nTest Loss: 1.7276767492294312\nTest Accuracy: 0.6277372241020203\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score, classification_report\n\n# Get model predictions (probability distributions)\ny_pred_probs = fine_tuned_model.predict(X_test)\n\n# Convert predicted probabilities to class labels\ny_pred_labels = np.argmax(y_pred_probs, axis=1)\n\n# Convert one-hot encoded y_test to class labels (if necessary)\nif len(y_test.shape) > 1 and y_test.shape[1] > 1:\n    y_test_labels = np.argmax(y_test, axis=1)  # Convert from one-hot to categorical labels\nelse:\n    y_test_labels = y_test  # Already categorical\n\n# Compute F1 Score\nf1_weighted = f1_score(y_test_labels, y_pred_labels, average=\"weighted\")\nf1_macro = f1_score(y_test_labels, y_pred_labels, average=\"macro\")\n\n# Print F1 Scores\nprint(\"Weighted F1 Score:\", f1_weighted)\nprint(\"Macro F1 Score:\", f1_macro)\n\n# Print full classification report\nprint(classification_report(y_test_labels, y_pred_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T21:28:10.359883Z","iopub.execute_input":"2025-03-27T21:28:10.361610Z","iopub.status.idle":"2025-03-27T21:29:02.589858Z","shell.execute_reply.started":"2025-03-27T21:28:10.361493Z","shell.execute_reply":"2025-03-27T21:29:02.588401Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m23633/23633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step\nWeighted F1 Score: 0.7097103918592812\nMacro F1 Score: 0.22147873190144804\n              precision    recall  f1-score   support\n\n           0       1.00      0.58      0.74    628518\n           1       0.03      0.51      0.06       584\n           2       0.49      0.79      0.60     38404\n           3       0.17      0.84      0.28      3086\n           4       0.53      0.82      0.64     51854\n           5       0.05      0.76      0.09      1568\n           6       0.04      0.82      0.08      1616\n           7       0.07      0.96      0.14      1779\n           8       0.01      1.00      0.01         3\n           9       0.00      0.64      0.00        11\n          10       0.41      0.97      0.57     27208\n          11       0.04      0.85      0.08       966\n          12       0.01      0.04      0.01       441\n          13       0.00      1.00      0.00         6\n          14       0.01      0.95      0.02       196\n\n    accuracy                           0.63    756240\n   macro avg       0.19      0.77      0.22    756240\nweighted avg       0.91      0.63      0.71    756240\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import load_model, Model\n# from tensorflow.keras.layers import Dense, Input\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.layers import Flatten\n\n# # Load the pre-trained model\n# pretrained_model = load_model(\"/kaggle/input/unsw-nb15-gru-model-h5/unsw_nb15_gru_model.h5\")\n\n# # Freeze all layers except the last layer\n# for layer in pretrained_model.layers[:-1]:\n#     layer.trainable = False\n\n# # Check the model summary before modification\n# print(\"Pre-trained model summary:\")\n# pretrained_model.summary()\n\n# # Number of classes in CICIDS2017 dataset\n# num_classes_cicids2017 = 15\n\n# # Assuming the original input shape was (time_steps, features) -> (1, 56)\n# input_layer = Input(shape=(1, 56))  # Add an explicit time_steps dimension\n\n# # Pass input through the model except the final Dense layer\n# x = input_layer\n# for layer in pretrained_model.layers[:-1]:  # Exclude the last output layer\n#     x = layer(x)\n\n# # Flatten the output before the new Dense layer\n# x = Flatten()(x)\n\n# # Add a new output layer\n# output_layer = Dense(num_classes_cicids2017, activation=\"softmax\")(x)\n\n# # Create the fine-tuned model\n# fine_tuned_model = Model(inputs=input_layer, outputs=output_layer)\n\n# # Compile the fine-tuned model\n# fine_tuned_model.compile(\n#     optimizer=Adam(learning_rate=1e-4),\n#     loss=\"sparse_categorical_crossentropy\",\n#     metrics=[\"accuracy\"]\n# )\n\n# # Print model summary\n# fine_tuned_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:40:28.682524Z","iopub.execute_input":"2025-03-06T15:40:28.682896Z","iopub.status.idle":"2025-03-06T15:40:28.687526Z","shell.execute_reply.started":"2025-03-06T15:40:28.682861Z","shell.execute_reply":"2025-03-06T15:40:28.686419Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# # Reshape the training and validation data to (samples, time_steps, features)\n# X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], 1, 56)\n# X_val = X_val.reshape(X_val.shape[0], 1, 56)\n\n\n\n# # Train the fine-tuned model\n# history = fine_tuned_model.fit(\n#     X_train_resampled,  # Features from CICIDS2017\n#     y_train_resampled,  # Labels from CICIDS2017\n#     validation_data=(X_val, y_val),  # Validation set\n#     epochs=50,  # Adjust based on the dataset size\n#     batch_size=64,  # Adjust batch size as needed\n#     verbose=2,\n#     callbacks=[model_checkpoint]\n# )\n\n# Epoch 50/50\n# 22687/22687 - 48s - 2ms/step - accuracy: 0.7439 - loss: 0.7466 - val_accuracy: 0.5533 - val_loss: 2.0748\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:40:28.688415Z","iopub.execute_input":"2025-03-06T15:40:28.688724Z","iopub.status.idle":"2025-03-06T15:40:28.713510Z","shell.execute_reply.started":"2025-03-06T15:40:28.688701Z","shell.execute_reply":"2025-03-06T15:40:28.712314Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], 1, 56)\nX_val = X_val.reshape(X_val.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled,  # Features from CICIDS2017\n    y_train_resampled,  # Labels from CICIDS2017\n    validation_data=(X_val, y_val),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T16:11:43.484369Z","iopub.execute_input":"2025-03-06T16:11:43.484769Z","iopub.status.idle":"2025-03-06T16:56:01.883328Z","shell.execute_reply.started":"2025-03-06T16:11:43.484737Z","shell.execute_reply":"2025-03-06T16:56:01.882171Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy improved from -inf to 0.05013, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 8s - 11ms/step - accuracy: 0.0932 - loss: 2.6692 - val_accuracy: 0.0501 - val_loss: 2.4197\nEpoch 2/500\n\nEpoch 2: val_accuracy improved from 0.05013 to 0.11588, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.2281 - loss: 2.4452 - val_accuracy: 0.1159 - val_loss: 2.3953\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.2821 - loss: 2.3201 - val_accuracy: 0.1127 - val_loss: 2.3955\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.2918 - loss: 2.2376 - val_accuracy: 0.1065 - val_loss: 2.3924\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.3390 - loss: 2.1738 - val_accuracy: 0.0913 - val_loss: 2.3904\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.3608 - loss: 2.1202 - val_accuracy: 0.0827 - val_loss: 2.3881\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.3603 - loss: 2.0732 - val_accuracy: 0.0825 - val_loss: 2.3894\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.3637 - loss: 2.0309 - val_accuracy: 0.0833 - val_loss: 2.3934\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.3855 - loss: 1.9922 - val_accuracy: 0.0918 - val_loss: 2.3892\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4386 - loss: 1.9563 - val_accuracy: 0.0939 - val_loss: 2.3956\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4425 - loss: 1.9230 - val_accuracy: 0.0955 - val_loss: 2.3997\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4445 - loss: 1.8918 - val_accuracy: 0.0934 - val_loss: 2.3878\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.11588\n726/726 - 6s - 8ms/step - accuracy: 0.4467 - loss: 1.8626 - val_accuracy: 0.0979 - val_loss: 2.3915\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4529 - loss: 1.8352 - val_accuracy: 0.0976 - val_loss: 2.4038\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4856 - loss: 1.8095 - val_accuracy: 0.1040 - val_loss: 2.3999\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4976 - loss: 1.7852 - val_accuracy: 0.1041 - val_loss: 2.4005\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.4990 - loss: 1.7624 - val_accuracy: 0.1041 - val_loss: 2.4030\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5006 - loss: 1.7408 - val_accuracy: 0.1042 - val_loss: 2.3988\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.11588\n726/726 - 5s - 8ms/step - accuracy: 0.5040 - loss: 1.7203 - val_accuracy: 0.1062 - val_loss: 2.4029\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5061 - loss: 1.7009 - val_accuracy: 0.1063 - val_loss: 2.4047\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5125 - loss: 1.6824 - val_accuracy: 0.1062 - val_loss: 2.3958\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5233 - loss: 1.6648 - val_accuracy: 0.1072 - val_loss: 2.4001\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5290 - loss: 1.6480 - val_accuracy: 0.1075 - val_loss: 2.3948\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5303 - loss: 1.6321 - val_accuracy: 0.1099 - val_loss: 2.3993\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.11588\n726/726 - 6s - 8ms/step - accuracy: 0.5323 - loss: 1.6168 - val_accuracy: 0.1099 - val_loss: 2.3969\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5327 - loss: 1.6022 - val_accuracy: 0.1099 - val_loss: 2.3989\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5394 - loss: 1.5882 - val_accuracy: 0.1104 - val_loss: 2.3920\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5523 - loss: 1.5748 - val_accuracy: 0.1107 - val_loss: 2.3966\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5634 - loss: 1.5619 - val_accuracy: 0.1107 - val_loss: 2.3922\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.11588\n726/726 - 5s - 7ms/step - accuracy: 0.5632 - loss: 1.5495 - val_accuracy: 0.1107 - val_loss: 2.3933\nEpoch 31/500\n\nEpoch 31: val_accuracy improved from 0.11588 to 0.11826, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.5677 - loss: 1.5376 - val_accuracy: 0.1183 - val_loss: 2.3905\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.11826\n726/726 - 5s - 7ms/step - accuracy: 0.5732 - loss: 1.5262 - val_accuracy: 0.1183 - val_loss: 2.3878\nEpoch 33/500\n\nEpoch 33: val_accuracy improved from 0.11826 to 0.11847, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5774 - loss: 1.5152 - val_accuracy: 0.1185 - val_loss: 2.3921\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.11847\n726/726 - 5s - 7ms/step - accuracy: 0.5789 - loss: 1.5046 - val_accuracy: 0.1185 - val_loss: 2.3912\nEpoch 35/500\n\nEpoch 35: val_accuracy improved from 0.11847 to 0.11847, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5789 - loss: 1.4943 - val_accuracy: 0.1185 - val_loss: 2.3852\nEpoch 36/500\n\nEpoch 36: val_accuracy improved from 0.11847 to 0.11850, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5791 - loss: 1.4845 - val_accuracy: 0.1185 - val_loss: 2.3796\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.11850\n726/726 - 6s - 8ms/step - accuracy: 0.5791 - loss: 1.4750 - val_accuracy: 0.1185 - val_loss: 2.3824\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.11850\n726/726 - 5s - 7ms/step - accuracy: 0.5839 - loss: 1.4658 - val_accuracy: 0.1185 - val_loss: 2.3806\nEpoch 39/500\n\nEpoch 39: val_accuracy improved from 0.11850 to 0.11871, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5877 - loss: 1.4569 - val_accuracy: 0.1187 - val_loss: 2.3809\nEpoch 40/500\n\nEpoch 40: val_accuracy improved from 0.11871 to 0.11871, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5889 - loss: 1.4483 - val_accuracy: 0.1187 - val_loss: 2.3815\nEpoch 41/500\n\nEpoch 41: val_accuracy improved from 0.11871 to 0.11874, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5893 - loss: 1.4400 - val_accuracy: 0.1187 - val_loss: 2.3732\nEpoch 42/500\n\nEpoch 42: val_accuracy improved from 0.11874 to 0.11888, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5901 - loss: 1.4319 - val_accuracy: 0.1189 - val_loss: 2.3746\nEpoch 43/500\n\nEpoch 43: val_accuracy improved from 0.11888 to 0.11930, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5910 - loss: 1.4241 - val_accuracy: 0.1193 - val_loss: 2.3736\nEpoch 44/500\n\nEpoch 44: val_accuracy improved from 0.11930 to 0.11930, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5911 - loss: 1.4166 - val_accuracy: 0.1193 - val_loss: 2.3724\nEpoch 45/500\n\nEpoch 45: val_accuracy improved from 0.11930 to 0.12459, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5915 - loss: 1.4092 - val_accuracy: 0.1246 - val_loss: 2.3673\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.12459\n726/726 - 5s - 7ms/step - accuracy: 0.5919 - loss: 1.4021 - val_accuracy: 0.1246 - val_loss: 2.3663\nEpoch 47/500\n\nEpoch 47: val_accuracy improved from 0.12459 to 0.12529, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.5923 - loss: 1.3952 - val_accuracy: 0.1253 - val_loss: 2.3690\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.12529\n726/726 - 5s - 7ms/step - accuracy: 0.5945 - loss: 1.3884 - val_accuracy: 0.1246 - val_loss: 2.3671\nEpoch 49/500\n\nEpoch 49: val_accuracy improved from 0.12529 to 0.12750, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.5995 - loss: 1.3818 - val_accuracy: 0.1275 - val_loss: 2.3613\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.12750\n726/726 - 5s - 7ms/step - accuracy: 0.6130 - loss: 1.3754 - val_accuracy: 0.1268 - val_loss: 2.3629\nEpoch 51/500\n\nEpoch 51: val_accuracy improved from 0.12750 to 0.12755, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6152 - loss: 1.3692 - val_accuracy: 0.1276 - val_loss: 2.3564\nEpoch 52/500\n\nEpoch 52: val_accuracy improved from 0.12755 to 0.12755, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6158 - loss: 1.3631 - val_accuracy: 0.1276 - val_loss: 2.3537\nEpoch 53/500\n\nEpoch 53: val_accuracy improved from 0.12755 to 0.12756, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6159 - loss: 1.3572 - val_accuracy: 0.1276 - val_loss: 2.3560\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.12756\n726/726 - 5s - 7ms/step - accuracy: 0.6159 - loss: 1.3515 - val_accuracy: 0.1275 - val_loss: 2.3538\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.12756\n726/726 - 5s - 7ms/step - accuracy: 0.6159 - loss: 1.3459 - val_accuracy: 0.1274 - val_loss: 2.3537\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.12756\n726/726 - 5s - 8ms/step - accuracy: 0.6159 - loss: 1.3404 - val_accuracy: 0.1274 - val_loss: 2.3488\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.12756\n726/726 - 5s - 7ms/step - accuracy: 0.6157 - loss: 1.3350 - val_accuracy: 0.1274 - val_loss: 2.3461\nEpoch 58/500\n\nEpoch 58: val_accuracy improved from 0.12756 to 0.12905, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6158 - loss: 1.3298 - val_accuracy: 0.1291 - val_loss: 2.3469\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.12905\n726/726 - 5s - 7ms/step - accuracy: 0.6156 - loss: 1.3247 - val_accuracy: 0.1291 - val_loss: 2.3397\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.12905\n726/726 - 5s - 7ms/step - accuracy: 0.6156 - loss: 1.3197 - val_accuracy: 0.1290 - val_loss: 2.3422\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.12905\n726/726 - 5s - 7ms/step - accuracy: 0.6157 - loss: 1.3148 - val_accuracy: 0.1290 - val_loss: 2.3328\nEpoch 62/500\n\nEpoch 62: val_accuracy improved from 0.12905 to 0.12913, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6157 - loss: 1.3100 - val_accuracy: 0.1291 - val_loss: 2.3339\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.12913\n726/726 - 5s - 7ms/step - accuracy: 0.6158 - loss: 1.3053 - val_accuracy: 0.1291 - val_loss: 2.3327\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.12913\n726/726 - 5s - 7ms/step - accuracy: 0.6160 - loss: 1.3008 - val_accuracy: 0.1291 - val_loss: 2.3322\nEpoch 65/500\n\nEpoch 65: val_accuracy improved from 0.12913 to 0.13027, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6162 - loss: 1.2963 - val_accuracy: 0.1303 - val_loss: 2.3253\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.13027\n726/726 - 5s - 7ms/step - accuracy: 0.6162 - loss: 1.2919 - val_accuracy: 0.1303 - val_loss: 2.3294\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.13027\n726/726 - 5s - 7ms/step - accuracy: 0.6162 - loss: 1.2876 - val_accuracy: 0.1303 - val_loss: 2.3306\nEpoch 68/500\n\nEpoch 68: val_accuracy improved from 0.13027 to 0.13028, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6161 - loss: 1.2834 - val_accuracy: 0.1303 - val_loss: 2.3244\nEpoch 69/500\n\nEpoch 69: val_accuracy improved from 0.13028 to 0.13028, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6168 - loss: 1.2792 - val_accuracy: 0.1303 - val_loss: 2.3206\nEpoch 70/500\n\nEpoch 70: val_accuracy improved from 0.13028 to 0.13030, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6188 - loss: 1.2751 - val_accuracy: 0.1303 - val_loss: 2.3193\nEpoch 71/500\n\nEpoch 71: val_accuracy improved from 0.13030 to 0.13031, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6190 - loss: 1.2712 - val_accuracy: 0.1303 - val_loss: 2.3114\nEpoch 72/500\n\nEpoch 72: val_accuracy improved from 0.13031 to 0.13222, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6199 - loss: 1.2673 - val_accuracy: 0.1322 - val_loss: 2.3090\nEpoch 73/500\n\nEpoch 73: val_accuracy improved from 0.13222 to 0.13223, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6210 - loss: 1.2634 - val_accuracy: 0.1322 - val_loss: 2.3110\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.13223\n726/726 - 6s - 8ms/step - accuracy: 0.6225 - loss: 1.2597 - val_accuracy: 0.1322 - val_loss: 2.3076\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.13223\n726/726 - 5s - 7ms/step - accuracy: 0.6231 - loss: 1.2560 - val_accuracy: 0.1322 - val_loss: 2.3002\nEpoch 76/500\n\nEpoch 76: val_accuracy improved from 0.13223 to 0.13223, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6231 - loss: 1.2524 - val_accuracy: 0.1322 - val_loss: 2.3052\nEpoch 77/500\n\nEpoch 77: val_accuracy improved from 0.13223 to 0.13333, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6232 - loss: 1.2488 - val_accuracy: 0.1333 - val_loss: 2.3010\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.13333\n726/726 - 5s - 7ms/step - accuracy: 0.6234 - loss: 1.2453 - val_accuracy: 0.1333 - val_loss: 2.3026\nEpoch 79/500\n\nEpoch 79: val_accuracy improved from 0.13333 to 0.13350, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6235 - loss: 1.2419 - val_accuracy: 0.1335 - val_loss: 2.2933\nEpoch 80/500\n\nEpoch 80: val_accuracy improved from 0.13350 to 0.13359, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6236 - loss: 1.2385 - val_accuracy: 0.1336 - val_loss: 2.2932\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.13359\n726/726 - 5s - 7ms/step - accuracy: 0.6239 - loss: 1.2352 - val_accuracy: 0.1336 - val_loss: 2.2939\nEpoch 82/500\n\nEpoch 82: val_accuracy improved from 0.13359 to 0.13361, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6242 - loss: 1.2320 - val_accuracy: 0.1336 - val_loss: 2.2955\nEpoch 83/500\n\nEpoch 83: val_accuracy improved from 0.13361 to 0.13364, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6270 - loss: 1.2288 - val_accuracy: 0.1336 - val_loss: 2.2987\nEpoch 84/500\n\nEpoch 84: val_accuracy improved from 0.13364 to 0.21757, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6291 - loss: 1.2257 - val_accuracy: 0.2176 - val_loss: 2.2922\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.21757\n726/726 - 5s - 7ms/step - accuracy: 0.6337 - loss: 1.2226 - val_accuracy: 0.2176 - val_loss: 2.2916\nEpoch 86/500\n\nEpoch 86: val_accuracy improved from 0.21757 to 0.21771, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6335 - loss: 1.2196 - val_accuracy: 0.2177 - val_loss: 2.2861\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.21771\n726/726 - 5s - 7ms/step - accuracy: 0.6361 - loss: 1.2166 - val_accuracy: 0.2176 - val_loss: 2.2871\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.21771\n726/726 - 5s - 7ms/step - accuracy: 0.6363 - loss: 1.2136 - val_accuracy: 0.2174 - val_loss: 2.2863\nEpoch 89/500\n\nEpoch 89: val_accuracy improved from 0.21771 to 0.21774, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6364 - loss: 1.2108 - val_accuracy: 0.2177 - val_loss: 2.2756\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6365 - loss: 1.2079 - val_accuracy: 0.2175 - val_loss: 2.2773\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6365 - loss: 1.2051 - val_accuracy: 0.2175 - val_loss: 2.2772\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6367 - loss: 1.2024 - val_accuracy: 0.2175 - val_loss: 2.2768\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6379 - loss: 1.1997 - val_accuracy: 0.2175 - val_loss: 2.2662\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6380 - loss: 1.1970 - val_accuracy: 0.2175 - val_loss: 2.2717\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6391 - loss: 1.1944 - val_accuracy: 0.2175 - val_loss: 2.2694\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.21774\n726/726 - 5s - 7ms/step - accuracy: 0.6394 - loss: 1.1918 - val_accuracy: 0.2175 - val_loss: 2.2664\nEpoch 97/500\n\nEpoch 97: val_accuracy improved from 0.21774 to 0.21969, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6391 - loss: 1.1892 - val_accuracy: 0.2197 - val_loss: 2.2604\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.21969\n726/726 - 5s - 7ms/step - accuracy: 0.6393 - loss: 1.1867 - val_accuracy: 0.2196 - val_loss: 2.2597\nEpoch 99/500\n\nEpoch 99: val_accuracy improved from 0.21969 to 0.21973, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6390 - loss: 1.1843 - val_accuracy: 0.2197 - val_loss: 2.2639\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.21973\n726/726 - 5s - 7ms/step - accuracy: 0.6392 - loss: 1.1818 - val_accuracy: 0.2197 - val_loss: 2.2625\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.21973\n726/726 - 5s - 7ms/step - accuracy: 0.6377 - loss: 1.1794 - val_accuracy: 0.2197 - val_loss: 2.2533\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.21973\n726/726 - 5s - 7ms/step - accuracy: 0.6390 - loss: 1.1771 - val_accuracy: 0.2197 - val_loss: 2.2535\nEpoch 103/500\n\nEpoch 103: val_accuracy improved from 0.21973 to 0.21984, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6376 - loss: 1.1747 - val_accuracy: 0.2198 - val_loss: 2.2625\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.21984\n726/726 - 5s - 7ms/step - accuracy: 0.6382 - loss: 1.1725 - val_accuracy: 0.2197 - val_loss: 2.2529\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.21984\n726/726 - 6s - 8ms/step - accuracy: 0.6370 - loss: 1.1702 - val_accuracy: 0.2198 - val_loss: 2.2486\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.21984\n726/726 - 5s - 7ms/step - accuracy: 0.6361 - loss: 1.1680 - val_accuracy: 0.2197 - val_loss: 2.2538\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.21984\n726/726 - 5s - 7ms/step - accuracy: 0.6365 - loss: 1.1658 - val_accuracy: 0.2198 - val_loss: 2.2534\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.21984\n726/726 - 5s - 7ms/step - accuracy: 0.6361 - loss: 1.1636 - val_accuracy: 0.2198 - val_loss: 2.2492\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.21984\n726/726 - 5s - 7ms/step - accuracy: 0.6362 - loss: 1.1615 - val_accuracy: 0.2198 - val_loss: 2.2487\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.21984\n726/726 - 5s - 7ms/step - accuracy: 0.6363 - loss: 1.1594 - val_accuracy: 0.2197 - val_loss: 2.2449\nEpoch 111/500\n\nEpoch 111: val_accuracy improved from 0.21984 to 0.23483, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6364 - loss: 1.1573 - val_accuracy: 0.2348 - val_loss: 2.2441\nEpoch 112/500\n\nEpoch 112: val_accuracy improved from 0.23483 to 0.23497, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6365 - loss: 1.1553 - val_accuracy: 0.2350 - val_loss: 2.2369\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.23497\n726/726 - 5s - 7ms/step - accuracy: 0.6368 - loss: 1.1533 - val_accuracy: 0.2348 - val_loss: 2.2415\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.23497\n726/726 - 5s - 7ms/step - accuracy: 0.6366 - loss: 1.1513 - val_accuracy: 0.2348 - val_loss: 2.2449\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.23497\n726/726 - 5s - 7ms/step - accuracy: 0.6366 - loss: 1.1493 - val_accuracy: 0.2348 - val_loss: 2.2395\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.23497\n726/726 - 5s - 7ms/step - accuracy: 0.6369 - loss: 1.1474 - val_accuracy: 0.2349 - val_loss: 2.2349\nEpoch 117/500\n\nEpoch 117: val_accuracy improved from 0.23497 to 0.23593, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6375 - loss: 1.1455 - val_accuracy: 0.2359 - val_loss: 2.2350\nEpoch 118/500\n\nEpoch 118: val_accuracy improved from 0.23593 to 0.23606, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6382 - loss: 1.1436 - val_accuracy: 0.2361 - val_loss: 2.2352\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.23606\n726/726 - 5s - 7ms/step - accuracy: 0.6390 - loss: 1.1417 - val_accuracy: 0.2361 - val_loss: 2.2302\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.23606\n726/726 - 5s - 7ms/step - accuracy: 0.6388 - loss: 1.1399 - val_accuracy: 0.2359 - val_loss: 2.2337\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.23606\n726/726 - 5s - 7ms/step - accuracy: 0.6390 - loss: 1.1381 - val_accuracy: 0.2361 - val_loss: 2.2294\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.23606\n726/726 - 5s - 7ms/step - accuracy: 0.6397 - loss: 1.1363 - val_accuracy: 0.2359 - val_loss: 2.2268\nEpoch 123/500\n\nEpoch 123: val_accuracy improved from 0.23606 to 0.23628, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6406 - loss: 1.1345 - val_accuracy: 0.2363 - val_loss: 2.2286\nEpoch 124/500\n\nEpoch 124: val_accuracy improved from 0.23628 to 0.23629, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6409 - loss: 1.1328 - val_accuracy: 0.2363 - val_loss: 2.2229\nEpoch 125/500\n\nEpoch 125: val_accuracy improved from 0.23629 to 0.23632, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6410 - loss: 1.1310 - val_accuracy: 0.2363 - val_loss: 2.2242\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.23632\n726/726 - 5s - 7ms/step - accuracy: 0.6411 - loss: 1.1293 - val_accuracy: 0.2363 - val_loss: 2.2236\nEpoch 127/500\n\nEpoch 127: val_accuracy improved from 0.23632 to 0.23852, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6412 - loss: 1.1276 - val_accuracy: 0.2385 - val_loss: 2.2166\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.23852\n726/726 - 5s - 7ms/step - accuracy: 0.6417 - loss: 1.1260 - val_accuracy: 0.2365 - val_loss: 2.2192\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.23852\n726/726 - 6s - 8ms/step - accuracy: 0.6419 - loss: 1.1243 - val_accuracy: 0.2376 - val_loss: 2.2213\nEpoch 130/500\n\nEpoch 130: val_accuracy improved from 0.23852 to 0.23979, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6423 - loss: 1.1227 - val_accuracy: 0.2398 - val_loss: 2.2154\nEpoch 131/500\n\nEpoch 131: val_accuracy improved from 0.23979 to 0.23988, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6425 - loss: 1.1211 - val_accuracy: 0.2399 - val_loss: 2.2146\nEpoch 132/500\n\nEpoch 132: val_accuracy improved from 0.23988 to 0.24016, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6425 - loss: 1.1195 - val_accuracy: 0.2402 - val_loss: 2.2160\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.24016\n726/726 - 5s - 7ms/step - accuracy: 0.6425 - loss: 1.1179 - val_accuracy: 0.2401 - val_loss: 2.2163\nEpoch 134/500\n\nEpoch 134: val_accuracy improved from 0.24016 to 0.24072, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6425 - loss: 1.1163 - val_accuracy: 0.2407 - val_loss: 2.2158\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.24072\n726/726 - 6s - 8ms/step - accuracy: 0.6426 - loss: 1.1148 - val_accuracy: 0.2407 - val_loss: 2.2165\nEpoch 136/500\n\nEpoch 136: val_accuracy improved from 0.24072 to 0.24074, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6426 - loss: 1.1133 - val_accuracy: 0.2407 - val_loss: 2.2102\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.24074\n726/726 - 5s - 7ms/step - accuracy: 0.6426 - loss: 1.1117 - val_accuracy: 0.2407 - val_loss: 2.2103\nEpoch 138/500\n\nEpoch 138: val_accuracy improved from 0.24074 to 0.24134, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6426 - loss: 1.1103 - val_accuracy: 0.2413 - val_loss: 2.2088\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.24134\n726/726 - 5s - 7ms/step - accuracy: 0.6427 - loss: 1.1088 - val_accuracy: 0.2413 - val_loss: 2.2120\nEpoch 140/500\n\nEpoch 140: val_accuracy improved from 0.24134 to 0.24135, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6427 - loss: 1.1073 - val_accuracy: 0.2413 - val_loss: 2.2036\nEpoch 141/500\n\nEpoch 141: val_accuracy improved from 0.24135 to 0.24135, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6427 - loss: 1.1059 - val_accuracy: 0.2413 - val_loss: 2.2038\nEpoch 142/500\n\nEpoch 142: val_accuracy improved from 0.24135 to 0.24241, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6430 - loss: 1.1044 - val_accuracy: 0.2424 - val_loss: 2.2033\nEpoch 143/500\n\nEpoch 143: val_accuracy improved from 0.24241 to 0.24241, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.1030 - val_accuracy: 0.2424 - val_loss: 2.2037\nEpoch 144/500\n\nEpoch 144: val_accuracy improved from 0.24241 to 0.24420, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.1016 - val_accuracy: 0.2442 - val_loss: 2.1991\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.24420\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.1002 - val_accuracy: 0.2424 - val_loss: 2.2013\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.24420\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.0989 - val_accuracy: 0.2436 - val_loss: 2.2031\nEpoch 147/500\n\nEpoch 147: val_accuracy improved from 0.24420 to 0.24421, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.0975 - val_accuracy: 0.2442 - val_loss: 2.1995\nEpoch 148/500\n\nEpoch 148: val_accuracy improved from 0.24421 to 0.24421, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6436 - loss: 1.0962 - val_accuracy: 0.2442 - val_loss: 2.2003\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.24421\n726/726 - 5s - 7ms/step - accuracy: 0.6436 - loss: 1.0949 - val_accuracy: 0.2436 - val_loss: 2.2030\nEpoch 150/500\n\nEpoch 150: val_accuracy improved from 0.24421 to 0.24421, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6436 - loss: 1.0935 - val_accuracy: 0.2442 - val_loss: 2.2002\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.24421\n726/726 - 5s - 7ms/step - accuracy: 0.6436 - loss: 1.0922 - val_accuracy: 0.2437 - val_loss: 2.1967\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.24421\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.0909 - val_accuracy: 0.2431 - val_loss: 2.1986\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.24421\n726/726 - 5s - 7ms/step - accuracy: 0.6437 - loss: 1.0897 - val_accuracy: 0.2439 - val_loss: 2.1867\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.24421\n726/726 - 5s - 8ms/step - accuracy: 0.6438 - loss: 1.0884 - val_accuracy: 0.2439 - val_loss: 2.1935\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.24421\n726/726 - 5s - 7ms/step - accuracy: 0.6439 - loss: 1.0872 - val_accuracy: 0.2439 - val_loss: 2.1935\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.24421\n726/726 - 5s - 7ms/step - accuracy: 0.6446 - loss: 1.0859 - val_accuracy: 0.2439 - val_loss: 2.1916\nEpoch 157/500\n\nEpoch 157: val_accuracy improved from 0.24421 to 0.24622, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6449 - loss: 1.0847 - val_accuracy: 0.2462 - val_loss: 2.1886\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.24622\n726/726 - 5s - 7ms/step - accuracy: 0.6473 - loss: 1.0834 - val_accuracy: 0.2461 - val_loss: 2.1864\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.24622\n726/726 - 5s - 7ms/step - accuracy: 0.6465 - loss: 1.0822 - val_accuracy: 0.2440 - val_loss: 2.1863\nEpoch 160/500\n\nEpoch 160: val_accuracy improved from 0.24622 to 0.24676, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6481 - loss: 1.0810 - val_accuracy: 0.2468 - val_loss: 2.1870\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.24676\n726/726 - 5s - 7ms/step - accuracy: 0.6508 - loss: 1.0799 - val_accuracy: 0.2464 - val_loss: 2.1874\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.24676\n726/726 - 5s - 7ms/step - accuracy: 0.6513 - loss: 1.0787 - val_accuracy: 0.2466 - val_loss: 2.1875\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.24676\n726/726 - 5s - 7ms/step - accuracy: 0.6510 - loss: 1.0775 - val_accuracy: 0.2466 - val_loss: 2.1878\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.24676\n726/726 - 5s - 8ms/step - accuracy: 0.6517 - loss: 1.0764 - val_accuracy: 0.2467 - val_loss: 2.1869\nEpoch 165/500\n\nEpoch 165: val_accuracy improved from 0.24676 to 0.24679, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6519 - loss: 1.0752 - val_accuracy: 0.2468 - val_loss: 2.1829\nEpoch 166/500\n\nEpoch 166: val_accuracy improved from 0.24679 to 0.24737, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6515 - loss: 1.0741 - val_accuracy: 0.2474 - val_loss: 2.1789\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.24737\n726/726 - 5s - 7ms/step - accuracy: 0.6519 - loss: 1.0730 - val_accuracy: 0.2474 - val_loss: 2.1812\nEpoch 168/500\n\nEpoch 168: val_accuracy improved from 0.24737 to 0.24751, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6520 - loss: 1.0718 - val_accuracy: 0.2475 - val_loss: 2.1790\nEpoch 169/500\n\nEpoch 169: val_accuracy improved from 0.24751 to 0.24757, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6519 - loss: 1.0707 - val_accuracy: 0.2476 - val_loss: 2.1791\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.24757\n726/726 - 5s - 7ms/step - accuracy: 0.6519 - loss: 1.0697 - val_accuracy: 0.2475 - val_loss: 2.1755\nEpoch 171/500\n\nEpoch 171: val_accuracy improved from 0.24757 to 0.24900, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6520 - loss: 1.0686 - val_accuracy: 0.2490 - val_loss: 2.1725\nEpoch 172/500\n\nEpoch 172: val_accuracy improved from 0.24900 to 0.24900, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6527 - loss: 1.0675 - val_accuracy: 0.2490 - val_loss: 2.1774\nEpoch 173/500\n\nEpoch 173: val_accuracy improved from 0.24900 to 0.24902, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6534 - loss: 1.0664 - val_accuracy: 0.2490 - val_loss: 2.1735\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.24902\n726/726 - 5s - 7ms/step - accuracy: 0.6536 - loss: 1.0654 - val_accuracy: 0.2490 - val_loss: 2.1794\nEpoch 175/500\n\nEpoch 175: val_accuracy improved from 0.24902 to 0.24903, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6537 - loss: 1.0643 - val_accuracy: 0.2490 - val_loss: 2.1753\nEpoch 176/500\n\nEpoch 176: val_accuracy improved from 0.24903 to 0.24905, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6537 - loss: 1.0633 - val_accuracy: 0.2491 - val_loss: 2.1726\nEpoch 177/500\n\nEpoch 177: val_accuracy improved from 0.24905 to 0.24906, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6540 - loss: 1.0622 - val_accuracy: 0.2491 - val_loss: 2.1723\nEpoch 178/500\n\nEpoch 178: val_accuracy improved from 0.24906 to 0.24907, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6543 - loss: 1.0612 - val_accuracy: 0.2491 - val_loss: 2.1715\nEpoch 179/500\n\nEpoch 179: val_accuracy improved from 0.24907 to 0.24944, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6543 - loss: 1.0602 - val_accuracy: 0.2494 - val_loss: 2.1684\nEpoch 180/500\n\nEpoch 180: val_accuracy improved from 0.24944 to 0.24945, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6543 - loss: 1.0592 - val_accuracy: 0.2495 - val_loss: 2.1653\nEpoch 181/500\n\nEpoch 181: val_accuracy improved from 0.24945 to 0.24946, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6543 - loss: 1.0582 - val_accuracy: 0.2495 - val_loss: 2.1670\nEpoch 182/500\n\nEpoch 182: val_accuracy improved from 0.24946 to 0.25008, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6546 - loss: 1.0572 - val_accuracy: 0.2501 - val_loss: 2.1625\nEpoch 183/500\n\nEpoch 183: val_accuracy improved from 0.25008 to 0.25453, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6582 - loss: 1.0562 - val_accuracy: 0.2545 - val_loss: 2.1688\nEpoch 184/500\n\nEpoch 184: val_accuracy improved from 0.25453 to 0.25487, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6614 - loss: 1.0552 - val_accuracy: 0.2549 - val_loss: 2.1697\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.25487\n726/726 - 5s - 7ms/step - accuracy: 0.6614 - loss: 1.0543 - val_accuracy: 0.2546 - val_loss: 2.1668\nEpoch 186/500\n\nEpoch 186: val_accuracy improved from 0.25487 to 0.25492, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6612 - loss: 1.0533 - val_accuracy: 0.2549 - val_loss: 2.1631\nEpoch 187/500\n\nEpoch 187: val_accuracy improved from 0.25492 to 0.25606, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6614 - loss: 1.0523 - val_accuracy: 0.2561 - val_loss: 2.1641\nEpoch 188/500\n\nEpoch 188: val_accuracy improved from 0.25606 to 0.25608, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6613 - loss: 1.0514 - val_accuracy: 0.2561 - val_loss: 2.1532\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.25608\n726/726 - 5s - 7ms/step - accuracy: 0.6613 - loss: 1.0505 - val_accuracy: 0.2559 - val_loss: 2.1631\nEpoch 190/500\n\nEpoch 190: val_accuracy improved from 0.25608 to 0.25645, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6613 - loss: 1.0495 - val_accuracy: 0.2564 - val_loss: 2.1586\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.25645\n726/726 - 5s - 7ms/step - accuracy: 0.6611 - loss: 1.0486 - val_accuracy: 0.2563 - val_loss: 2.1612\nEpoch 192/500\n\nEpoch 192: val_accuracy improved from 0.25645 to 0.25646, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6612 - loss: 1.0477 - val_accuracy: 0.2565 - val_loss: 2.1576\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.25646\n726/726 - 5s - 7ms/step - accuracy: 0.6663 - loss: 1.0468 - val_accuracy: 0.2564 - val_loss: 2.1604\nEpoch 194/500\n\nEpoch 194: val_accuracy improved from 0.25646 to 0.26184, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6667 - loss: 1.0459 - val_accuracy: 0.2618 - val_loss: 2.1575\nEpoch 195/500\n\nEpoch 195: val_accuracy improved from 0.26184 to 0.26203, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6683 - loss: 1.0450 - val_accuracy: 0.2620 - val_loss: 2.1589\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.26203\n726/726 - 6s - 8ms/step - accuracy: 0.6685 - loss: 1.0441 - val_accuracy: 0.2620 - val_loss: 2.1553\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.26203\n726/726 - 5s - 7ms/step - accuracy: 0.6685 - loss: 1.0432 - val_accuracy: 0.2620 - val_loss: 2.1538\nEpoch 198/500\n\nEpoch 198: val_accuracy improved from 0.26203 to 0.26205, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6684 - loss: 1.0423 - val_accuracy: 0.2620 - val_loss: 2.1564\nEpoch 199/500\n\nEpoch 199: val_accuracy improved from 0.26205 to 0.26215, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6683 - loss: 1.0414 - val_accuracy: 0.2622 - val_loss: 2.1500\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.26215\n726/726 - 5s - 7ms/step - accuracy: 0.6683 - loss: 1.0405 - val_accuracy: 0.2622 - val_loss: 2.1573\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.26215\n726/726 - 5s - 7ms/step - accuracy: 0.6683 - loss: 1.0397 - val_accuracy: 0.2621 - val_loss: 2.1542\nEpoch 202/500\n\nEpoch 202: val_accuracy improved from 0.26215 to 0.26216, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6683 - loss: 1.0388 - val_accuracy: 0.2622 - val_loss: 2.1568\nEpoch 203/500\n\nEpoch 203: val_accuracy improved from 0.26216 to 0.27452, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6682 - loss: 1.0380 - val_accuracy: 0.2745 - val_loss: 2.1464\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.27452\n726/726 - 5s - 7ms/step - accuracy: 0.6683 - loss: 1.0371 - val_accuracy: 0.2622 - val_loss: 2.1586\nEpoch 205/500\n\nEpoch 205: val_accuracy improved from 0.27452 to 0.27455, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6682 - loss: 1.0363 - val_accuracy: 0.2745 - val_loss: 2.1513\nEpoch 206/500\n\nEpoch 206: val_accuracy improved from 0.27455 to 0.27458, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6683 - loss: 1.0355 - val_accuracy: 0.2746 - val_loss: 2.1505\nEpoch 207/500\n\nEpoch 207: val_accuracy improved from 0.27458 to 0.27465, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6682 - loss: 1.0346 - val_accuracy: 0.2747 - val_loss: 2.1519\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.27465\n726/726 - 6s - 8ms/step - accuracy: 0.6703 - loss: 1.0338 - val_accuracy: 0.2632 - val_loss: 2.1544\nEpoch 209/500\n\nEpoch 209: val_accuracy improved from 0.27465 to 0.27476, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6683 - loss: 1.0330 - val_accuracy: 0.2748 - val_loss: 2.1415\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.27476\n726/726 - 6s - 8ms/step - accuracy: 0.6726 - loss: 1.0322 - val_accuracy: 0.2747 - val_loss: 2.1487\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.27476\n726/726 - 6s - 8ms/step - accuracy: 0.6761 - loss: 1.0314 - val_accuracy: 0.2747 - val_loss: 2.1456\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.27476\n726/726 - 6s - 8ms/step - accuracy: 0.6770 - loss: 1.0306 - val_accuracy: 0.2747 - val_loss: 2.1492\nEpoch 213/500\n\nEpoch 213: val_accuracy improved from 0.27476 to 0.27480, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6790 - loss: 1.0298 - val_accuracy: 0.2748 - val_loss: 2.1428\nEpoch 214/500\n\nEpoch 214: val_accuracy improved from 0.27480 to 0.27481, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6825 - loss: 1.0290 - val_accuracy: 0.2748 - val_loss: 2.1429\nEpoch 215/500\n\nEpoch 215: val_accuracy improved from 0.27481 to 0.27507, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6854 - loss: 1.0282 - val_accuracy: 0.2751 - val_loss: 2.1430\nEpoch 216/500\n\nEpoch 216: val_accuracy improved from 0.27507 to 0.27508, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.6871 - loss: 1.0274 - val_accuracy: 0.2751 - val_loss: 2.1464\nEpoch 217/500\n\nEpoch 217: val_accuracy improved from 0.27508 to 0.27509, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6865 - loss: 1.0266 - val_accuracy: 0.2751 - val_loss: 2.1431\nEpoch 218/500\n\nEpoch 218: val_accuracy improved from 0.27509 to 0.27510, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6866 - loss: 1.0259 - val_accuracy: 0.2751 - val_loss: 2.1445\nEpoch 219/500\n\nEpoch 219: val_accuracy improved from 0.27510 to 0.27526, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6905 - loss: 1.0251 - val_accuracy: 0.2753 - val_loss: 2.1387\nEpoch 220/500\n\nEpoch 220: val_accuracy improved from 0.27526 to 0.27526, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6906 - loss: 1.0243 - val_accuracy: 0.2753 - val_loss: 2.1424\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.27526\n726/726 - 5s - 7ms/step - accuracy: 0.6897 - loss: 1.0236 - val_accuracy: 0.2752 - val_loss: 2.1432\nEpoch 222/500\n\nEpoch 222: val_accuracy improved from 0.27526 to 0.27526, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6906 - loss: 1.0228 - val_accuracy: 0.2753 - val_loss: 2.1368\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.27526\n726/726 - 5s - 7ms/step - accuracy: 0.6905 - loss: 1.0221 - val_accuracy: 0.2752 - val_loss: 2.1401\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.27526\n726/726 - 5s - 7ms/step - accuracy: 0.6908 - loss: 1.0213 - val_accuracy: 0.2753 - val_loss: 2.1431\nEpoch 225/500\n\nEpoch 225: val_accuracy improved from 0.27526 to 0.27561, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6906 - loss: 1.0206 - val_accuracy: 0.2756 - val_loss: 2.1359\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.27561\n726/726 - 6s - 8ms/step - accuracy: 0.6905 - loss: 1.0199 - val_accuracy: 0.2756 - val_loss: 2.1358\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.27561\n726/726 - 5s - 7ms/step - accuracy: 0.6908 - loss: 1.0191 - val_accuracy: 0.2756 - val_loss: 2.1350\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.27561\n726/726 - 5s - 7ms/step - accuracy: 0.6913 - loss: 1.0184 - val_accuracy: 0.2756 - val_loss: 2.1391\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.27561\n726/726 - 5s - 7ms/step - accuracy: 0.6912 - loss: 1.0177 - val_accuracy: 0.2756 - val_loss: 2.1391\nEpoch 230/500\n\nEpoch 230: val_accuracy improved from 0.27561 to 0.27562, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6923 - loss: 1.0170 - val_accuracy: 0.2756 - val_loss: 2.1372\nEpoch 231/500\n\nEpoch 231: val_accuracy improved from 0.27562 to 0.27577, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6925 - loss: 1.0163 - val_accuracy: 0.2758 - val_loss: 2.1381\nEpoch 232/500\n\nEpoch 232: val_accuracy improved from 0.27577 to 0.27586, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.6934 - loss: 1.0155 - val_accuracy: 0.2759 - val_loss: 2.1292\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.27586\n726/726 - 5s - 7ms/step - accuracy: 0.6937 - loss: 1.0148 - val_accuracy: 0.2757 - val_loss: 2.1325\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.27586\n726/726 - 5s - 7ms/step - accuracy: 0.6933 - loss: 1.0141 - val_accuracy: 0.2756 - val_loss: 2.1353\nEpoch 235/500\n\nEpoch 235: val_accuracy improved from 0.27586 to 0.27963, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6937 - loss: 1.0134 - val_accuracy: 0.2796 - val_loss: 2.1280\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.27963\n726/726 - 5s - 7ms/step - accuracy: 0.6943 - loss: 1.0127 - val_accuracy: 0.2784 - val_loss: 2.1386\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.27963\n726/726 - 5s - 7ms/step - accuracy: 0.6963 - loss: 1.0121 - val_accuracy: 0.2785 - val_loss: 2.1331\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.27963\n726/726 - 5s - 7ms/step - accuracy: 0.6951 - loss: 1.0114 - val_accuracy: 0.2788 - val_loss: 2.1255\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.27963\n726/726 - 5s - 7ms/step - accuracy: 0.6970 - loss: 1.0107 - val_accuracy: 0.2758 - val_loss: 2.1292\nEpoch 240/500\n\nEpoch 240: val_accuracy improved from 0.27963 to 0.28270, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.6962 - loss: 1.0100 - val_accuracy: 0.2827 - val_loss: 2.1265\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6970 - loss: 1.0094 - val_accuracy: 0.2787 - val_loss: 2.1301\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6968 - loss: 1.0087 - val_accuracy: 0.2797 - val_loss: 2.1230\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6973 - loss: 1.0080 - val_accuracy: 0.2787 - val_loss: 2.1263\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6976 - loss: 1.0074 - val_accuracy: 0.2787 - val_loss: 2.1266\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6970 - loss: 1.0067 - val_accuracy: 0.2786 - val_loss: 2.1302\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6977 - loss: 1.0060 - val_accuracy: 0.2797 - val_loss: 2.1230\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6969 - loss: 1.0054 - val_accuracy: 0.2798 - val_loss: 2.1235\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6969 - loss: 1.0047 - val_accuracy: 0.2797 - val_loss: 2.1261\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6975 - loss: 1.0041 - val_accuracy: 0.2798 - val_loss: 2.1205\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.28270\n726/726 - 5s - 8ms/step - accuracy: 0.6973 - loss: 1.0035 - val_accuracy: 0.2826 - val_loss: 2.1265\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.28270\n726/726 - 6s - 8ms/step - accuracy: 0.6978 - loss: 1.0028 - val_accuracy: 0.2798 - val_loss: 2.1213\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6995 - loss: 1.0022 - val_accuracy: 0.2798 - val_loss: 2.1239\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.6985 - loss: 1.0016 - val_accuracy: 0.2827 - val_loss: 2.1219\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.28270\n726/726 - 5s - 8ms/step - accuracy: 0.6987 - loss: 1.0010 - val_accuracy: 0.2798 - val_loss: 2.1220\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.7011 - loss: 1.0003 - val_accuracy: 0.2798 - val_loss: 2.1187\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.28270\n726/726 - 6s - 8ms/step - accuracy: 0.7025 - loss: 0.9997 - val_accuracy: 0.2826 - val_loss: 2.1250\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.7021 - loss: 0.9991 - val_accuracy: 0.2826 - val_loss: 2.1205\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.7059 - loss: 0.9985 - val_accuracy: 0.2797 - val_loss: 2.1244\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.28270\n726/726 - 5s - 7ms/step - accuracy: 0.7047 - loss: 0.9979 - val_accuracy: 0.2797 - val_loss: 2.1190\nEpoch 260/500\n\nEpoch 260: val_accuracy improved from 0.28270 to 0.38967, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7062 - loss: 0.9973 - val_accuracy: 0.3897 - val_loss: 2.1175\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.38967\n726/726 - 5s - 7ms/step - accuracy: 0.7077 - loss: 0.9967 - val_accuracy: 0.3897 - val_loss: 2.1182\nEpoch 262/500\n\nEpoch 262: val_accuracy improved from 0.38967 to 0.39001, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7066 - loss: 0.9961 - val_accuracy: 0.3900 - val_loss: 2.1078\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.39001\n726/726 - 5s - 7ms/step - accuracy: 0.7102 - loss: 0.9955 - val_accuracy: 0.3900 - val_loss: 2.1195\nEpoch 264/500\n\nEpoch 264: val_accuracy improved from 0.39001 to 0.39003, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7098 - loss: 0.9949 - val_accuracy: 0.3900 - val_loss: 2.1142\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.39003\n726/726 - 5s - 7ms/step - accuracy: 0.7115 - loss: 0.9943 - val_accuracy: 0.3871 - val_loss: 2.1151\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.39003\n726/726 - 5s - 7ms/step - accuracy: 0.7108 - loss: 0.9937 - val_accuracy: 0.3871 - val_loss: 2.1146\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.39003\n726/726 - 5s - 8ms/step - accuracy: 0.7113 - loss: 0.9931 - val_accuracy: 0.3872 - val_loss: 2.1126\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.39003\n726/726 - 5s - 7ms/step - accuracy: 0.7110 - loss: 0.9925 - val_accuracy: 0.3871 - val_loss: 2.1120\nEpoch 269/500\n\nEpoch 269: val_accuracy improved from 0.39003 to 0.39011, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7113 - loss: 0.9920 - val_accuracy: 0.3901 - val_loss: 2.1128\nEpoch 270/500\n\nEpoch 270: val_accuracy improved from 0.39011 to 0.39020, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7124 - loss: 0.9914 - val_accuracy: 0.3902 - val_loss: 2.1122\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.39020\n726/726 - 5s - 7ms/step - accuracy: 0.7128 - loss: 0.9908 - val_accuracy: 0.3873 - val_loss: 2.1160\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.39020\n726/726 - 5s - 7ms/step - accuracy: 0.7118 - loss: 0.9902 - val_accuracy: 0.3902 - val_loss: 2.1141\nEpoch 273/500\n\nEpoch 273: val_accuracy improved from 0.39020 to 0.39020, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7125 - loss: 0.9897 - val_accuracy: 0.3902 - val_loss: 2.1083\nEpoch 274/500\n\nEpoch 274: val_accuracy improved from 0.39020 to 0.39020, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7128 - loss: 0.9891 - val_accuracy: 0.3902 - val_loss: 2.1096\nEpoch 275/500\n\nEpoch 275: val_accuracy improved from 0.39020 to 0.39024, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7129 - loss: 0.9886 - val_accuracy: 0.3902 - val_loss: 2.1074\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.39024\n726/726 - 5s - 7ms/step - accuracy: 0.7132 - loss: 0.9880 - val_accuracy: 0.3902 - val_loss: 2.1104\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.39024\n726/726 - 5s - 7ms/step - accuracy: 0.7132 - loss: 0.9875 - val_accuracy: 0.3874 - val_loss: 2.1054\nEpoch 278/500\n\nEpoch 278: val_accuracy improved from 0.39024 to 0.39027, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7134 - loss: 0.9869 - val_accuracy: 0.3903 - val_loss: 2.1087\nEpoch 279/500\n\nEpoch 279: val_accuracy improved from 0.39027 to 0.39029, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7135 - loss: 0.9864 - val_accuracy: 0.3903 - val_loss: 2.1081\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.39029\n726/726 - 5s - 8ms/step - accuracy: 0.7130 - loss: 0.9858 - val_accuracy: 0.3903 - val_loss: 2.1118\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.39029\n726/726 - 5s - 7ms/step - accuracy: 0.7136 - loss: 0.9853 - val_accuracy: 0.3903 - val_loss: 2.1127\nEpoch 282/500\n\nEpoch 282: val_accuracy improved from 0.39029 to 0.39030, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7140 - loss: 0.9847 - val_accuracy: 0.3903 - val_loss: 2.1052\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.39030\n726/726 - 5s - 7ms/step - accuracy: 0.7142 - loss: 0.9842 - val_accuracy: 0.3903 - val_loss: 2.1071\nEpoch 284/500\n\nEpoch 284: val_accuracy improved from 0.39030 to 0.39031, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7143 - loss: 0.9837 - val_accuracy: 0.3903 - val_loss: 2.1076\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.39031\n726/726 - 5s - 7ms/step - accuracy: 0.7147 - loss: 0.9831 - val_accuracy: 0.3903 - val_loss: 2.1069\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.39031\n726/726 - 6s - 8ms/step - accuracy: 0.7145 - loss: 0.9826 - val_accuracy: 0.3903 - val_loss: 2.1061\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.39031\n726/726 - 5s - 7ms/step - accuracy: 0.7149 - loss: 0.9821 - val_accuracy: 0.3903 - val_loss: 2.1072\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.39031\n726/726 - 5s - 7ms/step - accuracy: 0.7148 - loss: 0.9815 - val_accuracy: 0.3903 - val_loss: 2.1039\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.39031\n726/726 - 5s - 7ms/step - accuracy: 0.7147 - loss: 0.9810 - val_accuracy: 0.3874 - val_loss: 2.1058\nEpoch 290/500\n\nEpoch 290: val_accuracy improved from 0.39031 to 0.39051, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7147 - loss: 0.9805 - val_accuracy: 0.3905 - val_loss: 2.1026\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.39051\n726/726 - 5s - 7ms/step - accuracy: 0.7153 - loss: 0.9800 - val_accuracy: 0.3905 - val_loss: 2.1079\nEpoch 292/500\n\nEpoch 292: val_accuracy improved from 0.39051 to 0.39071, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7148 - loss: 0.9795 - val_accuracy: 0.3907 - val_loss: 2.0990\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.39071\n726/726 - 5s - 8ms/step - accuracy: 0.7145 - loss: 0.9790 - val_accuracy: 0.3904 - val_loss: 2.1002\nEpoch 294/500\n\nEpoch 294: val_accuracy improved from 0.39071 to 0.39072, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7197 - loss: 0.9785 - val_accuracy: 0.3907 - val_loss: 2.0988\nEpoch 295/500\n\nEpoch 295: val_accuracy improved from 0.39072 to 0.39087, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7239 - loss: 0.9779 - val_accuracy: 0.3909 - val_loss: 2.1015\nEpoch 296/500\n\nEpoch 296: val_accuracy improved from 0.39087 to 0.39104, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9774 - val_accuracy: 0.3910 - val_loss: 2.0995\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.39104\n726/726 - 5s - 7ms/step - accuracy: 0.7252 - loss: 0.9769 - val_accuracy: 0.3907 - val_loss: 2.1050\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.39104\n726/726 - 6s - 8ms/step - accuracy: 0.7257 - loss: 0.9764 - val_accuracy: 0.3910 - val_loss: 2.0928\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.39104\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9759 - val_accuracy: 0.3908 - val_loss: 2.0982\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.39104\n726/726 - 5s - 7ms/step - accuracy: 0.7250 - loss: 0.9754 - val_accuracy: 0.3908 - val_loss: 2.1021\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.39104\n726/726 - 5s - 7ms/step - accuracy: 0.7246 - loss: 0.9749 - val_accuracy: 0.3908 - val_loss: 2.0987\nEpoch 302/500\n\nEpoch 302: val_accuracy improved from 0.39104 to 0.39115, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7246 - loss: 0.9745 - val_accuracy: 0.3912 - val_loss: 2.0938\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7242 - loss: 0.9740 - val_accuracy: 0.3911 - val_loss: 2.0968\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.39115\n726/726 - 6s - 8ms/step - accuracy: 0.7246 - loss: 0.9735 - val_accuracy: 0.3907 - val_loss: 2.0985\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7242 - loss: 0.9730 - val_accuracy: 0.3909 - val_loss: 2.0956\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.39115\n726/726 - 6s - 8ms/step - accuracy: 0.7242 - loss: 0.9725 - val_accuracy: 0.3908 - val_loss: 2.0972\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9720 - val_accuracy: 0.3907 - val_loss: 2.0991\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9715 - val_accuracy: 0.3911 - val_loss: 2.0948\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7245 - loss: 0.9711 - val_accuracy: 0.3911 - val_loss: 2.0969\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.39115\n726/726 - 6s - 8ms/step - accuracy: 0.7243 - loss: 0.9706 - val_accuracy: 0.3912 - val_loss: 2.0870\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9701 - val_accuracy: 0.3909 - val_loss: 2.0953\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7242 - loss: 0.9696 - val_accuracy: 0.3910 - val_loss: 2.0908\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7242 - loss: 0.9692 - val_accuracy: 0.3909 - val_loss: 2.0994\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9687 - val_accuracy: 0.3908 - val_loss: 2.0938\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7242 - loss: 0.9682 - val_accuracy: 0.3908 - val_loss: 2.0932\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9678 - val_accuracy: 0.3911 - val_loss: 2.0897\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.39115\n726/726 - 5s - 8ms/step - accuracy: 0.7243 - loss: 0.9673 - val_accuracy: 0.3909 - val_loss: 2.0936\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9669 - val_accuracy: 0.3909 - val_loss: 2.0878\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9664 - val_accuracy: 0.3909 - val_loss: 2.0906\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9659 - val_accuracy: 0.3910 - val_loss: 2.0886\nEpoch 321/500\n\nEpoch 321: val_accuracy improved from 0.39115 to 0.39115, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9655 - val_accuracy: 0.3912 - val_loss: 2.0882\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.39115\n726/726 - 5s - 7ms/step - accuracy: 0.7243 - loss: 0.9650 - val_accuracy: 0.3908 - val_loss: 2.0910\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.39115\n726/726 - 6s - 8ms/step - accuracy: 0.7244 - loss: 0.9646 - val_accuracy: 0.3909 - val_loss: 2.0959\nEpoch 324/500\n\nEpoch 324: val_accuracy improved from 0.39115 to 0.39127, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9641 - val_accuracy: 0.3913 - val_loss: 2.0814\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9637 - val_accuracy: 0.3910 - val_loss: 2.0878\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9633 - val_accuracy: 0.3912 - val_loss: 2.0841\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9628 - val_accuracy: 0.3911 - val_loss: 2.0898\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7246 - loss: 0.9624 - val_accuracy: 0.3912 - val_loss: 2.0868\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7245 - loss: 0.9619 - val_accuracy: 0.3911 - val_loss: 2.0854\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7244 - loss: 0.9615 - val_accuracy: 0.3910 - val_loss: 2.0887\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.39127\n726/726 - 5s - 7ms/step - accuracy: 0.7252 - loss: 0.9611 - val_accuracy: 0.3910 - val_loss: 2.0861\nEpoch 332/500\n\nEpoch 332: val_accuracy improved from 0.39127 to 0.39414, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7247 - loss: 0.9606 - val_accuracy: 0.3941 - val_loss: 2.0827\nEpoch 333/500\n\nEpoch 333: val_accuracy improved from 0.39414 to 0.39416, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7257 - loss: 0.9602 - val_accuracy: 0.3942 - val_loss: 2.0787\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.39416\n726/726 - 5s - 7ms/step - accuracy: 0.7256 - loss: 0.9598 - val_accuracy: 0.3941 - val_loss: 2.0832\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.39416\n726/726 - 5s - 8ms/step - accuracy: 0.7259 - loss: 0.9593 - val_accuracy: 0.3941 - val_loss: 2.0845\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.39416\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9589 - val_accuracy: 0.3941 - val_loss: 2.0846\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.39416\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9585 - val_accuracy: 0.3941 - val_loss: 2.0800\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.39416\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9581 - val_accuracy: 0.3941 - val_loss: 2.0860\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.39416\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9576 - val_accuracy: 0.3942 - val_loss: 2.0822\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.39416\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9572 - val_accuracy: 0.3941 - val_loss: 2.0839\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.39416\n726/726 - 6s - 8ms/step - accuracy: 0.7259 - loss: 0.9568 - val_accuracy: 0.3941 - val_loss: 2.0835\nEpoch 342/500\n\nEpoch 342: val_accuracy improved from 0.39416 to 0.39453, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9564 - val_accuracy: 0.3945 - val_loss: 2.0848\nEpoch 343/500\n\nEpoch 343: val_accuracy improved from 0.39453 to 0.39456, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9560 - val_accuracy: 0.3946 - val_loss: 2.0791\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.39456\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9556 - val_accuracy: 0.3942 - val_loss: 2.0806\nEpoch 345/500\n\nEpoch 345: val_accuracy improved from 0.39456 to 0.39456, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9552 - val_accuracy: 0.3946 - val_loss: 2.0791\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.39456\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9548 - val_accuracy: 0.3941 - val_loss: 2.0854\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.39456\n726/726 - 6s - 8ms/step - accuracy: 0.7259 - loss: 0.9543 - val_accuracy: 0.3946 - val_loss: 2.0815\nEpoch 348/500\n\nEpoch 348: val_accuracy improved from 0.39456 to 0.39457, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9539 - val_accuracy: 0.3946 - val_loss: 2.0776\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.39457\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9535 - val_accuracy: 0.3946 - val_loss: 2.0816\nEpoch 350/500\n\nEpoch 350: val_accuracy improved from 0.39457 to 0.39483, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9531 - val_accuracy: 0.3948 - val_loss: 2.0752\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.39483\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9527 - val_accuracy: 0.3948 - val_loss: 2.0737\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.39483\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9523 - val_accuracy: 0.3946 - val_loss: 2.0819\nEpoch 353/500\n\nEpoch 353: val_accuracy improved from 0.39483 to 0.39484, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7259 - loss: 0.9519 - val_accuracy: 0.3948 - val_loss: 2.0765\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.39484\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9515 - val_accuracy: 0.3948 - val_loss: 2.0774\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.39484\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9512 - val_accuracy: 0.3948 - val_loss: 2.0762\nEpoch 356/500\n\nEpoch 356: val_accuracy improved from 0.39484 to 0.39487, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9508 - val_accuracy: 0.3949 - val_loss: 2.0705\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.39487\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9504 - val_accuracy: 0.3948 - val_loss: 2.0781\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.39487\n726/726 - 5s - 7ms/step - accuracy: 0.7259 - loss: 0.9500 - val_accuracy: 0.3949 - val_loss: 2.0794\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.39487\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9496 - val_accuracy: 0.3948 - val_loss: 2.0800\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.39487\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9492 - val_accuracy: 0.3948 - val_loss: 2.0753\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.39487\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9488 - val_accuracy: 0.3948 - val_loss: 2.0811\nEpoch 362/500\n\nEpoch 362: val_accuracy improved from 0.39487 to 0.39487, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9484 - val_accuracy: 0.3949 - val_loss: 2.0744\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.39487\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9481 - val_accuracy: 0.3949 - val_loss: 2.0737\nEpoch 364/500\n\nEpoch 364: val_accuracy improved from 0.39487 to 0.39491, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9477 - val_accuracy: 0.3949 - val_loss: 2.0738\nEpoch 365/500\n\nEpoch 365: val_accuracy improved from 0.39491 to 0.39496, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7258 - loss: 0.9473 - val_accuracy: 0.3950 - val_loss: 2.0712\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.39496\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9469 - val_accuracy: 0.3949 - val_loss: 2.0731\nEpoch 367/500\n\nEpoch 367: val_accuracy improved from 0.39496 to 0.39497, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9465 - val_accuracy: 0.3950 - val_loss: 2.0725\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.39497\n726/726 - 5s - 8ms/step - accuracy: 0.7258 - loss: 0.9462 - val_accuracy: 0.3950 - val_loss: 2.0697\nEpoch 369/500\n\nEpoch 369: val_accuracy improved from 0.39497 to 0.39500, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9458 - val_accuracy: 0.3950 - val_loss: 2.0693\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.39500\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9454 - val_accuracy: 0.3950 - val_loss: 2.0651\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.39500\n726/726 - 6s - 8ms/step - accuracy: 0.7258 - loss: 0.9450 - val_accuracy: 0.3949 - val_loss: 2.0737\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.39500\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9447 - val_accuracy: 0.3950 - val_loss: 2.0721\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.39500\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9443 - val_accuracy: 0.3950 - val_loss: 2.0715\nEpoch 374/500\n\nEpoch 374: val_accuracy improved from 0.39500 to 0.39502, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9439 - val_accuracy: 0.3950 - val_loss: 2.0647\nEpoch 375/500\n\nEpoch 375: val_accuracy improved from 0.39502 to 0.39503, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9436 - val_accuracy: 0.3950 - val_loss: 2.0670\nEpoch 376/500\n\nEpoch 376: val_accuracy improved from 0.39503 to 0.39503, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9432 - val_accuracy: 0.3950 - val_loss: 2.0648\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.39503\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9428 - val_accuracy: 0.3950 - val_loss: 2.0673\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.39503\n726/726 - 5s - 8ms/step - accuracy: 0.7258 - loss: 0.9425 - val_accuracy: 0.3950 - val_loss: 2.0726\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.39503\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9421 - val_accuracy: 0.3950 - val_loss: 2.0690\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.39503\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9418 - val_accuracy: 0.3950 - val_loss: 2.0661\nEpoch 381/500\n\nEpoch 381: val_accuracy improved from 0.39503 to 0.39585, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7248 - loss: 0.9414 - val_accuracy: 0.3958 - val_loss: 2.0692\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.39585\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9410 - val_accuracy: 0.3917 - val_loss: 2.0636\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.39585\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9407 - val_accuracy: 0.3916 - val_loss: 2.0688\nEpoch 384/500\n\nEpoch 384: val_accuracy improved from 0.39585 to 0.39589, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7227 - loss: 0.9403 - val_accuracy: 0.3959 - val_loss: 2.0663\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7240 - loss: 0.9400 - val_accuracy: 0.3917 - val_loss: 2.0654\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7228 - loss: 0.9396 - val_accuracy: 0.3917 - val_loss: 2.0648\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9393 - val_accuracy: 0.3914 - val_loss: 2.0639\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7221 - loss: 0.9389 - val_accuracy: 0.3914 - val_loss: 2.0627\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9386 - val_accuracy: 0.3914 - val_loss: 2.0628\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7226 - loss: 0.9382 - val_accuracy: 0.3914 - val_loss: 2.0655\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9379 - val_accuracy: 0.3914 - val_loss: 2.0669\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9375 - val_accuracy: 0.3914 - val_loss: 2.0627\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9372 - val_accuracy: 0.3914 - val_loss: 2.0663\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9368 - val_accuracy: 0.3914 - val_loss: 2.0644\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9365 - val_accuracy: 0.3916 - val_loss: 2.0629\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7223 - loss: 0.9362 - val_accuracy: 0.3916 - val_loss: 2.0627\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9358 - val_accuracy: 0.3916 - val_loss: 2.0646\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9355 - val_accuracy: 0.3917 - val_loss: 2.0596\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9351 - val_accuracy: 0.3918 - val_loss: 2.0611\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9348 - val_accuracy: 0.3917 - val_loss: 2.0625\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9345 - val_accuracy: 0.3914 - val_loss: 2.0610\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7223 - loss: 0.9341 - val_accuracy: 0.3914 - val_loss: 2.0646\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9338 - val_accuracy: 0.3914 - val_loss: 2.0606\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9335 - val_accuracy: 0.3914 - val_loss: 2.0627\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9331 - val_accuracy: 0.3916 - val_loss: 2.0555\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9328 - val_accuracy: 0.3916 - val_loss: 2.0575\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9325 - val_accuracy: 0.3916 - val_loss: 2.0587\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7223 - loss: 0.9322 - val_accuracy: 0.3916 - val_loss: 2.0585\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9318 - val_accuracy: 0.3917 - val_loss: 2.0607\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9315 - val_accuracy: 0.3917 - val_loss: 2.0582\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7223 - loss: 0.9312 - val_accuracy: 0.3917 - val_loss: 2.0590\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9309 - val_accuracy: 0.3920 - val_loss: 2.0601\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9305 - val_accuracy: 0.3917 - val_loss: 2.0542\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7224 - loss: 0.9302 - val_accuracy: 0.3920 - val_loss: 2.0594\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9299 - val_accuracy: 0.3920 - val_loss: 2.0542\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9296 - val_accuracy: 0.3917 - val_loss: 2.0600\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9293 - val_accuracy: 0.3917 - val_loss: 2.0572\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9289 - val_accuracy: 0.3917 - val_loss: 2.0582\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9286 - val_accuracy: 0.3920 - val_loss: 2.0583\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9283 - val_accuracy: 0.3920 - val_loss: 2.0570\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9280 - val_accuracy: 0.3918 - val_loss: 2.0568\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9277 - val_accuracy: 0.3917 - val_loss: 2.0581\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9274 - val_accuracy: 0.3923 - val_loss: 2.0465\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9271 - val_accuracy: 0.3918 - val_loss: 2.0544\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9268 - val_accuracy: 0.3921 - val_loss: 2.0516\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9265 - val_accuracy: 0.3921 - val_loss: 2.0508\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9261 - val_accuracy: 0.3923 - val_loss: 2.0510\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9258 - val_accuracy: 0.3911 - val_loss: 2.0535\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9255 - val_accuracy: 0.3911 - val_loss: 2.0520\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9252 - val_accuracy: 0.3914 - val_loss: 2.0526\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9249 - val_accuracy: 0.3914 - val_loss: 2.0528\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7224 - loss: 0.9246 - val_accuracy: 0.3911 - val_loss: 2.0561\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7224 - loss: 0.9243 - val_accuracy: 0.3911 - val_loss: 2.0566\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9240 - val_accuracy: 0.3916 - val_loss: 2.0464\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9237 - val_accuracy: 0.3911 - val_loss: 2.0537\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9234 - val_accuracy: 0.3914 - val_loss: 2.0527\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9231 - val_accuracy: 0.3911 - val_loss: 2.0549\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9228 - val_accuracy: 0.3914 - val_loss: 2.0494\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7225 - loss: 0.9225 - val_accuracy: 0.3915 - val_loss: 2.0510\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9222 - val_accuracy: 0.3916 - val_loss: 2.0524\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7225 - loss: 0.9219 - val_accuracy: 0.3916 - val_loss: 2.0534\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9216 - val_accuracy: 0.3916 - val_loss: 2.0530\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9213 - val_accuracy: 0.3916 - val_loss: 2.0482\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9211 - val_accuracy: 0.3916 - val_loss: 2.0466\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.39589\n726/726 - 5s - 8ms/step - accuracy: 0.7226 - loss: 0.9208 - val_accuracy: 0.3916 - val_loss: 2.0493\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7225 - loss: 0.9205 - val_accuracy: 0.3917 - val_loss: 2.0481\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7226 - loss: 0.9202 - val_accuracy: 0.3916 - val_loss: 2.0471\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7226 - loss: 0.9199 - val_accuracy: 0.3916 - val_loss: 2.0464\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7228 - loss: 0.9196 - val_accuracy: 0.3917 - val_loss: 2.0417\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7229 - loss: 0.9193 - val_accuracy: 0.3918 - val_loss: 2.0468\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7242 - loss: 0.9190 - val_accuracy: 0.3920 - val_loss: 2.0447\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7241 - loss: 0.9188 - val_accuracy: 0.3918 - val_loss: 2.0462\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7248 - loss: 0.9185 - val_accuracy: 0.3918 - val_loss: 2.0503\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9182 - val_accuracy: 0.3918 - val_loss: 2.0456\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7250 - loss: 0.9179 - val_accuracy: 0.3918 - val_loss: 2.0490\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9176 - val_accuracy: 0.3933 - val_loss: 2.0444\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.39589\n726/726 - 5s - 8ms/step - accuracy: 0.7251 - loss: 0.9173 - val_accuracy: 0.3933 - val_loss: 2.0434\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9171 - val_accuracy: 0.3933 - val_loss: 2.0452\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9168 - val_accuracy: 0.3922 - val_loss: 2.0460\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9165 - val_accuracy: 0.3922 - val_loss: 2.0453\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9162 - val_accuracy: 0.3933 - val_loss: 2.0399\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9159 - val_accuracy: 0.3932 - val_loss: 2.0459\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9157 - val_accuracy: 0.3933 - val_loss: 2.0426\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9154 - val_accuracy: 0.3933 - val_loss: 2.0421\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7251 - loss: 0.9151 - val_accuracy: 0.3933 - val_loss: 2.0459\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7252 - loss: 0.9148 - val_accuracy: 0.3933 - val_loss: 2.0471\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7252 - loss: 0.9146 - val_accuracy: 0.3933 - val_loss: 2.0460\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7253 - loss: 0.9143 - val_accuracy: 0.3933 - val_loss: 2.0432\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9140 - val_accuracy: 0.3934 - val_loss: 2.0410\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7254 - loss: 0.9138 - val_accuracy: 0.3934 - val_loss: 2.0429\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9135 - val_accuracy: 0.3931 - val_loss: 2.0434\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9132 - val_accuracy: 0.3936 - val_loss: 2.0413\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9130 - val_accuracy: 0.3933 - val_loss: 2.0455\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9127 - val_accuracy: 0.3937 - val_loss: 2.0361\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9124 - val_accuracy: 0.3937 - val_loss: 2.0419\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7254 - loss: 0.9122 - val_accuracy: 0.3937 - val_loss: 2.0387\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9119 - val_accuracy: 0.3936 - val_loss: 2.0451\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9116 - val_accuracy: 0.3937 - val_loss: 2.0379\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7255 - loss: 0.9114 - val_accuracy: 0.3938 - val_loss: 2.0370\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9111 - val_accuracy: 0.3938 - val_loss: 2.0425\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7254 - loss: 0.9108 - val_accuracy: 0.3930 - val_loss: 2.0430\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7255 - loss: 0.9106 - val_accuracy: 0.3937 - val_loss: 2.0413\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7256 - loss: 0.9103 - val_accuracy: 0.3937 - val_loss: 2.0383\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9101 - val_accuracy: 0.3938 - val_loss: 2.0355\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7256 - loss: 0.9098 - val_accuracy: 0.3938 - val_loss: 2.0344\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7255 - loss: 0.9095 - val_accuracy: 0.3934 - val_loss: 2.0397\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7262 - loss: 0.9093 - val_accuracy: 0.3938 - val_loss: 2.0343\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7263 - loss: 0.9090 - val_accuracy: 0.3935 - val_loss: 2.0316\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7258 - loss: 0.9088 - val_accuracy: 0.3932 - val_loss: 2.0393\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7267 - loss: 0.9085 - val_accuracy: 0.3932 - val_loss: 2.0381\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7263 - loss: 0.9083 - val_accuracy: 0.3957 - val_loss: 2.0354\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7271 - loss: 0.9080 - val_accuracy: 0.3954 - val_loss: 2.0427\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7272 - loss: 0.9077 - val_accuracy: 0.3959 - val_loss: 2.0352\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7269 - loss: 0.9075 - val_accuracy: 0.3958 - val_loss: 2.0356\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7276 - loss: 0.9072 - val_accuracy: 0.3958 - val_loss: 2.0325\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7275 - loss: 0.9070 - val_accuracy: 0.3958 - val_loss: 2.0381\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7277 - loss: 0.9067 - val_accuracy: 0.3958 - val_loss: 2.0316\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7278 - loss: 0.9065 - val_accuracy: 0.3956 - val_loss: 2.0373\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7278 - loss: 0.9062 - val_accuracy: 0.3956 - val_loss: 2.0355\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7274 - loss: 0.9060 - val_accuracy: 0.3956 - val_loss: 2.0366\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n    X, y, test_size=0.3, random_state=43, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(\n    X_train_1, y_train_1, test_size=0.2, random_state=43, stratify=y_train_1\n)\n# Check for extremely large values\nprint(\"Max value in X_train_1:\", np.max(X_train_1))\nprint(\"Min value in X_train_1:\", np.min(X_train_1))\n\nX_train_1_scaled = scaler.fit_transform(X_train_1)\n\n# Get the original class distribution\nclass_counts_1 = Counter(y_train_1)\nprint(\"Original class distribution:\", class_counts_1)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_1 = class_counts_1[min(class_counts_1, key=class_counts_1.get)]\ndesired_majority_size_1 = minority_class_size_1 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_1 = {0: desired_majority_size_1, 1: minority_class_size_1}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_1 = RandomUnderSampler(sampling_strategy=sampling_strategy_1, random_state=42)\nX_resampled_1, y_resampled_1 = undersampler_1.fit_resample(X_train_1, y_train_1)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_1))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_1, y_train_resampled_1 = smote.fit_resample(X_resampled_1, y_resampled_1)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_1))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T16:56:01.884913Z","iopub.execute_input":"2025-03-06T16:56:01.885271Z","iopub.status.idle":"2025-03-06T16:56:37.360688Z","shell.execute_reply.started":"2025-03-06T16:56:01.885237Z","shell.execute_reply":"2025-03-06T16:56:37.359528Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_1: 2071000000.0\nMin value in X_train_1: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_1 = X_train_resampled_1.reshape(X_train_resampled_1.shape[0], 1, 56)\nX_val_1 = X_val_1.reshape(X_val_1.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_1,  # Features from CICIDS2017\n    y_train_resampled_1,  # Labels from CICIDS2017\n    validation_data=(X_val_1, y_val_1),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T16:56:37.362464Z","iopub.execute_input":"2025-03-06T16:56:37.362803Z","iopub.status.idle":"2025-03-06T17:40:51.436560Z","shell.execute_reply.started":"2025-03-06T16:56:37.362775Z","shell.execute_reply":"2025-03-06T17:40:51.435246Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.39589\n726/726 - 6s - 8ms/step - accuracy: 0.7167 - loss: 0.9475 - val_accuracy: 0.3783 - val_loss: 2.0566\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7170 - loss: 0.9363 - val_accuracy: 0.3786 - val_loss: 2.0585\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7175 - loss: 0.9307 - val_accuracy: 0.3784 - val_loss: 2.0620\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7150 - loss: 0.9266 - val_accuracy: 0.3782 - val_loss: 2.0709\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.39589\n726/726 - 5s - 7ms/step - accuracy: 0.7206 - loss: 0.9234 - val_accuracy: 0.3761 - val_loss: 2.0766\nEpoch 6/500\n\nEpoch 6: val_accuracy improved from 0.39589 to 0.51093, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7239 - loss: 0.9206 - val_accuracy: 0.5109 - val_loss: 2.0762\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.51093\n726/726 - 5s - 7ms/step - accuracy: 0.7294 - loss: 0.9182 - val_accuracy: 0.5108 - val_loss: 2.0825\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.51093\n726/726 - 5s - 7ms/step - accuracy: 0.7268 - loss: 0.9160 - val_accuracy: 0.5105 - val_loss: 2.0871\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.51093\n726/726 - 5s - 7ms/step - accuracy: 0.7279 - loss: 0.9140 - val_accuracy: 0.5098 - val_loss: 2.0847\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.51093\n726/726 - 5s - 7ms/step - accuracy: 0.7328 - loss: 0.9121 - val_accuracy: 0.5092 - val_loss: 2.0868\nEpoch 11/500\n\nEpoch 11: val_accuracy improved from 0.51093 to 0.51122, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7302 - loss: 0.9104 - val_accuracy: 0.5112 - val_loss: 2.0925\nEpoch 12/500\n\nEpoch 12: val_accuracy improved from 0.51122 to 0.51132, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7375 - loss: 0.9087 - val_accuracy: 0.5113 - val_loss: 2.0924\nEpoch 13/500\n\nEpoch 13: val_accuracy improved from 0.51132 to 0.51139, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7361 - loss: 0.9072 - val_accuracy: 0.5114 - val_loss: 2.0906\nEpoch 14/500\n\nEpoch 14: val_accuracy improved from 0.51139 to 0.52253, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7348 - loss: 0.9056 - val_accuracy: 0.5225 - val_loss: 2.0929\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7373 - loss: 0.9042 - val_accuracy: 0.5225 - val_loss: 2.0953\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7385 - loss: 0.9028 - val_accuracy: 0.5110 - val_loss: 2.0969\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7362 - loss: 0.9015 - val_accuracy: 0.5110 - val_loss: 2.0909\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.9002 - val_accuracy: 0.5109 - val_loss: 2.0973\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7349 - loss: 0.8989 - val_accuracy: 0.5224 - val_loss: 2.0943\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7352 - loss: 0.8977 - val_accuracy: 0.5105 - val_loss: 2.0975\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7368 - loss: 0.8965 - val_accuracy: 0.5104 - val_loss: 2.0989\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7340 - loss: 0.8954 - val_accuracy: 0.5104 - val_loss: 2.0976\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7350 - loss: 0.8943 - val_accuracy: 0.5104 - val_loss: 2.0976\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7350 - loss: 0.8932 - val_accuracy: 0.5218 - val_loss: 2.0950\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7326 - loss: 0.8921 - val_accuracy: 0.5103 - val_loss: 2.0957\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7340 - loss: 0.8911 - val_accuracy: 0.5105 - val_loss: 2.0942\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7319 - loss: 0.8901 - val_accuracy: 0.5103 - val_loss: 2.0984\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7354 - loss: 0.8891 - val_accuracy: 0.5103 - val_loss: 2.0954\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7365 - loss: 0.8882 - val_accuracy: 0.5103 - val_loss: 2.0943\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7355 - loss: 0.8872 - val_accuracy: 0.5102 - val_loss: 2.0945\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7400 - loss: 0.8863 - val_accuracy: 0.5103 - val_loss: 2.0954\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7369 - loss: 0.8854 - val_accuracy: 0.5111 - val_loss: 2.0903\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7357 - loss: 0.8845 - val_accuracy: 0.5107 - val_loss: 2.0998\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7364 - loss: 0.8836 - val_accuracy: 0.5111 - val_loss: 2.0944\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7391 - loss: 0.8828 - val_accuracy: 0.5111 - val_loss: 2.0910\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7366 - loss: 0.8820 - val_accuracy: 0.5108 - val_loss: 2.0964\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7387 - loss: 0.8812 - val_accuracy: 0.5108 - val_loss: 2.0949\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7370 - loss: 0.8804 - val_accuracy: 0.5108 - val_loss: 2.0941\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.52253\n726/726 - 6s - 8ms/step - accuracy: 0.7411 - loss: 0.8796 - val_accuracy: 0.5110 - val_loss: 2.0929\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.52253\n726/726 - 5s - 8ms/step - accuracy: 0.7396 - loss: 0.8789 - val_accuracy: 0.5109 - val_loss: 2.0942\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.52253\n726/726 - 6s - 8ms/step - accuracy: 0.7400 - loss: 0.8781 - val_accuracy: 0.5224 - val_loss: 2.0929\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7394 - loss: 0.8774 - val_accuracy: 0.5114 - val_loss: 2.0913\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.52253\n726/726 - 6s - 8ms/step - accuracy: 0.7410 - loss: 0.8767 - val_accuracy: 0.5113 - val_loss: 2.0921\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8759 - val_accuracy: 0.5115 - val_loss: 2.0914\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.52253\n726/726 - 5s - 7ms/step - accuracy: 0.7414 - loss: 0.8753 - val_accuracy: 0.5115 - val_loss: 2.0898\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.52253\n726/726 - 5s - 8ms/step - accuracy: 0.7413 - loss: 0.8746 - val_accuracy: 0.5124 - val_loss: 2.0948\nEpoch 47/500\n\nEpoch 47: val_accuracy improved from 0.52253 to 0.52414, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8739 - val_accuracy: 0.5241 - val_loss: 2.0893\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7418 - loss: 0.8733 - val_accuracy: 0.5126 - val_loss: 2.0917\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7434 - loss: 0.8726 - val_accuracy: 0.5126 - val_loss: 2.0944\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7449 - loss: 0.8720 - val_accuracy: 0.5126 - val_loss: 2.0944\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8714 - val_accuracy: 0.5127 - val_loss: 2.0863\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8708 - val_accuracy: 0.5126 - val_loss: 2.0926\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7435 - loss: 0.8702 - val_accuracy: 0.5127 - val_loss: 2.0890\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7443 - loss: 0.8696 - val_accuracy: 0.5127 - val_loss: 2.0941\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8690 - val_accuracy: 0.5127 - val_loss: 2.0910\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7469 - loss: 0.8684 - val_accuracy: 0.5127 - val_loss: 2.0873\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7465 - loss: 0.8678 - val_accuracy: 0.5127 - val_loss: 2.0959\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7459 - loss: 0.8673 - val_accuracy: 0.5128 - val_loss: 2.0887\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7478 - loss: 0.8667 - val_accuracy: 0.5128 - val_loss: 2.0892\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7461 - loss: 0.8662 - val_accuracy: 0.5128 - val_loss: 2.0945\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7478 - loss: 0.8657 - val_accuracy: 0.5128 - val_loss: 2.0889\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7454 - loss: 0.8652 - val_accuracy: 0.5129 - val_loss: 2.0899\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7481 - loss: 0.8646 - val_accuracy: 0.5128 - val_loss: 2.0909\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7473 - loss: 0.8641 - val_accuracy: 0.5129 - val_loss: 2.0871\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7479 - loss: 0.8636 - val_accuracy: 0.5129 - val_loss: 2.0882\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7481 - loss: 0.8631 - val_accuracy: 0.5129 - val_loss: 2.0836\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8627 - val_accuracy: 0.5129 - val_loss: 2.0909\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8622 - val_accuracy: 0.5129 - val_loss: 2.0910\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8617 - val_accuracy: 0.5129 - val_loss: 2.0906\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8612 - val_accuracy: 0.5129 - val_loss: 2.0849\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8608 - val_accuracy: 0.5130 - val_loss: 2.0885\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8603 - val_accuracy: 0.5130 - val_loss: 2.0840\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7485 - loss: 0.8599 - val_accuracy: 0.5129 - val_loss: 2.0913\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8594 - val_accuracy: 0.5129 - val_loss: 2.0871\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8590 - val_accuracy: 0.5130 - val_loss: 2.0877\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8585 - val_accuracy: 0.5130 - val_loss: 2.0874\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8581 - val_accuracy: 0.5130 - val_loss: 2.0864\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7485 - loss: 0.8577 - val_accuracy: 0.5130 - val_loss: 2.0884\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7486 - loss: 0.8573 - val_accuracy: 0.5134 - val_loss: 2.0821\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7499 - loss: 0.8569 - val_accuracy: 0.5130 - val_loss: 2.0870\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7503 - loss: 0.8564 - val_accuracy: 0.5134 - val_loss: 2.0873\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8560 - val_accuracy: 0.5137 - val_loss: 2.0847\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8556 - val_accuracy: 0.5137 - val_loss: 2.0868\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8552 - val_accuracy: 0.5134 - val_loss: 2.0865\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7504 - loss: 0.8548 - val_accuracy: 0.5136 - val_loss: 2.0863\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8544 - val_accuracy: 0.5137 - val_loss: 2.0843\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8540 - val_accuracy: 0.5136 - val_loss: 2.0868\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7505 - loss: 0.8537 - val_accuracy: 0.5137 - val_loss: 2.0855\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8533 - val_accuracy: 0.5137 - val_loss: 2.0823\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8529 - val_accuracy: 0.5137 - val_loss: 2.0891\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7505 - loss: 0.8525 - val_accuracy: 0.5137 - val_loss: 2.0856\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8521 - val_accuracy: 0.5137 - val_loss: 2.0856\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8518 - val_accuracy: 0.5137 - val_loss: 2.0877\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8514 - val_accuracy: 0.5137 - val_loss: 2.0871\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8510 - val_accuracy: 0.5137 - val_loss: 2.0848\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8507 - val_accuracy: 0.5137 - val_loss: 2.0862\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.52414\n726/726 - 5s - 8ms/step - accuracy: 0.7505 - loss: 0.8503 - val_accuracy: 0.5137 - val_loss: 2.0897\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8499 - val_accuracy: 0.5137 - val_loss: 2.0846\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8496 - val_accuracy: 0.5138 - val_loss: 2.0892\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8492 - val_accuracy: 0.5137 - val_loss: 2.0848\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8489 - val_accuracy: 0.5137 - val_loss: 2.0862\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8485 - val_accuracy: 0.5138 - val_loss: 2.0842\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7505 - loss: 0.8482 - val_accuracy: 0.5137 - val_loss: 2.0845\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.8478 - val_accuracy: 0.5139 - val_loss: 2.0819\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.8475 - val_accuracy: 0.5138 - val_loss: 2.0857\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7506 - loss: 0.8472 - val_accuracy: 0.5137 - val_loss: 2.0830\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7510 - loss: 0.8468 - val_accuracy: 0.5138 - val_loss: 2.0878\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7511 - loss: 0.8465 - val_accuracy: 0.5137 - val_loss: 2.0839\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7511 - loss: 0.8461 - val_accuracy: 0.5139 - val_loss: 2.0783\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7511 - loss: 0.8458 - val_accuracy: 0.5138 - val_loss: 2.0800\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7512 - loss: 0.8455 - val_accuracy: 0.5138 - val_loss: 2.0880\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7512 - loss: 0.8452 - val_accuracy: 0.5139 - val_loss: 2.0809\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7512 - loss: 0.8448 - val_accuracy: 0.5140 - val_loss: 2.0825\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7512 - loss: 0.8445 - val_accuracy: 0.5138 - val_loss: 2.0855\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.52414\n726/726 - 6s - 8ms/step - accuracy: 0.7512 - loss: 0.8442 - val_accuracy: 0.5140 - val_loss: 2.0802\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7512 - loss: 0.8439 - val_accuracy: 0.5140 - val_loss: 2.0892\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7512 - loss: 0.8435 - val_accuracy: 0.5140 - val_loss: 2.0819\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.8432 - val_accuracy: 0.5140 - val_loss: 2.0887\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.8429 - val_accuracy: 0.5140 - val_loss: 2.0822\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.8426 - val_accuracy: 0.5140 - val_loss: 2.0864\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.8423 - val_accuracy: 0.5140 - val_loss: 2.0838\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.8420 - val_accuracy: 0.5140 - val_loss: 2.0820\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.52414\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.8417 - val_accuracy: 0.5140 - val_loss: 2.0877\nEpoch 124/500\n\nEpoch 124: val_accuracy improved from 0.52414 to 0.52551, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8414 - val_accuracy: 0.5255 - val_loss: 2.0807\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8410 - val_accuracy: 0.5141 - val_loss: 2.0828\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8407 - val_accuracy: 0.5141 - val_loss: 2.0785\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.52551\n726/726 - 6s - 8ms/step - accuracy: 0.7514 - loss: 0.8404 - val_accuracy: 0.5140 - val_loss: 2.0846\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8401 - val_accuracy: 0.5142 - val_loss: 2.0813\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8398 - val_accuracy: 0.5254 - val_loss: 2.0823\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8395 - val_accuracy: 0.5141 - val_loss: 2.0874\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8392 - val_accuracy: 0.5142 - val_loss: 2.0814\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8389 - val_accuracy: 0.5141 - val_loss: 2.0871\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.52551\n726/726 - 6s - 8ms/step - accuracy: 0.7514 - loss: 0.8386 - val_accuracy: 0.5142 - val_loss: 2.0785\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8383 - val_accuracy: 0.5141 - val_loss: 2.0851\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8380 - val_accuracy: 0.5141 - val_loss: 2.0863\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.52551\n726/726 - 5s - 8ms/step - accuracy: 0.7514 - loss: 0.8378 - val_accuracy: 0.5141 - val_loss: 2.0867\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.52551\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8375 - val_accuracy: 0.5141 - val_loss: 2.0848\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.52551\n726/726 - 5s - 8ms/step - accuracy: 0.7514 - loss: 0.8372 - val_accuracy: 0.5141 - val_loss: 2.0834\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.52551\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8369 - val_accuracy: 0.5141 - val_loss: 2.0812\nEpoch 140/500\n\nEpoch 140: val_accuracy improved from 0.52551 to 0.52558, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8366 - val_accuracy: 0.5256 - val_loss: 2.0793\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.52558\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8363 - val_accuracy: 0.5256 - val_loss: 2.0844\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.52558\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8360 - val_accuracy: 0.5141 - val_loss: 2.0833\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.52558\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8357 - val_accuracy: 0.5141 - val_loss: 2.0865\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.52558\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8355 - val_accuracy: 0.5141 - val_loss: 2.0845\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.52558\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8352 - val_accuracy: 0.5141 - val_loss: 2.0841\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.52558\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8349 - val_accuracy: 0.5256 - val_loss: 2.0832\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.52558\n726/726 - 5s - 8ms/step - accuracy: 0.7515 - loss: 0.8346 - val_accuracy: 0.5142 - val_loss: 2.0854\nEpoch 148/500\n\nEpoch 148: val_accuracy improved from 0.52558 to 0.52567, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7515 - loss: 0.8343 - val_accuracy: 0.5257 - val_loss: 2.0816\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.52567\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8341 - val_accuracy: 0.5141 - val_loss: 2.0858\nEpoch 150/500\n\nEpoch 150: val_accuracy improved from 0.52567 to 0.52572, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8338 - val_accuracy: 0.5257 - val_loss: 2.0794\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.52572\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8335 - val_accuracy: 0.5141 - val_loss: 2.0807\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.52572\n726/726 - 5s - 8ms/step - accuracy: 0.7515 - loss: 0.8333 - val_accuracy: 0.5256 - val_loss: 2.0847\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.52572\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8330 - val_accuracy: 0.5256 - val_loss: 2.0843\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.52572\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8327 - val_accuracy: 0.5257 - val_loss: 2.0804\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.52572\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8325 - val_accuracy: 0.5257 - val_loss: 2.0800\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.52572\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8322 - val_accuracy: 0.5257 - val_loss: 2.0853\nEpoch 157/500\n\nEpoch 157: val_accuracy improved from 0.52572 to 0.52603, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.8319 - val_accuracy: 0.5260 - val_loss: 2.0815\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8316 - val_accuracy: 0.5146 - val_loss: 2.0826\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8314 - val_accuracy: 0.5142 - val_loss: 2.0852\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7515 - loss: 0.8311 - val_accuracy: 0.5145 - val_loss: 2.0805\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7516 - loss: 0.8309 - val_accuracy: 0.5146 - val_loss: 2.0823\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7516 - loss: 0.8306 - val_accuracy: 0.5260 - val_loss: 2.0851\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.52603\n726/726 - 6s - 8ms/step - accuracy: 0.7516 - loss: 0.8303 - val_accuracy: 0.5145 - val_loss: 2.0836\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7523 - loss: 0.8301 - val_accuracy: 0.5146 - val_loss: 2.0870\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.52603\n726/726 - 5s - 7ms/step - accuracy: 0.7528 - loss: 0.8298 - val_accuracy: 0.5147 - val_loss: 2.0853\nEpoch 166/500\n\nEpoch 166: val_accuracy improved from 0.52603 to 0.52615, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7533 - loss: 0.8295 - val_accuracy: 0.5261 - val_loss: 2.0823\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.52615\n726/726 - 5s - 7ms/step - accuracy: 0.7533 - loss: 0.8293 - val_accuracy: 0.5261 - val_loss: 2.0813\nEpoch 168/500\n\nEpoch 168: val_accuracy improved from 0.52615 to 0.52617, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7533 - loss: 0.8290 - val_accuracy: 0.5262 - val_loss: 2.0793\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.52617\n726/726 - 6s - 8ms/step - accuracy: 0.7533 - loss: 0.8288 - val_accuracy: 0.5262 - val_loss: 2.0826\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.52617\n726/726 - 5s - 7ms/step - accuracy: 0.7533 - loss: 0.8285 - val_accuracy: 0.5147 - val_loss: 2.0884\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.52617\n726/726 - 5s - 7ms/step - accuracy: 0.7532 - loss: 0.8283 - val_accuracy: 0.5262 - val_loss: 2.0858\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.52617\n726/726 - 5s - 7ms/step - accuracy: 0.7532 - loss: 0.8280 - val_accuracy: 0.5262 - val_loss: 2.0834\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.52617\n726/726 - 5s - 7ms/step - accuracy: 0.7558 - loss: 0.8278 - val_accuracy: 0.5262 - val_loss: 2.0838\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.52617\n726/726 - 5s - 7ms/step - accuracy: 0.7559 - loss: 0.8275 - val_accuracy: 0.5147 - val_loss: 2.0862\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.52617\n726/726 - 6s - 8ms/step - accuracy: 0.7566 - loss: 0.8273 - val_accuracy: 0.5149 - val_loss: 2.0826\nEpoch 176/500\n\nEpoch 176: val_accuracy improved from 0.52617 to 0.52630, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7576 - loss: 0.8270 - val_accuracy: 0.5263 - val_loss: 2.0800\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.52630\n726/726 - 5s - 7ms/step - accuracy: 0.7574 - loss: 0.8268 - val_accuracy: 0.5149 - val_loss: 2.0825\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.52630\n726/726 - 5s - 8ms/step - accuracy: 0.7574 - loss: 0.8265 - val_accuracy: 0.5263 - val_loss: 2.0824\nEpoch 179/500\n\nEpoch 179: val_accuracy improved from 0.52630 to 0.52675, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7575 - loss: 0.8263 - val_accuracy: 0.5268 - val_loss: 2.0800\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.52675\n726/726 - 5s - 7ms/step - accuracy: 0.7574 - loss: 0.8260 - val_accuracy: 0.5263 - val_loss: 2.0877\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.52675\n726/726 - 6s - 8ms/step - accuracy: 0.7577 - loss: 0.8258 - val_accuracy: 0.5268 - val_loss: 2.0815\nEpoch 182/500\n\nEpoch 182: val_accuracy improved from 0.52675 to 0.52678, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7574 - loss: 0.8255 - val_accuracy: 0.5268 - val_loss: 2.0823\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.52678\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8253 - val_accuracy: 0.5268 - val_loss: 2.0806\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.52678\n726/726 - 5s - 7ms/step - accuracy: 0.7577 - loss: 0.8250 - val_accuracy: 0.5268 - val_loss: 2.0829\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.52678\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8248 - val_accuracy: 0.5268 - val_loss: 2.0844\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.52678\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8246 - val_accuracy: 0.5268 - val_loss: 2.0841\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.52678\n726/726 - 6s - 8ms/step - accuracy: 0.7579 - loss: 0.8243 - val_accuracy: 0.5268 - val_loss: 2.0805\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.52678\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8241 - val_accuracy: 0.5268 - val_loss: 2.0797\nEpoch 189/500\n\nEpoch 189: val_accuracy improved from 0.52678 to 0.52679, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8238 - val_accuracy: 0.5268 - val_loss: 2.0777\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8236 - val_accuracy: 0.5268 - val_loss: 2.0816\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8234 - val_accuracy: 0.5268 - val_loss: 2.0796\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8231 - val_accuracy: 0.5268 - val_loss: 2.0829\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.52679\n726/726 - 6s - 8ms/step - accuracy: 0.7579 - loss: 0.8229 - val_accuracy: 0.5268 - val_loss: 2.0889\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8227 - val_accuracy: 0.5153 - val_loss: 2.0878\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8224 - val_accuracy: 0.5268 - val_loss: 2.0828\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8222 - val_accuracy: 0.5268 - val_loss: 2.0847\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.52679\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8220 - val_accuracy: 0.5268 - val_loss: 2.0873\nEpoch 198/500\n\nEpoch 198: val_accuracy improved from 0.52679 to 0.52696, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8217 - val_accuracy: 0.5270 - val_loss: 2.0724\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.52696\n726/726 - 6s - 8ms/step - accuracy: 0.7578 - loss: 0.8215 - val_accuracy: 0.5267 - val_loss: 2.0846\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8213 - val_accuracy: 0.5267 - val_loss: 2.0837\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8210 - val_accuracy: 0.5269 - val_loss: 2.0827\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8208 - val_accuracy: 0.5269 - val_loss: 2.0808\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8206 - val_accuracy: 0.5267 - val_loss: 2.0779\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8203 - val_accuracy: 0.5153 - val_loss: 2.0915\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.52696\n726/726 - 6s - 8ms/step - accuracy: 0.7578 - loss: 0.8201 - val_accuracy: 0.5267 - val_loss: 2.0812\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.52696\n726/726 - 5s - 8ms/step - accuracy: 0.7578 - loss: 0.8199 - val_accuracy: 0.5267 - val_loss: 2.0867\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.52696\n726/726 - 5s - 8ms/step - accuracy: 0.7578 - loss: 0.8197 - val_accuracy: 0.5267 - val_loss: 2.0828\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8194 - val_accuracy: 0.5267 - val_loss: 2.0886\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8192 - val_accuracy: 0.5269 - val_loss: 2.0807\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8190 - val_accuracy: 0.5269 - val_loss: 2.0804\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.52696\n726/726 - 6s - 8ms/step - accuracy: 0.7578 - loss: 0.8188 - val_accuracy: 0.5269 - val_loss: 2.0787\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8186 - val_accuracy: 0.5269 - val_loss: 2.0837\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8183 - val_accuracy: 0.5269 - val_loss: 2.0845\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.52696\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8181 - val_accuracy: 0.5267 - val_loss: 2.0860\nEpoch 215/500\n\nEpoch 215: val_accuracy improved from 0.52696 to 0.52850, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8179 - val_accuracy: 0.5285 - val_loss: 2.0821\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.52850\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8177 - val_accuracy: 0.5285 - val_loss: 2.0832\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.52850\n726/726 - 6s - 8ms/step - accuracy: 0.7578 - loss: 0.8174 - val_accuracy: 0.5285 - val_loss: 2.0858\nEpoch 218/500\n\nEpoch 218: val_accuracy improved from 0.52850 to 0.52851, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8172 - val_accuracy: 0.5285 - val_loss: 2.0823\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.52851\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8170 - val_accuracy: 0.5283 - val_loss: 2.0882\nEpoch 220/500\n\nEpoch 220: val_accuracy improved from 0.52851 to 0.52851, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8168 - val_accuracy: 0.5285 - val_loss: 2.0802\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.52851\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8166 - val_accuracy: 0.5285 - val_loss: 2.0866\nEpoch 222/500\n\nEpoch 222: val_accuracy improved from 0.52851 to 0.52851, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8164 - val_accuracy: 0.5285 - val_loss: 2.0809\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.52851\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8161 - val_accuracy: 0.5285 - val_loss: 2.0819\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.52851\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8159 - val_accuracy: 0.5285 - val_loss: 2.0800\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.52851\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8157 - val_accuracy: 0.5285 - val_loss: 2.0802\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.52851\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8155 - val_accuracy: 0.5285 - val_loss: 2.0850\nEpoch 227/500\n\nEpoch 227: val_accuracy improved from 0.52851 to 0.52852, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8153 - val_accuracy: 0.5285 - val_loss: 2.0806\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8151 - val_accuracy: 0.5285 - val_loss: 2.0834\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.8149 - val_accuracy: 0.5285 - val_loss: 2.0779\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.52852\n726/726 - 5s - 8ms/step - accuracy: 0.7578 - loss: 0.8147 - val_accuracy: 0.5285 - val_loss: 2.0855\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8145 - val_accuracy: 0.5285 - val_loss: 2.0866\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8142 - val_accuracy: 0.5285 - val_loss: 2.0827\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8140 - val_accuracy: 0.5285 - val_loss: 2.0887\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8138 - val_accuracy: 0.5285 - val_loss: 2.0858\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8136 - val_accuracy: 0.5285 - val_loss: 2.0757\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.52852\n726/726 - 6s - 8ms/step - accuracy: 0.7579 - loss: 0.8134 - val_accuracy: 0.5285 - val_loss: 2.0834\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8132 - val_accuracy: 0.5285 - val_loss: 2.0838\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8130 - val_accuracy: 0.5285 - val_loss: 2.0841\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.52852\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8128 - val_accuracy: 0.5285 - val_loss: 2.0801\nEpoch 240/500\n\nEpoch 240: val_accuracy improved from 0.52852 to 0.52853, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8126 - val_accuracy: 0.5285 - val_loss: 2.0841\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.52853\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8124 - val_accuracy: 0.5285 - val_loss: 2.0840\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.52853\n726/726 - 6s - 8ms/step - accuracy: 0.7579 - loss: 0.8122 - val_accuracy: 0.5285 - val_loss: 2.0846\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.52853\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8120 - val_accuracy: 0.5285 - val_loss: 2.0843\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.52853\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8118 - val_accuracy: 0.5285 - val_loss: 2.0888\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.52853\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8116 - val_accuracy: 0.5285 - val_loss: 2.0830\nEpoch 246/500\n\nEpoch 246: val_accuracy improved from 0.52853 to 0.52854, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8114 - val_accuracy: 0.5285 - val_loss: 2.0799\nEpoch 247/500\n\nEpoch 247: val_accuracy improved from 0.52854 to 0.52854, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8112 - val_accuracy: 0.5285 - val_loss: 2.0827\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.52854\n726/726 - 6s - 8ms/step - accuracy: 0.7579 - loss: 0.8110 - val_accuracy: 0.5285 - val_loss: 2.0820\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.52854\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8108 - val_accuracy: 0.5285 - val_loss: 2.0846\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.52854\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8106 - val_accuracy: 0.5285 - val_loss: 2.0846\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.52854\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8104 - val_accuracy: 0.5285 - val_loss: 2.0836\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.52854\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8102 - val_accuracy: 0.5285 - val_loss: 2.0862\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.52854\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8100 - val_accuracy: 0.5285 - val_loss: 2.0843\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.52854\n726/726 - 6s - 8ms/step - accuracy: 0.7579 - loss: 0.8098 - val_accuracy: 0.5285 - val_loss: 2.0874\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.52854\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8096 - val_accuracy: 0.5285 - val_loss: 2.0848\nEpoch 256/500\n\nEpoch 256: val_accuracy improved from 0.52854 to 0.52855, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8094 - val_accuracy: 0.5285 - val_loss: 2.0821\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.52855\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8092 - val_accuracy: 0.5285 - val_loss: 2.0842\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.52855\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8090 - val_accuracy: 0.5285 - val_loss: 2.0873\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.52855\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8088 - val_accuracy: 0.5285 - val_loss: 2.0852\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.52855\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8086 - val_accuracy: 0.5285 - val_loss: 2.0832\nEpoch 261/500\n\nEpoch 261: val_accuracy improved from 0.52855 to 0.52856, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.8084 - val_accuracy: 0.5286 - val_loss: 2.0835\nEpoch 262/500\n\nEpoch 262: val_accuracy improved from 0.52856 to 0.52857, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8082 - val_accuracy: 0.5286 - val_loss: 2.0791\nEpoch 263/500\n\nEpoch 263: val_accuracy improved from 0.52857 to 0.52857, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8080 - val_accuracy: 0.5286 - val_loss: 2.0794\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.52857\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8078 - val_accuracy: 0.5285 - val_loss: 2.0856\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.52857\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8077 - val_accuracy: 0.5285 - val_loss: 2.0871\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.52857\n726/726 - 5s - 8ms/step - accuracy: 0.7580 - loss: 0.8075 - val_accuracy: 0.5286 - val_loss: 2.0815\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.52857\n726/726 - 6s - 8ms/step - accuracy: 0.7580 - loss: 0.8073 - val_accuracy: 0.5286 - val_loss: 2.0835\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.52857\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8071 - val_accuracy: 0.5286 - val_loss: 2.0823\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.52857\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8069 - val_accuracy: 0.5285 - val_loss: 2.0848\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.52857\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8067 - val_accuracy: 0.5285 - val_loss: 2.0816\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.52857\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8065 - val_accuracy: 0.5285 - val_loss: 2.0900\nEpoch 272/500\n\nEpoch 272: val_accuracy improved from 0.52857 to 0.52860, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8063 - val_accuracy: 0.5286 - val_loss: 2.0788\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8061 - val_accuracy: 0.5286 - val_loss: 2.0815\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8060 - val_accuracy: 0.5286 - val_loss: 2.0849\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8058 - val_accuracy: 0.5285 - val_loss: 2.0895\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8056 - val_accuracy: 0.5286 - val_loss: 2.0838\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8054 - val_accuracy: 0.5286 - val_loss: 2.0856\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8052 - val_accuracy: 0.5286 - val_loss: 2.0853\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.52860\n726/726 - 6s - 8ms/step - accuracy: 0.7580 - loss: 0.8050 - val_accuracy: 0.5286 - val_loss: 2.0836\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8048 - val_accuracy: 0.5286 - val_loss: 2.0841\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8047 - val_accuracy: 0.5286 - val_loss: 2.0841\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8045 - val_accuracy: 0.5286 - val_loss: 2.0823\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8043 - val_accuracy: 0.5286 - val_loss: 2.0879\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.52860\n726/726 - 5s - 8ms/step - accuracy: 0.7580 - loss: 0.8041 - val_accuracy: 0.5286 - val_loss: 2.0845\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.52860\n726/726 - 6s - 8ms/step - accuracy: 0.7580 - loss: 0.8039 - val_accuracy: 0.5286 - val_loss: 2.0851\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8038 - val_accuracy: 0.5286 - val_loss: 2.0831\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8036 - val_accuracy: 0.5286 - val_loss: 2.0874\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8034 - val_accuracy: 0.5286 - val_loss: 2.0895\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8032 - val_accuracy: 0.5286 - val_loss: 2.0850\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8030 - val_accuracy: 0.5286 - val_loss: 2.0854\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.52860\n726/726 - 6s - 8ms/step - accuracy: 0.7580 - loss: 0.8029 - val_accuracy: 0.5286 - val_loss: 2.0817\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8027 - val_accuracy: 0.5286 - val_loss: 2.0866\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8025 - val_accuracy: 0.5286 - val_loss: 2.0804\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.8023 - val_accuracy: 0.5286 - val_loss: 2.0827\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8021 - val_accuracy: 0.5286 - val_loss: 2.0859\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8020 - val_accuracy: 0.5286 - val_loss: 2.0886\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.52860\n726/726 - 6s - 8ms/step - accuracy: 0.7581 - loss: 0.8018 - val_accuracy: 0.5286 - val_loss: 2.0842\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.52860\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8016 - val_accuracy: 0.5286 - val_loss: 2.0827\nEpoch 299/500\n\nEpoch 299: val_accuracy improved from 0.52860 to 0.52874, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8014 - val_accuracy: 0.5287 - val_loss: 2.0782\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8013 - val_accuracy: 0.5286 - val_loss: 2.0883\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8011 - val_accuracy: 0.5287 - val_loss: 2.0820\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8009 - val_accuracy: 0.5287 - val_loss: 2.0859\nEpoch 303/500\n\nEpoch 303: val_accuracy improved from 0.52874 to 0.52874, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7581 - loss: 0.8007 - val_accuracy: 0.5287 - val_loss: 2.0790\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8006 - val_accuracy: 0.5287 - val_loss: 2.0819\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.8004 - val_accuracy: 0.5287 - val_loss: 2.0837\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8002 - val_accuracy: 0.5287 - val_loss: 2.0902\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.52874\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.8001 - val_accuracy: 0.5287 - val_loss: 2.0830\nEpoch 308/500\n\nEpoch 308: val_accuracy improved from 0.52874 to 0.52875, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7999 - val_accuracy: 0.5287 - val_loss: 2.0793\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.52875\n726/726 - 6s - 8ms/step - accuracy: 0.7582 - loss: 0.7997 - val_accuracy: 0.5287 - val_loss: 2.0846\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7995 - val_accuracy: 0.5287 - val_loss: 2.0851\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7994 - val_accuracy: 0.5284 - val_loss: 2.0851\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7992 - val_accuracy: 0.5284 - val_loss: 2.0837\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7990 - val_accuracy: 0.5284 - val_loss: 2.0855\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7989 - val_accuracy: 0.5284 - val_loss: 2.0891\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.52875\n726/726 - 5s - 8ms/step - accuracy: 0.7582 - loss: 0.7987 - val_accuracy: 0.5284 - val_loss: 2.0843\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7985 - val_accuracy: 0.5285 - val_loss: 2.0840\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7984 - val_accuracy: 0.5284 - val_loss: 2.0885\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7982 - val_accuracy: 0.5285 - val_loss: 2.0808\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7980 - val_accuracy: 0.5285 - val_loss: 2.0851\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7979 - val_accuracy: 0.5287 - val_loss: 2.0836\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7977 - val_accuracy: 0.5287 - val_loss: 2.0815\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7975 - val_accuracy: 0.5287 - val_loss: 2.0876\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7974 - val_accuracy: 0.5287 - val_loss: 2.0865\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7972 - val_accuracy: 0.5287 - val_loss: 2.0858\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.52875\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7970 - val_accuracy: 0.5287 - val_loss: 2.0843\nEpoch 326/500\n\nEpoch 326: val_accuracy improved from 0.52875 to 0.52885, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7969 - val_accuracy: 0.5289 - val_loss: 2.0785\nEpoch 327/500\n\nEpoch 327: val_accuracy improved from 0.52885 to 0.52886, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7967 - val_accuracy: 0.5289 - val_loss: 2.0871\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.52886\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7965 - val_accuracy: 0.5289 - val_loss: 2.0872\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.52886\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7964 - val_accuracy: 0.5289 - val_loss: 2.0869\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.52886\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7962 - val_accuracy: 0.5288 - val_loss: 2.0891\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.52886\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7961 - val_accuracy: 0.5288 - val_loss: 2.0910\nEpoch 332/500\n\nEpoch 332: val_accuracy improved from 0.52886 to 0.52889, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7959 - val_accuracy: 0.5289 - val_loss: 2.0845\nEpoch 333/500\n\nEpoch 333: val_accuracy improved from 0.52889 to 0.52891, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7957 - val_accuracy: 0.5289 - val_loss: 2.0807\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.52891\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7956 - val_accuracy: 0.5289 - val_loss: 2.0887\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.52891\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7954 - val_accuracy: 0.5289 - val_loss: 2.0868\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.52891\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7952 - val_accuracy: 0.5289 - val_loss: 2.0901\nEpoch 337/500\n\nEpoch 337: val_accuracy improved from 0.52891 to 0.52898, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7951 - val_accuracy: 0.5290 - val_loss: 2.0830\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.52898\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7949 - val_accuracy: 0.5290 - val_loss: 2.0844\nEpoch 339/500\n\nEpoch 339: val_accuracy improved from 0.52898 to 0.52900, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7948 - val_accuracy: 0.5290 - val_loss: 2.0839\nEpoch 340/500\n\nEpoch 340: val_accuracy improved from 0.52900 to 0.52904, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7946 - val_accuracy: 0.5290 - val_loss: 2.0811\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7945 - val_accuracy: 0.5289 - val_loss: 2.0907\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7943 - val_accuracy: 0.5290 - val_loss: 2.0860\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7941 - val_accuracy: 0.5290 - val_loss: 2.0841\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7940 - val_accuracy: 0.5290 - val_loss: 2.0835\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7938 - val_accuracy: 0.5289 - val_loss: 2.0925\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7937 - val_accuracy: 0.5289 - val_loss: 2.0903\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7935 - val_accuracy: 0.5290 - val_loss: 2.0853\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7934 - val_accuracy: 0.5289 - val_loss: 2.0916\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7932 - val_accuracy: 0.5290 - val_loss: 2.0894\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7930 - val_accuracy: 0.5290 - val_loss: 2.0862\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7929 - val_accuracy: 0.5290 - val_loss: 2.0870\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7927 - val_accuracy: 0.5290 - val_loss: 2.0819\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7926 - val_accuracy: 0.5290 - val_loss: 2.0923\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7924 - val_accuracy: 0.5290 - val_loss: 2.0822\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7923 - val_accuracy: 0.5290 - val_loss: 2.0860\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7921 - val_accuracy: 0.5290 - val_loss: 2.0816\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7920 - val_accuracy: 0.5290 - val_loss: 2.0872\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.52904\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7918 - val_accuracy: 0.5290 - val_loss: 2.0860\nEpoch 359/500\n\nEpoch 359: val_accuracy improved from 0.52904 to 0.52918, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7917 - val_accuracy: 0.5292 - val_loss: 2.0846\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7915 - val_accuracy: 0.5290 - val_loss: 2.0867\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7914 - val_accuracy: 0.5290 - val_loss: 2.0878\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7912 - val_accuracy: 0.5290 - val_loss: 2.0825\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7581 - loss: 0.7911 - val_accuracy: 0.5290 - val_loss: 2.0885\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7580 - loss: 0.7909 - val_accuracy: 0.5290 - val_loss: 2.0875\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7576 - loss: 0.7907 - val_accuracy: 0.5290 - val_loss: 2.0888\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7573 - loss: 0.7906 - val_accuracy: 0.5290 - val_loss: 2.0872\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7904 - val_accuracy: 0.5290 - val_loss: 2.0880\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7903 - val_accuracy: 0.5290 - val_loss: 2.0895\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7902 - val_accuracy: 0.5290 - val_loss: 2.0865\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7900 - val_accuracy: 0.5290 - val_loss: 2.0874\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7899 - val_accuracy: 0.5290 - val_loss: 2.0874\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7897 - val_accuracy: 0.5290 - val_loss: 2.0846\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7896 - val_accuracy: 0.5290 - val_loss: 2.0901\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7894 - val_accuracy: 0.5290 - val_loss: 2.0903\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7893 - val_accuracy: 0.5290 - val_loss: 2.0927\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7891 - val_accuracy: 0.5290 - val_loss: 2.0871\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7890 - val_accuracy: 0.5290 - val_loss: 2.0911\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.52918\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7888 - val_accuracy: 0.5290 - val_loss: 2.0858\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7887 - val_accuracy: 0.5290 - val_loss: 2.0913\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.52918\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7885 - val_accuracy: 0.5290 - val_loss: 2.0899\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.52918\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7884 - val_accuracy: 0.5290 - val_loss: 2.0849\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7882 - val_accuracy: 0.5290 - val_loss: 2.0886\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7881 - val_accuracy: 0.5290 - val_loss: 2.0892\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.52918\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7880 - val_accuracy: 0.5290 - val_loss: 2.0899\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7878 - val_accuracy: 0.5290 - val_loss: 2.0874\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7877 - val_accuracy: 0.5290 - val_loss: 2.0921\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7875 - val_accuracy: 0.5290 - val_loss: 2.0903\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7874 - val_accuracy: 0.5290 - val_loss: 2.0899\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.52918\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7872 - val_accuracy: 0.5290 - val_loss: 2.0898\nEpoch 390/500\n\nEpoch 390: val_accuracy improved from 0.52918 to 0.52923, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7871 - val_accuracy: 0.5292 - val_loss: 2.0888\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7870 - val_accuracy: 0.5290 - val_loss: 2.0916\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7868 - val_accuracy: 0.5292 - val_loss: 2.0870\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7867 - val_accuracy: 0.5292 - val_loss: 2.0903\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7865 - val_accuracy: 0.5290 - val_loss: 2.0914\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7864 - val_accuracy: 0.5292 - val_loss: 2.0941\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.52923\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7862 - val_accuracy: 0.5292 - val_loss: 2.0895\nEpoch 397/500\n\nEpoch 397: val_accuracy improved from 0.52923 to 0.52923, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7861 - val_accuracy: 0.5292 - val_loss: 2.0897\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7860 - val_accuracy: 0.5292 - val_loss: 2.0859\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7858 - val_accuracy: 0.5292 - val_loss: 2.0879\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7857 - val_accuracy: 0.5292 - val_loss: 2.0880\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7855 - val_accuracy: 0.5289 - val_loss: 2.0938\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.52923\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7854 - val_accuracy: 0.5292 - val_loss: 2.0857\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7853 - val_accuracy: 0.5289 - val_loss: 2.0918\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7851 - val_accuracy: 0.5289 - val_loss: 2.0932\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7850 - val_accuracy: 0.5289 - val_loss: 2.0933\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7848 - val_accuracy: 0.5289 - val_loss: 2.0925\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7847 - val_accuracy: 0.5289 - val_loss: 2.0918\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.52923\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.7846 - val_accuracy: 0.5289 - val_loss: 2.0920\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7844 - val_accuracy: 0.5292 - val_loss: 2.0914\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7843 - val_accuracy: 0.5292 - val_loss: 2.0879\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7842 - val_accuracy: 0.5289 - val_loss: 2.0915\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7840 - val_accuracy: 0.5289 - val_loss: 2.0929\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7839 - val_accuracy: 0.5289 - val_loss: 2.0937\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7838 - val_accuracy: 0.5289 - val_loss: 2.0945\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7836 - val_accuracy: 0.5289 - val_loss: 2.0901\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7835 - val_accuracy: 0.5289 - val_loss: 2.0940\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7833 - val_accuracy: 0.5292 - val_loss: 2.0900\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.52923\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7832 - val_accuracy: 0.5289 - val_loss: 2.0896\nEpoch 419/500\n\nEpoch 419: val_accuracy improved from 0.52923 to 0.52938, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7831 - val_accuracy: 0.5294 - val_loss: 2.0858\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.52938\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7829 - val_accuracy: 0.5290 - val_loss: 2.0913\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.52938\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.7828 - val_accuracy: 0.5289 - val_loss: 2.0950\nEpoch 422/500\n\nEpoch 422: val_accuracy improved from 0.52938 to 0.52939, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7827 - val_accuracy: 0.5294 - val_loss: 2.0911\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7825 - val_accuracy: 0.5290 - val_loss: 2.0948\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7824 - val_accuracy: 0.5290 - val_loss: 2.0899\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7823 - val_accuracy: 0.5290 - val_loss: 2.0915\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7821 - val_accuracy: 0.5290 - val_loss: 2.0906\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.52939\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7820 - val_accuracy: 0.5290 - val_loss: 2.0914\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7819 - val_accuracy: 0.5290 - val_loss: 2.0945\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7817 - val_accuracy: 0.5290 - val_loss: 2.0914\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7816 - val_accuracy: 0.5290 - val_loss: 2.0880\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7815 - val_accuracy: 0.5290 - val_loss: 2.0987\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7813 - val_accuracy: 0.5290 - val_loss: 2.0885\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.52939\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.7812 - val_accuracy: 0.5290 - val_loss: 2.0906\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7811 - val_accuracy: 0.5290 - val_loss: 2.0966\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7809 - val_accuracy: 0.5290 - val_loss: 2.0941\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7808 - val_accuracy: 0.5290 - val_loss: 2.0933\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7807 - val_accuracy: 0.5290 - val_loss: 2.0938\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7806 - val_accuracy: 0.5290 - val_loss: 2.0950\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.52939\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7804 - val_accuracy: 0.5290 - val_loss: 2.0937\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7803 - val_accuracy: 0.5290 - val_loss: 2.0933\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7802 - val_accuracy: 0.5292 - val_loss: 2.0914\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7800 - val_accuracy: 0.5290 - val_loss: 2.0920\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7799 - val_accuracy: 0.5290 - val_loss: 2.0909\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7798 - val_accuracy: 0.5290 - val_loss: 2.0944\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7796 - val_accuracy: 0.5290 - val_loss: 2.0897\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7795 - val_accuracy: 0.5290 - val_loss: 2.0917\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7794 - val_accuracy: 0.5290 - val_loss: 2.0901\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7793 - val_accuracy: 0.5290 - val_loss: 2.0923\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7791 - val_accuracy: 0.5290 - val_loss: 2.0926\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7790 - val_accuracy: 0.5290 - val_loss: 2.0891\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7789 - val_accuracy: 0.5290 - val_loss: 2.0901\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7788 - val_accuracy: 0.5290 - val_loss: 2.0946\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7786 - val_accuracy: 0.5290 - val_loss: 2.0952\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7785 - val_accuracy: 0.5290 - val_loss: 2.0934\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7784 - val_accuracy: 0.5290 - val_loss: 2.0940\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7783 - val_accuracy: 0.5290 - val_loss: 2.0962\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7781 - val_accuracy: 0.5292 - val_loss: 2.0930\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.52939\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.7780 - val_accuracy: 0.5290 - val_loss: 2.0920\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7779 - val_accuracy: 0.5292 - val_loss: 2.0917\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7777 - val_accuracy: 0.5292 - val_loss: 2.0942\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7776 - val_accuracy: 0.5292 - val_loss: 2.0866\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7775 - val_accuracy: 0.5292 - val_loss: 2.0957\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7774 - val_accuracy: 0.5292 - val_loss: 2.0944\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7772 - val_accuracy: 0.5292 - val_loss: 2.0945\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7771 - val_accuracy: 0.5292 - val_loss: 2.0978\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7770 - val_accuracy: 0.5292 - val_loss: 2.0961\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7769 - val_accuracy: 0.5294 - val_loss: 2.0907\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7768 - val_accuracy: 0.5292 - val_loss: 2.0954\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7766 - val_accuracy: 0.5292 - val_loss: 2.0964\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.52939\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7765 - val_accuracy: 0.5292 - val_loss: 2.0941\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7764 - val_accuracy: 0.5292 - val_loss: 2.0965\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7763 - val_accuracy: 0.5292 - val_loss: 2.0959\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7761 - val_accuracy: 0.5292 - val_loss: 2.0965\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7760 - val_accuracy: 0.5292 - val_loss: 2.0932\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7759 - val_accuracy: 0.5292 - val_loss: 2.0965\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7758 - val_accuracy: 0.5292 - val_loss: 2.0955\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.52939\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7756 - val_accuracy: 0.5292 - val_loss: 2.1023\nEpoch 478/500\n\nEpoch 478: val_accuracy improved from 0.52939 to 0.52942, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7755 - val_accuracy: 0.5294 - val_loss: 2.0957\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.52942\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7754 - val_accuracy: 0.5292 - val_loss: 2.0982\nEpoch 480/500\n\nEpoch 480: val_accuracy improved from 0.52942 to 0.52959, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7753 - val_accuracy: 0.5296 - val_loss: 2.0941\nEpoch 481/500\n\nEpoch 481: val_accuracy improved from 0.52959 to 0.52965, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7752 - val_accuracy: 0.5296 - val_loss: 2.0921\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.52965\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7750 - val_accuracy: 0.5296 - val_loss: 2.0956\nEpoch 483/500\n\nEpoch 483: val_accuracy improved from 0.52965 to 0.52996, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7749 - val_accuracy: 0.5300 - val_loss: 2.0947\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7748 - val_accuracy: 0.5294 - val_loss: 2.0966\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7747 - val_accuracy: 0.5297 - val_loss: 2.0938\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7746 - val_accuracy: 0.5297 - val_loss: 2.0948\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7745 - val_accuracy: 0.5294 - val_loss: 2.0987\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7743 - val_accuracy: 0.5294 - val_loss: 2.0913\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.52996\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7742 - val_accuracy: 0.5296 - val_loss: 2.0956\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7741 - val_accuracy: 0.5294 - val_loss: 2.0948\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7740 - val_accuracy: 0.5294 - val_loss: 2.0962\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7739 - val_accuracy: 0.5296 - val_loss: 2.0942\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7737 - val_accuracy: 0.5294 - val_loss: 2.0983\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7736 - val_accuracy: 0.5294 - val_loss: 2.0994\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.52996\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7735 - val_accuracy: 0.5297 - val_loss: 2.0924\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.52996\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7734 - val_accuracy: 0.5294 - val_loss: 2.0972\nEpoch 497/500\n\nEpoch 497: val_accuracy improved from 0.52996 to 0.52999, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7733 - val_accuracy: 0.5300 - val_loss: 2.0979\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7732 - val_accuracy: 0.5295 - val_loss: 2.0970\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7730 - val_accuracy: 0.5295 - val_loss: 2.0958\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7729 - val_accuracy: 0.5295 - val_loss: 2.0987\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(\n    X, y, test_size=0.3, random_state=44, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(\n    X_train_2, y_train_2, test_size=0.2, random_state=44, stratify=y_train_2\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_2:\", np.max(X_train_2))\nprint(\"Min value in X_train_2:\", np.min(X_train_2))\n\nX_train_2_scaled = scaler.fit_transform(X_train_2)\n# Get the original class distribution\nclass_counts_2 = Counter(y_train_2)\nprint(\"Original class distribution:\", class_counts_2)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_2 = class_counts_2[min(class_counts_2, key=class_counts_2.get)]\ndesired_majority_size_2 = minority_class_size_2 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_2 = {0: desired_majority_size_2, 1: minority_class_size_2}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_2 = RandomUnderSampler(sampling_strategy=sampling_strategy_2, random_state=42)\nX_resampled_2, y_resampled_2 = undersampler_2.fit_resample(X_train_2, y_train_2)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_2))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_2, y_train_resampled_2 = smote.fit_resample(X_resampled_2, y_resampled_2)\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_2))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T17:40:51.438482Z","iopub.execute_input":"2025-03-06T17:40:51.438812Z","iopub.status.idle":"2025-03-06T17:41:25.543094Z","shell.execute_reply.started":"2025-03-06T17:40:51.438785Z","shell.execute_reply":"2025-03-06T17:41:25.542023Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_2: 2071000000.0\nMin value in X_train_2: -9663668122.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_2 = X_train_resampled_2.reshape(X_train_resampled_2.shape[0], 1, 56)\nX_val_2 = X_val_2.reshape(X_val_2.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_2,  # Features from CICIDS2017\n    y_train_resampled_2,  # Labels from CICIDS2017\n    validation_data=(X_val_2, y_val_2),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T17:41:25.544186Z","iopub.execute_input":"2025-03-06T17:41:25.544593Z","iopub.status.idle":"2025-03-06T18:25:20.464617Z","shell.execute_reply.started":"2025-03-06T17:41:25.544566Z","shell.execute_reply":"2025-03-06T18:25:20.463364Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7122 - loss: 1.0755 - val_accuracy: 0.3934 - val_loss: 2.1473\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7142 - loss: 1.0675 - val_accuracy: 0.3937 - val_loss: 2.1361\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7082 - loss: 1.0617 - val_accuracy: 0.3941 - val_loss: 2.1333\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7087 - loss: 1.0565 - val_accuracy: 0.3945 - val_loss: 2.1206\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7087 - loss: 1.0515 - val_accuracy: 0.3945 - val_loss: 2.1070\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7100 - loss: 1.0468 - val_accuracy: 0.3946 - val_loss: 2.0965\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7103 - loss: 1.0422 - val_accuracy: 0.3941 - val_loss: 2.0900\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7141 - loss: 1.0377 - val_accuracy: 0.3943 - val_loss: 2.0861\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7152 - loss: 1.0334 - val_accuracy: 0.3943 - val_loss: 2.0797\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7168 - loss: 1.0292 - val_accuracy: 0.3944 - val_loss: 2.0678\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7177 - loss: 1.0251 - val_accuracy: 0.3946 - val_loss: 2.0631\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7179 - loss: 1.0212 - val_accuracy: 0.3946 - val_loss: 2.0597\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7184 - loss: 1.0174 - val_accuracy: 0.3946 - val_loss: 2.0512\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7179 - loss: 1.0136 - val_accuracy: 0.3946 - val_loss: 2.0480\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7175 - loss: 1.0100 - val_accuracy: 0.3948 - val_loss: 2.0405\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7174 - loss: 1.0066 - val_accuracy: 0.3948 - val_loss: 2.0446\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7173 - loss: 1.0032 - val_accuracy: 0.3948 - val_loss: 2.0379\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7174 - loss: 0.9999 - val_accuracy: 0.3967 - val_loss: 2.0314\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7172 - loss: 0.9968 - val_accuracy: 0.3969 - val_loss: 2.0308\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7172 - loss: 0.9937 - val_accuracy: 0.3969 - val_loss: 2.0210\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7172 - loss: 0.9907 - val_accuracy: 0.3972 - val_loss: 2.0154\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7172 - loss: 0.9878 - val_accuracy: 0.3972 - val_loss: 2.0151\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7201 - loss: 0.9849 - val_accuracy: 0.3973 - val_loss: 2.0152\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7172 - loss: 0.9821 - val_accuracy: 0.3973 - val_loss: 2.0072\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7172 - loss: 0.9794 - val_accuracy: 0.3974 - val_loss: 2.0050\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7171 - loss: 0.9768 - val_accuracy: 0.3977 - val_loss: 2.0041\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7199 - loss: 0.9742 - val_accuracy: 0.3977 - val_loss: 2.0052\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7220 - loss: 0.9717 - val_accuracy: 0.3977 - val_loss: 2.0027\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7226 - loss: 0.9692 - val_accuracy: 0.3977 - val_loss: 1.9959\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7235 - loss: 0.9667 - val_accuracy: 0.3977 - val_loss: 1.9924\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7263 - loss: 0.9644 - val_accuracy: 0.3994 - val_loss: 1.9862\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7280 - loss: 0.9620 - val_accuracy: 0.3993 - val_loss: 1.9900\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7302 - loss: 0.9597 - val_accuracy: 0.4006 - val_loss: 1.9878\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7357 - loss: 0.9575 - val_accuracy: 0.4006 - val_loss: 1.9863\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7364 - loss: 0.9553 - val_accuracy: 0.4006 - val_loss: 1.9869\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7384 - loss: 0.9531 - val_accuracy: 0.4006 - val_loss: 1.9826\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7388 - loss: 0.9510 - val_accuracy: 0.4006 - val_loss: 1.9837\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7382 - loss: 0.9489 - val_accuracy: 0.4005 - val_loss: 1.9807\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7405 - loss: 0.9468 - val_accuracy: 0.4008 - val_loss: 1.9733\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7405 - loss: 0.9448 - val_accuracy: 0.4008 - val_loss: 1.9719\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7405 - loss: 0.9428 - val_accuracy: 0.4005 - val_loss: 1.9711\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9409 - val_accuracy: 0.4005 - val_loss: 1.9677\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9390 - val_accuracy: 0.4005 - val_loss: 1.9729\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9372 - val_accuracy: 0.4005 - val_loss: 1.9687\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9354 - val_accuracy: 0.4005 - val_loss: 1.9717\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9336 - val_accuracy: 0.4005 - val_loss: 1.9683\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7405 - loss: 0.9319 - val_accuracy: 0.4016 - val_loss: 1.9618\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.9302 - val_accuracy: 0.4016 - val_loss: 1.9616\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.9285 - val_accuracy: 0.4014 - val_loss: 1.9645\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.9269 - val_accuracy: 0.4014 - val_loss: 1.9603\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7405 - loss: 0.9254 - val_accuracy: 0.4014 - val_loss: 1.9643\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9239 - val_accuracy: 0.4014 - val_loss: 1.9599\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9224 - val_accuracy: 0.4014 - val_loss: 1.9619\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9210 - val_accuracy: 0.4004 - val_loss: 1.9636\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.9196 - val_accuracy: 0.4004 - val_loss: 1.9613\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7404 - loss: 0.9183 - val_accuracy: 0.4004 - val_loss: 1.9552\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7411 - loss: 0.9170 - val_accuracy: 0.4004 - val_loss: 1.9591\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7435 - loss: 0.9157 - val_accuracy: 0.4004 - val_loss: 1.9545\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7435 - loss: 0.9145 - val_accuracy: 0.4001 - val_loss: 1.9591\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.9133 - val_accuracy: 0.3997 - val_loss: 1.9563\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.9121 - val_accuracy: 0.3997 - val_loss: 1.9563\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.9110 - val_accuracy: 0.3998 - val_loss: 1.9520\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.9099 - val_accuracy: 0.3998 - val_loss: 1.9576\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.9088 - val_accuracy: 0.3998 - val_loss: 1.9540\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.9077 - val_accuracy: 0.3998 - val_loss: 1.9560\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.9067 - val_accuracy: 0.3995 - val_loss: 1.9558\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.9057 - val_accuracy: 0.3993 - val_loss: 1.9549\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.9048 - val_accuracy: 0.3994 - val_loss: 1.9551\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.9038 - val_accuracy: 0.3994 - val_loss: 1.9516\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.9029 - val_accuracy: 0.3994 - val_loss: 1.9523\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.9020 - val_accuracy: 0.3994 - val_loss: 1.9539\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.9011 - val_accuracy: 0.3997 - val_loss: 1.9503\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.9002 - val_accuracy: 0.3997 - val_loss: 1.9514\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8993 - val_accuracy: 0.3997 - val_loss: 1.9533\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7428 - loss: 0.8985 - val_accuracy: 0.3997 - val_loss: 1.9496\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8977 - val_accuracy: 0.3997 - val_loss: 1.9529\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8969 - val_accuracy: 0.3997 - val_loss: 1.9467\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8961 - val_accuracy: 0.3997 - val_loss: 1.9484\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8953 - val_accuracy: 0.3995 - val_loss: 1.9532\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8946 - val_accuracy: 0.3996 - val_loss: 1.9522\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7426 - loss: 0.8938 - val_accuracy: 0.3995 - val_loss: 1.9516\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8931 - val_accuracy: 0.3996 - val_loss: 1.9504\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8924 - val_accuracy: 0.3996 - val_loss: 1.9520\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8916 - val_accuracy: 0.3996 - val_loss: 1.9492\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8910 - val_accuracy: 0.3996 - val_loss: 1.9520\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8903 - val_accuracy: 0.3996 - val_loss: 1.9482\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8896 - val_accuracy: 0.3997 - val_loss: 1.9495\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8889 - val_accuracy: 0.3997 - val_loss: 1.9500\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.8883 - val_accuracy: 0.3966 - val_loss: 1.9457\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.8877 - val_accuracy: 0.3967 - val_loss: 1.9527\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.8870 - val_accuracy: 0.3967 - val_loss: 1.9503\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.8864 - val_accuracy: 0.3967 - val_loss: 1.9515\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.8858 - val_accuracy: 0.3967 - val_loss: 1.9428\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7407 - loss: 0.8852 - val_accuracy: 0.3967 - val_loss: 1.9458\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8846 - val_accuracy: 0.3967 - val_loss: 1.9451\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8840 - val_accuracy: 0.3967 - val_loss: 1.9448\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8834 - val_accuracy: 0.3967 - val_loss: 1.9486\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8829 - val_accuracy: 0.3967 - val_loss: 1.9429\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8823 - val_accuracy: 0.3967 - val_loss: 1.9448\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7408 - loss: 0.8818 - val_accuracy: 0.3967 - val_loss: 1.9446\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8812 - val_accuracy: 0.3971 - val_loss: 1.9425\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.8807 - val_accuracy: 0.3971 - val_loss: 1.9429\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7411 - loss: 0.8802 - val_accuracy: 0.3967 - val_loss: 1.9428\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7415 - loss: 0.8797 - val_accuracy: 0.3967 - val_loss: 1.9430\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8791 - val_accuracy: 0.3967 - val_loss: 1.9488\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7416 - loss: 0.8786 - val_accuracy: 0.3967 - val_loss: 1.9480\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8782 - val_accuracy: 0.3967 - val_loss: 1.9457\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8777 - val_accuracy: 0.3967 - val_loss: 1.9402\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8772 - val_accuracy: 0.3967 - val_loss: 1.9446\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8767 - val_accuracy: 0.3967 - val_loss: 1.9440\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8762 - val_accuracy: 0.3967 - val_loss: 1.9441\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7416 - loss: 0.8758 - val_accuracy: 0.3968 - val_loss: 1.9411\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8753 - val_accuracy: 0.3968 - val_loss: 1.9392\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8749 - val_accuracy: 0.3968 - val_loss: 1.9416\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8744 - val_accuracy: 0.3968 - val_loss: 1.9414\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8740 - val_accuracy: 0.3969 - val_loss: 1.9426\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8736 - val_accuracy: 0.3969 - val_loss: 1.9410\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8732 - val_accuracy: 0.3969 - val_loss: 1.9358\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8727 - val_accuracy: 0.3969 - val_loss: 1.9370\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8723 - val_accuracy: 0.3969 - val_loss: 1.9389\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8719 - val_accuracy: 0.3969 - val_loss: 1.9369\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8715 - val_accuracy: 0.3969 - val_loss: 1.9389\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7415 - loss: 0.8711 - val_accuracy: 0.3969 - val_loss: 1.9386\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8707 - val_accuracy: 0.3969 - val_loss: 1.9410\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8703 - val_accuracy: 0.3969 - val_loss: 1.9400\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8700 - val_accuracy: 0.3969 - val_loss: 1.9357\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8696 - val_accuracy: 0.3969 - val_loss: 1.9414\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8692 - val_accuracy: 0.3969 - val_loss: 1.9364\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8688 - val_accuracy: 0.3970 - val_loss: 1.9377\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7421 - loss: 0.8685 - val_accuracy: 0.3970 - val_loss: 1.9375\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7422 - loss: 0.8681 - val_accuracy: 0.3970 - val_loss: 1.9384\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8678 - val_accuracy: 0.3970 - val_loss: 1.9419\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8674 - val_accuracy: 0.3970 - val_loss: 1.9375\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8671 - val_accuracy: 0.3972 - val_loss: 1.9363\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8667 - val_accuracy: 0.3972 - val_loss: 1.9355\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8664 - val_accuracy: 0.3972 - val_loss: 1.9364\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7424 - loss: 0.8660 - val_accuracy: 0.3972 - val_loss: 1.9359\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8657 - val_accuracy: 0.4026 - val_loss: 1.9315\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8654 - val_accuracy: 0.3972 - val_loss: 1.9337\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8651 - val_accuracy: 0.3972 - val_loss: 1.9285\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8647 - val_accuracy: 0.4026 - val_loss: 1.9327\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8644 - val_accuracy: 0.3971 - val_loss: 1.9335\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7424 - loss: 0.8641 - val_accuracy: 0.3971 - val_loss: 1.9368\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8638 - val_accuracy: 0.3971 - val_loss: 1.9395\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8635 - val_accuracy: 0.4029 - val_loss: 1.9334\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8632 - val_accuracy: 0.3974 - val_loss: 1.9355\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8629 - val_accuracy: 0.4029 - val_loss: 1.9315\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8626 - val_accuracy: 0.3977 - val_loss: 1.9235\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7424 - loss: 0.8623 - val_accuracy: 0.4031 - val_loss: 1.9301\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8620 - val_accuracy: 0.3976 - val_loss: 1.9339\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8617 - val_accuracy: 0.3976 - val_loss: 1.9335\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8614 - val_accuracy: 0.4031 - val_loss: 1.9302\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8611 - val_accuracy: 0.4031 - val_loss: 1.9269\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8609 - val_accuracy: 0.3976 - val_loss: 1.9289\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7425 - loss: 0.8606 - val_accuracy: 0.4031 - val_loss: 1.9306\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8603 - val_accuracy: 0.3976 - val_loss: 1.9326\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8600 - val_accuracy: 0.4031 - val_loss: 1.9267\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8598 - val_accuracy: 0.4031 - val_loss: 1.9320\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8595 - val_accuracy: 0.4031 - val_loss: 1.9285\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8592 - val_accuracy: 0.4031 - val_loss: 1.9248\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8590 - val_accuracy: 0.4031 - val_loss: 1.9292\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8587 - val_accuracy: 0.4031 - val_loss: 1.9253\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8585 - val_accuracy: 0.4031 - val_loss: 1.9253\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8582 - val_accuracy: 0.4032 - val_loss: 1.9257\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8579 - val_accuracy: 0.4031 - val_loss: 1.9321\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8577 - val_accuracy: 0.4076 - val_loss: 1.9311\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8574 - val_accuracy: 0.4032 - val_loss: 1.9260\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7431 - loss: 0.8572 - val_accuracy: 0.4031 - val_loss: 1.9292\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8569 - val_accuracy: 0.4131 - val_loss: 1.9249\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8567 - val_accuracy: 0.4131 - val_loss: 1.9297\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8565 - val_accuracy: 0.4132 - val_loss: 1.9253\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8562 - val_accuracy: 0.4132 - val_loss: 1.9270\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8560 - val_accuracy: 0.4132 - val_loss: 1.9242\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7432 - loss: 0.8557 - val_accuracy: 0.4131 - val_loss: 1.9294\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8555 - val_accuracy: 0.4132 - val_loss: 1.9266\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8553 - val_accuracy: 0.4132 - val_loss: 1.9221\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8550 - val_accuracy: 0.4132 - val_loss: 1.9225\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8548 - val_accuracy: 0.4062 - val_loss: 1.9327\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8546 - val_accuracy: 0.4132 - val_loss: 1.9234\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7432 - loss: 0.8544 - val_accuracy: 0.4117 - val_loss: 1.9257\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8541 - val_accuracy: 0.4117 - val_loss: 1.9267\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8539 - val_accuracy: 0.4117 - val_loss: 1.9286\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8537 - val_accuracy: 0.4117 - val_loss: 1.9266\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8535 - val_accuracy: 0.4120 - val_loss: 1.9231\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8533 - val_accuracy: 0.4117 - val_loss: 1.9238\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7432 - loss: 0.8530 - val_accuracy: 0.4120 - val_loss: 1.9254\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7433 - loss: 0.8528 - val_accuracy: 0.4120 - val_loss: 1.9280\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8526 - val_accuracy: 0.4120 - val_loss: 1.9278\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8524 - val_accuracy: 0.4120 - val_loss: 1.9223\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8522 - val_accuracy: 0.4121 - val_loss: 1.9198\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8520 - val_accuracy: 0.4120 - val_loss: 1.9258\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8518 - val_accuracy: 0.4120 - val_loss: 1.9229\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7435 - loss: 0.8516 - val_accuracy: 0.4120 - val_loss: 1.9262\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7437 - loss: 0.8514 - val_accuracy: 0.4121 - val_loss: 1.9222\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8512 - val_accuracy: 0.4121 - val_loss: 1.9254\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8510 - val_accuracy: 0.4121 - val_loss: 1.9200\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8507 - val_accuracy: 0.4121 - val_loss: 1.9238\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8506 - val_accuracy: 0.4120 - val_loss: 1.9244\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8504 - val_accuracy: 0.4121 - val_loss: 1.9203\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8502 - val_accuracy: 0.4121 - val_loss: 1.9250\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8500 - val_accuracy: 0.4121 - val_loss: 1.9186\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8498 - val_accuracy: 0.4121 - val_loss: 1.9237\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8496 - val_accuracy: 0.4121 - val_loss: 1.9245\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8494 - val_accuracy: 0.4121 - val_loss: 1.9180\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7440 - loss: 0.8492 - val_accuracy: 0.4121 - val_loss: 1.9228\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8490 - val_accuracy: 0.4122 - val_loss: 1.9178\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8488 - val_accuracy: 0.4122 - val_loss: 1.9287\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8486 - val_accuracy: 0.4122 - val_loss: 1.9217\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8484 - val_accuracy: 0.4122 - val_loss: 1.9242\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8482 - val_accuracy: 0.4122 - val_loss: 1.9205\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7441 - loss: 0.8480 - val_accuracy: 0.4122 - val_loss: 1.9218\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8479 - val_accuracy: 0.4122 - val_loss: 1.9246\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8477 - val_accuracy: 0.4126 - val_loss: 1.9191\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7442 - loss: 0.8475 - val_accuracy: 0.4122 - val_loss: 1.9190\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7442 - loss: 0.8473 - val_accuracy: 0.4122 - val_loss: 1.9225\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7442 - loss: 0.8471 - val_accuracy: 0.4131 - val_loss: 1.9134\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7441 - loss: 0.8470 - val_accuracy: 0.4119 - val_loss: 1.9273\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8468 - val_accuracy: 0.4133 - val_loss: 1.9169\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8466 - val_accuracy: 0.4127 - val_loss: 1.9225\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8464 - val_accuracy: 0.4121 - val_loss: 1.9247\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8462 - val_accuracy: 0.4131 - val_loss: 1.9200\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8461 - val_accuracy: 0.4131 - val_loss: 1.9212\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7440 - loss: 0.8459 - val_accuracy: 0.4131 - val_loss: 1.9273\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8457 - val_accuracy: 0.4136 - val_loss: 1.9157\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8455 - val_accuracy: 0.4136 - val_loss: 1.9198\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8454 - val_accuracy: 0.4138 - val_loss: 1.9214\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8452 - val_accuracy: 0.4133 - val_loss: 1.9204\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8450 - val_accuracy: 0.4133 - val_loss: 1.9242\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7439 - loss: 0.8449 - val_accuracy: 0.4133 - val_loss: 1.9233\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8447 - val_accuracy: 0.4138 - val_loss: 1.9187\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8445 - val_accuracy: 0.4138 - val_loss: 1.9196\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8443 - val_accuracy: 0.4117 - val_loss: 1.9211\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7437 - loss: 0.8442 - val_accuracy: 0.4117 - val_loss: 1.9207\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8440 - val_accuracy: 0.4112 - val_loss: 1.9232\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7437 - loss: 0.8438 - val_accuracy: 0.4117 - val_loss: 1.9213\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7437 - loss: 0.8437 - val_accuracy: 0.4117 - val_loss: 1.9176\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8435 - val_accuracy: 0.4117 - val_loss: 1.9217\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8433 - val_accuracy: 0.4117 - val_loss: 1.9177\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8432 - val_accuracy: 0.4117 - val_loss: 1.9222\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8430 - val_accuracy: 0.4117 - val_loss: 1.9207\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8429 - val_accuracy: 0.4117 - val_loss: 1.9199\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7438 - loss: 0.8427 - val_accuracy: 0.4117 - val_loss: 1.9233\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8425 - val_accuracy: 0.4117 - val_loss: 1.9209\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8424 - val_accuracy: 0.4117 - val_loss: 1.9215\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8422 - val_accuracy: 0.4117 - val_loss: 1.9182\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7438 - loss: 0.8421 - val_accuracy: 0.4117 - val_loss: 1.9204\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8419 - val_accuracy: 0.4117 - val_loss: 1.9239\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7438 - loss: 0.8417 - val_accuracy: 0.4118 - val_loss: 1.9215\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8416 - val_accuracy: 0.4117 - val_loss: 1.9233\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8414 - val_accuracy: 0.4118 - val_loss: 1.9185\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8413 - val_accuracy: 0.4117 - val_loss: 1.9245\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8411 - val_accuracy: 0.4117 - val_loss: 1.9208\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8410 - val_accuracy: 0.4118 - val_loss: 1.9222\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7440 - loss: 0.8408 - val_accuracy: 0.4118 - val_loss: 1.9184\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8407 - val_accuracy: 0.4117 - val_loss: 1.9175\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8405 - val_accuracy: 0.4118 - val_loss: 1.9177\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8403 - val_accuracy: 0.4117 - val_loss: 1.9262\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8402 - val_accuracy: 0.4117 - val_loss: 1.9193\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8400 - val_accuracy: 0.4118 - val_loss: 1.9182\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7444 - loss: 0.8399 - val_accuracy: 0.4118 - val_loss: 1.9169\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8397 - val_accuracy: 0.4116 - val_loss: 1.9226\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8396 - val_accuracy: 0.4116 - val_loss: 1.9201\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8394 - val_accuracy: 0.4061 - val_loss: 1.9208\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8393 - val_accuracy: 0.4061 - val_loss: 1.9178\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8391 - val_accuracy: 0.4061 - val_loss: 1.9205\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8390 - val_accuracy: 0.4061 - val_loss: 1.9194\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8389 - val_accuracy: 0.4061 - val_loss: 1.9200\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8387 - val_accuracy: 0.4061 - val_loss: 1.9202\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8386 - val_accuracy: 0.4059 - val_loss: 1.9206\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8384 - val_accuracy: 0.4059 - val_loss: 1.9146\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8383 - val_accuracy: 0.4062 - val_loss: 1.9167\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7445 - loss: 0.8381 - val_accuracy: 0.4040 - val_loss: 1.9235\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8380 - val_accuracy: 0.4062 - val_loss: 1.9182\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8378 - val_accuracy: 0.4059 - val_loss: 1.9229\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8377 - val_accuracy: 0.4041 - val_loss: 1.9184\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8375 - val_accuracy: 0.4040 - val_loss: 1.9252\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8374 - val_accuracy: 0.4040 - val_loss: 1.9185\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8373 - val_accuracy: 0.4040 - val_loss: 1.9197\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8371 - val_accuracy: 0.4040 - val_loss: 1.9199\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8370 - val_accuracy: 0.4041 - val_loss: 1.9190\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8368 - val_accuracy: 0.4041 - val_loss: 1.9186\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8367 - val_accuracy: 0.4040 - val_loss: 1.9228\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8366 - val_accuracy: 0.4040 - val_loss: 1.9208\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8364 - val_accuracy: 0.4040 - val_loss: 1.9194\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8363 - val_accuracy: 0.4041 - val_loss: 1.9218\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8361 - val_accuracy: 0.4041 - val_loss: 1.9245\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8360 - val_accuracy: 0.4041 - val_loss: 1.9210\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8359 - val_accuracy: 0.4041 - val_loss: 1.9191\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8357 - val_accuracy: 0.4041 - val_loss: 1.9270\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8356 - val_accuracy: 0.4040 - val_loss: 1.9252\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8355 - val_accuracy: 0.4041 - val_loss: 1.9209\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8353 - val_accuracy: 0.4042 - val_loss: 1.9213\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8352 - val_accuracy: 0.4029 - val_loss: 1.9235\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8350 - val_accuracy: 0.4042 - val_loss: 1.9187\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8349 - val_accuracy: 0.4029 - val_loss: 1.9238\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7445 - loss: 0.8348 - val_accuracy: 0.4043 - val_loss: 1.9206\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8346 - val_accuracy: 0.4043 - val_loss: 1.9173\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8345 - val_accuracy: 0.4043 - val_loss: 1.9169\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7445 - loss: 0.8344 - val_accuracy: 0.4043 - val_loss: 1.9205\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8342 - val_accuracy: 0.4043 - val_loss: 1.9174\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7445 - loss: 0.8341 - val_accuracy: 0.4030 - val_loss: 1.9220\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8340 - val_accuracy: 0.4030 - val_loss: 1.9218\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8338 - val_accuracy: 0.4043 - val_loss: 1.9205\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8337 - val_accuracy: 0.4028 - val_loss: 1.9253\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8336 - val_accuracy: 0.4043 - val_loss: 1.9192\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8334 - val_accuracy: 0.4030 - val_loss: 1.9185\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8333 - val_accuracy: 0.4043 - val_loss: 1.9187\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8332 - val_accuracy: 0.4030 - val_loss: 1.9241\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8331 - val_accuracy: 0.4030 - val_loss: 1.9236\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8329 - val_accuracy: 0.4042 - val_loss: 1.9184\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8328 - val_accuracy: 0.4043 - val_loss: 1.9174\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8327 - val_accuracy: 0.4075 - val_loss: 1.9118\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7445 - loss: 0.8325 - val_accuracy: 0.4031 - val_loss: 1.9224\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8324 - val_accuracy: 0.4030 - val_loss: 1.9235\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8323 - val_accuracy: 0.4031 - val_loss: 1.9225\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8322 - val_accuracy: 0.4030 - val_loss: 1.9211\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8320 - val_accuracy: 0.4031 - val_loss: 1.9198\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8319 - val_accuracy: 0.4031 - val_loss: 1.9206\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8318 - val_accuracy: 0.4030 - val_loss: 1.9269\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8316 - val_accuracy: 0.4031 - val_loss: 1.9203\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8315 - val_accuracy: 0.4043 - val_loss: 1.9171\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8314 - val_accuracy: 0.4031 - val_loss: 1.9213\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8313 - val_accuracy: 0.4031 - val_loss: 1.9196\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8311 - val_accuracy: 0.4031 - val_loss: 1.9211\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8310 - val_accuracy: 0.4031 - val_loss: 1.9245\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7445 - loss: 0.8309 - val_accuracy: 0.4031 - val_loss: 1.9233\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8308 - val_accuracy: 0.4031 - val_loss: 1.9237\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8307 - val_accuracy: 0.4031 - val_loss: 1.9220\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8305 - val_accuracy: 0.4063 - val_loss: 1.9194\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.8304 - val_accuracy: 0.4063 - val_loss: 1.9153\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8303 - val_accuracy: 0.4031 - val_loss: 1.9243\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7445 - loss: 0.8302 - val_accuracy: 0.4031 - val_loss: 1.9208\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8300 - val_accuracy: 0.4031 - val_loss: 1.9213\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8299 - val_accuracy: 0.4063 - val_loss: 1.9151\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8298 - val_accuracy: 0.4063 - val_loss: 1.9190\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8297 - val_accuracy: 0.4031 - val_loss: 1.9209\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8296 - val_accuracy: 0.4063 - val_loss: 1.9191\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8294 - val_accuracy: 0.4063 - val_loss: 1.9207\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8293 - val_accuracy: 0.4031 - val_loss: 1.9220\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8292 - val_accuracy: 0.4031 - val_loss: 1.9235\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8291 - val_accuracy: 0.4031 - val_loss: 1.9239\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8290 - val_accuracy: 0.4063 - val_loss: 1.9203\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8289 - val_accuracy: 0.4063 - val_loss: 1.9220\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8287 - val_accuracy: 0.4063 - val_loss: 1.9181\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7446 - loss: 0.8286 - val_accuracy: 0.4063 - val_loss: 1.9182\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8285 - val_accuracy: 0.4063 - val_loss: 1.9184\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8284 - val_accuracy: 0.4063 - val_loss: 1.9205\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8283 - val_accuracy: 0.4063 - val_loss: 1.9193\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8281 - val_accuracy: 0.4062 - val_loss: 1.9254\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8280 - val_accuracy: 0.4062 - val_loss: 1.9258\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7446 - loss: 0.8279 - val_accuracy: 0.4063 - val_loss: 1.9206\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8278 - val_accuracy: 0.4063 - val_loss: 1.9227\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8277 - val_accuracy: 0.4063 - val_loss: 1.9209\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8276 - val_accuracy: 0.4063 - val_loss: 1.9197\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8275 - val_accuracy: 0.4063 - val_loss: 1.9188\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8273 - val_accuracy: 0.4063 - val_loss: 1.9173\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7446 - loss: 0.8272 - val_accuracy: 0.4063 - val_loss: 1.9205\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8271 - val_accuracy: 0.4063 - val_loss: 1.9210\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8270 - val_accuracy: 0.4062 - val_loss: 1.9221\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8269 - val_accuracy: 0.4063 - val_loss: 1.9156\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8268 - val_accuracy: 0.4062 - val_loss: 1.9235\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.8267 - val_accuracy: 0.4063 - val_loss: 1.9235\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7447 - loss: 0.8265 - val_accuracy: 0.4063 - val_loss: 1.9205\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7447 - loss: 0.8264 - val_accuracy: 0.4063 - val_loss: 1.9186\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7448 - loss: 0.8263 - val_accuracy: 0.4063 - val_loss: 1.9228\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7447 - loss: 0.8262 - val_accuracy: 0.4074 - val_loss: 1.9217\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7450 - loss: 0.8261 - val_accuracy: 0.4062 - val_loss: 1.9244\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8260 - val_accuracy: 0.4074 - val_loss: 1.9208\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7450 - loss: 0.8259 - val_accuracy: 0.4074 - val_loss: 1.9222\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8258 - val_accuracy: 0.4074 - val_loss: 1.9228\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8256 - val_accuracy: 0.4074 - val_loss: 1.9152\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8255 - val_accuracy: 0.4074 - val_loss: 1.9223\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8254 - val_accuracy: 0.4074 - val_loss: 1.9204\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8253 - val_accuracy: 0.4072 - val_loss: 1.9179\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8252 - val_accuracy: 0.4074 - val_loss: 1.9246\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7451 - loss: 0.8251 - val_accuracy: 0.4074 - val_loss: 1.9238\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7450 - loss: 0.8250 - val_accuracy: 0.4074 - val_loss: 1.9224\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8249 - val_accuracy: 0.4074 - val_loss: 1.9192\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8248 - val_accuracy: 0.4074 - val_loss: 1.9225\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8247 - val_accuracy: 0.4072 - val_loss: 1.9212\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7451 - loss: 0.8246 - val_accuracy: 0.4072 - val_loss: 1.9267\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7450 - loss: 0.8245 - val_accuracy: 0.4074 - val_loss: 1.9283\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8243 - val_accuracy: 0.4072 - val_loss: 1.9239\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8242 - val_accuracy: 0.4074 - val_loss: 1.9217\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7453 - loss: 0.8241 - val_accuracy: 0.4072 - val_loss: 1.9206\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7453 - loss: 0.8240 - val_accuracy: 0.4072 - val_loss: 1.9243\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7452 - loss: 0.8239 - val_accuracy: 0.4072 - val_loss: 1.9241\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8238 - val_accuracy: 0.4072 - val_loss: 1.9216\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7453 - loss: 0.8237 - val_accuracy: 0.4072 - val_loss: 1.9195\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8236 - val_accuracy: 0.4072 - val_loss: 1.9234\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8235 - val_accuracy: 0.4072 - val_loss: 1.9151\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8234 - val_accuracy: 0.4072 - val_loss: 1.9193\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8233 - val_accuracy: 0.4068 - val_loss: 1.9254\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7452 - loss: 0.8232 - val_accuracy: 0.4072 - val_loss: 1.9184\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8231 - val_accuracy: 0.4068 - val_loss: 1.9255\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8230 - val_accuracy: 0.4069 - val_loss: 1.9177\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8229 - val_accuracy: 0.4069 - val_loss: 1.9269\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8228 - val_accuracy: 0.4068 - val_loss: 1.9254\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8226 - val_accuracy: 0.4069 - val_loss: 1.9223\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7452 - loss: 0.8225 - val_accuracy: 0.4069 - val_loss: 1.9195\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8224 - val_accuracy: 0.4068 - val_loss: 1.9246\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7449 - loss: 0.8223 - val_accuracy: 0.4068 - val_loss: 1.9239\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8222 - val_accuracy: 0.4068 - val_loss: 1.9217\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8221 - val_accuracy: 0.4068 - val_loss: 1.9217\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8220 - val_accuracy: 0.4068 - val_loss: 1.9229\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7452 - loss: 0.8219 - val_accuracy: 0.4068 - val_loss: 1.9235\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8218 - val_accuracy: 0.4068 - val_loss: 1.9202\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7452 - loss: 0.8217 - val_accuracy: 0.4068 - val_loss: 1.9230\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8216 - val_accuracy: 0.4068 - val_loss: 1.9201\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8215 - val_accuracy: 0.4068 - val_loss: 1.9218\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8214 - val_accuracy: 0.4068 - val_loss: 1.9222\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7448 - loss: 0.8213 - val_accuracy: 0.4068 - val_loss: 1.9252\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7448 - loss: 0.8212 - val_accuracy: 0.4068 - val_loss: 1.9236\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7449 - loss: 0.8211 - val_accuracy: 0.4068 - val_loss: 1.9248\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7450 - loss: 0.8210 - val_accuracy: 0.4068 - val_loss: 1.9263\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8209 - val_accuracy: 0.4068 - val_loss: 1.9256\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8208 - val_accuracy: 0.4068 - val_loss: 1.9216\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7448 - loss: 0.8207 - val_accuracy: 0.4068 - val_loss: 1.9213\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7449 - loss: 0.8206 - val_accuracy: 0.4068 - val_loss: 1.9246\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7451 - loss: 0.8205 - val_accuracy: 0.4068 - val_loss: 1.9194\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7449 - loss: 0.8204 - val_accuracy: 0.4068 - val_loss: 1.9294\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7442 - loss: 0.8203 - val_accuracy: 0.4068 - val_loss: 1.9223\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7448 - loss: 0.8202 - val_accuracy: 0.4068 - val_loss: 1.9253\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7444 - loss: 0.8201 - val_accuracy: 0.4068 - val_loss: 1.9247\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7448 - loss: 0.8200 - val_accuracy: 0.2992 - val_loss: 1.9255\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7443 - loss: 0.8199 - val_accuracy: 0.4068 - val_loss: 1.9227\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8198 - val_accuracy: 0.4068 - val_loss: 1.9237\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8197 - val_accuracy: 0.4068 - val_loss: 1.9197\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7441 - loss: 0.8196 - val_accuracy: 0.4068 - val_loss: 1.9203\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7440 - loss: 0.8195 - val_accuracy: 0.2992 - val_loss: 1.9265\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7445 - loss: 0.8194 - val_accuracy: 0.2992 - val_loss: 1.9251\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7434 - loss: 0.8193 - val_accuracy: 0.2992 - val_loss: 1.9266\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7437 - loss: 0.8192 - val_accuracy: 0.4068 - val_loss: 1.9216\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.8191 - val_accuracy: 0.4068 - val_loss: 1.9242\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7443 - loss: 0.8190 - val_accuracy: 0.2992 - val_loss: 1.9260\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7436 - loss: 0.8189 - val_accuracy: 0.2992 - val_loss: 1.9277\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8188 - val_accuracy: 0.2992 - val_loss: 1.9258\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8187 - val_accuracy: 0.4068 - val_loss: 1.9251\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7434 - loss: 0.8186 - val_accuracy: 0.4069 - val_loss: 1.9197\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7439 - loss: 0.8186 - val_accuracy: 0.4068 - val_loss: 1.9219\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8185 - val_accuracy: 0.4069 - val_loss: 1.9235\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7433 - loss: 0.8184 - val_accuracy: 0.4068 - val_loss: 1.9191\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7436 - loss: 0.8183 - val_accuracy: 0.2992 - val_loss: 1.9255\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8182 - val_accuracy: 0.4069 - val_loss: 1.9204\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8181 - val_accuracy: 0.4069 - val_loss: 1.9197\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8180 - val_accuracy: 0.4069 - val_loss: 1.9209\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8179 - val_accuracy: 0.4068 - val_loss: 1.9194\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8178 - val_accuracy: 0.2992 - val_loss: 1.9252\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8177 - val_accuracy: 0.4068 - val_loss: 1.9275\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8176 - val_accuracy: 0.2992 - val_loss: 1.9275\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8175 - val_accuracy: 0.2992 - val_loss: 1.9275\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7422 - loss: 0.8174 - val_accuracy: 0.4069 - val_loss: 1.9261\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7422 - loss: 0.8173 - val_accuracy: 0.2992 - val_loss: 1.9280\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7422 - loss: 0.8172 - val_accuracy: 0.4069 - val_loss: 1.9223\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8171 - val_accuracy: 0.2992 - val_loss: 1.9328\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8170 - val_accuracy: 0.2992 - val_loss: 1.9253\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7419 - loss: 0.8170 - val_accuracy: 0.2993 - val_loss: 1.9309\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8169 - val_accuracy: 0.2992 - val_loss: 1.9271\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7419 - loss: 0.8168 - val_accuracy: 0.4069 - val_loss: 1.9251\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.8167 - val_accuracy: 0.2992 - val_loss: 1.9275\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7414 - loss: 0.8166 - val_accuracy: 0.2993 - val_loss: 1.9260\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8165 - val_accuracy: 0.2992 - val_loss: 1.9287\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7414 - loss: 0.8164 - val_accuracy: 0.2993 - val_loss: 1.9268\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.8163 - val_accuracy: 0.2992 - val_loss: 1.9261\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7417 - loss: 0.8162 - val_accuracy: 0.2992 - val_loss: 1.9271\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7414 - loss: 0.8161 - val_accuracy: 0.2993 - val_loss: 1.9222\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7423 - loss: 0.8160 - val_accuracy: 0.2992 - val_loss: 1.9269\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7418 - loss: 0.8159 - val_accuracy: 0.2992 - val_loss: 1.9253\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7415 - loss: 0.8159 - val_accuracy: 0.2992 - val_loss: 1.9271\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.8158 - val_accuracy: 0.2992 - val_loss: 1.9248\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7412 - loss: 0.8157 - val_accuracy: 0.2993 - val_loss: 1.9215\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7415 - loss: 0.8156 - val_accuracy: 0.2992 - val_loss: 1.9253\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7412 - loss: 0.8155 - val_accuracy: 0.2992 - val_loss: 1.9285\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8154 - val_accuracy: 0.2992 - val_loss: 1.9269\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7412 - loss: 0.8153 - val_accuracy: 0.2993 - val_loss: 1.9198\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8152 - val_accuracy: 0.2993 - val_loss: 1.9233\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7417 - loss: 0.8151 - val_accuracy: 0.2993 - val_loss: 1.9277\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7417 - loss: 0.8150 - val_accuracy: 0.2993 - val_loss: 1.9258\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8149 - val_accuracy: 0.2992 - val_loss: 1.9262\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8149 - val_accuracy: 0.2993 - val_loss: 1.9278\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8148 - val_accuracy: 0.2992 - val_loss: 1.9302\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.8147 - val_accuracy: 0.2992 - val_loss: 1.9281\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8146 - val_accuracy: 0.4069 - val_loss: 1.9225\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.8145 - val_accuracy: 0.2992 - val_loss: 1.9246\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.8144 - val_accuracy: 0.2992 - val_loss: 1.9311\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8143 - val_accuracy: 0.2992 - val_loss: 1.9260\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8142 - val_accuracy: 0.2993 - val_loss: 1.9268\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8141 - val_accuracy: 0.2992 - val_loss: 1.9276\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7425 - loss: 0.8141 - val_accuracy: 0.2993 - val_loss: 1.9223\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8140 - val_accuracy: 0.2992 - val_loss: 1.9234\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.8139 - val_accuracy: 0.2993 - val_loss: 1.9283\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.52999\n726/726 - 6s - 8ms/step - accuracy: 0.7428 - loss: 0.8138 - val_accuracy: 0.2993 - val_loss: 1.9222\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.8137 - val_accuracy: 0.2993 - val_loss: 1.9240\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8136 - val_accuracy: 0.2993 - val_loss: 1.9276\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.8135 - val_accuracy: 0.2993 - val_loss: 1.9268\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8134 - val_accuracy: 0.2994 - val_loss: 1.9225\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8134 - val_accuracy: 0.2993 - val_loss: 1.9283\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.52999\n726/726 - 5s - 8ms/step - accuracy: 0.7429 - loss: 0.8133 - val_accuracy: 0.2993 - val_loss: 1.9290\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8132 - val_accuracy: 0.2993 - val_loss: 1.9280\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.52999\n726/726 - 5s - 7ms/step - accuracy: 0.7430 - loss: 0.8131 - val_accuracy: 0.2993 - val_loss: 1.9278\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(\n    X, y, test_size=0.3, random_state=45, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_3, X_val_3, y_train_3, y_val_3 = train_test_split(\n    X_train_3, y_train_3, test_size=0.3, random_state=44, stratify=y_train_3\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_3:\", np.max(X_train_3))\nprint(\"Min value in X_train_3:\", np.min(X_train_3))\n\nX_train_3_scaled = scaler.fit_transform(X_train_3)\n\n# Get the original class distribution\nclass_counts_3 = Counter(y_train_3)\nprint(\"Original class distribution:\", class_counts_3)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_3 = class_counts_3[min(class_counts_3, key=class_counts_3.get)]\ndesired_majority_size_3 = minority_class_size_3 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_3 = {0: desired_majority_size_3, 1: minority_class_size_3}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_3 = RandomUnderSampler(sampling_strategy=sampling_strategy_3, random_state=42)\nX_resampled_3, y_resampled_3 = undersampler_3.fit_resample(X_train_3, y_train_3)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_3))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_3, y_train_resampled_3 = smote.fit_resample(X_resampled_3, y_resampled_3)\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_3))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_3))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:25:20.466259Z","iopub.execute_input":"2025-03-06T18:25:20.466666Z","iopub.status.idle":"2025-03-06T18:25:52.105371Z","shell.execute_reply.started":"2025-03-06T18:25:20.466636Z","shell.execute_reply":"2025-03-06T18:25:52.104236Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_3: 2071000000.0\nMin value in X_train_3: -9663668122.0\nOriginal class distribution: Counter({0: 1026577, 4: 84694, 2: 62727, 10: 44440, 3: 5040, 7: 2906, 6: 2638, 5: 2562, 11: 1577, 1: 955, 12: 720, 14: 319, 9: 18, 13: 11, 8: 6})\nClass distribution after undersampling: Counter({4: 84694, 2: 62727, 10: 44440, 3: 5040, 7: 2906, 6: 2638, 5: 2562, 11: 1577, 12: 720, 14: 319, 0: 30, 9: 18, 13: 11, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 84694, 2: 62727, 10: 44440, 3: 5040, 7: 2906, 6: 2638, 5: 2562, 11: 1577, 12: 720, 14: 319, 0: 30, 9: 18, 13: 11, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 84694, 1: 84694, 2: 84694, 3: 84694, 4: 84694, 5: 84694, 6: 84694, 7: 84694, 8: 84694, 9: 84694, 10: 84694, 11: 84694, 12: 84694, 13: 84694, 14: 84694})\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_3 = X_train_resampled_3.reshape(X_train_resampled_3.shape[0], 1, 56)\nX_val_3 = X_val_3.reshape(X_val_3.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_3,  # Features from CICIDS2017\n    y_train_resampled_3,  # Labels from CICIDS2017\n    validation_data=(X_val_3, y_val_3),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:25:52.106501Z","iopub.execute_input":"2025-03-06T18:25:52.106867Z","iopub.status.idle":"2025-03-06T19:09:33.016359Z","shell.execute_reply.started":"2025-03-06T18:25:52.106833Z","shell.execute_reply":"2025-03-06T19:09:33.015447Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7419 - loss: 0.7949 - val_accuracy: 0.4429 - val_loss: 1.9602\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7473 - loss: 0.7830 - val_accuracy: 0.4507 - val_loss: 1.9624\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7481 - loss: 0.7758 - val_accuracy: 0.4519 - val_loss: 1.9564\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7478 - loss: 0.7702 - val_accuracy: 0.4520 - val_loss: 1.9618\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7481 - loss: 0.7654 - val_accuracy: 0.4512 - val_loss: 1.9622\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7483 - loss: 0.7612 - val_accuracy: 0.4524 - val_loss: 1.9598\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7483 - loss: 0.7574 - val_accuracy: 0.4524 - val_loss: 1.9565\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7483 - loss: 0.7540 - val_accuracy: 0.4630 - val_loss: 1.9527\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7485 - loss: 0.7509 - val_accuracy: 0.4629 - val_loss: 1.9525\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7487 - loss: 0.7480 - val_accuracy: 0.4629 - val_loss: 1.9490\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7526 - loss: 0.7454 - val_accuracy: 0.4640 - val_loss: 1.9512\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7429 - val_accuracy: 0.4640 - val_loss: 1.9441\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7588 - loss: 0.7406 - val_accuracy: 0.4642 - val_loss: 1.9436\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7385 - val_accuracy: 0.4644 - val_loss: 1.9417\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7365 - val_accuracy: 0.4638 - val_loss: 1.9418\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7346 - val_accuracy: 0.4641 - val_loss: 1.9366\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7586 - loss: 0.7328 - val_accuracy: 0.4640 - val_loss: 1.9372\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7586 - loss: 0.7311 - val_accuracy: 0.4640 - val_loss: 1.9353\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7575 - loss: 0.7295 - val_accuracy: 0.4637 - val_loss: 1.9346\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7280 - val_accuracy: 0.4637 - val_loss: 1.9314\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7613 - loss: 0.7265 - val_accuracy: 0.4631 - val_loss: 1.9335\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7623 - loss: 0.7252 - val_accuracy: 0.4656 - val_loss: 1.9280\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7623 - loss: 0.7239 - val_accuracy: 0.4654 - val_loss: 1.9257\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7624 - loss: 0.7227 - val_accuracy: 0.4649 - val_loss: 1.9289\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7634 - loss: 0.7215 - val_accuracy: 0.4649 - val_loss: 1.9225\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7204 - val_accuracy: 0.4646 - val_loss: 1.9248\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7194 - val_accuracy: 0.4647 - val_loss: 1.9219\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7184 - val_accuracy: 0.4648 - val_loss: 1.9220\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7644 - loss: 0.7174 - val_accuracy: 0.4649 - val_loss: 1.9180\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7659 - loss: 0.7165 - val_accuracy: 0.4677 - val_loss: 1.9264\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7672 - loss: 0.7157 - val_accuracy: 0.4729 - val_loss: 1.9131\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7679 - loss: 0.7148 - val_accuracy: 0.4730 - val_loss: 1.9172\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7686 - loss: 0.7141 - val_accuracy: 0.4728 - val_loss: 1.9182\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7689 - loss: 0.7133 - val_accuracy: 0.4728 - val_loss: 1.9162\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7690 - loss: 0.7126 - val_accuracy: 0.4728 - val_loss: 1.9177\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7690 - loss: 0.7119 - val_accuracy: 0.4737 - val_loss: 1.9115\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7690 - loss: 0.7113 - val_accuracy: 0.4735 - val_loss: 1.9130\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7690 - loss: 0.7106 - val_accuracy: 0.4735 - val_loss: 1.9133\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7690 - loss: 0.7100 - val_accuracy: 0.4735 - val_loss: 1.9099\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7690 - loss: 0.7095 - val_accuracy: 0.4733 - val_loss: 1.9125\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7691 - loss: 0.7089 - val_accuracy: 0.4731 - val_loss: 1.9109\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7691 - loss: 0.7084 - val_accuracy: 0.4731 - val_loss: 1.9077\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7690 - loss: 0.7078 - val_accuracy: 0.4730 - val_loss: 1.9093\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7691 - loss: 0.7073 - val_accuracy: 0.4741 - val_loss: 1.9080\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7692 - loss: 0.7068 - val_accuracy: 0.4743 - val_loss: 1.9035\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7692 - loss: 0.7064 - val_accuracy: 0.4743 - val_loss: 1.9070\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7692 - loss: 0.7059 - val_accuracy: 0.4745 - val_loss: 1.9028\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7692 - loss: 0.7055 - val_accuracy: 0.4747 - val_loss: 1.9054\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7694 - loss: 0.7050 - val_accuracy: 0.4747 - val_loss: 1.9042\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7694 - loss: 0.7046 - val_accuracy: 0.4747 - val_loss: 1.9057\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7694 - loss: 0.7042 - val_accuracy: 0.4750 - val_loss: 1.9062\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7694 - loss: 0.7038 - val_accuracy: 0.4750 - val_loss: 1.9049\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7694 - loss: 0.7034 - val_accuracy: 0.4750 - val_loss: 1.9054\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7694 - loss: 0.7030 - val_accuracy: 0.4750 - val_loss: 1.9017\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7694 - loss: 0.7026 - val_accuracy: 0.4750 - val_loss: 1.9057\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.7022 - val_accuracy: 0.4750 - val_loss: 1.9004\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.7019 - val_accuracy: 0.4750 - val_loss: 1.9010\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.7015 - val_accuracy: 0.4750 - val_loss: 1.9002\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.7012 - val_accuracy: 0.4637 - val_loss: 1.9028\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.7008 - val_accuracy: 0.4751 - val_loss: 1.9007\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7695 - loss: 0.7005 - val_accuracy: 0.4751 - val_loss: 1.9006\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.7002 - val_accuracy: 0.4750 - val_loss: 1.9000\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6999 - val_accuracy: 0.4751 - val_loss: 1.9032\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7695 - loss: 0.6995 - val_accuracy: 0.4751 - val_loss: 1.9004\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6992 - val_accuracy: 0.4751 - val_loss: 1.8972\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6989 - val_accuracy: 0.4751 - val_loss: 1.9007\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7696 - loss: 0.6986 - val_accuracy: 0.4747 - val_loss: 1.8993\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6983 - val_accuracy: 0.4634 - val_loss: 1.9022\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6980 - val_accuracy: 0.4749 - val_loss: 1.8982\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6977 - val_accuracy: 0.4634 - val_loss: 1.8992\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6974 - val_accuracy: 0.4636 - val_loss: 1.8995\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7697 - loss: 0.6972 - val_accuracy: 0.4749 - val_loss: 1.8972\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7696 - loss: 0.6969 - val_accuracy: 0.4749 - val_loss: 1.8941\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6966 - val_accuracy: 0.4636 - val_loss: 1.8957\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7697 - loss: 0.6963 - val_accuracy: 0.4749 - val_loss: 1.8937\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7698 - loss: 0.6961 - val_accuracy: 0.4752 - val_loss: 1.8961\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7698 - loss: 0.6958 - val_accuracy: 0.4639 - val_loss: 1.8927\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6956 - val_accuracy: 0.4639 - val_loss: 1.8965\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7698 - loss: 0.6953 - val_accuracy: 0.4639 - val_loss: 1.8992\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6951 - val_accuracy: 0.4751 - val_loss: 1.8935\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6948 - val_accuracy: 0.4638 - val_loss: 1.8950\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6946 - val_accuracy: 0.4638 - val_loss: 1.8938\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6943 - val_accuracy: 0.4639 - val_loss: 1.8934\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6941 - val_accuracy: 0.4638 - val_loss: 1.8915\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7700 - loss: 0.6938 - val_accuracy: 0.4638 - val_loss: 1.8933\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6936 - val_accuracy: 0.4638 - val_loss: 1.8922\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6934 - val_accuracy: 0.4638 - val_loss: 1.8946\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6931 - val_accuracy: 0.4638 - val_loss: 1.8923\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6929 - val_accuracy: 0.4638 - val_loss: 1.8947\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6927 - val_accuracy: 0.4638 - val_loss: 1.8925\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7700 - loss: 0.6925 - val_accuracy: 0.4638 - val_loss: 1.8936\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6922 - val_accuracy: 0.4638 - val_loss: 1.8896\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6920 - val_accuracy: 0.4636 - val_loss: 1.8958\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6918 - val_accuracy: 0.4637 - val_loss: 1.8931\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7699 - loss: 0.6916 - val_accuracy: 0.4639 - val_loss: 1.8898\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7698 - loss: 0.6914 - val_accuracy: 0.4639 - val_loss: 1.8899\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7699 - loss: 0.6912 - val_accuracy: 0.4642 - val_loss: 1.8907\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7699 - loss: 0.6910 - val_accuracy: 0.4642 - val_loss: 1.8884\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7698 - loss: 0.6908 - val_accuracy: 0.4642 - val_loss: 1.8905\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7698 - loss: 0.6906 - val_accuracy: 0.4640 - val_loss: 1.8904\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7698 - loss: 0.6904 - val_accuracy: 0.4642 - val_loss: 1.8894\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7698 - loss: 0.6902 - val_accuracy: 0.4640 - val_loss: 1.8917\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7698 - loss: 0.6900 - val_accuracy: 0.4640 - val_loss: 1.8882\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7698 - loss: 0.6898 - val_accuracy: 0.4531 - val_loss: 1.8931\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7698 - loss: 0.6896 - val_accuracy: 0.4639 - val_loss: 1.8878\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7697 - loss: 0.6894 - val_accuracy: 0.4532 - val_loss: 1.8892\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6892 - val_accuracy: 0.4532 - val_loss: 1.8904\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6890 - val_accuracy: 0.4532 - val_loss: 1.8905\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7697 - loss: 0.6888 - val_accuracy: 0.4530 - val_loss: 1.8917\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6887 - val_accuracy: 0.4532 - val_loss: 1.8855\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6885 - val_accuracy: 0.4532 - val_loss: 1.8890\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6883 - val_accuracy: 0.4532 - val_loss: 1.8902\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6881 - val_accuracy: 0.4530 - val_loss: 1.8892\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6879 - val_accuracy: 0.4529 - val_loss: 1.8945\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7697 - loss: 0.6878 - val_accuracy: 0.4529 - val_loss: 1.8880\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7710 - loss: 0.6876 - val_accuracy: 0.4529 - val_loss: 1.8918\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7696 - loss: 0.6874 - val_accuracy: 0.4529 - val_loss: 1.8925\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.6873 - val_accuracy: 0.4530 - val_loss: 1.8922\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7703 - loss: 0.6871 - val_accuracy: 0.4530 - val_loss: 1.8916\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7748 - loss: 0.6869 - val_accuracy: 0.4530 - val_loss: 1.8936\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7726 - loss: 0.6868 - val_accuracy: 0.4531 - val_loss: 1.8910\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7763 - loss: 0.6866 - val_accuracy: 0.4531 - val_loss: 1.8950\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7758 - loss: 0.6864 - val_accuracy: 0.4530 - val_loss: 1.8909\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7768 - loss: 0.6863 - val_accuracy: 0.4531 - val_loss: 1.8890\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7781 - loss: 0.6861 - val_accuracy: 0.4531 - val_loss: 1.8891\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6859 - val_accuracy: 0.4531 - val_loss: 1.8886\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6858 - val_accuracy: 0.4531 - val_loss: 1.8893\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7780 - loss: 0.6856 - val_accuracy: 0.4531 - val_loss: 1.8894\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6855 - val_accuracy: 0.4531 - val_loss: 1.8887\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6853 - val_accuracy: 0.4545 - val_loss: 1.8865\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6852 - val_accuracy: 0.4531 - val_loss: 1.8870\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6850 - val_accuracy: 0.4531 - val_loss: 1.8930\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6849 - val_accuracy: 0.4545 - val_loss: 1.8858\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7780 - loss: 0.6847 - val_accuracy: 0.4531 - val_loss: 1.8945\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6846 - val_accuracy: 0.4545 - val_loss: 1.8869\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6844 - val_accuracy: 0.4531 - val_loss: 1.8921\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6843 - val_accuracy: 0.4531 - val_loss: 1.8901\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6841 - val_accuracy: 0.4545 - val_loss: 1.8883\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6840 - val_accuracy: 0.4531 - val_loss: 1.8890\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7779 - loss: 0.6838 - val_accuracy: 0.4548 - val_loss: 1.8919\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6837 - val_accuracy: 0.4546 - val_loss: 1.8884\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6835 - val_accuracy: 0.4546 - val_loss: 1.8904\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6834 - val_accuracy: 0.4548 - val_loss: 1.8887\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6832 - val_accuracy: 0.4547 - val_loss: 1.8877\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6831 - val_accuracy: 0.4531 - val_loss: 1.8917\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6830 - val_accuracy: 0.4547 - val_loss: 1.8887\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6828 - val_accuracy: 0.4547 - val_loss: 1.8897\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6827 - val_accuracy: 0.4532 - val_loss: 1.8927\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6826 - val_accuracy: 0.4546 - val_loss: 1.8931\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6824 - val_accuracy: 0.4547 - val_loss: 1.8875\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6823 - val_accuracy: 0.4546 - val_loss: 1.8911\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6821 - val_accuracy: 0.4546 - val_loss: 1.8880\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7779 - loss: 0.6820 - val_accuracy: 0.4546 - val_loss: 1.8907\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6819 - val_accuracy: 0.4548 - val_loss: 1.8851\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6817 - val_accuracy: 0.4532 - val_loss: 1.8923\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6816 - val_accuracy: 0.4547 - val_loss: 1.8881\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6815 - val_accuracy: 0.4547 - val_loss: 1.8918\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6814 - val_accuracy: 0.4547 - val_loss: 1.8881\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7779 - loss: 0.6812 - val_accuracy: 0.4547 - val_loss: 1.8896\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6811 - val_accuracy: 0.4547 - val_loss: 1.8917\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6810 - val_accuracy: 0.4547 - val_loss: 1.8893\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7779 - loss: 0.6808 - val_accuracy: 0.4547 - val_loss: 1.8899\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6807 - val_accuracy: 0.4546 - val_loss: 1.8896\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6806 - val_accuracy: 0.4547 - val_loss: 1.8907\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7779 - loss: 0.6805 - val_accuracy: 0.4547 - val_loss: 1.8962\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6803 - val_accuracy: 0.4567 - val_loss: 1.8923\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6802 - val_accuracy: 0.4567 - val_loss: 1.8930\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6801 - val_accuracy: 0.4567 - val_loss: 1.8924\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6800 - val_accuracy: 0.4573 - val_loss: 1.8911\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6799 - val_accuracy: 0.4572 - val_loss: 1.8922\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6797 - val_accuracy: 0.4572 - val_loss: 1.8887\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6796 - val_accuracy: 0.4573 - val_loss: 1.8900\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6795 - val_accuracy: 0.4573 - val_loss: 1.8920\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6794 - val_accuracy: 0.4573 - val_loss: 1.8933\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6793 - val_accuracy: 0.4559 - val_loss: 1.8921\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6791 - val_accuracy: 0.4572 - val_loss: 1.8953\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6790 - val_accuracy: 0.4572 - val_loss: 1.8931\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6789 - val_accuracy: 0.4572 - val_loss: 1.8957\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6788 - val_accuracy: 0.4558 - val_loss: 1.8982\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6787 - val_accuracy: 0.4572 - val_loss: 1.8945\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6786 - val_accuracy: 0.4572 - val_loss: 1.8899\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6784 - val_accuracy: 0.4572 - val_loss: 1.8938\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6783 - val_accuracy: 0.4572 - val_loss: 1.8966\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7779 - loss: 0.6782 - val_accuracy: 0.4572 - val_loss: 1.8941\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.6781 - val_accuracy: 0.4572 - val_loss: 1.8950\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6780 - val_accuracy: 0.4572 - val_loss: 1.8937\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.6779 - val_accuracy: 0.4576 - val_loss: 1.8937\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7781 - loss: 0.6778 - val_accuracy: 0.4576 - val_loss: 1.8927\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7783 - loss: 0.6777 - val_accuracy: 0.4576 - val_loss: 1.8909\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7782 - loss: 0.6776 - val_accuracy: 0.4576 - val_loss: 1.8962\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6774 - val_accuracy: 0.4576 - val_loss: 1.8944\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6773 - val_accuracy: 0.4576 - val_loss: 1.8952\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6772 - val_accuracy: 0.4576 - val_loss: 1.8948\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6771 - val_accuracy: 0.4576 - val_loss: 1.8942\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6770 - val_accuracy: 0.4575 - val_loss: 1.8966\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7782 - loss: 0.6769 - val_accuracy: 0.4575 - val_loss: 1.8945\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7784 - loss: 0.6768 - val_accuracy: 0.4576 - val_loss: 1.8961\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7784 - loss: 0.6767 - val_accuracy: 0.4575 - val_loss: 1.8939\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6766 - val_accuracy: 0.4561 - val_loss: 1.8950\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6765 - val_accuracy: 0.4576 - val_loss: 1.8940\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7787 - loss: 0.6764 - val_accuracy: 0.4575 - val_loss: 1.8962\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6763 - val_accuracy: 0.4575 - val_loss: 1.8998\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7785 - loss: 0.6762 - val_accuracy: 0.4575 - val_loss: 1.8950\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7784 - loss: 0.6761 - val_accuracy: 0.4575 - val_loss: 1.8982\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6760 - val_accuracy: 0.4576 - val_loss: 1.8979\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7783 - loss: 0.6759 - val_accuracy: 0.4576 - val_loss: 1.8974\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7782 - loss: 0.6757 - val_accuracy: 0.4561 - val_loss: 1.8992\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7784 - loss: 0.6756 - val_accuracy: 0.4577 - val_loss: 1.8993\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7789 - loss: 0.6755 - val_accuracy: 0.4576 - val_loss: 1.8952\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7785 - loss: 0.6754 - val_accuracy: 0.4576 - val_loss: 1.8981\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7789 - loss: 0.6753 - val_accuracy: 0.4574 - val_loss: 1.9000\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7788 - loss: 0.6752 - val_accuracy: 0.4575 - val_loss: 1.8994\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7785 - loss: 0.6751 - val_accuracy: 0.4565 - val_loss: 1.8983\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7790 - loss: 0.6750 - val_accuracy: 0.4576 - val_loss: 1.8949\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.52999\n636/636 - 6s - 9ms/step - accuracy: 0.7794 - loss: 0.6749 - val_accuracy: 0.4565 - val_loss: 1.8996\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7784 - loss: 0.6748 - val_accuracy: 0.4569 - val_loss: 1.8981\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7795 - loss: 0.6747 - val_accuracy: 0.4569 - val_loss: 1.8986\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7804 - loss: 0.6747 - val_accuracy: 0.4571 - val_loss: 1.8951\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7802 - loss: 0.6746 - val_accuracy: 0.4569 - val_loss: 1.8966\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7807 - loss: 0.6745 - val_accuracy: 0.4569 - val_loss: 1.8973\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7813 - loss: 0.6744 - val_accuracy: 0.4569 - val_loss: 1.8980\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7814 - loss: 0.6743 - val_accuracy: 0.4568 - val_loss: 1.9019\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7818 - loss: 0.6742 - val_accuracy: 0.4570 - val_loss: 1.8929\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7820 - loss: 0.6741 - val_accuracy: 0.4568 - val_loss: 1.8994\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7816 - loss: 0.6740 - val_accuracy: 0.4569 - val_loss: 1.8987\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7819 - loss: 0.6739 - val_accuracy: 0.4568 - val_loss: 1.9030\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.52999\n636/636 - 5s - 9ms/step - accuracy: 0.7827 - loss: 0.6738 - val_accuracy: 0.4571 - val_loss: 1.8971\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7838 - loss: 0.6737 - val_accuracy: 0.4570 - val_loss: 1.9020\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7834 - loss: 0.6736 - val_accuracy: 0.4570 - val_loss: 1.9040\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.52999\n636/636 - 5s - 8ms/step - accuracy: 0.7845 - loss: 0.6735 - val_accuracy: 0.4556 - val_loss: 1.9039\nEpoch 231/500\n\nEpoch 231: val_accuracy improved from 0.52999 to 0.56384, saving model to /kaggle/working/checkpoint_model_lstm.keras\n636/636 - 5s - 8ms/step - accuracy: 0.7839 - loss: 0.6734 - val_accuracy: 0.5638 - val_loss: 1.8973\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.56384\n636/636 - 5s - 8ms/step - accuracy: 0.7855 - loss: 0.6733 - val_accuracy: 0.4556 - val_loss: 1.9030\nEpoch 233/500\n\nEpoch 233: val_accuracy improved from 0.56384 to 0.56400, saving model to /kaggle/working/checkpoint_model_lstm.keras\n636/636 - 5s - 8ms/step - accuracy: 0.7848 - loss: 0.6732 - val_accuracy: 0.5640 - val_loss: 1.9000\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7849 - loss: 0.6731 - val_accuracy: 0.5624 - val_loss: 1.9004\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7860 - loss: 0.6730 - val_accuracy: 0.5640 - val_loss: 1.9001\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7870 - loss: 0.6730 - val_accuracy: 0.4556 - val_loss: 1.9030\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7856 - loss: 0.6729 - val_accuracy: 0.5640 - val_loss: 1.8998\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7866 - loss: 0.6728 - val_accuracy: 0.5640 - val_loss: 1.9015\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7875 - loss: 0.6727 - val_accuracy: 0.5638 - val_loss: 1.9000\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.56400\n636/636 - 6s - 9ms/step - accuracy: 0.7868 - loss: 0.6726 - val_accuracy: 0.5626 - val_loss: 1.9055\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7880 - loss: 0.6725 - val_accuracy: 0.5629 - val_loss: 1.9034\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7867 - loss: 0.6724 - val_accuracy: 0.5640 - val_loss: 1.9010\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7879 - loss: 0.6723 - val_accuracy: 0.5640 - val_loss: 1.8995\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7883 - loss: 0.6722 - val_accuracy: 0.5639 - val_loss: 1.9008\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6721 - val_accuracy: 0.5639 - val_loss: 1.9013\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.56400\n636/636 - 6s - 9ms/step - accuracy: 0.7888 - loss: 0.6721 - val_accuracy: 0.5623 - val_loss: 1.9030\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7887 - loss: 0.6720 - val_accuracy: 0.5625 - val_loss: 1.9022\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6719 - val_accuracy: 0.5625 - val_loss: 1.9060\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.56400\n636/636 - 5s - 8ms/step - accuracy: 0.7888 - loss: 0.6718 - val_accuracy: 0.5639 - val_loss: 1.9043\nEpoch 250/500\n\nEpoch 250: val_accuracy improved from 0.56400 to 0.56420, saving model to /kaggle/working/checkpoint_model_lstm.keras\n636/636 - 5s - 8ms/step - accuracy: 0.7888 - loss: 0.6717 - val_accuracy: 0.5642 - val_loss: 1.9002\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6716 - val_accuracy: 0.5642 - val_loss: 1.9023\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.56420\n636/636 - 6s - 9ms/step - accuracy: 0.7885 - loss: 0.6715 - val_accuracy: 0.5623 - val_loss: 1.9071\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6714 - val_accuracy: 0.5624 - val_loss: 1.9066\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6714 - val_accuracy: 0.5638 - val_loss: 1.9039\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6713 - val_accuracy: 0.5625 - val_loss: 1.9015\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6712 - val_accuracy: 0.5639 - val_loss: 1.9019\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7887 - loss: 0.6711 - val_accuracy: 0.5637 - val_loss: 1.9051\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6710 - val_accuracy: 0.5640 - val_loss: 1.9049\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6709 - val_accuracy: 0.5623 - val_loss: 1.9064\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6708 - val_accuracy: 0.5624 - val_loss: 1.9043\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6707 - val_accuracy: 0.5626 - val_loss: 1.9043\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6707 - val_accuracy: 0.5615 - val_loss: 1.9061\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6706 - val_accuracy: 0.5615 - val_loss: 1.9064\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6705 - val_accuracy: 0.5612 - val_loss: 1.9106\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.56420\n636/636 - 6s - 9ms/step - accuracy: 0.7889 - loss: 0.6704 - val_accuracy: 0.5615 - val_loss: 1.9073\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6703 - val_accuracy: 0.5612 - val_loss: 1.9108\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6702 - val_accuracy: 0.5615 - val_loss: 1.9064\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6702 - val_accuracy: 0.5615 - val_loss: 1.9062\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6701 - val_accuracy: 0.5615 - val_loss: 1.9131\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6700 - val_accuracy: 0.5612 - val_loss: 1.9070\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6699 - val_accuracy: 0.5612 - val_loss: 1.9097\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6698 - val_accuracy: 0.5629 - val_loss: 1.9055\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6697 - val_accuracy: 0.5612 - val_loss: 1.9090\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6697 - val_accuracy: 0.5612 - val_loss: 1.9099\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6696 - val_accuracy: 0.5612 - val_loss: 1.9091\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6695 - val_accuracy: 0.5612 - val_loss: 1.9119\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.56420\n636/636 - 6s - 9ms/step - accuracy: 0.7889 - loss: 0.6694 - val_accuracy: 0.5613 - val_loss: 1.9086\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6693 - val_accuracy: 0.5613 - val_loss: 1.9062\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6693 - val_accuracy: 0.5612 - val_loss: 1.9121\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6692 - val_accuracy: 0.5616 - val_loss: 1.9113\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6691 - val_accuracy: 0.5617 - val_loss: 1.9067\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6690 - val_accuracy: 0.5613 - val_loss: 1.9119\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6689 - val_accuracy: 0.5616 - val_loss: 1.9116\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6689 - val_accuracy: 0.5616 - val_loss: 1.9100\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6688 - val_accuracy: 0.5616 - val_loss: 1.9102\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6687 - val_accuracy: 0.5616 - val_loss: 1.9081\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6686 - val_accuracy: 0.5613 - val_loss: 1.9100\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6685 - val_accuracy: 0.5613 - val_loss: 1.9135\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6685 - val_accuracy: 0.5613 - val_loss: 1.9086\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6684 - val_accuracy: 0.5616 - val_loss: 1.9107\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6683 - val_accuracy: 0.5613 - val_loss: 1.9159\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6682 - val_accuracy: 0.5616 - val_loss: 1.9115\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6682 - val_accuracy: 0.5616 - val_loss: 1.9150\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6681 - val_accuracy: 0.5616 - val_loss: 1.9148\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6680 - val_accuracy: 0.5616 - val_loss: 1.9126\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.56420\n636/636 - 6s - 9ms/step - accuracy: 0.7889 - loss: 0.6679 - val_accuracy: 0.5616 - val_loss: 1.9070\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6678 - val_accuracy: 0.5616 - val_loss: 1.9154\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6678 - val_accuracy: 0.5616 - val_loss: 1.9111\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6677 - val_accuracy: 0.5613 - val_loss: 1.9135\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6676 - val_accuracy: 0.5613 - val_loss: 1.9147\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6675 - val_accuracy: 0.5616 - val_loss: 1.9128\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6675 - val_accuracy: 0.5616 - val_loss: 1.9119\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6674 - val_accuracy: 0.5616 - val_loss: 1.9097\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6673 - val_accuracy: 0.5613 - val_loss: 1.9162\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6672 - val_accuracy: 0.5613 - val_loss: 1.9131\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6672 - val_accuracy: 0.5616 - val_loss: 1.9125\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6671 - val_accuracy: 0.5613 - val_loss: 1.9146\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6670 - val_accuracy: 0.5616 - val_loss: 1.9122\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6669 - val_accuracy: 0.5616 - val_loss: 1.9120\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6669 - val_accuracy: 0.5613 - val_loss: 1.9143\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6668 - val_accuracy: 0.5616 - val_loss: 1.9153\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6667 - val_accuracy: 0.5613 - val_loss: 1.9148\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6666 - val_accuracy: 0.5617 - val_loss: 1.9101\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6666 - val_accuracy: 0.5613 - val_loss: 1.9176\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6665 - val_accuracy: 0.5616 - val_loss: 1.9155\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6664 - val_accuracy: 0.5616 - val_loss: 1.9134\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6663 - val_accuracy: 0.5613 - val_loss: 1.9154\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6663 - val_accuracy: 0.5616 - val_loss: 1.9193\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6662 - val_accuracy: 0.5616 - val_loss: 1.9152\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6661 - val_accuracy: 0.5613 - val_loss: 1.9185\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6661 - val_accuracy: 0.5616 - val_loss: 1.9166\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6660 - val_accuracy: 0.5613 - val_loss: 1.9184\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6659 - val_accuracy: 0.5616 - val_loss: 1.9173\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6658 - val_accuracy: 0.5618 - val_loss: 1.9153\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6658 - val_accuracy: 0.5618 - val_loss: 1.9147\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6657 - val_accuracy: 0.5615 - val_loss: 1.9183\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6656 - val_accuracy: 0.5618 - val_loss: 1.9201\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6656 - val_accuracy: 0.5615 - val_loss: 1.9208\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6655 - val_accuracy: 0.5618 - val_loss: 1.9156\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6654 - val_accuracy: 0.5615 - val_loss: 1.9244\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6653 - val_accuracy: 0.5615 - val_loss: 1.9183\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6653 - val_accuracy: 0.5618 - val_loss: 1.9213\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6652 - val_accuracy: 0.5618 - val_loss: 1.9171\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7889 - loss: 0.6651 - val_accuracy: 0.5618 - val_loss: 1.9189\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6651 - val_accuracy: 0.5618 - val_loss: 1.9203\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6650 - val_accuracy: 0.5618 - val_loss: 1.9181\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6649 - val_accuracy: 0.5615 - val_loss: 1.9242\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6649 - val_accuracy: 0.5618 - val_loss: 1.9214\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6648 - val_accuracy: 0.5618 - val_loss: 1.9176\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.56420\n636/636 - 6s - 9ms/step - accuracy: 0.7889 - loss: 0.6647 - val_accuracy: 0.5619 - val_loss: 1.9193\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6646 - val_accuracy: 0.5619 - val_loss: 1.9194\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6646 - val_accuracy: 0.5619 - val_loss: 1.9197\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7889 - loss: 0.6645 - val_accuracy: 0.5619 - val_loss: 1.9203\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7890 - loss: 0.6644 - val_accuracy: 0.5619 - val_loss: 1.9217\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7890 - loss: 0.6644 - val_accuracy: 0.5619 - val_loss: 1.9234\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.56420\n636/636 - 6s - 9ms/step - accuracy: 0.7891 - loss: 0.6643 - val_accuracy: 0.5617 - val_loss: 1.9218\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6642 - val_accuracy: 0.5617 - val_loss: 1.9250\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7892 - loss: 0.6642 - val_accuracy: 0.5617 - val_loss: 1.9220\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6641 - val_accuracy: 0.5620 - val_loss: 1.9242\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6640 - val_accuracy: 0.5620 - val_loss: 1.9195\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6640 - val_accuracy: 0.5620 - val_loss: 1.9204\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7893 - loss: 0.6639 - val_accuracy: 0.5616 - val_loss: 1.9237\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6638 - val_accuracy: 0.5616 - val_loss: 1.9243\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6638 - val_accuracy: 0.5620 - val_loss: 1.9209\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6637 - val_accuracy: 0.5620 - val_loss: 1.9193\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6636 - val_accuracy: 0.5620 - val_loss: 1.9192\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6635 - val_accuracy: 0.5620 - val_loss: 1.9224\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6635 - val_accuracy: 0.5616 - val_loss: 1.9267\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6634 - val_accuracy: 0.5620 - val_loss: 1.9237\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6633 - val_accuracy: 0.5620 - val_loss: 1.9220\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6633 - val_accuracy: 0.5620 - val_loss: 1.9230\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6632 - val_accuracy: 0.5616 - val_loss: 1.9253\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6632 - val_accuracy: 0.5620 - val_loss: 1.9219\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6631 - val_accuracy: 0.5620 - val_loss: 1.9258\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7894 - loss: 0.6630 - val_accuracy: 0.5620 - val_loss: 1.9238\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6630 - val_accuracy: 0.5620 - val_loss: 1.9258\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6629 - val_accuracy: 0.5620 - val_loss: 1.9256\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6628 - val_accuracy: 0.5620 - val_loss: 1.9258\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7893 - loss: 0.6628 - val_accuracy: 0.5620 - val_loss: 1.9221\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7895 - loss: 0.6627 - val_accuracy: 0.5620 - val_loss: 1.9252\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.56420\n636/636 - 5s - 9ms/step - accuracy: 0.7896 - loss: 0.6626 - val_accuracy: 0.5631 - val_loss: 1.9211\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7894 - loss: 0.6626 - val_accuracy: 0.5631 - val_loss: 1.9222\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7896 - loss: 0.6625 - val_accuracy: 0.5620 - val_loss: 1.9263\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7896 - loss: 0.6624 - val_accuracy: 0.5620 - val_loss: 1.9257\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6624 - val_accuracy: 0.5620 - val_loss: 1.9244\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6623 - val_accuracy: 0.5620 - val_loss: 1.9311\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.56420\n636/636 - 5s - 8ms/step - accuracy: 0.7898 - loss: 0.6622 - val_accuracy: 0.5620 - val_loss: 1.9280\nEpoch 378/500\n\nEpoch 378: val_accuracy improved from 0.56420 to 0.56601, saving model to /kaggle/working/checkpoint_model_lstm.keras\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6622 - val_accuracy: 0.5660 - val_loss: 1.9251\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6621 - val_accuracy: 0.5660 - val_loss: 1.9262\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6620 - val_accuracy: 0.5660 - val_loss: 1.9241\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6620 - val_accuracy: 0.5649 - val_loss: 1.9286\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6619 - val_accuracy: 0.5660 - val_loss: 1.9258\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6619 - val_accuracy: 0.5660 - val_loss: 1.9293\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.56601\n636/636 - 5s - 9ms/step - accuracy: 0.7897 - loss: 0.6618 - val_accuracy: 0.5660 - val_loss: 1.9276\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6617 - val_accuracy: 0.5649 - val_loss: 1.9322\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6617 - val_accuracy: 0.5660 - val_loss: 1.9274\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6616 - val_accuracy: 0.5660 - val_loss: 1.9274\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6615 - val_accuracy: 0.5660 - val_loss: 1.9276\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6615 - val_accuracy: 0.5660 - val_loss: 1.9285\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.56601\n636/636 - 6s - 9ms/step - accuracy: 0.7897 - loss: 0.6614 - val_accuracy: 0.5660 - val_loss: 1.9296\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6613 - val_accuracy: 0.5660 - val_loss: 1.9245\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6613 - val_accuracy: 0.5660 - val_loss: 1.9301\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6612 - val_accuracy: 0.5660 - val_loss: 1.9334\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6612 - val_accuracy: 0.5657 - val_loss: 1.9335\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7899 - loss: 0.6611 - val_accuracy: 0.5649 - val_loss: 1.9317\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.56601\n636/636 - 6s - 9ms/step - accuracy: 0.7897 - loss: 0.6610 - val_accuracy: 0.5660 - val_loss: 1.9302\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.6610 - val_accuracy: 0.5660 - val_loss: 1.9285\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7899 - loss: 0.6609 - val_accuracy: 0.5660 - val_loss: 1.9306\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7899 - loss: 0.6608 - val_accuracy: 0.5660 - val_loss: 1.9304\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7898 - loss: 0.6608 - val_accuracy: 0.5660 - val_loss: 1.9286\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7911 - loss: 0.6607 - val_accuracy: 0.5660 - val_loss: 1.9321\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7903 - loss: 0.6607 - val_accuracy: 0.5660 - val_loss: 1.9305\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7906 - loss: 0.6606 - val_accuracy: 0.5660 - val_loss: 1.9344\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6605 - val_accuracy: 0.5660 - val_loss: 1.9338\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6605 - val_accuracy: 0.5660 - val_loss: 1.9326\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6604 - val_accuracy: 0.5660 - val_loss: 1.9298\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6604 - val_accuracy: 0.5660 - val_loss: 1.9318\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6603 - val_accuracy: 0.5660 - val_loss: 1.9329\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6602 - val_accuracy: 0.5660 - val_loss: 1.9352\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6602 - val_accuracy: 0.5657 - val_loss: 1.9365\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6601 - val_accuracy: 0.5660 - val_loss: 1.9301\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6601 - val_accuracy: 0.5658 - val_loss: 1.9363\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7919 - loss: 0.6600 - val_accuracy: 0.5660 - val_loss: 1.9324\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6599 - val_accuracy: 0.5660 - val_loss: 1.9312\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.56601\n636/636 - 6s - 9ms/step - accuracy: 0.7912 - loss: 0.6599 - val_accuracy: 0.5660 - val_loss: 1.9331\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6598 - val_accuracy: 0.5660 - val_loss: 1.9349\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6598 - val_accuracy: 0.5658 - val_loss: 1.9362\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6597 - val_accuracy: 0.5660 - val_loss: 1.9340\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6596 - val_accuracy: 0.5658 - val_loss: 1.9369\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6596 - val_accuracy: 0.5660 - val_loss: 1.9334\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.56601\n636/636 - 6s - 9ms/step - accuracy: 0.7912 - loss: 0.6595 - val_accuracy: 0.5660 - val_loss: 1.9322\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6595 - val_accuracy: 0.5658 - val_loss: 1.9317\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6594 - val_accuracy: 0.5658 - val_loss: 1.9329\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6593 - val_accuracy: 0.5658 - val_loss: 1.9356\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6593 - val_accuracy: 0.5655 - val_loss: 1.9401\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6592 - val_accuracy: 0.5658 - val_loss: 1.9353\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.56601\n636/636 - 5s - 9ms/step - accuracy: 0.7917 - loss: 0.6592 - val_accuracy: 0.5658 - val_loss: 1.9342\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6591 - val_accuracy: 0.5658 - val_loss: 1.9343\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6590 - val_accuracy: 0.5658 - val_loss: 1.9335\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6590 - val_accuracy: 0.5658 - val_loss: 1.9353\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6589 - val_accuracy: 0.5658 - val_loss: 1.9362\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6589 - val_accuracy: 0.5658 - val_loss: 1.9372\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6588 - val_accuracy: 0.5658 - val_loss: 1.9407\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6588 - val_accuracy: 0.5658 - val_loss: 1.9353\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6587 - val_accuracy: 0.5658 - val_loss: 1.9370\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7917 - loss: 0.6586 - val_accuracy: 0.5658 - val_loss: 1.9381\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6586 - val_accuracy: 0.5658 - val_loss: 1.9390\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6585 - val_accuracy: 0.5658 - val_loss: 1.9369\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6585 - val_accuracy: 0.5658 - val_loss: 1.9396\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.56601\n636/636 - 5s - 9ms/step - accuracy: 0.7912 - loss: 0.6584 - val_accuracy: 0.5658 - val_loss: 1.9410\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6583 - val_accuracy: 0.5658 - val_loss: 1.9405\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6583 - val_accuracy: 0.5658 - val_loss: 1.9375\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6582 - val_accuracy: 0.5658 - val_loss: 1.9388\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6582 - val_accuracy: 0.5658 - val_loss: 1.9393\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6581 - val_accuracy: 0.5658 - val_loss: 1.9423\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.56601\n636/636 - 5s - 9ms/step - accuracy: 0.7912 - loss: 0.6581 - val_accuracy: 0.5658 - val_loss: 1.9363\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6580 - val_accuracy: 0.5658 - val_loss: 1.9382\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6579 - val_accuracy: 0.5658 - val_loss: 1.9406\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6579 - val_accuracy: 0.5658 - val_loss: 1.9437\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6578 - val_accuracy: 0.5658 - val_loss: 1.9389\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6578 - val_accuracy: 0.5656 - val_loss: 1.9459\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7917 - loss: 0.6577 - val_accuracy: 0.5658 - val_loss: 1.9395\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6577 - val_accuracy: 0.5658 - val_loss: 1.9405\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6576 - val_accuracy: 0.5658 - val_loss: 1.9411\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7917 - loss: 0.6575 - val_accuracy: 0.5660 - val_loss: 1.9399\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6575 - val_accuracy: 0.5658 - val_loss: 1.9432\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6574 - val_accuracy: 0.5658 - val_loss: 1.9404\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7923 - loss: 0.6574 - val_accuracy: 0.5658 - val_loss: 1.9440\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6573 - val_accuracy: 0.5658 - val_loss: 1.9417\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6573 - val_accuracy: 0.5659 - val_loss: 1.9332\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6572 - val_accuracy: 0.5658 - val_loss: 1.9416\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7912 - loss: 0.6571 - val_accuracy: 0.5658 - val_loss: 1.9416\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6571 - val_accuracy: 0.5659 - val_loss: 1.9430\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6570 - val_accuracy: 0.5658 - val_loss: 1.9426\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.56601\n636/636 - 5s - 9ms/step - accuracy: 0.7915 - loss: 0.6570 - val_accuracy: 0.5658 - val_loss: 1.9433\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6569 - val_accuracy: 0.5658 - val_loss: 1.9433\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6569 - val_accuracy: 0.5658 - val_loss: 1.9431\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7917 - loss: 0.6568 - val_accuracy: 0.5658 - val_loss: 1.9466\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6568 - val_accuracy: 0.5658 - val_loss: 1.9440\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6567 - val_accuracy: 0.5659 - val_loss: 1.9428\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6567 - val_accuracy: 0.5657 - val_loss: 1.9460\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6566 - val_accuracy: 0.5658 - val_loss: 1.9450\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6565 - val_accuracy: 0.5657 - val_loss: 1.9451\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6565 - val_accuracy: 0.5659 - val_loss: 1.9420\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6564 - val_accuracy: 0.5657 - val_loss: 1.9425\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7920 - loss: 0.6564 - val_accuracy: 0.5657 - val_loss: 1.9456\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.56601\n636/636 - 5s - 9ms/step - accuracy: 0.7916 - loss: 0.6563 - val_accuracy: 0.5656 - val_loss: 1.9478\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7917 - loss: 0.6563 - val_accuracy: 0.5657 - val_loss: 1.9421\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6562 - val_accuracy: 0.5653 - val_loss: 1.9494\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7915 - loss: 0.6562 - val_accuracy: 0.5654 - val_loss: 1.9461\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6561 - val_accuracy: 0.5657 - val_loss: 1.9466\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.56601\n636/636 - 5s - 8ms/step - accuracy: 0.7917 - loss: 0.6561 - val_accuracy: 0.5657 - val_loss: 1.9435\nEpoch 483/500\n\nEpoch 483: val_accuracy improved from 0.56601 to 0.56614, saving model to /kaggle/working/checkpoint_model_lstm.keras\n636/636 - 6s - 9ms/step - accuracy: 0.7914 - loss: 0.6560 - val_accuracy: 0.5661 - val_loss: 1.9473\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.56614\n636/636 - 5s - 8ms/step - accuracy: 0.7913 - loss: 0.6559 - val_accuracy: 0.5661 - val_loss: 1.9494\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.56614\n636/636 - 5s - 8ms/step - accuracy: 0.7919 - loss: 0.6559 - val_accuracy: 0.5661 - val_loss: 1.9511\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.56614\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6558 - val_accuracy: 0.5661 - val_loss: 1.9484\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.56614\n636/636 - 5s - 8ms/step - accuracy: 0.7921 - loss: 0.6558 - val_accuracy: 0.5658 - val_loss: 1.9525\nEpoch 488/500\n\nEpoch 488: val_accuracy improved from 0.56614 to 0.56628, saving model to /kaggle/working/checkpoint_model_lstm.keras\n636/636 - 5s - 8ms/step - accuracy: 0.7922 - loss: 0.6557 - val_accuracy: 0.5663 - val_loss: 1.9488\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7925 - loss: 0.6557 - val_accuracy: 0.5661 - val_loss: 1.9485\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7919 - loss: 0.6556 - val_accuracy: 0.5663 - val_loss: 1.9471\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7916 - loss: 0.6556 - val_accuracy: 0.5661 - val_loss: 1.9501\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6555 - val_accuracy: 0.5663 - val_loss: 1.9463\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7919 - loss: 0.6555 - val_accuracy: 0.5661 - val_loss: 1.9463\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7918 - loss: 0.6554 - val_accuracy: 0.5661 - val_loss: 1.9481\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7920 - loss: 0.6554 - val_accuracy: 0.5661 - val_loss: 1.9481\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.56628\n636/636 - 5s - 9ms/step - accuracy: 0.7923 - loss: 0.6553 - val_accuracy: 0.5661 - val_loss: 1.9463\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7920 - loss: 0.6553 - val_accuracy: 0.5661 - val_loss: 1.9448\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7914 - loss: 0.6552 - val_accuracy: 0.5661 - val_loss: 1.9492\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7925 - loss: 0.6551 - val_accuracy: 0.5661 - val_loss: 1.9483\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.56628\n636/636 - 5s - 8ms/step - accuracy: 0.7918 - loss: 0.6551 - val_accuracy: 0.5661 - val_loss: 1.9549\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(\n    X, y, test_size=0.3, random_state=46, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_4, X_val_4, y_train_4, y_val_4 = train_test_split(\n    X_train_4, y_train_4, test_size=0.2, random_state=46, stratify=y_train_4\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_4:\", np.max(X_train_4))\nprint(\"Min value in X_train_4:\", np.min(X_train_4))\n\nX_train_4_scaled = scaler.fit_transform(X_train_4)\n\n# Get the original class distribution\nclass_counts_4 = Counter(y_train_4)\nprint(\"Original class distribution:\", class_counts_4)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_4 = class_counts_4[min(class_counts_4, key=class_counts_4.get)]\ndesired_majority_size_4 = minority_class_size_4 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_4 = {0: desired_majority_size_4, 1: minority_class_size_4}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_4 = RandomUnderSampler(sampling_strategy=sampling_strategy_4, random_state=42)\nX_resampled_4, y_resampled_4 = undersampler_4.fit_resample(X_train_4, y_train_4)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_4))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_4, y_train_resampled_4 = smote.fit_resample(X_resampled_4, y_resampled_4)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_4))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_4))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:09:33.019757Z","iopub.execute_input":"2025-03-06T19:09:33.020093Z","iopub.status.idle":"2025-03-06T19:10:07.932158Z","shell.execute_reply.started":"2025-03-06T19:09:33.020066Z","shell.execute_reply":"2025-03-06T19:10:07.931110Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_4: 2071000000.0\nMin value in X_train_4: -9663668122.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_4 = X_train_resampled_4.reshape(X_train_resampled_4.shape[0], 1, 56)\nX_val_4 = X_val_4.reshape(X_val_4.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_4,  # Features from CICIDS2017\n    y_train_resampled_4,  # Labels from CICIDS2017\n    validation_data=(X_val_4, y_val_4),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:10:07.934129Z","iopub.execute_input":"2025-03-06T19:10:07.934508Z","iopub.status.idle":"2025-03-06T19:54:11.278129Z","shell.execute_reply.started":"2025-03-06T19:10:07.934476Z","shell.execute_reply":"2025-03-06T19:54:11.276939Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.56628\n726/726 - 6s - 8ms/step - accuracy: 0.7666 - loss: 0.9158 - val_accuracy: 0.5632 - val_loss: 1.9271\nEpoch 2/500\n\nEpoch 2: val_accuracy improved from 0.56628 to 0.58655, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.8429 - val_accuracy: 0.5865 - val_loss: 1.9179\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.58655\n726/726 - 5s - 8ms/step - accuracy: 0.7665 - loss: 0.8183 - val_accuracy: 0.5848 - val_loss: 1.9159\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.8115 - val_accuracy: 0.5746 - val_loss: 1.9194\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7626 - loss: 0.8093 - val_accuracy: 0.5721 - val_loss: 1.9213\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.8080 - val_accuracy: 0.5720 - val_loss: 1.9252\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.8069 - val_accuracy: 0.5718 - val_loss: 1.9238\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.8059 - val_accuracy: 0.5727 - val_loss: 1.9223\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.8050 - val_accuracy: 0.5727 - val_loss: 1.9262\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.8042 - val_accuracy: 0.5841 - val_loss: 1.9254\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.8034 - val_accuracy: 0.5841 - val_loss: 1.9243\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.8027 - val_accuracy: 0.5841 - val_loss: 1.9247\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.8020 - val_accuracy: 0.5839 - val_loss: 1.9274\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.58655\n726/726 - 6s - 8ms/step - accuracy: 0.7663 - loss: 0.8013 - val_accuracy: 0.5841 - val_loss: 1.9256\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.8007 - val_accuracy: 0.5841 - val_loss: 1.9193\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.8001 - val_accuracy: 0.5841 - val_loss: 1.9217\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7995 - val_accuracy: 0.5842 - val_loss: 1.9208\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7989 - val_accuracy: 0.5842 - val_loss: 1.9214\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7984 - val_accuracy: 0.5842 - val_loss: 1.9208\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.58655\n726/726 - 6s - 8ms/step - accuracy: 0.7667 - loss: 0.7979 - val_accuracy: 0.5842 - val_loss: 1.9199\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7974 - val_accuracy: 0.5842 - val_loss: 1.9166\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7969 - val_accuracy: 0.5854 - val_loss: 1.9166\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.58655\n726/726 - 5s - 8ms/step - accuracy: 0.7663 - loss: 0.7965 - val_accuracy: 0.5854 - val_loss: 1.9172\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7960 - val_accuracy: 0.5854 - val_loss: 1.9122\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.58655\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7956 - val_accuracy: 0.5854 - val_loss: 1.9150\nEpoch 26/500\n\nEpoch 26: val_accuracy improved from 0.58655 to 0.58708, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7663 - loss: 0.7952 - val_accuracy: 0.5871 - val_loss: 1.9122\nEpoch 27/500\n\nEpoch 27: val_accuracy improved from 0.58708 to 0.58710, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7947 - val_accuracy: 0.5871 - val_loss: 1.9050\nEpoch 28/500\n\nEpoch 28: val_accuracy improved from 0.58710 to 0.58712, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7943 - val_accuracy: 0.5871 - val_loss: 1.9098\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.58712\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7939 - val_accuracy: 0.5871 - val_loss: 1.9035\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.58712\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.7935 - val_accuracy: 0.5871 - val_loss: 1.9040\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.58712\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.7932 - val_accuracy: 0.5871 - val_loss: 1.9027\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.58712\n726/726 - 6s - 8ms/step - accuracy: 0.7663 - loss: 0.7928 - val_accuracy: 0.5871 - val_loss: 1.9033\nEpoch 33/500\n\nEpoch 33: val_accuracy improved from 0.58712 to 0.58723, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7924 - val_accuracy: 0.5872 - val_loss: 1.8988\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7921 - val_accuracy: 0.5869 - val_loss: 1.9039\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7917 - val_accuracy: 0.5869 - val_loss: 1.9019\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7914 - val_accuracy: 0.5869 - val_loss: 1.8958\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7910 - val_accuracy: 0.5869 - val_loss: 1.8976\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.58723\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7907 - val_accuracy: 0.5869 - val_loss: 1.8976\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7904 - val_accuracy: 0.5868 - val_loss: 1.8949\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.58723\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7900 - val_accuracy: 0.5868 - val_loss: 1.8947\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7897 - val_accuracy: 0.5867 - val_loss: 1.8953\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7626 - loss: 0.7894 - val_accuracy: 0.5867 - val_loss: 1.8919\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7891 - val_accuracy: 0.5866 - val_loss: 1.8920\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.58723\n726/726 - 6s - 8ms/step - accuracy: 0.7626 - loss: 0.7888 - val_accuracy: 0.5866 - val_loss: 1.8899\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7885 - val_accuracy: 0.5867 - val_loss: 1.8888\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7882 - val_accuracy: 0.5867 - val_loss: 1.8881\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7879 - val_accuracy: 0.5868 - val_loss: 1.8856\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7876 - val_accuracy: 0.5866 - val_loss: 1.8854\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7873 - val_accuracy: 0.5867 - val_loss: 1.8845\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.58723\n726/726 - 6s - 8ms/step - accuracy: 0.7626 - loss: 0.7870 - val_accuracy: 0.5867 - val_loss: 1.8840\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7867 - val_accuracy: 0.5869 - val_loss: 1.8817\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7864 - val_accuracy: 0.5867 - val_loss: 1.8841\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7861 - val_accuracy: 0.5867 - val_loss: 1.8839\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7859 - val_accuracy: 0.5869 - val_loss: 1.8816\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7856 - val_accuracy: 0.5869 - val_loss: 1.8810\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.58723\n726/726 - 5s - 8ms/step - accuracy: 0.7620 - loss: 0.7853 - val_accuracy: 0.5867 - val_loss: 1.8810\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7851 - val_accuracy: 0.5869 - val_loss: 1.8807\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.58723\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7848 - val_accuracy: 0.5869 - val_loss: 1.8732\nEpoch 59/500\n\nEpoch 59: val_accuracy improved from 0.58723 to 0.58723, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7845 - val_accuracy: 0.5872 - val_loss: 1.8734\nEpoch 60/500\n\nEpoch 60: val_accuracy improved from 0.58723 to 0.58744, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7843 - val_accuracy: 0.5874 - val_loss: 1.8730\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.58744\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7840 - val_accuracy: 0.5874 - val_loss: 1.8743\nEpoch 62/500\n\nEpoch 62: val_accuracy improved from 0.58744 to 0.58744, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7622 - loss: 0.7838 - val_accuracy: 0.5874 - val_loss: 1.8719\nEpoch 63/500\n\nEpoch 63: val_accuracy improved from 0.58744 to 0.58744, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7835 - val_accuracy: 0.5874 - val_loss: 1.8686\nEpoch 64/500\n\nEpoch 64: val_accuracy improved from 0.58744 to 0.59051, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7833 - val_accuracy: 0.5905 - val_loss: 1.8730\nEpoch 65/500\n\nEpoch 65: val_accuracy improved from 0.59051 to 0.59052, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7830 - val_accuracy: 0.5905 - val_loss: 1.8730\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.59052\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7828 - val_accuracy: 0.5905 - val_loss: 1.8700\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.59052\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7825 - val_accuracy: 0.5905 - val_loss: 1.8678\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.59052\n726/726 - 5s - 8ms/step - accuracy: 0.7636 - loss: 0.7823 - val_accuracy: 0.5905 - val_loss: 1.8669\nEpoch 69/500\n\nEpoch 69: val_accuracy improved from 0.59052 to 0.59063, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7820 - val_accuracy: 0.5906 - val_loss: 1.8682\nEpoch 70/500\n\nEpoch 70: val_accuracy improved from 0.59063 to 0.59063, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7818 - val_accuracy: 0.5906 - val_loss: 1.8675\nEpoch 71/500\n\nEpoch 71: val_accuracy improved from 0.59063 to 0.59064, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7816 - val_accuracy: 0.5906 - val_loss: 1.8643\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.59064\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7813 - val_accuracy: 0.5906 - val_loss: 1.8664\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.59064\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7811 - val_accuracy: 0.5906 - val_loss: 1.8662\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.59064\n726/726 - 6s - 8ms/step - accuracy: 0.7636 - loss: 0.7809 - val_accuracy: 0.5906 - val_loss: 1.8660\nEpoch 75/500\n\nEpoch 75: val_accuracy improved from 0.59064 to 0.59071, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7806 - val_accuracy: 0.5907 - val_loss: 1.8637\nEpoch 76/500\n\nEpoch 76: val_accuracy improved from 0.59071 to 0.59131, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7804 - val_accuracy: 0.5913 - val_loss: 1.8628\nEpoch 77/500\n\nEpoch 77: val_accuracy improved from 0.59131 to 0.59132, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7802 - val_accuracy: 0.5913 - val_loss: 1.8630\nEpoch 78/500\n\nEpoch 78: val_accuracy improved from 0.59132 to 0.59133, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7799 - val_accuracy: 0.5913 - val_loss: 1.8605\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.59133\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7797 - val_accuracy: 0.5912 - val_loss: 1.8629\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.59133\n726/726 - 5s - 8ms/step - accuracy: 0.7636 - loss: 0.7795 - val_accuracy: 0.5913 - val_loss: 1.8568\nEpoch 81/500\n\nEpoch 81: val_accuracy improved from 0.59133 to 0.59135, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7793 - val_accuracy: 0.5914 - val_loss: 1.8539\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.59135\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7791 - val_accuracy: 0.5914 - val_loss: 1.8554\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.59135\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7788 - val_accuracy: 0.5913 - val_loss: 1.8577\nEpoch 84/500\n\nEpoch 84: val_accuracy improved from 0.59135 to 0.59136, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7786 - val_accuracy: 0.5914 - val_loss: 1.8561\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.59136\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7784 - val_accuracy: 0.5913 - val_loss: 1.8566\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.59136\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7782 - val_accuracy: 0.5913 - val_loss: 1.8535\nEpoch 87/500\n\nEpoch 87: val_accuracy improved from 0.59136 to 0.59137, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7780 - val_accuracy: 0.5914 - val_loss: 1.8525\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7778 - val_accuracy: 0.5913 - val_loss: 1.8565\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7776 - val_accuracy: 0.5914 - val_loss: 1.8556\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7774 - val_accuracy: 0.5913 - val_loss: 1.8586\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7771 - val_accuracy: 0.5913 - val_loss: 1.8540\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7769 - val_accuracy: 0.5913 - val_loss: 1.8489\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.59137\n726/726 - 6s - 8ms/step - accuracy: 0.7638 - loss: 0.7767 - val_accuracy: 0.5913 - val_loss: 1.8552\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7765 - val_accuracy: 0.5913 - val_loss: 1.8555\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.59137\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7763 - val_accuracy: 0.5914 - val_loss: 1.8506\nEpoch 96/500\n\nEpoch 96: val_accuracy improved from 0.59137 to 0.59141, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7761 - val_accuracy: 0.5914 - val_loss: 1.8479\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.59141\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7759 - val_accuracy: 0.5914 - val_loss: 1.8506\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.59141\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7757 - val_accuracy: 0.5914 - val_loss: 1.8526\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.59141\n726/726 - 6s - 8ms/step - accuracy: 0.7638 - loss: 0.7755 - val_accuracy: 0.5914 - val_loss: 1.8497\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.59141\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7753 - val_accuracy: 0.5914 - val_loss: 1.8509\nEpoch 101/500\n\nEpoch 101: val_accuracy improved from 0.59141 to 0.59142, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7751 - val_accuracy: 0.5914 - val_loss: 1.8494\nEpoch 102/500\n\nEpoch 102: val_accuracy improved from 0.59142 to 0.59147, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7749 - val_accuracy: 0.5915 - val_loss: 1.8429\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.59147\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7748 - val_accuracy: 0.5914 - val_loss: 1.8481\nEpoch 104/500\n\nEpoch 104: val_accuracy improved from 0.59147 to 0.59148, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7746 - val_accuracy: 0.5915 - val_loss: 1.8439\nEpoch 105/500\n\nEpoch 105: val_accuracy improved from 0.59148 to 0.59149, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7638 - loss: 0.7744 - val_accuracy: 0.5915 - val_loss: 1.8437\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.59149\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7742 - val_accuracy: 0.5915 - val_loss: 1.8420\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.59149\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7740 - val_accuracy: 0.5915 - val_loss: 1.8443\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.59149\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7738 - val_accuracy: 0.5914 - val_loss: 1.8473\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.59149\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7736 - val_accuracy: 0.5915 - val_loss: 1.8396\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.59149\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7734 - val_accuracy: 0.5915 - val_loss: 1.8419\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.59149\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7732 - val_accuracy: 0.5915 - val_loss: 1.8417\nEpoch 112/500\n\nEpoch 112: val_accuracy improved from 0.59149 to 0.59159, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7639 - loss: 0.7731 - val_accuracy: 0.5916 - val_loss: 1.8452\nEpoch 113/500\n\nEpoch 113: val_accuracy improved from 0.59159 to 0.59160, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7729 - val_accuracy: 0.5916 - val_loss: 1.8405\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.59160\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7727 - val_accuracy: 0.5916 - val_loss: 1.8456\nEpoch 115/500\n\nEpoch 115: val_accuracy improved from 0.59160 to 0.59160, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7725 - val_accuracy: 0.5916 - val_loss: 1.8412\nEpoch 116/500\n\nEpoch 116: val_accuracy improved from 0.59160 to 0.59161, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7723 - val_accuracy: 0.5916 - val_loss: 1.8408\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.59161\n726/726 - 5s - 8ms/step - accuracy: 0.7639 - loss: 0.7721 - val_accuracy: 0.5915 - val_loss: 1.8456\nEpoch 118/500\n\nEpoch 118: val_accuracy improved from 0.59161 to 0.59188, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7720 - val_accuracy: 0.5919 - val_loss: 1.8394\nEpoch 119/500\n\nEpoch 119: val_accuracy improved from 0.59188 to 0.59191, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7718 - val_accuracy: 0.5919 - val_loss: 1.8401\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.59191\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7716 - val_accuracy: 0.5919 - val_loss: 1.8432\nEpoch 121/500\n\nEpoch 121: val_accuracy improved from 0.59191 to 0.59215, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7714 - val_accuracy: 0.5922 - val_loss: 1.8367\nEpoch 122/500\n\nEpoch 122: val_accuracy improved from 0.59215 to 0.59218, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7712 - val_accuracy: 0.5922 - val_loss: 1.8349\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.59218\n726/726 - 5s - 8ms/step - accuracy: 0.7639 - loss: 0.7711 - val_accuracy: 0.5922 - val_loss: 1.8369\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.59218\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7709 - val_accuracy: 0.5922 - val_loss: 1.8431\nEpoch 125/500\n\nEpoch 125: val_accuracy improved from 0.59218 to 0.59218, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7707 - val_accuracy: 0.5922 - val_loss: 1.8363\nEpoch 126/500\n\nEpoch 126: val_accuracy improved from 0.59218 to 0.59229, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7705 - val_accuracy: 0.5923 - val_loss: 1.8357\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7704 - val_accuracy: 0.5923 - val_loss: 1.8336\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7702 - val_accuracy: 0.5921 - val_loss: 1.8393\nEpoch 129/500\n\nEpoch 129: val_accuracy improved from 0.59229 to 0.59229, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7700 - val_accuracy: 0.5923 - val_loss: 1.8356\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.59229\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7698 - val_accuracy: 0.5923 - val_loss: 1.8355\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7697 - val_accuracy: 0.5922 - val_loss: 1.8337\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7695 - val_accuracy: 0.5922 - val_loss: 1.8338\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7693 - val_accuracy: 0.5922 - val_loss: 1.8321\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7692 - val_accuracy: 0.5922 - val_loss: 1.8367\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7690 - val_accuracy: 0.5922 - val_loss: 1.8361\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.59229\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7688 - val_accuracy: 0.5922 - val_loss: 1.8346\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7687 - val_accuracy: 0.5922 - val_loss: 1.8370\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.59229\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7685 - val_accuracy: 0.5922 - val_loss: 1.8332\nEpoch 139/500\n\nEpoch 139: val_accuracy improved from 0.59229 to 0.59268, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7683 - val_accuracy: 0.5927 - val_loss: 1.8315\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7682 - val_accuracy: 0.5927 - val_loss: 1.8312\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7680 - val_accuracy: 0.5927 - val_loss: 1.8309\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.59268\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7678 - val_accuracy: 0.5927 - val_loss: 1.8292\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7677 - val_accuracy: 0.5927 - val_loss: 1.8287\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7675 - val_accuracy: 0.5927 - val_loss: 1.8306\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7673 - val_accuracy: 0.5927 - val_loss: 1.8311\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7672 - val_accuracy: 0.5927 - val_loss: 1.8273\nEpoch 147/500\n\nEpoch 147: val_accuracy improved from 0.59268 to 0.59268, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7670 - val_accuracy: 0.5927 - val_loss: 1.8289\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7669 - val_accuracy: 0.5927 - val_loss: 1.8315\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7667 - val_accuracy: 0.5927 - val_loss: 1.8286\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7665 - val_accuracy: 0.5925 - val_loss: 1.8274\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7664 - val_accuracy: 0.5927 - val_loss: 1.8254\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7662 - val_accuracy: 0.5925 - val_loss: 1.8324\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7661 - val_accuracy: 0.5927 - val_loss: 1.8282\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.59268\n726/726 - 5s - 8ms/step - accuracy: 0.7631 - loss: 0.7659 - val_accuracy: 0.5926 - val_loss: 1.8238\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7658 - val_accuracy: 0.5925 - val_loss: 1.8258\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7656 - val_accuracy: 0.5926 - val_loss: 1.8236\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.59268\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7654 - val_accuracy: 0.5894 - val_loss: 1.8297\nEpoch 158/500\n\nEpoch 158: val_accuracy improved from 0.59268 to 0.59273, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7653 - val_accuracy: 0.5927 - val_loss: 1.8192\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7651 - val_accuracy: 0.5896 - val_loss: 1.8266\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7650 - val_accuracy: 0.5894 - val_loss: 1.8254\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7618 - loss: 0.7648 - val_accuracy: 0.5895 - val_loss: 1.8221\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7647 - val_accuracy: 0.5927 - val_loss: 1.8220\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7645 - val_accuracy: 0.5896 - val_loss: 1.8228\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7644 - val_accuracy: 0.5896 - val_loss: 1.8228\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7642 - val_accuracy: 0.5897 - val_loss: 1.8215\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7641 - val_accuracy: 0.5897 - val_loss: 1.8238\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7619 - loss: 0.7639 - val_accuracy: 0.5897 - val_loss: 1.8202\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7638 - val_accuracy: 0.5897 - val_loss: 1.8197\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7636 - val_accuracy: 0.5897 - val_loss: 1.8202\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7635 - val_accuracy: 0.5897 - val_loss: 1.8218\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7633 - val_accuracy: 0.5899 - val_loss: 1.8179\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7632 - val_accuracy: 0.5897 - val_loss: 1.8207\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7619 - loss: 0.7630 - val_accuracy: 0.5897 - val_loss: 1.8198\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7629 - val_accuracy: 0.5897 - val_loss: 1.8198\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7627 - val_accuracy: 0.5897 - val_loss: 1.8223\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7626 - val_accuracy: 0.5898 - val_loss: 1.8186\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7625 - val_accuracy: 0.5900 - val_loss: 1.8182\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7623 - val_accuracy: 0.5897 - val_loss: 1.8177\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7622 - val_accuracy: 0.5900 - val_loss: 1.8176\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7620 - val_accuracy: 0.5898 - val_loss: 1.8206\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7619 - val_accuracy: 0.5898 - val_loss: 1.8163\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7617 - val_accuracy: 0.5897 - val_loss: 1.8164\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7616 - val_accuracy: 0.5900 - val_loss: 1.8147\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7614 - val_accuracy: 0.5898 - val_loss: 1.8148\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7613 - val_accuracy: 0.5900 - val_loss: 1.8157\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7612 - val_accuracy: 0.5898 - val_loss: 1.8123\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7610 - val_accuracy: 0.5898 - val_loss: 1.8162\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7609 - val_accuracy: 0.5898 - val_loss: 1.8176\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7607 - val_accuracy: 0.5897 - val_loss: 1.8192\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7606 - val_accuracy: 0.5898 - val_loss: 1.8153\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7605 - val_accuracy: 0.5897 - val_loss: 1.8163\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7620 - loss: 0.7603 - val_accuracy: 0.5897 - val_loss: 1.8186\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7602 - val_accuracy: 0.5898 - val_loss: 1.8127\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7600 - val_accuracy: 0.5897 - val_loss: 1.8145\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7599 - val_accuracy: 0.5897 - val_loss: 1.8144\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7598 - val_accuracy: 0.5897 - val_loss: 1.8162\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7596 - val_accuracy: 0.5897 - val_loss: 1.8139\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7621 - loss: 0.7595 - val_accuracy: 0.5897 - val_loss: 1.8146\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7594 - val_accuracy: 0.5899 - val_loss: 1.8129\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7592 - val_accuracy: 0.5899 - val_loss: 1.8137\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7591 - val_accuracy: 0.5897 - val_loss: 1.8122\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7590 - val_accuracy: 0.5899 - val_loss: 1.8111\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7588 - val_accuracy: 0.5900 - val_loss: 1.8112\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7587 - val_accuracy: 0.5899 - val_loss: 1.8119\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7586 - val_accuracy: 0.5897 - val_loss: 1.8131\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7584 - val_accuracy: 0.5899 - val_loss: 1.8095\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7583 - val_accuracy: 0.5899 - val_loss: 1.8126\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7582 - val_accuracy: 0.5899 - val_loss: 1.8099\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7580 - val_accuracy: 0.5899 - val_loss: 1.8123\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7634 - loss: 0.7579 - val_accuracy: 0.5899 - val_loss: 1.8104\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7578 - val_accuracy: 0.5897 - val_loss: 1.8134\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7576 - val_accuracy: 0.5900 - val_loss: 1.8059\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7575 - val_accuracy: 0.5900 - val_loss: 1.8053\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7574 - val_accuracy: 0.5899 - val_loss: 1.8088\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7573 - val_accuracy: 0.5900 - val_loss: 1.8086\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7571 - val_accuracy: 0.5900 - val_loss: 1.8053\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7570 - val_accuracy: 0.5900 - val_loss: 1.8079\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7569 - val_accuracy: 0.5900 - val_loss: 1.8102\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7567 - val_accuracy: 0.5900 - val_loss: 1.8051\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7566 - val_accuracy: 0.5900 - val_loss: 1.8069\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7565 - val_accuracy: 0.5900 - val_loss: 1.8059\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7634 - loss: 0.7564 - val_accuracy: 0.5899 - val_loss: 1.8112\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7562 - val_accuracy: 0.5900 - val_loss: 1.8034\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7561 - val_accuracy: 0.5899 - val_loss: 1.8088\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7560 - val_accuracy: 0.5900 - val_loss: 1.8062\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7559 - val_accuracy: 0.5899 - val_loss: 1.8039\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7557 - val_accuracy: 0.5899 - val_loss: 1.8076\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7635 - loss: 0.7556 - val_accuracy: 0.5900 - val_loss: 1.8020\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7555 - val_accuracy: 0.5900 - val_loss: 1.8040\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7554 - val_accuracy: 0.5899 - val_loss: 1.8046\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7552 - val_accuracy: 0.5899 - val_loss: 1.8067\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7551 - val_accuracy: 0.5899 - val_loss: 1.8030\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7550 - val_accuracy: 0.5899 - val_loss: 1.8051\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7549 - val_accuracy: 0.5899 - val_loss: 1.8061\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7547 - val_accuracy: 0.5899 - val_loss: 1.8041\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7546 - val_accuracy: 0.5900 - val_loss: 1.8023\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7545 - val_accuracy: 0.5900 - val_loss: 1.8019\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7544 - val_accuracy: 0.5899 - val_loss: 1.8057\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7543 - val_accuracy: 0.5900 - val_loss: 1.8002\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7541 - val_accuracy: 0.5899 - val_loss: 1.8061\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7639 - loss: 0.7540 - val_accuracy: 0.5899 - val_loss: 1.8028\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7539 - val_accuracy: 0.5898 - val_loss: 1.8004\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7538 - val_accuracy: 0.5898 - val_loss: 1.8008\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7537 - val_accuracy: 0.5898 - val_loss: 1.8041\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7535 - val_accuracy: 0.5898 - val_loss: 1.8065\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7534 - val_accuracy: 0.5898 - val_loss: 1.8037\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7640 - loss: 0.7533 - val_accuracy: 0.5898 - val_loss: 1.8036\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7532 - val_accuracy: 0.5898 - val_loss: 1.8013\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7531 - val_accuracy: 0.5898 - val_loss: 1.7985\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7530 - val_accuracy: 0.5898 - val_loss: 1.7994\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7528 - val_accuracy: 0.5899 - val_loss: 1.7995\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7527 - val_accuracy: 0.5898 - val_loss: 1.8021\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7640 - loss: 0.7526 - val_accuracy: 0.5898 - val_loss: 1.7989\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7525 - val_accuracy: 0.5898 - val_loss: 1.8007\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7524 - val_accuracy: 0.5898 - val_loss: 1.8016\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7523 - val_accuracy: 0.5898 - val_loss: 1.8024\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7522 - val_accuracy: 0.5899 - val_loss: 1.7987\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7520 - val_accuracy: 0.5899 - val_loss: 1.8009\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7519 - val_accuracy: 0.5899 - val_loss: 1.7992\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7518 - val_accuracy: 0.5899 - val_loss: 1.7987\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7517 - val_accuracy: 0.5899 - val_loss: 1.7999\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7516 - val_accuracy: 0.5899 - val_loss: 1.8014\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7515 - val_accuracy: 0.5899 - val_loss: 1.7985\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7514 - val_accuracy: 0.5899 - val_loss: 1.7973\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7512 - val_accuracy: 0.5899 - val_loss: 1.7968\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7511 - val_accuracy: 0.5899 - val_loss: 1.7951\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7510 - val_accuracy: 0.5899 - val_loss: 1.7970\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7509 - val_accuracy: 0.5899 - val_loss: 1.7992\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7508 - val_accuracy: 0.5898 - val_loss: 1.8012\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7507 - val_accuracy: 0.5899 - val_loss: 1.7998\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7506 - val_accuracy: 0.5899 - val_loss: 1.7963\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7505 - val_accuracy: 0.5899 - val_loss: 1.7953\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7504 - val_accuracy: 0.5899 - val_loss: 1.7948\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7503 - val_accuracy: 0.5899 - val_loss: 1.7944\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7501 - val_accuracy: 0.5899 - val_loss: 1.7958\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7500 - val_accuracy: 0.5798 - val_loss: 1.7992\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7499 - val_accuracy: 0.5798 - val_loss: 1.7956\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7641 - loss: 0.7498 - val_accuracy: 0.5798 - val_loss: 1.7934\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7497 - val_accuracy: 0.5798 - val_loss: 1.7972\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7496 - val_accuracy: 0.5798 - val_loss: 1.7966\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7495 - val_accuracy: 0.5798 - val_loss: 1.7949\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7494 - val_accuracy: 0.5798 - val_loss: 1.7936\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7493 - val_accuracy: 0.5798 - val_loss: 1.8001\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7641 - loss: 0.7492 - val_accuracy: 0.5798 - val_loss: 1.7977\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7491 - val_accuracy: 0.5798 - val_loss: 1.7984\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7490 - val_accuracy: 0.5799 - val_loss: 1.7914\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7489 - val_accuracy: 0.5799 - val_loss: 1.7926\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7487 - val_accuracy: 0.5799 - val_loss: 1.7916\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7486 - val_accuracy: 0.5799 - val_loss: 1.7941\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7485 - val_accuracy: 0.5798 - val_loss: 1.7952\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7484 - val_accuracy: 0.5798 - val_loss: 1.7948\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7483 - val_accuracy: 0.5799 - val_loss: 1.7927\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7482 - val_accuracy: 0.5799 - val_loss: 1.7929\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7481 - val_accuracy: 0.5799 - val_loss: 1.7911\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7480 - val_accuracy: 0.5798 - val_loss: 1.7930\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7479 - val_accuracy: 0.5798 - val_loss: 1.7914\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7651 - loss: 0.7478 - val_accuracy: 0.5799 - val_loss: 1.7873\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7477 - val_accuracy: 0.5798 - val_loss: 1.7913\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7476 - val_accuracy: 0.5799 - val_loss: 1.7884\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7475 - val_accuracy: 0.5797 - val_loss: 1.7925\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7474 - val_accuracy: 0.5798 - val_loss: 1.7926\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7473 - val_accuracy: 0.5798 - val_loss: 1.7904\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7472 - val_accuracy: 0.5797 - val_loss: 1.7942\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7471 - val_accuracy: 0.5802 - val_loss: 1.7843\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7470 - val_accuracy: 0.5802 - val_loss: 1.7906\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7469 - val_accuracy: 0.5799 - val_loss: 1.7915\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7468 - val_accuracy: 0.5799 - val_loss: 1.7926\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7467 - val_accuracy: 0.5800 - val_loss: 1.7884\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7466 - val_accuracy: 0.5800 - val_loss: 1.7921\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7465 - val_accuracy: 0.5800 - val_loss: 1.7935\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7464 - val_accuracy: 0.5800 - val_loss: 1.7878\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7463 - val_accuracy: 0.5800 - val_loss: 1.7876\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7462 - val_accuracy: 0.5800 - val_loss: 1.7872\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7461 - val_accuracy: 0.5800 - val_loss: 1.7926\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7644 - loss: 0.7460 - val_accuracy: 0.5800 - val_loss: 1.7871\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7459 - val_accuracy: 0.5800 - val_loss: 1.7909\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7458 - val_accuracy: 0.5800 - val_loss: 1.7914\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7457 - val_accuracy: 0.5800 - val_loss: 1.7923\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7456 - val_accuracy: 0.5800 - val_loss: 1.7878\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7455 - val_accuracy: 0.5800 - val_loss: 1.7845\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7454 - val_accuracy: 0.5800 - val_loss: 1.7869\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7643 - loss: 0.7453 - val_accuracy: 0.5801 - val_loss: 1.7888\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7452 - val_accuracy: 0.5800 - val_loss: 1.7885\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7451 - val_accuracy: 0.5800 - val_loss: 1.7864\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7450 - val_accuracy: 0.5800 - val_loss: 1.7885\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7449 - val_accuracy: 0.5801 - val_loss: 1.7839\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7448 - val_accuracy: 0.5800 - val_loss: 1.7887\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7645 - loss: 0.7447 - val_accuracy: 0.5800 - val_loss: 1.7846\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7447 - val_accuracy: 0.5800 - val_loss: 1.7892\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7446 - val_accuracy: 0.5800 - val_loss: 1.7867\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7445 - val_accuracy: 0.5801 - val_loss: 1.7844\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7444 - val_accuracy: 0.5801 - val_loss: 1.7859\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7443 - val_accuracy: 0.5800 - val_loss: 1.7854\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7442 - val_accuracy: 0.5800 - val_loss: 1.7868\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7441 - val_accuracy: 0.5800 - val_loss: 1.7884\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7440 - val_accuracy: 0.5799 - val_loss: 1.7904\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7439 - val_accuracy: 0.5801 - val_loss: 1.7845\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7438 - val_accuracy: 0.5799 - val_loss: 1.7866\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7437 - val_accuracy: 0.5800 - val_loss: 1.7869\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7436 - val_accuracy: 0.5799 - val_loss: 1.7856\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7435 - val_accuracy: 0.5800 - val_loss: 1.7848\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7434 - val_accuracy: 0.5801 - val_loss: 1.7839\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7434 - val_accuracy: 0.5800 - val_loss: 1.7845\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7433 - val_accuracy: 0.5800 - val_loss: 1.7834\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7432 - val_accuracy: 0.5800 - val_loss: 1.7811\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7431 - val_accuracy: 0.5800 - val_loss: 1.7876\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7646 - loss: 0.7430 - val_accuracy: 0.5799 - val_loss: 1.7834\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7429 - val_accuracy: 0.5799 - val_loss: 1.7845\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7428 - val_accuracy: 0.5799 - val_loss: 1.7899\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7427 - val_accuracy: 0.5799 - val_loss: 1.7859\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7426 - val_accuracy: 0.5799 - val_loss: 1.7811\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7425 - val_accuracy: 0.5799 - val_loss: 1.7855\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7660 - loss: 0.7424 - val_accuracy: 0.5799 - val_loss: 1.7810\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7424 - val_accuracy: 0.5799 - val_loss: 1.7885\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7423 - val_accuracy: 0.5799 - val_loss: 1.7831\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7422 - val_accuracy: 0.5799 - val_loss: 1.7799\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7665 - loss: 0.7421 - val_accuracy: 0.5802 - val_loss: 1.7810\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7420 - val_accuracy: 0.5802 - val_loss: 1.7808\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7419 - val_accuracy: 0.5802 - val_loss: 1.7818\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7418 - val_accuracy: 0.5802 - val_loss: 1.7827\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7687 - loss: 0.7417 - val_accuracy: 0.5799 - val_loss: 1.7846\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7417 - val_accuracy: 0.5799 - val_loss: 1.7865\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7416 - val_accuracy: 0.5803 - val_loss: 1.7794\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7415 - val_accuracy: 0.5803 - val_loss: 1.7820\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7414 - val_accuracy: 0.5802 - val_loss: 1.7833\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7682 - loss: 0.7413 - val_accuracy: 0.5801 - val_loss: 1.7854\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7674 - loss: 0.7412 - val_accuracy: 0.5802 - val_loss: 1.7858\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7411 - val_accuracy: 0.5803 - val_loss: 1.7840\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7694 - loss: 0.7411 - val_accuracy: 0.5802 - val_loss: 1.7850\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7410 - val_accuracy: 0.5804 - val_loss: 1.7783\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7684 - loss: 0.7409 - val_accuracy: 0.5802 - val_loss: 1.7810\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7648 - loss: 0.7408 - val_accuracy: 0.5804 - val_loss: 1.7780\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7407 - val_accuracy: 0.5802 - val_loss: 1.7816\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7670 - loss: 0.7406 - val_accuracy: 0.5803 - val_loss: 1.7783\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7678 - loss: 0.7405 - val_accuracy: 0.5804 - val_loss: 1.7821\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7680 - loss: 0.7405 - val_accuracy: 0.5804 - val_loss: 1.7770\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7404 - val_accuracy: 0.5802 - val_loss: 1.7818\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7672 - loss: 0.7403 - val_accuracy: 0.5802 - val_loss: 1.7838\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7402 - val_accuracy: 0.5804 - val_loss: 1.7798\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7401 - val_accuracy: 0.5802 - val_loss: 1.7814\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7695 - loss: 0.7400 - val_accuracy: 0.5802 - val_loss: 1.7786\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7400 - val_accuracy: 0.5802 - val_loss: 1.7779\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7399 - val_accuracy: 0.5802 - val_loss: 1.7824\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7657 - loss: 0.7398 - val_accuracy: 0.5802 - val_loss: 1.7781\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7665 - loss: 0.7397 - val_accuracy: 0.5803 - val_loss: 1.7813\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7677 - loss: 0.7396 - val_accuracy: 0.5804 - val_loss: 1.7743\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7675 - loss: 0.7395 - val_accuracy: 0.5802 - val_loss: 1.7780\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7675 - loss: 0.7395 - val_accuracy: 0.5802 - val_loss: 1.7808\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7668 - loss: 0.7394 - val_accuracy: 0.5802 - val_loss: 1.7773\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7693 - loss: 0.7393 - val_accuracy: 0.5803 - val_loss: 1.7819\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7701 - loss: 0.7392 - val_accuracy: 0.5802 - val_loss: 1.7762\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7674 - loss: 0.7391 - val_accuracy: 0.5802 - val_loss: 1.7732\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7675 - loss: 0.7391 - val_accuracy: 0.5799 - val_loss: 1.7797\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.7390 - val_accuracy: 0.5800 - val_loss: 1.7780\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7712 - loss: 0.7389 - val_accuracy: 0.5802 - val_loss: 1.7785\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7388 - val_accuracy: 0.5804 - val_loss: 1.7762\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7701 - loss: 0.7387 - val_accuracy: 0.5802 - val_loss: 1.7773\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7670 - loss: 0.7387 - val_accuracy: 0.5802 - val_loss: 1.7784\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7686 - loss: 0.7386 - val_accuracy: 0.5804 - val_loss: 1.7762\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7723 - loss: 0.7385 - val_accuracy: 0.5802 - val_loss: 1.7775\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7690 - loss: 0.7384 - val_accuracy: 0.5804 - val_loss: 1.7764\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7693 - loss: 0.7383 - val_accuracy: 0.5800 - val_loss: 1.7808\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7694 - loss: 0.7383 - val_accuracy: 0.5799 - val_loss: 1.7782\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7686 - loss: 0.7382 - val_accuracy: 0.5796 - val_loss: 1.7818\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7700 - loss: 0.7381 - val_accuracy: 0.5796 - val_loss: 1.7764\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7380 - val_accuracy: 0.5796 - val_loss: 1.7778\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7712 - loss: 0.7379 - val_accuracy: 0.5796 - val_loss: 1.7800\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7700 - loss: 0.7379 - val_accuracy: 0.5796 - val_loss: 1.7776\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7708 - loss: 0.7378 - val_accuracy: 0.5796 - val_loss: 1.7783\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7684 - loss: 0.7377 - val_accuracy: 0.5794 - val_loss: 1.7799\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7700 - loss: 0.7376 - val_accuracy: 0.5796 - val_loss: 1.7768\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7678 - loss: 0.7375 - val_accuracy: 0.5796 - val_loss: 1.7755\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7727 - loss: 0.7375 - val_accuracy: 0.5796 - val_loss: 1.7775\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7721 - loss: 0.7374 - val_accuracy: 0.5796 - val_loss: 1.7754\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7690 - loss: 0.7373 - val_accuracy: 0.5796 - val_loss: 1.7787\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7372 - val_accuracy: 0.5801 - val_loss: 1.7731\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7720 - loss: 0.7372 - val_accuracy: 0.5795 - val_loss: 1.7771\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7746 - loss: 0.7371 - val_accuracy: 0.5796 - val_loss: 1.7770\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7679 - loss: 0.7370 - val_accuracy: 0.5796 - val_loss: 1.7783\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7734 - loss: 0.7369 - val_accuracy: 0.5796 - val_loss: 1.7756\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7700 - loss: 0.7369 - val_accuracy: 0.5798 - val_loss: 1.7745\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7726 - loss: 0.7368 - val_accuracy: 0.5796 - val_loss: 1.7762\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7717 - loss: 0.7367 - val_accuracy: 0.5800 - val_loss: 1.7739\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7724 - loss: 0.7366 - val_accuracy: 0.5797 - val_loss: 1.7770\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7749 - loss: 0.7366 - val_accuracy: 0.5797 - val_loss: 1.7770\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.7365 - val_accuracy: 0.5798 - val_loss: 1.7760\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7742 - loss: 0.7364 - val_accuracy: 0.5798 - val_loss: 1.7762\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7363 - val_accuracy: 0.5798 - val_loss: 1.7744\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7742 - loss: 0.7362 - val_accuracy: 0.5798 - val_loss: 1.7743\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7746 - loss: 0.7362 - val_accuracy: 0.5798 - val_loss: 1.7717\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7725 - loss: 0.7361 - val_accuracy: 0.5799 - val_loss: 1.7741\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7360 - val_accuracy: 0.5799 - val_loss: 1.7773\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7760 - loss: 0.7360 - val_accuracy: 0.5799 - val_loss: 1.7752\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7747 - loss: 0.7359 - val_accuracy: 0.5798 - val_loss: 1.7756\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7742 - loss: 0.7358 - val_accuracy: 0.5796 - val_loss: 1.7756\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7725 - loss: 0.7357 - val_accuracy: 0.5796 - val_loss: 1.7776\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.7357 - val_accuracy: 0.5799 - val_loss: 1.7749\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7356 - val_accuracy: 0.5798 - val_loss: 1.7758\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7748 - loss: 0.7355 - val_accuracy: 0.5798 - val_loss: 1.7744\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7354 - val_accuracy: 0.5798 - val_loss: 1.7764\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7354 - val_accuracy: 0.5799 - val_loss: 1.7733\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7353 - val_accuracy: 0.5799 - val_loss: 1.7678\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7730 - loss: 0.7352 - val_accuracy: 0.5797 - val_loss: 1.7753\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7351 - val_accuracy: 0.5796 - val_loss: 1.7746\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7754 - loss: 0.7351 - val_accuracy: 0.5794 - val_loss: 1.7726\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7350 - val_accuracy: 0.5799 - val_loss: 1.7701\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7754 - loss: 0.7349 - val_accuracy: 0.5794 - val_loss: 1.7727\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7738 - loss: 0.7349 - val_accuracy: 0.5795 - val_loss: 1.7719\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7738 - loss: 0.7348 - val_accuracy: 0.5793 - val_loss: 1.7733\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7347 - val_accuracy: 0.5797 - val_loss: 1.7718\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7783 - loss: 0.7346 - val_accuracy: 0.5796 - val_loss: 1.7692\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7346 - val_accuracy: 0.5796 - val_loss: 1.7715\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7750 - loss: 0.7345 - val_accuracy: 0.5797 - val_loss: 1.7700\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7344 - val_accuracy: 0.5794 - val_loss: 1.7746\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7344 - val_accuracy: 0.5794 - val_loss: 1.7724\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7343 - val_accuracy: 0.5794 - val_loss: 1.7729\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7342 - val_accuracy: 0.5795 - val_loss: 1.7711\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7750 - loss: 0.7342 - val_accuracy: 0.5793 - val_loss: 1.7748\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7341 - val_accuracy: 0.5795 - val_loss: 1.7710\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7340 - val_accuracy: 0.5795 - val_loss: 1.7711\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7339 - val_accuracy: 0.5797 - val_loss: 1.7717\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7798 - loss: 0.7339 - val_accuracy: 0.5793 - val_loss: 1.7746\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7338 - val_accuracy: 0.5797 - val_loss: 1.7701\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7768 - loss: 0.7337 - val_accuracy: 0.5794 - val_loss: 1.7736\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7763 - loss: 0.7337 - val_accuracy: 0.5798 - val_loss: 1.7705\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7336 - val_accuracy: 0.5794 - val_loss: 1.7744\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7335 - val_accuracy: 0.5795 - val_loss: 1.7726\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7335 - val_accuracy: 0.5795 - val_loss: 1.7715\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7334 - val_accuracy: 0.5794 - val_loss: 1.7736\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7783 - loss: 0.7333 - val_accuracy: 0.5795 - val_loss: 1.7733\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7333 - val_accuracy: 0.5795 - val_loss: 1.7682\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7332 - val_accuracy: 0.5792 - val_loss: 1.7707\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7331 - val_accuracy: 0.5794 - val_loss: 1.7718\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7808 - loss: 0.7331 - val_accuracy: 0.5797 - val_loss: 1.7692\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7330 - val_accuracy: 0.5796 - val_loss: 1.7683\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7807 - loss: 0.7329 - val_accuracy: 0.5795 - val_loss: 1.7673\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7777 - loss: 0.7328 - val_accuracy: 0.5799 - val_loss: 1.7676\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7328 - val_accuracy: 0.5794 - val_loss: 1.7730\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7810 - loss: 0.7327 - val_accuracy: 0.5794 - val_loss: 1.7742\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7814 - loss: 0.7326 - val_accuracy: 0.5792 - val_loss: 1.7746\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7812 - loss: 0.7326 - val_accuracy: 0.5792 - val_loss: 1.7677\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7802 - loss: 0.7325 - val_accuracy: 0.5794 - val_loss: 1.7717\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7324 - val_accuracy: 0.5795 - val_loss: 1.7703\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7804 - loss: 0.7324 - val_accuracy: 0.5794 - val_loss: 1.7698\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7817 - loss: 0.7323 - val_accuracy: 0.5792 - val_loss: 1.7687\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7786 - loss: 0.7323 - val_accuracy: 0.5795 - val_loss: 1.7700\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7322 - val_accuracy: 0.5794 - val_loss: 1.7720\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7804 - loss: 0.7321 - val_accuracy: 0.5795 - val_loss: 1.7729\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7321 - val_accuracy: 0.5795 - val_loss: 1.7699\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7844 - loss: 0.7320 - val_accuracy: 0.5793 - val_loss: 1.7724\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7811 - loss: 0.7319 - val_accuracy: 0.5795 - val_loss: 1.7692\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7837 - loss: 0.7319 - val_accuracy: 0.5794 - val_loss: 1.7711\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7840 - loss: 0.7318 - val_accuracy: 0.5795 - val_loss: 1.7710\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7839 - loss: 0.7317 - val_accuracy: 0.5794 - val_loss: 1.7702\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7829 - loss: 0.7317 - val_accuracy: 0.5794 - val_loss: 1.7694\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7316 - val_accuracy: 0.5794 - val_loss: 1.7702\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7818 - loss: 0.7315 - val_accuracy: 0.5794 - val_loss: 1.7731\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7315 - val_accuracy: 0.5794 - val_loss: 1.7663\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7845 - loss: 0.7314 - val_accuracy: 0.5793 - val_loss: 1.7672\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7809 - loss: 0.7313 - val_accuracy: 0.5795 - val_loss: 1.7680\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(\n    X, y, test_size=0.3, random_state=47, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_5, X_val_5, y_train_5, y_val_5 = train_test_split(\n    X_train_5, y_train_5, test_size=0.2, random_state=47, stratify=y_train_5\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_5:\", np.max(X_train_5))\nprint(\"Min value in X_train_5:\", np.min(X_train_5))\n\nX_train_5_scaled = scaler.fit_transform(X_train_5)\n\n# Get the original class distribution\nclass_counts_5 = Counter(y_train_5)\nprint(\"Original class distribution:\", class_counts_5)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_5 = class_counts_5[min(class_counts_5, key=class_counts_5.get)]\ndesired_majority_size_5 = minority_class_size_5 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_5 = {0: desired_majority_size_5, 1: minority_class_size_5}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_5 = RandomUnderSampler(sampling_strategy=sampling_strategy_5, random_state=42)\nX_resampled_5, y_resampled_5 = undersampler_5.fit_resample(X_train_5, y_train_5)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_5))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_5, y_train_resampled_5 = smote.fit_resample(X_resampled_5, y_resampled_5)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_5))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:54:11.279954Z","iopub.execute_input":"2025-03-06T19:54:11.280298Z","iopub.status.idle":"2025-03-06T19:54:49.945003Z","shell.execute_reply.started":"2025-03-06T19:54:11.280269Z","shell.execute_reply":"2025-03-06T19:54:49.943363Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_5: 2071000000.0\nMin value in X_train_5: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_5 = X_train_resampled_5.reshape(X_train_resampled_5.shape[0], 1, 56)\nX_val_5 = X_val_5.reshape(X_val_5.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_5,  # Features from CICIDS2017\n    y_train_resampled_5,  # Labels from CICIDS2017\n    validation_data=(X_val_5, y_val_5),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:54:49.946911Z","iopub.execute_input":"2025-03-06T19:54:49.947338Z","iopub.status.idle":"2025-03-06T20:39:24.141488Z","shell.execute_reply.started":"2025-03-06T19:54:49.947304Z","shell.execute_reply":"2025-03-06T20:39:24.139846Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7332 - loss: 0.7977 - val_accuracy: 0.4346 - val_loss: 1.8670\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.7900 - val_accuracy: 0.4351 - val_loss: 1.8669\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7407 - loss: 0.7867 - val_accuracy: 0.4406 - val_loss: 1.8679\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7412 - loss: 0.7844 - val_accuracy: 0.4347 - val_loss: 1.8685\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.7826 - val_accuracy: 0.4348 - val_loss: 1.8713\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7456 - loss: 0.7811 - val_accuracy: 0.4341 - val_loss: 1.8795\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.7799 - val_accuracy: 0.4340 - val_loss: 1.8858\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7428 - loss: 0.7788 - val_accuracy: 0.4342 - val_loss: 1.8869\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7468 - loss: 0.7779 - val_accuracy: 0.4343 - val_loss: 1.8877\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7463 - loss: 0.7771 - val_accuracy: 0.4342 - val_loss: 1.8864\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7489 - loss: 0.7763 - val_accuracy: 0.4342 - val_loss: 1.8931\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7510 - loss: 0.7756 - val_accuracy: 0.4341 - val_loss: 1.8934\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7513 - loss: 0.7750 - val_accuracy: 0.4341 - val_loss: 1.8921\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7527 - loss: 0.7744 - val_accuracy: 0.4342 - val_loss: 1.8945\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7505 - loss: 0.7738 - val_accuracy: 0.4344 - val_loss: 1.9001\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7576 - loss: 0.7733 - val_accuracy: 0.4341 - val_loss: 1.8970\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7540 - loss: 0.7727 - val_accuracy: 0.4344 - val_loss: 1.9001\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7557 - loss: 0.7722 - val_accuracy: 0.4344 - val_loss: 1.9014\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7576 - loss: 0.7717 - val_accuracy: 0.4343 - val_loss: 1.9055\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7598 - loss: 0.7712 - val_accuracy: 0.4341 - val_loss: 1.9058\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7573 - loss: 0.7708 - val_accuracy: 0.4359 - val_loss: 1.9045\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.7704 - val_accuracy: 0.4333 - val_loss: 1.9074\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7699 - val_accuracy: 0.4348 - val_loss: 1.9105\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7612 - loss: 0.7695 - val_accuracy: 0.4347 - val_loss: 1.9148\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7612 - loss: 0.7691 - val_accuracy: 0.4331 - val_loss: 1.9118\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.7687 - val_accuracy: 0.4331 - val_loss: 1.9111\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7684 - val_accuracy: 0.4377 - val_loss: 1.9110\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7680 - val_accuracy: 0.4375 - val_loss: 1.9122\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.7676 - val_accuracy: 0.4374 - val_loss: 1.9153\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7673 - val_accuracy: 0.4373 - val_loss: 1.9167\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7670 - val_accuracy: 0.4373 - val_loss: 1.9149\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7666 - val_accuracy: 0.4377 - val_loss: 1.9200\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7663 - val_accuracy: 0.4375 - val_loss: 1.9186\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7660 - val_accuracy: 0.4373 - val_loss: 1.9229\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7657 - val_accuracy: 0.4377 - val_loss: 1.9164\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7654 - val_accuracy: 0.4376 - val_loss: 1.9200\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7661 - loss: 0.7651 - val_accuracy: 0.4376 - val_loss: 1.9215\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7648 - val_accuracy: 0.4377 - val_loss: 1.9225\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7645 - val_accuracy: 0.4377 - val_loss: 1.9258\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7643 - val_accuracy: 0.4377 - val_loss: 1.9252\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7640 - val_accuracy: 0.4377 - val_loss: 1.9254\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7637 - val_accuracy: 0.4377 - val_loss: 1.9265\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7635 - val_accuracy: 0.4377 - val_loss: 1.9253\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7632 - val_accuracy: 0.4377 - val_loss: 1.9278\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7629 - val_accuracy: 0.4380 - val_loss: 1.9252\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7627 - val_accuracy: 0.4379 - val_loss: 1.9318\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7625 - val_accuracy: 0.4380 - val_loss: 1.9295\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7622 - val_accuracy: 0.4380 - val_loss: 1.9313\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7651 - loss: 0.7620 - val_accuracy: 0.4377 - val_loss: 1.9317\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7618 - val_accuracy: 0.4382 - val_loss: 1.9353\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7615 - val_accuracy: 0.4382 - val_loss: 1.9328\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7613 - val_accuracy: 0.4379 - val_loss: 1.9370\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7611 - val_accuracy: 0.4381 - val_loss: 1.9371\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7609 - val_accuracy: 0.4382 - val_loss: 1.9346\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7637 - loss: 0.7607 - val_accuracy: 0.4380 - val_loss: 1.9369\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.7605 - val_accuracy: 0.4380 - val_loss: 1.9406\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7603 - val_accuracy: 0.4382 - val_loss: 1.9364\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7601 - val_accuracy: 0.4380 - val_loss: 1.9379\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7599 - val_accuracy: 0.4378 - val_loss: 1.9434\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7597 - val_accuracy: 0.4379 - val_loss: 1.9346\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7651 - loss: 0.7595 - val_accuracy: 0.4378 - val_loss: 1.9422\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7593 - val_accuracy: 0.4379 - val_loss: 1.9412\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7647 - loss: 0.7591 - val_accuracy: 0.4379 - val_loss: 1.9407\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7589 - val_accuracy: 0.4378 - val_loss: 1.9469\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7587 - val_accuracy: 0.4379 - val_loss: 1.9445\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7657 - loss: 0.7585 - val_accuracy: 0.4378 - val_loss: 1.9439\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7612 - loss: 0.7584 - val_accuracy: 0.4377 - val_loss: 1.9444\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7626 - loss: 0.7582 - val_accuracy: 0.4378 - val_loss: 1.9443\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7580 - val_accuracy: 0.4378 - val_loss: 1.9460\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7579 - val_accuracy: 0.4378 - val_loss: 1.9484\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7577 - val_accuracy: 0.4378 - val_loss: 1.9470\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7613 - loss: 0.7575 - val_accuracy: 0.4377 - val_loss: 1.9479\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7574 - val_accuracy: 0.4379 - val_loss: 1.9488\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7615 - loss: 0.7572 - val_accuracy: 0.4268 - val_loss: 1.9516\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7570 - val_accuracy: 0.4376 - val_loss: 1.9514\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7569 - val_accuracy: 0.4377 - val_loss: 1.9551\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7614 - loss: 0.7567 - val_accuracy: 0.4378 - val_loss: 1.9517\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7566 - val_accuracy: 0.4392 - val_loss: 1.9468\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7615 - loss: 0.7564 - val_accuracy: 0.4382 - val_loss: 1.9487\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7563 - val_accuracy: 0.4392 - val_loss: 1.9505\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7616 - loss: 0.7561 - val_accuracy: 0.4382 - val_loss: 1.9554\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7560 - val_accuracy: 0.4382 - val_loss: 1.9540\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7558 - val_accuracy: 0.4393 - val_loss: 1.9527\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.7557 - val_accuracy: 0.4271 - val_loss: 1.9605\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7636 - loss: 0.7555 - val_accuracy: 0.4381 - val_loss: 1.9589\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7554 - val_accuracy: 0.4381 - val_loss: 1.9584\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7553 - val_accuracy: 0.4379 - val_loss: 1.9580\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7551 - val_accuracy: 0.4393 - val_loss: 1.9527\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7665 - loss: 0.7550 - val_accuracy: 0.4393 - val_loss: 1.9548\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7549 - val_accuracy: 0.4391 - val_loss: 1.9554\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7592 - loss: 0.7547 - val_accuracy: 0.4273 - val_loss: 1.9615\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7546 - val_accuracy: 0.4393 - val_loss: 1.9565\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7545 - val_accuracy: 0.4283 - val_loss: 1.9614\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7543 - val_accuracy: 0.4283 - val_loss: 1.9623\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7542 - val_accuracy: 0.4272 - val_loss: 1.9658\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7615 - loss: 0.7541 - val_accuracy: 0.4283 - val_loss: 1.9623\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7649 - loss: 0.7539 - val_accuracy: 0.4391 - val_loss: 1.9625\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7612 - loss: 0.7538 - val_accuracy: 0.4273 - val_loss: 1.9653\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7537 - val_accuracy: 0.4273 - val_loss: 1.9660\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7536 - val_accuracy: 0.4393 - val_loss: 1.9599\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7534 - val_accuracy: 0.4393 - val_loss: 1.9600\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7533 - val_accuracy: 0.4285 - val_loss: 1.9631\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7624 - loss: 0.7532 - val_accuracy: 0.4288 - val_loss: 1.9643\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7531 - val_accuracy: 0.4394 - val_loss: 1.9661\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.7530 - val_accuracy: 0.4274 - val_loss: 1.9684\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7529 - val_accuracy: 0.4285 - val_loss: 1.9647\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7527 - val_accuracy: 0.4285 - val_loss: 1.9673\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7526 - val_accuracy: 0.4273 - val_loss: 1.9676\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7617 - loss: 0.7525 - val_accuracy: 0.4393 - val_loss: 1.9649\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7524 - val_accuracy: 0.4285 - val_loss: 1.9639\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7523 - val_accuracy: 0.4285 - val_loss: 1.9657\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7522 - val_accuracy: 0.4284 - val_loss: 1.9672\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7620 - loss: 0.7521 - val_accuracy: 0.4274 - val_loss: 1.9685\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7520 - val_accuracy: 0.4396 - val_loss: 1.9698\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7618 - loss: 0.7518 - val_accuracy: 0.4276 - val_loss: 1.9724\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7614 - loss: 0.7517 - val_accuracy: 0.4280 - val_loss: 1.9734\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.7516 - val_accuracy: 0.4286 - val_loss: 1.9681\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7612 - loss: 0.7515 - val_accuracy: 0.4286 - val_loss: 1.9703\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7596 - loss: 0.7514 - val_accuracy: 0.4280 - val_loss: 1.9742\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7513 - val_accuracy: 0.4286 - val_loss: 1.9739\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7641 - loss: 0.7512 - val_accuracy: 0.4269 - val_loss: 1.9805\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.7511 - val_accuracy: 0.4269 - val_loss: 1.9756\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7510 - val_accuracy: 0.4280 - val_loss: 1.9736\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.7509 - val_accuracy: 0.4285 - val_loss: 1.9712\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7508 - val_accuracy: 0.4249 - val_loss: 1.9756\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.7507 - val_accuracy: 0.4249 - val_loss: 1.9786\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7612 - loss: 0.7506 - val_accuracy: 0.4367 - val_loss: 1.9738\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7596 - loss: 0.7505 - val_accuracy: 0.4259 - val_loss: 1.9777\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7607 - loss: 0.7504 - val_accuracy: 0.4249 - val_loss: 1.9771\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7503 - val_accuracy: 0.4265 - val_loss: 1.9730\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7502 - val_accuracy: 0.4253 - val_loss: 1.9758\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7501 - val_accuracy: 0.4249 - val_loss: 1.9784\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7626 - loss: 0.7500 - val_accuracy: 0.4254 - val_loss: 1.9757\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7499 - val_accuracy: 0.4253 - val_loss: 1.9769\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7583 - loss: 0.7499 - val_accuracy: 0.4254 - val_loss: 1.9828\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7498 - val_accuracy: 0.4254 - val_loss: 1.9803\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7607 - loss: 0.7497 - val_accuracy: 0.4253 - val_loss: 1.9806\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.7496 - val_accuracy: 0.4254 - val_loss: 1.9788\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.7495 - val_accuracy: 0.4265 - val_loss: 1.9759\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7626 - loss: 0.7494 - val_accuracy: 0.4253 - val_loss: 1.9831\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7493 - val_accuracy: 0.4265 - val_loss: 1.9802\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7606 - loss: 0.7492 - val_accuracy: 0.4252 - val_loss: 1.9799\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7579 - loss: 0.7491 - val_accuracy: 0.4254 - val_loss: 1.9821\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.7490 - val_accuracy: 0.4254 - val_loss: 1.9842\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.7489 - val_accuracy: 0.4254 - val_loss: 1.9803\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7586 - loss: 0.7489 - val_accuracy: 0.4254 - val_loss: 1.9848\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7488 - val_accuracy: 0.4254 - val_loss: 1.9844\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7606 - loss: 0.7487 - val_accuracy: 0.4252 - val_loss: 1.9832\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7486 - val_accuracy: 0.4254 - val_loss: 1.9866\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7485 - val_accuracy: 0.4254 - val_loss: 1.9848\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7484 - val_accuracy: 0.4254 - val_loss: 1.9883\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7483 - val_accuracy: 0.4255 - val_loss: 1.9843\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7610 - loss: 0.7483 - val_accuracy: 0.4254 - val_loss: 1.9826\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7482 - val_accuracy: 0.4255 - val_loss: 1.9841\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7481 - val_accuracy: 0.4364 - val_loss: 1.9811\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7480 - val_accuracy: 0.4252 - val_loss: 1.9813\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7479 - val_accuracy: 0.4254 - val_loss: 1.9896\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7616 - loss: 0.7478 - val_accuracy: 0.4254 - val_loss: 1.9874\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7478 - val_accuracy: 0.4251 - val_loss: 1.9861\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7477 - val_accuracy: 0.4253 - val_loss: 1.9824\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7476 - val_accuracy: 0.4251 - val_loss: 1.9856\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7475 - val_accuracy: 0.4252 - val_loss: 1.9891\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7474 - val_accuracy: 0.4254 - val_loss: 1.9911\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7626 - loss: 0.7474 - val_accuracy: 0.4254 - val_loss: 1.9884\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7473 - val_accuracy: 0.4252 - val_loss: 1.9897\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7472 - val_accuracy: 0.4251 - val_loss: 1.9877\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.7471 - val_accuracy: 0.4253 - val_loss: 1.9869\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7470 - val_accuracy: 0.4252 - val_loss: 1.9909\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7470 - val_accuracy: 0.4254 - val_loss: 1.9883\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7469 - val_accuracy: 0.4253 - val_loss: 1.9878\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7468 - val_accuracy: 0.4254 - val_loss: 1.9896\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7467 - val_accuracy: 0.4253 - val_loss: 1.9909\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7467 - val_accuracy: 0.4251 - val_loss: 1.9943\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.7466 - val_accuracy: 0.4249 - val_loss: 1.9917\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.7465 - val_accuracy: 0.4249 - val_loss: 1.9875\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7641 - loss: 0.7464 - val_accuracy: 0.4248 - val_loss: 1.9976\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7464 - val_accuracy: 0.4248 - val_loss: 1.9964\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7463 - val_accuracy: 0.4247 - val_loss: 1.9914\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7462 - val_accuracy: 0.4248 - val_loss: 1.9942\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7461 - val_accuracy: 0.4247 - val_loss: 1.9884\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7461 - val_accuracy: 0.4249 - val_loss: 1.9974\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7667 - loss: 0.7460 - val_accuracy: 0.4248 - val_loss: 1.9960\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7459 - val_accuracy: 0.4250 - val_loss: 1.9958\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7459 - val_accuracy: 0.4248 - val_loss: 1.9905\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7458 - val_accuracy: 0.4250 - val_loss: 1.9977\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7457 - val_accuracy: 0.4247 - val_loss: 1.9960\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7624 - loss: 0.7456 - val_accuracy: 0.4250 - val_loss: 1.9944\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7626 - loss: 0.7456 - val_accuracy: 0.4249 - val_loss: 1.9960\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7455 - val_accuracy: 0.4250 - val_loss: 1.9959\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7454 - val_accuracy: 0.4250 - val_loss: 1.9959\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7454 - val_accuracy: 0.4249 - val_loss: 1.9970\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7616 - loss: 0.7453 - val_accuracy: 0.4250 - val_loss: 2.0018\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7669 - loss: 0.7452 - val_accuracy: 0.4249 - val_loss: 1.9992\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7612 - loss: 0.7451 - val_accuracy: 0.4249 - val_loss: 1.9974\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7647 - loss: 0.7451 - val_accuracy: 0.4249 - val_loss: 2.0013\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7450 - val_accuracy: 0.4251 - val_loss: 1.9988\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7449 - val_accuracy: 0.4249 - val_loss: 2.0030\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7449 - val_accuracy: 0.4249 - val_loss: 2.0002\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7612 - loss: 0.7448 - val_accuracy: 0.4238 - val_loss: 2.0023\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7657 - loss: 0.7447 - val_accuracy: 0.4240 - val_loss: 2.0041\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7447 - val_accuracy: 0.4240 - val_loss: 2.0004\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7446 - val_accuracy: 0.4240 - val_loss: 2.0027\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7445 - val_accuracy: 0.4239 - val_loss: 2.0007\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7445 - val_accuracy: 0.4237 - val_loss: 2.0034\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7444 - val_accuracy: 0.4237 - val_loss: 2.0031\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.7443 - val_accuracy: 0.4240 - val_loss: 2.0023\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7443 - val_accuracy: 0.4240 - val_loss: 2.0030\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7442 - val_accuracy: 0.4240 - val_loss: 2.0005\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7442 - val_accuracy: 0.4240 - val_loss: 2.0037\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7441 - val_accuracy: 0.4239 - val_loss: 2.0052\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7675 - loss: 0.7440 - val_accuracy: 0.4239 - val_loss: 2.0031\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7674 - loss: 0.7440 - val_accuracy: 0.4240 - val_loss: 2.0054\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7665 - loss: 0.7439 - val_accuracy: 0.4237 - val_loss: 2.0043\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7438 - val_accuracy: 0.4237 - val_loss: 2.0023\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7438 - val_accuracy: 0.4240 - val_loss: 2.0058\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7437 - val_accuracy: 0.4240 - val_loss: 2.0095\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7660 - loss: 0.7436 - val_accuracy: 0.4240 - val_loss: 2.0071\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7436 - val_accuracy: 0.4238 - val_loss: 2.0028\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7435 - val_accuracy: 0.4240 - val_loss: 2.0098\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7435 - val_accuracy: 0.4240 - val_loss: 2.0069\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7434 - val_accuracy: 0.4240 - val_loss: 2.0079\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7433 - val_accuracy: 0.4239 - val_loss: 2.0085\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7669 - loss: 0.7433 - val_accuracy: 0.4237 - val_loss: 2.0066\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7432 - val_accuracy: 0.4239 - val_loss: 2.0097\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7636 - loss: 0.7431 - val_accuracy: 0.4239 - val_loss: 2.0095\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7679 - loss: 0.7431 - val_accuracy: 0.4240 - val_loss: 2.0080\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7430 - val_accuracy: 0.4240 - val_loss: 2.0117\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7430 - val_accuracy: 0.4238 - val_loss: 2.0052\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7429 - val_accuracy: 0.4240 - val_loss: 2.0058\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7428 - val_accuracy: 0.4240 - val_loss: 2.0116\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7646 - loss: 0.7428 - val_accuracy: 0.4238 - val_loss: 2.0068\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7427 - val_accuracy: 0.4237 - val_loss: 2.0156\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7427 - val_accuracy: 0.4238 - val_loss: 2.0137\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7426 - val_accuracy: 0.4238 - val_loss: 2.0119\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7425 - val_accuracy: 0.4239 - val_loss: 2.0112\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7425 - val_accuracy: 0.4240 - val_loss: 2.0094\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7657 - loss: 0.7424 - val_accuracy: 0.4237 - val_loss: 2.0146\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7670 - loss: 0.7424 - val_accuracy: 0.4237 - val_loss: 2.0126\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7673 - loss: 0.7423 - val_accuracy: 0.4226 - val_loss: 2.0134\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7423 - val_accuracy: 0.4231 - val_loss: 2.0155\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7422 - val_accuracy: 0.4228 - val_loss: 2.0142\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7685 - loss: 0.7421 - val_accuracy: 0.4229 - val_loss: 2.0208\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7668 - loss: 0.7421 - val_accuracy: 0.4229 - val_loss: 2.0117\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7420 - val_accuracy: 0.4228 - val_loss: 2.0183\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7671 - loss: 0.7420 - val_accuracy: 0.4227 - val_loss: 2.0129\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7419 - val_accuracy: 0.4229 - val_loss: 2.0153\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7419 - val_accuracy: 0.4229 - val_loss: 2.0146\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7418 - val_accuracy: 0.4337 - val_loss: 2.0135\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7642 - loss: 0.7417 - val_accuracy: 0.4228 - val_loss: 2.0129\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7676 - loss: 0.7417 - val_accuracy: 0.4229 - val_loss: 2.0143\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7416 - val_accuracy: 0.4226 - val_loss: 2.0191\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7671 - loss: 0.7416 - val_accuracy: 0.4229 - val_loss: 2.0195\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7415 - val_accuracy: 0.4229 - val_loss: 2.0201\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7683 - loss: 0.7415 - val_accuracy: 0.4228 - val_loss: 2.0216\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7414 - val_accuracy: 0.4229 - val_loss: 2.0175\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7675 - loss: 0.7414 - val_accuracy: 0.4229 - val_loss: 2.0189\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7672 - loss: 0.7413 - val_accuracy: 0.4229 - val_loss: 2.0202\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7670 - loss: 0.7412 - val_accuracy: 0.4225 - val_loss: 2.0238\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7412 - val_accuracy: 0.4229 - val_loss: 2.0205\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7411 - val_accuracy: 0.4229 - val_loss: 2.0194\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7685 - loss: 0.7411 - val_accuracy: 0.4227 - val_loss: 2.0148\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7672 - loss: 0.7410 - val_accuracy: 0.4229 - val_loss: 2.0228\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7685 - loss: 0.7410 - val_accuracy: 0.4229 - val_loss: 2.0228\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7687 - loss: 0.7409 - val_accuracy: 0.4226 - val_loss: 2.0224\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7409 - val_accuracy: 0.4228 - val_loss: 2.0203\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7680 - loss: 0.7408 - val_accuracy: 0.4229 - val_loss: 2.0196\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7660 - loss: 0.7408 - val_accuracy: 0.4229 - val_loss: 2.0221\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7682 - loss: 0.7407 - val_accuracy: 0.4228 - val_loss: 2.0258\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7673 - loss: 0.7407 - val_accuracy: 0.4229 - val_loss: 2.0226\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7680 - loss: 0.7406 - val_accuracy: 0.4228 - val_loss: 2.0281\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7670 - loss: 0.7406 - val_accuracy: 0.4226 - val_loss: 2.0257\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7405 - val_accuracy: 0.4228 - val_loss: 2.0311\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7405 - val_accuracy: 0.4229 - val_loss: 2.0273\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7678 - loss: 0.7404 - val_accuracy: 0.4229 - val_loss: 2.0276\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7669 - loss: 0.7404 - val_accuracy: 0.4227 - val_loss: 2.0293\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7403 - val_accuracy: 0.4224 - val_loss: 2.0301\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7403 - val_accuracy: 0.4229 - val_loss: 2.0241\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7402 - val_accuracy: 0.4227 - val_loss: 2.0273\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7691 - loss: 0.7402 - val_accuracy: 0.4229 - val_loss: 2.0217\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7685 - loss: 0.7401 - val_accuracy: 0.4226 - val_loss: 2.0297\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.7400 - val_accuracy: 0.4226 - val_loss: 2.0270\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7682 - loss: 0.7400 - val_accuracy: 0.4226 - val_loss: 2.0274\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7399 - val_accuracy: 0.4226 - val_loss: 2.0250\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7668 - loss: 0.7399 - val_accuracy: 0.4226 - val_loss: 2.0215\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7695 - loss: 0.7399 - val_accuracy: 0.4226 - val_loss: 2.0302\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7682 - loss: 0.7398 - val_accuracy: 0.4226 - val_loss: 2.0263\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7397 - val_accuracy: 0.4225 - val_loss: 2.0285\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7397 - val_accuracy: 0.4224 - val_loss: 2.0264\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7397 - val_accuracy: 0.4226 - val_loss: 2.0314\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7666 - loss: 0.7396 - val_accuracy: 0.4226 - val_loss: 2.0266\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7665 - loss: 0.7396 - val_accuracy: 0.4226 - val_loss: 2.0268\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7672 - loss: 0.7395 - val_accuracy: 0.4226 - val_loss: 2.0274\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7680 - loss: 0.7395 - val_accuracy: 0.4226 - val_loss: 2.0284\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7671 - loss: 0.7394 - val_accuracy: 0.4226 - val_loss: 2.0268\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7696 - loss: 0.7394 - val_accuracy: 0.4226 - val_loss: 2.0297\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7672 - loss: 0.7393 - val_accuracy: 0.4222 - val_loss: 2.0292\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7393 - val_accuracy: 0.4220 - val_loss: 2.0289\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7672 - loss: 0.7392 - val_accuracy: 0.4225 - val_loss: 2.0263\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7690 - loss: 0.7392 - val_accuracy: 0.4222 - val_loss: 2.0297\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7391 - val_accuracy: 0.4222 - val_loss: 2.0329\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7690 - loss: 0.7391 - val_accuracy: 0.4222 - val_loss: 2.0311\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7680 - loss: 0.7390 - val_accuracy: 0.4220 - val_loss: 2.0322\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7684 - loss: 0.7390 - val_accuracy: 0.4222 - val_loss: 2.0311\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7389 - val_accuracy: 0.4222 - val_loss: 2.0373\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7389 - val_accuracy: 0.4222 - val_loss: 2.0322\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7677 - loss: 0.7388 - val_accuracy: 0.4222 - val_loss: 2.0299\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7689 - loss: 0.7388 - val_accuracy: 0.4331 - val_loss: 2.0294\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7697 - loss: 0.7387 - val_accuracy: 0.4220 - val_loss: 2.0351\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7673 - loss: 0.7387 - val_accuracy: 0.4222 - val_loss: 2.0342\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7699 - loss: 0.7386 - val_accuracy: 0.4220 - val_loss: 2.0329\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7686 - loss: 0.7386 - val_accuracy: 0.4222 - val_loss: 2.0346\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7701 - loss: 0.7386 - val_accuracy: 0.4221 - val_loss: 2.0357\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7693 - loss: 0.7385 - val_accuracy: 0.4220 - val_loss: 2.0339\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7385 - val_accuracy: 0.4219 - val_loss: 2.0362\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7691 - loss: 0.7384 - val_accuracy: 0.4219 - val_loss: 2.0355\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7689 - loss: 0.7384 - val_accuracy: 0.4219 - val_loss: 2.0407\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7383 - val_accuracy: 0.4219 - val_loss: 2.0362\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7718 - loss: 0.7383 - val_accuracy: 0.4219 - val_loss: 2.0390\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7697 - loss: 0.7382 - val_accuracy: 0.4219 - val_loss: 2.0351\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7698 - loss: 0.7382 - val_accuracy: 0.4218 - val_loss: 2.0353\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7702 - loss: 0.7381 - val_accuracy: 0.4218 - val_loss: 2.0378\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7701 - loss: 0.7381 - val_accuracy: 0.4219 - val_loss: 2.0409\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7696 - loss: 0.7381 - val_accuracy: 0.4218 - val_loss: 2.0390\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7700 - loss: 0.7380 - val_accuracy: 0.4219 - val_loss: 2.0402\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7711 - loss: 0.7380 - val_accuracy: 0.4217 - val_loss: 2.0402\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7691 - loss: 0.7379 - val_accuracy: 0.4219 - val_loss: 2.0388\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7704 - loss: 0.7379 - val_accuracy: 0.4217 - val_loss: 2.0396\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7378 - val_accuracy: 0.4219 - val_loss: 2.0423\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7694 - loss: 0.7378 - val_accuracy: 0.4217 - val_loss: 2.0405\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7377 - val_accuracy: 0.4219 - val_loss: 2.0409\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7701 - loss: 0.7377 - val_accuracy: 0.4219 - val_loss: 2.0394\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7690 - loss: 0.7377 - val_accuracy: 0.4219 - val_loss: 2.0411\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7694 - loss: 0.7376 - val_accuracy: 0.4219 - val_loss: 2.0408\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7701 - loss: 0.7376 - val_accuracy: 0.4219 - val_loss: 2.0411\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7694 - loss: 0.7375 - val_accuracy: 0.4219 - val_loss: 2.0404\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7723 - loss: 0.7375 - val_accuracy: 0.4217 - val_loss: 2.0416\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7722 - loss: 0.7374 - val_accuracy: 0.4218 - val_loss: 2.0485\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7713 - loss: 0.7374 - val_accuracy: 0.4218 - val_loss: 2.0468\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7722 - loss: 0.7373 - val_accuracy: 0.4219 - val_loss: 2.0425\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7700 - loss: 0.7373 - val_accuracy: 0.5562 - val_loss: 2.0400\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7727 - loss: 0.7373 - val_accuracy: 0.4218 - val_loss: 2.0451\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7721 - loss: 0.7372 - val_accuracy: 0.4218 - val_loss: 2.0413\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7372 - val_accuracy: 0.4326 - val_loss: 2.0409\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7712 - loss: 0.7371 - val_accuracy: 0.4218 - val_loss: 2.0425\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7371 - val_accuracy: 0.4218 - val_loss: 2.0430\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7370 - val_accuracy: 0.4218 - val_loss: 2.0433\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7725 - loss: 0.7370 - val_accuracy: 0.4218 - val_loss: 2.0478\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7702 - loss: 0.7370 - val_accuracy: 0.4218 - val_loss: 2.0485\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7722 - loss: 0.7369 - val_accuracy: 0.5672 - val_loss: 2.0409\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7726 - loss: 0.7369 - val_accuracy: 0.4218 - val_loss: 2.0464\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7368 - val_accuracy: 0.4328 - val_loss: 2.0428\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7368 - val_accuracy: 0.4218 - val_loss: 2.0533\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.59273\n726/726 - 10s - 14ms/step - accuracy: 0.7731 - loss: 0.7367 - val_accuracy: 0.4218 - val_loss: 2.0486\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7701 - loss: 0.7367 - val_accuracy: 0.5574 - val_loss: 2.0437\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7367 - val_accuracy: 0.5574 - val_loss: 2.0438\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7366 - val_accuracy: 0.4218 - val_loss: 2.0513\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7727 - loss: 0.7366 - val_accuracy: 0.5562 - val_loss: 2.0472\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7752 - loss: 0.7365 - val_accuracy: 0.4218 - val_loss: 2.0478\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7744 - loss: 0.7365 - val_accuracy: 0.4218 - val_loss: 2.0500\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7365 - val_accuracy: 0.4312 - val_loss: 2.0488\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7692 - loss: 0.7364 - val_accuracy: 0.5545 - val_loss: 2.0491\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7364 - val_accuracy: 0.4202 - val_loss: 2.0510\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7737 - loss: 0.7363 - val_accuracy: 0.4202 - val_loss: 2.0531\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7363 - val_accuracy: 0.4201 - val_loss: 2.0553\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7746 - loss: 0.7363 - val_accuracy: 0.5667 - val_loss: 2.0495\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7758 - loss: 0.7362 - val_accuracy: 0.5667 - val_loss: 2.0436\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7362 - val_accuracy: 0.4201 - val_loss: 2.0531\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7772 - loss: 0.7361 - val_accuracy: 0.5667 - val_loss: 2.0477\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7361 - val_accuracy: 0.5557 - val_loss: 2.0480\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7788 - loss: 0.7361 - val_accuracy: 0.4201 - val_loss: 2.0546\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7779 - loss: 0.7360 - val_accuracy: 0.5556 - val_loss: 2.0496\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7360 - val_accuracy: 0.4201 - val_loss: 2.0542\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7359 - val_accuracy: 0.5666 - val_loss: 2.0509\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7359 - val_accuracy: 0.5556 - val_loss: 2.0512\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7359 - val_accuracy: 0.4323 - val_loss: 2.0540\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7358 - val_accuracy: 0.5556 - val_loss: 2.0528\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7760 - loss: 0.7358 - val_accuracy: 0.5666 - val_loss: 2.0509\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7357 - val_accuracy: 0.5556 - val_loss: 2.0508\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7810 - loss: 0.7357 - val_accuracy: 0.4213 - val_loss: 2.0549\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7816 - loss: 0.7357 - val_accuracy: 0.5556 - val_loss: 2.0531\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7817 - loss: 0.7356 - val_accuracy: 0.4213 - val_loss: 2.0543\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7810 - loss: 0.7356 - val_accuracy: 0.4201 - val_loss: 2.0631\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7798 - loss: 0.7355 - val_accuracy: 0.5666 - val_loss: 2.0531\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7355 - val_accuracy: 0.5665 - val_loss: 2.0563\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7817 - loss: 0.7355 - val_accuracy: 0.5556 - val_loss: 2.0565\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7816 - loss: 0.7354 - val_accuracy: 0.5664 - val_loss: 2.0558\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7354 - val_accuracy: 0.5555 - val_loss: 2.0574\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7353 - val_accuracy: 0.5555 - val_loss: 2.0554\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7824 - loss: 0.7353 - val_accuracy: 0.5555 - val_loss: 2.0571\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7353 - val_accuracy: 0.5555 - val_loss: 2.0548\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7352 - val_accuracy: 0.5664 - val_loss: 2.0584\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7814 - loss: 0.7352 - val_accuracy: 0.5555 - val_loss: 2.0599\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7812 - loss: 0.7352 - val_accuracy: 0.5663 - val_loss: 2.0585\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7351 - val_accuracy: 0.5664 - val_loss: 2.0587\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7824 - loss: 0.7351 - val_accuracy: 0.5555 - val_loss: 2.0567\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7803 - loss: 0.7350 - val_accuracy: 0.5664 - val_loss: 2.0567\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7350 - val_accuracy: 0.5664 - val_loss: 2.0568\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7799 - loss: 0.7350 - val_accuracy: 0.5553 - val_loss: 2.0562\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7816 - loss: 0.7349 - val_accuracy: 0.5554 - val_loss: 2.0629\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7815 - loss: 0.7349 - val_accuracy: 0.5664 - val_loss: 2.0574\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7830 - loss: 0.7348 - val_accuracy: 0.5555 - val_loss: 2.0605\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7348 - val_accuracy: 0.5554 - val_loss: 2.0627\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7348 - val_accuracy: 0.5664 - val_loss: 2.0607\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7823 - loss: 0.7347 - val_accuracy: 0.5664 - val_loss: 2.0560\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7347 - val_accuracy: 0.5664 - val_loss: 2.0619\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7347 - val_accuracy: 0.5555 - val_loss: 2.0595\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7827 - loss: 0.7346 - val_accuracy: 0.5664 - val_loss: 2.0583\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7346 - val_accuracy: 0.5555 - val_loss: 2.0633\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7346 - val_accuracy: 0.5664 - val_loss: 2.0610\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7345 - val_accuracy: 0.5664 - val_loss: 2.0625\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7345 - val_accuracy: 0.5554 - val_loss: 2.0625\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7344 - val_accuracy: 0.5664 - val_loss: 2.0623\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7833 - loss: 0.7344 - val_accuracy: 0.5663 - val_loss: 2.0606\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7344 - val_accuracy: 0.5664 - val_loss: 2.0577\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7343 - val_accuracy: 0.5664 - val_loss: 2.0595\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7343 - val_accuracy: 0.5554 - val_loss: 2.0600\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7343 - val_accuracy: 0.5664 - val_loss: 2.0628\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7342 - val_accuracy: 0.5551 - val_loss: 2.0640\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7342 - val_accuracy: 0.5664 - val_loss: 2.0611\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7341 - val_accuracy: 0.5664 - val_loss: 2.0611\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7341 - val_accuracy: 0.5664 - val_loss: 2.0625\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7341 - val_accuracy: 0.5554 - val_loss: 2.0640\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7340 - val_accuracy: 0.5663 - val_loss: 2.0635\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7340 - val_accuracy: 0.5661 - val_loss: 2.0651\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7340 - val_accuracy: 0.5661 - val_loss: 2.0633\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7833 - loss: 0.7339 - val_accuracy: 0.5554 - val_loss: 2.0648\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7339 - val_accuracy: 0.5661 - val_loss: 2.0671\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7339 - val_accuracy: 0.5664 - val_loss: 2.0627\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7338 - val_accuracy: 0.5659 - val_loss: 2.0665\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7338 - val_accuracy: 0.5550 - val_loss: 2.0696\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7338 - val_accuracy: 0.5664 - val_loss: 2.0650\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7834 - loss: 0.7337 - val_accuracy: 0.5664 - val_loss: 2.0656\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7337 - val_accuracy: 0.5663 - val_loss: 2.0654\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7336 - val_accuracy: 0.5660 - val_loss: 2.0686\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7336 - val_accuracy: 0.5658 - val_loss: 2.0679\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7336 - val_accuracy: 0.5663 - val_loss: 2.0633\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7335 - val_accuracy: 0.5538 - val_loss: 2.0705\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7831 - loss: 0.7335 - val_accuracy: 0.5655 - val_loss: 2.0664\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7335 - val_accuracy: 0.5655 - val_loss: 2.0655\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7334 - val_accuracy: 0.5649 - val_loss: 2.0667\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7334 - val_accuracy: 0.5649 - val_loss: 2.0687\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7334 - val_accuracy: 0.5648 - val_loss: 2.0670\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7333 - val_accuracy: 0.5648 - val_loss: 2.0683\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7333 - val_accuracy: 0.5648 - val_loss: 2.0706\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7333 - val_accuracy: 0.5649 - val_loss: 2.0688\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7332 - val_accuracy: 0.5647 - val_loss: 2.0702\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7332 - val_accuracy: 0.5647 - val_loss: 2.0696\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7332 - val_accuracy: 0.5651 - val_loss: 2.0689\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7331 - val_accuracy: 0.5648 - val_loss: 2.0705\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7331 - val_accuracy: 0.5647 - val_loss: 2.0716\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7331 - val_accuracy: 0.5647 - val_loss: 2.0759\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7330 - val_accuracy: 0.5647 - val_loss: 2.0734\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7330 - val_accuracy: 0.5647 - val_loss: 2.0732\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7330 - val_accuracy: 0.5648 - val_loss: 2.0710\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7329 - val_accuracy: 0.5645 - val_loss: 2.0758\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7834 - loss: 0.7329 - val_accuracy: 0.5648 - val_loss: 2.0687\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7329 - val_accuracy: 0.5645 - val_loss: 2.0724\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7328 - val_accuracy: 0.5644 - val_loss: 2.0721\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7328 - val_accuracy: 0.5644 - val_loss: 2.0707\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7823 - loss: 0.7328 - val_accuracy: 0.5645 - val_loss: 2.0767\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7327 - val_accuracy: 0.5645 - val_loss: 2.0748\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7327 - val_accuracy: 0.5645 - val_loss: 2.0744\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7327 - val_accuracy: 0.5645 - val_loss: 2.0756\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7326 - val_accuracy: 0.5645 - val_loss: 2.0721\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7326 - val_accuracy: 0.5645 - val_loss: 2.0741\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7326 - val_accuracy: 0.5645 - val_loss: 2.0741\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7325 - val_accuracy: 0.5644 - val_loss: 2.0755\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.59273\n726/726 - 5s - 8ms/step - accuracy: 0.7830 - loss: 0.7325 - val_accuracy: 0.5645 - val_loss: 2.0746\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7325 - val_accuracy: 0.5645 - val_loss: 2.0782\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7324 - val_accuracy: 0.5647 - val_loss: 2.0755\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7324 - val_accuracy: 0.5647 - val_loss: 2.0721\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7324 - val_accuracy: 0.5645 - val_loss: 2.0780\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7323 - val_accuracy: 0.5534 - val_loss: 2.0781\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7323 - val_accuracy: 0.5645 - val_loss: 2.0785\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7323 - val_accuracy: 0.5647 - val_loss: 2.0766\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7322 - val_accuracy: 0.5645 - val_loss: 2.0774\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7322 - val_accuracy: 0.5645 - val_loss: 2.0786\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7322 - val_accuracy: 0.5535 - val_loss: 2.0824\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7321 - val_accuracy: 0.5647 - val_loss: 2.0778\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7321 - val_accuracy: 0.5647 - val_loss: 2.0813\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7321 - val_accuracy: 0.5647 - val_loss: 2.0790\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7320 - val_accuracy: 0.5646 - val_loss: 2.0818\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7320 - val_accuracy: 0.5647 - val_loss: 2.0785\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7829 - loss: 0.7320 - val_accuracy: 0.5647 - val_loss: 2.0821\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7319 - val_accuracy: 0.5647 - val_loss: 2.0796\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7319 - val_accuracy: 0.5647 - val_loss: 2.0786\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7319 - val_accuracy: 0.5647 - val_loss: 2.0821\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7318 - val_accuracy: 0.5647 - val_loss: 2.0813\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7318 - val_accuracy: 0.5647 - val_loss: 2.0768\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7318 - val_accuracy: 0.5647 - val_loss: 2.0821\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7317 - val_accuracy: 0.5537 - val_loss: 2.0830\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7317 - val_accuracy: 0.5647 - val_loss: 2.0837\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7817 - loss: 0.7317 - val_accuracy: 0.5647 - val_loss: 2.0853\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7316 - val_accuracy: 0.5646 - val_loss: 2.0791\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7316 - val_accuracy: 0.5647 - val_loss: 2.0779\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7316 - val_accuracy: 0.5647 - val_loss: 2.0859\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7315 - val_accuracy: 0.5647 - val_loss: 2.0795\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7315 - val_accuracy: 0.5647 - val_loss: 2.0832\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.59273\n726/726 - 6s - 8ms/step - accuracy: 0.7827 - loss: 0.7315 - val_accuracy: 0.5647 - val_loss: 2.0819\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.59273\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7314 - val_accuracy: 0.5646 - val_loss: 2.0815\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_6, X_test_6, y_train_6, y_test_6 = train_test_split(\n    X, y, test_size=0.3, random_state=48, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_6, X_val_6, y_train_6, y_val_6 = train_test_split(\n    X_train_6, y_train_6, test_size=0.2, random_state=48, stratify=y_train_6\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_6:\", np.max(X_train_6))\nprint(\"Min value in X_train_6:\", np.min(X_train_6))\n\nX_train_6_scaled = scaler.fit_transform(X_train_6)\n\n# Get the original class distribution\nclass_counts_6 = Counter(y_train_6)\nprint(\"Original class distribution:\", class_counts_6)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_6 = class_counts_6[min(class_counts_6, key=class_counts_6.get)]\ndesired_majority_size_6 = minority_class_size_6 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_6 = {0: desired_majority_size_6, 1: minority_class_size_6}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_6 = RandomUnderSampler(sampling_strategy=sampling_strategy_6, random_state=42)\nX_resampled_6, y_resampled_6 = undersampler_6.fit_resample(X_train_6, y_train_6)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_6))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_6, y_train_resampled_6 = smote.fit_resample(X_resampled_6, y_resampled_6)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_6))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:16:23.577932Z","iopub.execute_input":"2025-03-06T23:16:23.578498Z","iopub.status.idle":"2025-03-06T23:16:57.720504Z","shell.execute_reply.started":"2025-03-06T23:16:23.578447Z","shell.execute_reply":"2025-03-06T23:16:57.719557Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_6: 2071000000.0\nMin value in X_train_6: -9663668122.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_6 = X_train_resampled_6.reshape(X_train_resampled_6.shape[0], 1, 56)\nX_val_6 = X_val_6.reshape(X_val_6.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_6,  # Features from CICIDS2017\n    y_train_resampled_6,  # Labels from CICIDS2017\n    validation_data=(X_val_6, y_val_6),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:16:57.721873Z","iopub.execute_input":"2025-03-06T23:16:57.722220Z","iopub.status.idle":"2025-03-07T00:02:17.402706Z","shell.execute_reply.started":"2025-03-06T23:16:57.722180Z","shell.execute_reply":"2025-03-07T00:02:17.401130Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy improved from -inf to 0.57787, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 8s - 12ms/step - accuracy: 0.7832 - loss: 0.7609 - val_accuracy: 0.5779 - val_loss: 1.8101\nEpoch 2/500\n\nEpoch 2: val_accuracy improved from 0.57787 to 0.58107, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7552 - val_accuracy: 0.5811 - val_loss: 1.8033\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7888 - loss: 0.7523 - val_accuracy: 0.5802 - val_loss: 1.7981\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7861 - loss: 0.7503 - val_accuracy: 0.5802 - val_loss: 1.7860\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7840 - loss: 0.7488 - val_accuracy: 0.5759 - val_loss: 1.7812\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7837 - loss: 0.7476 - val_accuracy: 0.5756 - val_loss: 1.7713\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7842 - loss: 0.7467 - val_accuracy: 0.5756 - val_loss: 1.7687\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7459 - val_accuracy: 0.5754 - val_loss: 1.7625\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7847 - loss: 0.7453 - val_accuracy: 0.5753 - val_loss: 1.7584\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7849 - loss: 0.7447 - val_accuracy: 0.5753 - val_loss: 1.7600\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7849 - loss: 0.7441 - val_accuracy: 0.5753 - val_loss: 1.7525\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7849 - loss: 0.7436 - val_accuracy: 0.5750 - val_loss: 1.7620\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7849 - loss: 0.7432 - val_accuracy: 0.5751 - val_loss: 1.7589\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7850 - loss: 0.7427 - val_accuracy: 0.5628 - val_loss: 1.7625\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7854 - loss: 0.7423 - val_accuracy: 0.5610 - val_loss: 1.7600\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7863 - loss: 0.7419 - val_accuracy: 0.5616 - val_loss: 1.7573\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7415 - val_accuracy: 0.5616 - val_loss: 1.7548\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7412 - val_accuracy: 0.5614 - val_loss: 1.7618\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7408 - val_accuracy: 0.5557 - val_loss: 1.7656\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7405 - val_accuracy: 0.5559 - val_loss: 1.7661\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7401 - val_accuracy: 0.5562 - val_loss: 1.7625\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7398 - val_accuracy: 0.5562 - val_loss: 1.7690\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7395 - val_accuracy: 0.5562 - val_loss: 1.7677\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7392 - val_accuracy: 0.5562 - val_loss: 1.7723\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7389 - val_accuracy: 0.5562 - val_loss: 1.7691\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7386 - val_accuracy: 0.5545 - val_loss: 1.7751\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7383 - val_accuracy: 0.5567 - val_loss: 1.7768\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7868 - loss: 0.7380 - val_accuracy: 0.5545 - val_loss: 1.7757\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7377 - val_accuracy: 0.5567 - val_loss: 1.7803\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7374 - val_accuracy: 0.5567 - val_loss: 1.7783\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7372 - val_accuracy: 0.5498 - val_loss: 1.7838\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7369 - val_accuracy: 0.5566 - val_loss: 1.7820\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7366 - val_accuracy: 0.5565 - val_loss: 1.7867\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7875 - loss: 0.7364 - val_accuracy: 0.5519 - val_loss: 1.7877\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7868 - loss: 0.7361 - val_accuracy: 0.5520 - val_loss: 1.7918\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7359 - val_accuracy: 0.5515 - val_loss: 1.7894\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7871 - loss: 0.7356 - val_accuracy: 0.5511 - val_loss: 1.7920\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7354 - val_accuracy: 0.5511 - val_loss: 1.7938\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7352 - val_accuracy: 0.5513 - val_loss: 1.7885\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7884 - loss: 0.7349 - val_accuracy: 0.5509 - val_loss: 1.7926\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7347 - val_accuracy: 0.5490 - val_loss: 1.7949\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7345 - val_accuracy: 0.5491 - val_loss: 1.7953\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7343 - val_accuracy: 0.5490 - val_loss: 1.7999\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.7340 - val_accuracy: 0.5491 - val_loss: 1.7985\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7338 - val_accuracy: 0.5491 - val_loss: 1.8005\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7892 - loss: 0.7336 - val_accuracy: 0.5491 - val_loss: 1.8054\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7334 - val_accuracy: 0.5489 - val_loss: 1.8081\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7905 - loss: 0.7332 - val_accuracy: 0.5489 - val_loss: 1.8067\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7330 - val_accuracy: 0.5490 - val_loss: 1.8047\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7899 - loss: 0.7328 - val_accuracy: 0.5488 - val_loss: 1.8091\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7899 - loss: 0.7326 - val_accuracy: 0.5489 - val_loss: 1.8077\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7921 - loss: 0.7324 - val_accuracy: 0.5491 - val_loss: 1.8073\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7913 - loss: 0.7322 - val_accuracy: 0.5491 - val_loss: 1.8100\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7927 - loss: 0.7320 - val_accuracy: 0.5489 - val_loss: 1.8156\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7926 - loss: 0.7318 - val_accuracy: 0.5490 - val_loss: 1.8171\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.58107\n726/726 - 6s - 9ms/step - accuracy: 0.7937 - loss: 0.7316 - val_accuracy: 0.5488 - val_loss: 1.8146\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.58107\n726/726 - 8s - 10ms/step - accuracy: 0.7917 - loss: 0.7314 - val_accuracy: 0.5489 - val_loss: 1.8116\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.58107\n726/726 - 7s - 9ms/step - accuracy: 0.7932 - loss: 0.7312 - val_accuracy: 0.5487 - val_loss: 1.8160\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7927 - loss: 0.7310 - val_accuracy: 0.5486 - val_loss: 1.8159\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.58107\n726/726 - 6s - 9ms/step - accuracy: 0.7936 - loss: 0.7308 - val_accuracy: 0.5489 - val_loss: 1.8158\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7938 - loss: 0.7306 - val_accuracy: 0.5484 - val_loss: 1.8231\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.58107\n726/726 - 6s - 9ms/step - accuracy: 0.7936 - loss: 0.7304 - val_accuracy: 0.5485 - val_loss: 1.8220\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.58107\n726/726 - 7s - 9ms/step - accuracy: 0.7936 - loss: 0.7303 - val_accuracy: 0.5485 - val_loss: 1.8189\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7936 - loss: 0.7301 - val_accuracy: 0.5484 - val_loss: 1.8248\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7938 - loss: 0.7299 - val_accuracy: 0.5484 - val_loss: 1.8278\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7297 - val_accuracy: 0.5484 - val_loss: 1.8271\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7942 - loss: 0.7295 - val_accuracy: 0.5464 - val_loss: 1.8262\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7932 - loss: 0.7294 - val_accuracy: 0.5464 - val_loss: 1.8283\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7937 - loss: 0.7292 - val_accuracy: 0.5464 - val_loss: 1.8275\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7933 - loss: 0.7290 - val_accuracy: 0.5463 - val_loss: 1.8320\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7937 - loss: 0.7288 - val_accuracy: 0.5463 - val_loss: 1.8334\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7287 - val_accuracy: 0.5431 - val_loss: 1.8352\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7939 - loss: 0.7285 - val_accuracy: 0.5431 - val_loss: 1.8316\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7283 - val_accuracy: 0.5431 - val_loss: 1.8338\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7282 - val_accuracy: 0.5431 - val_loss: 1.8375\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7280 - val_accuracy: 0.5432 - val_loss: 1.8330\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7278 - val_accuracy: 0.5431 - val_loss: 1.8369\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7277 - val_accuracy: 0.5432 - val_loss: 1.8366\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7959 - loss: 0.7275 - val_accuracy: 0.5432 - val_loss: 1.8382\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7960 - loss: 0.7274 - val_accuracy: 0.5432 - val_loss: 1.8356\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7272 - val_accuracy: 0.5432 - val_loss: 1.8376\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7270 - val_accuracy: 0.5432 - val_loss: 1.8450\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7960 - loss: 0.7269 - val_accuracy: 0.5432 - val_loss: 1.8392\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7960 - loss: 0.7267 - val_accuracy: 0.5399 - val_loss: 1.8420\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7955 - loss: 0.7266 - val_accuracy: 0.5430 - val_loss: 1.8413\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7960 - loss: 0.7264 - val_accuracy: 0.5398 - val_loss: 1.8417\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7263 - val_accuracy: 0.5398 - val_loss: 1.8457\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7261 - val_accuracy: 0.5398 - val_loss: 1.8499\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7960 - loss: 0.7260 - val_accuracy: 0.5398 - val_loss: 1.8505\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7961 - loss: 0.7258 - val_accuracy: 0.5398 - val_loss: 1.8493\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7960 - loss: 0.7257 - val_accuracy: 0.5397 - val_loss: 1.8496\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7962 - loss: 0.7255 - val_accuracy: 0.5397 - val_loss: 1.8537\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7254 - val_accuracy: 0.5397 - val_loss: 1.8539\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7252 - val_accuracy: 0.5397 - val_loss: 1.8543\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7962 - loss: 0.7251 - val_accuracy: 0.5405 - val_loss: 1.8510\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7249 - val_accuracy: 0.5405 - val_loss: 1.8532\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7963 - loss: 0.7248 - val_accuracy: 0.5405 - val_loss: 1.8541\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7246 - val_accuracy: 0.5394 - val_loss: 1.8588\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7245 - val_accuracy: 0.5395 - val_loss: 1.8513\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7244 - val_accuracy: 0.5394 - val_loss: 1.8581\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.7242 - val_accuracy: 0.5394 - val_loss: 1.8550\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7241 - val_accuracy: 0.5394 - val_loss: 1.8552\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7963 - loss: 0.7239 - val_accuracy: 0.5352 - val_loss: 1.8594\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7238 - val_accuracy: 0.5352 - val_loss: 1.8627\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7964 - loss: 0.7237 - val_accuracy: 0.5352 - val_loss: 1.8610\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7966 - loss: 0.7235 - val_accuracy: 0.5352 - val_loss: 1.8663\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7965 - loss: 0.7234 - val_accuracy: 0.5352 - val_loss: 1.8637\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7963 - loss: 0.7232 - val_accuracy: 0.5352 - val_loss: 1.8631\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7966 - loss: 0.7231 - val_accuracy: 0.5460 - val_loss: 1.8578\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.7230 - val_accuracy: 0.5351 - val_loss: 1.8635\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.7228 - val_accuracy: 0.5351 - val_loss: 1.8650\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7227 - val_accuracy: 0.5350 - val_loss: 1.8677\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7226 - val_accuracy: 0.5350 - val_loss: 1.8685\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7966 - loss: 0.7224 - val_accuracy: 0.5350 - val_loss: 1.8668\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7969 - loss: 0.7223 - val_accuracy: 0.5350 - val_loss: 1.8683\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7222 - val_accuracy: 0.5349 - val_loss: 1.8685\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7221 - val_accuracy: 0.5349 - val_loss: 1.8720\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7219 - val_accuracy: 0.5349 - val_loss: 1.8721\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7218 - val_accuracy: 0.5349 - val_loss: 1.8683\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7971 - loss: 0.7217 - val_accuracy: 0.5349 - val_loss: 1.8709\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7968 - loss: 0.7215 - val_accuracy: 0.5346 - val_loss: 1.8730\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7214 - val_accuracy: 0.5343 - val_loss: 1.8730\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7972 - loss: 0.7213 - val_accuracy: 0.5455 - val_loss: 1.8707\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7970 - loss: 0.7212 - val_accuracy: 0.5346 - val_loss: 1.8736\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7973 - loss: 0.7210 - val_accuracy: 0.5343 - val_loss: 1.8757\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7975 - loss: 0.7209 - val_accuracy: 0.5346 - val_loss: 1.8751\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7974 - loss: 0.7208 - val_accuracy: 0.5343 - val_loss: 1.8783\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7976 - loss: 0.7207 - val_accuracy: 0.5343 - val_loss: 1.8747\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7975 - loss: 0.7206 - val_accuracy: 0.5452 - val_loss: 1.8731\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7976 - loss: 0.7204 - val_accuracy: 0.5340 - val_loss: 1.8776\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7977 - loss: 0.7203 - val_accuracy: 0.5449 - val_loss: 1.8775\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7977 - loss: 0.7202 - val_accuracy: 0.5449 - val_loss: 1.8786\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7978 - loss: 0.7201 - val_accuracy: 0.5339 - val_loss: 1.8793\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7977 - loss: 0.7200 - val_accuracy: 0.5340 - val_loss: 1.8787\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7198 - val_accuracy: 0.5340 - val_loss: 1.8843\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7976 - loss: 0.7197 - val_accuracy: 0.5449 - val_loss: 1.8779\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7978 - loss: 0.7196 - val_accuracy: 0.5339 - val_loss: 1.8825\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7977 - loss: 0.7195 - val_accuracy: 0.5339 - val_loss: 1.8866\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7978 - loss: 0.7194 - val_accuracy: 0.5340 - val_loss: 1.8832\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7976 - loss: 0.7193 - val_accuracy: 0.5448 - val_loss: 1.8822\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7192 - val_accuracy: 0.5340 - val_loss: 1.8834\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7980 - loss: 0.7190 - val_accuracy: 0.5339 - val_loss: 1.8840\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.7189 - val_accuracy: 0.5450 - val_loss: 1.8825\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7979 - loss: 0.7188 - val_accuracy: 0.5448 - val_loss: 1.8873\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7187 - val_accuracy: 0.5340 - val_loss: 1.8831\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.7186 - val_accuracy: 0.5339 - val_loss: 1.8889\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7979 - loss: 0.7185 - val_accuracy: 0.5339 - val_loss: 1.8908\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7184 - val_accuracy: 0.5449 - val_loss: 1.8867\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.7183 - val_accuracy: 0.5449 - val_loss: 1.8870\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.7181 - val_accuracy: 0.5439 - val_loss: 1.8904\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.7180 - val_accuracy: 0.5449 - val_loss: 1.8856\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7179 - val_accuracy: 0.5330 - val_loss: 1.8950\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.7178 - val_accuracy: 0.5438 - val_loss: 1.8908\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7177 - val_accuracy: 0.5439 - val_loss: 1.8915\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7176 - val_accuracy: 0.5438 - val_loss: 1.8935\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.7175 - val_accuracy: 0.5440 - val_loss: 1.8875\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.7174 - val_accuracy: 0.5438 - val_loss: 1.8913\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7173 - val_accuracy: 0.5328 - val_loss: 1.8939\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7984 - loss: 0.7172 - val_accuracy: 0.5438 - val_loss: 1.8942\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7171 - val_accuracy: 0.5437 - val_loss: 1.8963\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.7170 - val_accuracy: 0.5438 - val_loss: 1.8926\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7169 - val_accuracy: 0.5437 - val_loss: 1.8970\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7168 - val_accuracy: 0.5437 - val_loss: 1.8982\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.7167 - val_accuracy: 0.5437 - val_loss: 1.8962\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7166 - val_accuracy: 0.5437 - val_loss: 1.8999\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7165 - val_accuracy: 0.5439 - val_loss: 1.8950\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7164 - val_accuracy: 0.5439 - val_loss: 1.8948\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7163 - val_accuracy: 0.5439 - val_loss: 1.8948\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7162 - val_accuracy: 0.5432 - val_loss: 1.9018\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7161 - val_accuracy: 0.5432 - val_loss: 1.9038\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7160 - val_accuracy: 0.5434 - val_loss: 1.8965\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7159 - val_accuracy: 0.5433 - val_loss: 1.9005\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7158 - val_accuracy: 0.5432 - val_loss: 1.9005\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7157 - val_accuracy: 0.5321 - val_loss: 1.9043\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7156 - val_accuracy: 0.5431 - val_loss: 1.9026\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7155 - val_accuracy: 0.5431 - val_loss: 1.9027\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7154 - val_accuracy: 0.5431 - val_loss: 1.9036\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7153 - val_accuracy: 0.5431 - val_loss: 1.9013\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7152 - val_accuracy: 0.5429 - val_loss: 1.9058\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7151 - val_accuracy: 0.5427 - val_loss: 1.9059\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7150 - val_accuracy: 0.5428 - val_loss: 1.9050\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7149 - val_accuracy: 0.5427 - val_loss: 1.9092\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7148 - val_accuracy: 0.5429 - val_loss: 1.9052\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7147 - val_accuracy: 0.5429 - val_loss: 1.9073\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7146 - val_accuracy: 0.5428 - val_loss: 1.9080\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7145 - val_accuracy: 0.5428 - val_loss: 1.9099\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7144 - val_accuracy: 0.5428 - val_loss: 1.9064\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7143 - val_accuracy: 0.5428 - val_loss: 1.9067\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7142 - val_accuracy: 0.5426 - val_loss: 1.9126\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7141 - val_accuracy: 0.5427 - val_loss: 1.9062\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7140 - val_accuracy: 0.5426 - val_loss: 1.9129\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7140 - val_accuracy: 0.5315 - val_loss: 1.9123\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.7139 - val_accuracy: 0.5426 - val_loss: 1.9114\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7138 - val_accuracy: 0.5424 - val_loss: 1.9123\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7137 - val_accuracy: 0.5424 - val_loss: 1.9138\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7136 - val_accuracy: 0.5426 - val_loss: 1.9104\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7135 - val_accuracy: 0.5424 - val_loss: 1.9136\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7134 - val_accuracy: 0.5423 - val_loss: 1.9150\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7133 - val_accuracy: 0.5423 - val_loss: 1.9150\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7132 - val_accuracy: 0.5423 - val_loss: 1.9170\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7131 - val_accuracy: 0.5423 - val_loss: 1.9149\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7131 - val_accuracy: 0.5423 - val_loss: 1.9136\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7130 - val_accuracy: 0.5423 - val_loss: 1.9141\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7129 - val_accuracy: 0.5423 - val_loss: 1.9146\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7128 - val_accuracy: 0.5423 - val_loss: 1.9171\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7127 - val_accuracy: 0.5423 - val_loss: 1.9147\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7126 - val_accuracy: 0.5423 - val_loss: 1.9150\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7125 - val_accuracy: 0.5423 - val_loss: 1.9189\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7125 - val_accuracy: 0.5422 - val_loss: 1.9203\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7124 - val_accuracy: 0.5415 - val_loss: 1.9224\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7986 - loss: 0.7123 - val_accuracy: 0.5422 - val_loss: 1.9185\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7122 - val_accuracy: 0.5436 - val_loss: 1.9168\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7121 - val_accuracy: 0.5436 - val_loss: 1.9235\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7120 - val_accuracy: 0.5422 - val_loss: 1.9226\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7119 - val_accuracy: 0.5436 - val_loss: 1.9231\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7119 - val_accuracy: 0.5422 - val_loss: 1.9206\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7118 - val_accuracy: 0.5422 - val_loss: 1.9216\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7117 - val_accuracy: 0.5415 - val_loss: 1.9250\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7116 - val_accuracy: 0.5415 - val_loss: 1.9252\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7115 - val_accuracy: 0.5415 - val_loss: 1.9230\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7115 - val_accuracy: 0.5414 - val_loss: 1.9196\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7114 - val_accuracy: 0.5415 - val_loss: 1.9281\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7113 - val_accuracy: 0.5414 - val_loss: 1.9232\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7112 - val_accuracy: 0.5414 - val_loss: 1.9281\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7111 - val_accuracy: 0.5414 - val_loss: 1.9299\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7111 - val_accuracy: 0.5414 - val_loss: 1.9229\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7110 - val_accuracy: 0.5414 - val_loss: 1.9270\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.7109 - val_accuracy: 0.5414 - val_loss: 1.9266\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7108 - val_accuracy: 0.5414 - val_loss: 1.9285\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7107 - val_accuracy: 0.5413 - val_loss: 1.9329\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7107 - val_accuracy: 0.5413 - val_loss: 1.9291\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7106 - val_accuracy: 0.5413 - val_loss: 1.9298\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7105 - val_accuracy: 0.5413 - val_loss: 1.9290\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7104 - val_accuracy: 0.5413 - val_loss: 1.9300\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7103 - val_accuracy: 0.5413 - val_loss: 1.9289\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7103 - val_accuracy: 0.5413 - val_loss: 1.9379\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7102 - val_accuracy: 0.5413 - val_loss: 1.9333\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7101 - val_accuracy: 0.5429 - val_loss: 1.9299\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7100 - val_accuracy: 0.5413 - val_loss: 1.9306\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7100 - val_accuracy: 0.5429 - val_loss: 1.9288\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7099 - val_accuracy: 0.5413 - val_loss: 1.9322\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7098 - val_accuracy: 0.5413 - val_loss: 1.9341\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7097 - val_accuracy: 0.5413 - val_loss: 1.9337\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7097 - val_accuracy: 0.5413 - val_loss: 1.9311\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7986 - loss: 0.7096 - val_accuracy: 0.5413 - val_loss: 1.9373\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7095 - val_accuracy: 0.5413 - val_loss: 1.9346\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7094 - val_accuracy: 0.5413 - val_loss: 1.9374\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7094 - val_accuracy: 0.5413 - val_loss: 1.9384\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.7093 - val_accuracy: 0.5413 - val_loss: 1.9368\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7092 - val_accuracy: 0.5416 - val_loss: 1.9346\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7091 - val_accuracy: 0.5413 - val_loss: 1.9338\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7091 - val_accuracy: 0.5413 - val_loss: 1.9364\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7090 - val_accuracy: 0.5426 - val_loss: 1.9371\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7985 - loss: 0.7089 - val_accuracy: 0.5413 - val_loss: 1.9408\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7088 - val_accuracy: 0.5413 - val_loss: 1.9378\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7088 - val_accuracy: 0.5413 - val_loss: 1.9427\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7087 - val_accuracy: 0.5414 - val_loss: 1.9423\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7086 - val_accuracy: 0.5414 - val_loss: 1.9432\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7086 - val_accuracy: 0.5414 - val_loss: 1.9436\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.7085 - val_accuracy: 0.5414 - val_loss: 1.9391\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7084 - val_accuracy: 0.5417 - val_loss: 1.9369\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7084 - val_accuracy: 0.5417 - val_loss: 1.9392\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7083 - val_accuracy: 0.5417 - val_loss: 1.9391\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7082 - val_accuracy: 0.5417 - val_loss: 1.9399\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7986 - loss: 0.7081 - val_accuracy: 0.5417 - val_loss: 1.9424\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7081 - val_accuracy: 0.5414 - val_loss: 1.9453\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7080 - val_accuracy: 0.5414 - val_loss: 1.9430\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7079 - val_accuracy: 0.5417 - val_loss: 1.9411\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7079 - val_accuracy: 0.5414 - val_loss: 1.9448\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7078 - val_accuracy: 0.5417 - val_loss: 1.9483\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7077 - val_accuracy: 0.5414 - val_loss: 1.9495\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7077 - val_accuracy: 0.5414 - val_loss: 1.9503\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7076 - val_accuracy: 0.5417 - val_loss: 1.9468\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7075 - val_accuracy: 0.5417 - val_loss: 1.9469\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7075 - val_accuracy: 0.5417 - val_loss: 1.9449\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7074 - val_accuracy: 0.5417 - val_loss: 1.9454\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7073 - val_accuracy: 0.5417 - val_loss: 1.9491\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7986 - loss: 0.7073 - val_accuracy: 0.5414 - val_loss: 1.9502\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7072 - val_accuracy: 0.5417 - val_loss: 1.9487\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7071 - val_accuracy: 0.5417 - val_loss: 1.9449\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7071 - val_accuracy: 0.5417 - val_loss: 1.9450\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7070 - val_accuracy: 0.5406 - val_loss: 1.9486\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7069 - val_accuracy: 0.5406 - val_loss: 1.9528\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7069 - val_accuracy: 0.5403 - val_loss: 1.9488\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7068 - val_accuracy: 0.5406 - val_loss: 1.9484\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7067 - val_accuracy: 0.5404 - val_loss: 1.9512\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7067 - val_accuracy: 0.5404 - val_loss: 1.9541\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7066 - val_accuracy: 0.5407 - val_loss: 1.9511\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.7065 - val_accuracy: 0.5407 - val_loss: 1.9477\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7065 - val_accuracy: 0.5407 - val_loss: 1.9489\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7064 - val_accuracy: 0.5407 - val_loss: 1.9548\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.7063 - val_accuracy: 0.5403 - val_loss: 1.9534\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7063 - val_accuracy: 0.5406 - val_loss: 1.9546\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7062 - val_accuracy: 0.5405 - val_loss: 1.9544\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.7061 - val_accuracy: 0.5402 - val_loss: 1.9565\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7061 - val_accuracy: 0.5407 - val_loss: 1.9501\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.7060 - val_accuracy: 0.5406 - val_loss: 1.9576\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7060 - val_accuracy: 0.5406 - val_loss: 1.9536\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7059 - val_accuracy: 0.5406 - val_loss: 1.9508\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7058 - val_accuracy: 0.5406 - val_loss: 1.9522\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7058 - val_accuracy: 0.5406 - val_loss: 1.9577\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7057 - val_accuracy: 0.5405 - val_loss: 1.9585\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7056 - val_accuracy: 0.5406 - val_loss: 1.9560\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7056 - val_accuracy: 0.5403 - val_loss: 1.9618\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7055 - val_accuracy: 0.5405 - val_loss: 1.9560\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7055 - val_accuracy: 0.5405 - val_loss: 1.9563\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7054 - val_accuracy: 0.5405 - val_loss: 1.9619\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7053 - val_accuracy: 0.5405 - val_loss: 1.9587\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7053 - val_accuracy: 0.5405 - val_loss: 1.9609\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7052 - val_accuracy: 0.5405 - val_loss: 1.9578\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7051 - val_accuracy: 0.5404 - val_loss: 1.9645\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7051 - val_accuracy: 0.5405 - val_loss: 1.9579\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7050 - val_accuracy: 0.5405 - val_loss: 1.9601\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7050 - val_accuracy: 0.5403 - val_loss: 1.9578\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7049 - val_accuracy: 0.5403 - val_loss: 1.9602\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7048 - val_accuracy: 0.5403 - val_loss: 1.9645\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7048 - val_accuracy: 0.5403 - val_loss: 1.9640\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7047 - val_accuracy: 0.5403 - val_loss: 1.9618\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7047 - val_accuracy: 0.5400 - val_loss: 1.9643\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7046 - val_accuracy: 0.5404 - val_loss: 1.9611\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7045 - val_accuracy: 0.5403 - val_loss: 1.9661\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7045 - val_accuracy: 0.5403 - val_loss: 1.9629\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7044 - val_accuracy: 0.5403 - val_loss: 1.9631\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7044 - val_accuracy: 0.5400 - val_loss: 1.9655\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7043 - val_accuracy: 0.5403 - val_loss: 1.9660\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7043 - val_accuracy: 0.5403 - val_loss: 1.9697\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.7042 - val_accuracy: 0.5403 - val_loss: 1.9654\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7041 - val_accuracy: 0.5400 - val_loss: 1.9730\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7041 - val_accuracy: 0.5403 - val_loss: 1.9656\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7040 - val_accuracy: 0.5403 - val_loss: 1.9684\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7040 - val_accuracy: 0.5403 - val_loss: 1.9641\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7039 - val_accuracy: 0.5403 - val_loss: 1.9659\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7039 - val_accuracy: 0.5403 - val_loss: 1.9661\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7038 - val_accuracy: 0.5403 - val_loss: 1.9680\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7037 - val_accuracy: 0.5403 - val_loss: 1.9705\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7037 - val_accuracy: 0.5403 - val_loss: 1.9650\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7036 - val_accuracy: 0.5403 - val_loss: 1.9688\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7036 - val_accuracy: 0.5403 - val_loss: 1.9675\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7035 - val_accuracy: 0.5403 - val_loss: 1.9714\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7035 - val_accuracy: 0.5403 - val_loss: 1.9686\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7034 - val_accuracy: 0.5403 - val_loss: 1.9732\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7988 - loss: 0.7033 - val_accuracy: 0.5403 - val_loss: 1.9703\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7033 - val_accuracy: 0.5403 - val_loss: 1.9654\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7032 - val_accuracy: 0.5403 - val_loss: 1.9684\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7032 - val_accuracy: 0.5403 - val_loss: 1.9736\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.7031 - val_accuracy: 0.5404 - val_loss: 1.9731\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7031 - val_accuracy: 0.5403 - val_loss: 1.9736\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7030 - val_accuracy: 0.5405 - val_loss: 1.9751\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7030 - val_accuracy: 0.5404 - val_loss: 1.9726\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.7029 - val_accuracy: 0.5404 - val_loss: 1.9720\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.7028 - val_accuracy: 0.5404 - val_loss: 1.9744\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7028 - val_accuracy: 0.5404 - val_loss: 1.9701\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7027 - val_accuracy: 0.5404 - val_loss: 1.9771\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8014 - loss: 0.7027 - val_accuracy: 0.5405 - val_loss: 1.9749\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7026 - val_accuracy: 0.5405 - val_loss: 1.9734\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7026 - val_accuracy: 0.5405 - val_loss: 1.9731\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7025 - val_accuracy: 0.5404 - val_loss: 1.9783\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7025 - val_accuracy: 0.5404 - val_loss: 1.9751\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7024 - val_accuracy: 0.5404 - val_loss: 1.9758\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7024 - val_accuracy: 0.5405 - val_loss: 1.9800\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7023 - val_accuracy: 0.5405 - val_loss: 1.9753\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7023 - val_accuracy: 0.5405 - val_loss: 1.9782\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7022 - val_accuracy: 0.5404 - val_loss: 1.9764\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7021 - val_accuracy: 0.5403 - val_loss: 1.9763\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7021 - val_accuracy: 0.5403 - val_loss: 1.9778\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.58107\n726/726 - 7s - 10ms/step - accuracy: 0.8013 - loss: 0.7020 - val_accuracy: 0.5405 - val_loss: 1.9780\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7020 - val_accuracy: 0.5403 - val_loss: 1.9753\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7019 - val_accuracy: 0.5403 - val_loss: 1.9745\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7019 - val_accuracy: 0.5403 - val_loss: 1.9769\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7018 - val_accuracy: 0.5404 - val_loss: 1.9818\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7018 - val_accuracy: 0.5405 - val_loss: 1.9828\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7017 - val_accuracy: 0.5405 - val_loss: 1.9807\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8013 - loss: 0.7017 - val_accuracy: 0.5405 - val_loss: 1.9824\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7016 - val_accuracy: 0.5405 - val_loss: 1.9803\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7016 - val_accuracy: 0.5405 - val_loss: 1.9777\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7015 - val_accuracy: 0.5405 - val_loss: 1.9791\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7015 - val_accuracy: 0.5405 - val_loss: 1.9797\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7014 - val_accuracy: 0.5404 - val_loss: 1.9814\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7014 - val_accuracy: 0.5404 - val_loss: 1.9834\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7013 - val_accuracy: 0.5404 - val_loss: 1.9787\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7013 - val_accuracy: 0.5404 - val_loss: 1.9832\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7012 - val_accuracy: 0.5404 - val_loss: 1.9791\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7012 - val_accuracy: 0.5404 - val_loss: 1.9807\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8013 - loss: 0.7011 - val_accuracy: 0.5404 - val_loss: 1.9810\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7011 - val_accuracy: 0.5404 - val_loss: 1.9849\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7010 - val_accuracy: 0.5404 - val_loss: 1.9813\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7010 - val_accuracy: 0.5404 - val_loss: 1.9843\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7009 - val_accuracy: 0.5404 - val_loss: 1.9848\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8013 - loss: 0.7009 - val_accuracy: 0.5404 - val_loss: 1.9818\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7008 - val_accuracy: 0.5401 - val_loss: 1.9872\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7008 - val_accuracy: 0.5401 - val_loss: 1.9867\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.7007 - val_accuracy: 0.5401 - val_loss: 1.9856\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7007 - val_accuracy: 0.5401 - val_loss: 1.9841\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.7006 - val_accuracy: 0.5401 - val_loss: 1.9879\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.7006 - val_accuracy: 0.5401 - val_loss: 1.9893\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.7005 - val_accuracy: 0.5401 - val_loss: 1.9849\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.7005 - val_accuracy: 0.5401 - val_loss: 1.9865\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7004 - val_accuracy: 0.5401 - val_loss: 1.9889\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7004 - val_accuracy: 0.5401 - val_loss: 1.9858\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7003 - val_accuracy: 0.5401 - val_loss: 1.9888\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7003 - val_accuracy: 0.5401 - val_loss: 1.9903\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7002 - val_accuracy: 0.5401 - val_loss: 1.9851\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.7002 - val_accuracy: 0.5401 - val_loss: 1.9875\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7001 - val_accuracy: 0.5401 - val_loss: 1.9900\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7001 - val_accuracy: 0.5400 - val_loss: 1.9943\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.7000 - val_accuracy: 0.5400 - val_loss: 1.9929\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.7000 - val_accuracy: 0.5403 - val_loss: 1.9888\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6999 - val_accuracy: 0.5400 - val_loss: 1.9897\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6999 - val_accuracy: 0.5400 - val_loss: 1.9894\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6998 - val_accuracy: 0.5400 - val_loss: 1.9933\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6998 - val_accuracy: 0.5400 - val_loss: 1.9933\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6997 - val_accuracy: 0.5398 - val_loss: 1.9911\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6997 - val_accuracy: 0.5400 - val_loss: 1.9879\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.58107\n726/726 - 10s - 14ms/step - accuracy: 0.8010 - loss: 0.6996 - val_accuracy: 0.5398 - val_loss: 1.9916\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6996 - val_accuracy: 0.5398 - val_loss: 1.9963\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6995 - val_accuracy: 0.5400 - val_loss: 1.9962\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6995 - val_accuracy: 0.5400 - val_loss: 1.9952\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6994 - val_accuracy: 0.5401 - val_loss: 1.9906\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6994 - val_accuracy: 0.5401 - val_loss: 1.9892\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6993 - val_accuracy: 0.5401 - val_loss: 1.9950\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6993 - val_accuracy: 0.5400 - val_loss: 1.9961\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6993 - val_accuracy: 0.5400 - val_loss: 1.9936\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6992 - val_accuracy: 0.5401 - val_loss: 1.9941\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6992 - val_accuracy: 0.5401 - val_loss: 1.9941\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6991 - val_accuracy: 0.5400 - val_loss: 1.9985\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6991 - val_accuracy: 0.5400 - val_loss: 1.9915\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6990 - val_accuracy: 0.5401 - val_loss: 1.9977\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6990 - val_accuracy: 0.5401 - val_loss: 1.9967\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6989 - val_accuracy: 0.5401 - val_loss: 1.9964\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6989 - val_accuracy: 0.5400 - val_loss: 1.9992\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6988 - val_accuracy: 0.5400 - val_loss: 1.9982\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6988 - val_accuracy: 0.5400 - val_loss: 1.9972\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6987 - val_accuracy: 0.5400 - val_loss: 1.9968\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6987 - val_accuracy: 0.5400 - val_loss: 1.9970\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6987 - val_accuracy: 0.5400 - val_loss: 1.9986\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6986 - val_accuracy: 0.5400 - val_loss: 2.0012\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6986 - val_accuracy: 0.5400 - val_loss: 2.0016\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6985 - val_accuracy: 0.5401 - val_loss: 1.9970\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8009 - loss: 0.6985 - val_accuracy: 0.5400 - val_loss: 1.9984\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6984 - val_accuracy: 0.5400 - val_loss: 2.0008\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8009 - loss: 0.6984 - val_accuracy: 0.5399 - val_loss: 2.0013\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8009 - loss: 0.6983 - val_accuracy: 0.5400 - val_loss: 2.0006\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8009 - loss: 0.6983 - val_accuracy: 0.5399 - val_loss: 2.0004\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6982 - val_accuracy: 0.5400 - val_loss: 1.9967\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6982 - val_accuracy: 0.5399 - val_loss: 2.0063\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6982 - val_accuracy: 0.5400 - val_loss: 1.9975\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6981 - val_accuracy: 0.5398 - val_loss: 2.0027\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6981 - val_accuracy: 0.5400 - val_loss: 1.9987\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6980 - val_accuracy: 0.5400 - val_loss: 2.0003\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6980 - val_accuracy: 0.5400 - val_loss: 2.0052\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6979 - val_accuracy: 0.5399 - val_loss: 2.0061\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6979 - val_accuracy: 0.5399 - val_loss: 2.0024\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6978 - val_accuracy: 0.5399 - val_loss: 2.0029\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6978 - val_accuracy: 0.5401 - val_loss: 2.0042\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6978 - val_accuracy: 0.5398 - val_loss: 2.0045\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6977 - val_accuracy: 0.5400 - val_loss: 2.0053\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6977 - val_accuracy: 0.5398 - val_loss: 2.0077\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6976 - val_accuracy: 0.5398 - val_loss: 2.0037\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6976 - val_accuracy: 0.5399 - val_loss: 2.0075\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6975 - val_accuracy: 0.5398 - val_loss: 2.0046\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8013 - loss: 0.6975 - val_accuracy: 0.5399 - val_loss: 2.0081\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6974 - val_accuracy: 0.5399 - val_loss: 2.0022\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6974 - val_accuracy: 0.5398 - val_loss: 2.0066\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6974 - val_accuracy: 0.5398 - val_loss: 2.0067\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6973 - val_accuracy: 0.5402 - val_loss: 2.0013\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6973 - val_accuracy: 0.5400 - val_loss: 2.0084\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6972 - val_accuracy: 0.5399 - val_loss: 2.0087\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6972 - val_accuracy: 0.5398 - val_loss: 2.0094\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6971 - val_accuracy: 0.5398 - val_loss: 2.0047\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6971 - val_accuracy: 0.5398 - val_loss: 2.0078\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6971 - val_accuracy: 0.5398 - val_loss: 2.0111\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6970 - val_accuracy: 0.5400 - val_loss: 2.0043\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6970 - val_accuracy: 0.5402 - val_loss: 2.0088\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6969 - val_accuracy: 0.5398 - val_loss: 2.0046\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6969 - val_accuracy: 0.5400 - val_loss: 2.0080\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6968 - val_accuracy: 0.5439 - val_loss: 2.0092\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6968 - val_accuracy: 0.5398 - val_loss: 2.0112\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6968 - val_accuracy: 0.5400 - val_loss: 2.0069\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6967 - val_accuracy: 0.5398 - val_loss: 2.0126\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6967 - val_accuracy: 0.5398 - val_loss: 2.0130\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6966 - val_accuracy: 0.5398 - val_loss: 2.0108\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6966 - val_accuracy: 0.5400 - val_loss: 2.0087\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.6965 - val_accuracy: 0.5398 - val_loss: 2.0121\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6965 - val_accuracy: 0.5398 - val_loss: 2.0159\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6965 - val_accuracy: 0.5398 - val_loss: 2.0102\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6964 - val_accuracy: 0.5398 - val_loss: 2.0120\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6964 - val_accuracy: 0.5398 - val_loss: 2.0128\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6963 - val_accuracy: 0.5398 - val_loss: 2.0167\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8022 - loss: 0.6963 - val_accuracy: 0.5400 - val_loss: 2.0096\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6962 - val_accuracy: 0.5398 - val_loss: 2.0117\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6962 - val_accuracy: 0.5398 - val_loss: 2.0124\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6962 - val_accuracy: 0.5400 - val_loss: 2.0093\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6961 - val_accuracy: 0.5400 - val_loss: 2.0081\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6961 - val_accuracy: 0.5400 - val_loss: 2.0119\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6960 - val_accuracy: 0.5397 - val_loss: 2.0148\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6960 - val_accuracy: 0.5400 - val_loss: 2.0140\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6960 - val_accuracy: 0.5400 - val_loss: 2.0079\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6959 - val_accuracy: 0.5400 - val_loss: 2.0140\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.8014 - loss: 0.6959 - val_accuracy: 0.5400 - val_loss: 2.0129\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6958 - val_accuracy: 0.5397 - val_loss: 2.0183\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_7, X_test_7, y_train_7, y_test_7 = train_test_split(\n    X, y, test_size=0.3, random_state=49, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_7, X_val_7, y_train_7, y_val_7 = train_test_split(\n    X_train_7, y_train_7, test_size=0.2, random_state=49, stratify=y_train_7\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_7:\", np.max(X_train_7))\nprint(\"Min value in X_train_7:\", np.min(X_train_7))\n\nscaler = StandardScaler()\nX_train_7_scaled = scaler.fit_transform(X_train_7)\n\n# Get the original class distribution\nclass_counts_7 = Counter(y_train_7)\nprint(\"Original class distribution:\", class_counts_7)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_7 = class_counts_7[min(class_counts_7, key=class_counts_7.get)]\ndesired_majority_size_7 = minority_class_size_7 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_7 = {0: desired_majority_size_7, 1: minority_class_size_7}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_7 = RandomUnderSampler(sampling_strategy=sampling_strategy_7, random_state=42)\nX_resampled_7, y_resampled_7 = undersampler_7.fit_resample(X_train_7, y_train_7)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_7))\n\n# Apply SMOTE on the smaller subset\nsmote = SMOTE(random_state=42)\nX_train_resampled_7, y_train_resampled_7 = smote.fit_resample(X_resampled_7, y_resampled_7)\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_7))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_7))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T00:02:17.405695Z","iopub.execute_input":"2025-03-07T00:02:17.406061Z","iopub.status.idle":"2025-03-07T00:02:52.015078Z","shell.execute_reply.started":"2025-03-07T00:02:17.406029Z","shell.execute_reply":"2025-03-07T00:02:52.013839Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_7: 2071000000.0\nMin value in X_train_7: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_7 = X_train_resampled_7.reshape(X_train_resampled_7.shape[0], 1, 56)\nX_val_7 = X_val_7.reshape(X_val_7.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_7,  # Features from CICIDS2017\n    y_train_resampled_7,  # Labels from CICIDS2017\n    validation_data=(X_val_7, y_val_7),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T00:02:52.016821Z","iopub.execute_input":"2025-03-07T00:02:52.017226Z","iopub.status.idle":"2025-03-07T00:47:00.032637Z","shell.execute_reply.started":"2025-03-07T00:02:52.017188Z","shell.execute_reply":"2025-03-07T00:47:00.030390Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7546 - loss: 0.8090 - val_accuracy: 0.5312 - val_loss: 2.0361\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7523 - loss: 0.8000 - val_accuracy: 0.5327 - val_loss: 2.0321\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 0.7982 - val_accuracy: 0.5328 - val_loss: 2.0335\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 0.7971 - val_accuracy: 0.5329 - val_loss: 2.0280\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7523 - loss: 0.7961 - val_accuracy: 0.5330 - val_loss: 2.0302\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 0.7953 - val_accuracy: 0.5333 - val_loss: 2.0266\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7522 - loss: 0.7945 - val_accuracy: 0.5333 - val_loss: 2.0201\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 0.7938 - val_accuracy: 0.5321 - val_loss: 2.0247\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7518 - loss: 0.7931 - val_accuracy: 0.5321 - val_loss: 2.0185\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7516 - loss: 0.7924 - val_accuracy: 0.5325 - val_loss: 2.0153\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.7918 - val_accuracy: 0.5325 - val_loss: 2.0126\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7507 - loss: 0.7911 - val_accuracy: 0.5376 - val_loss: 2.0110\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7510 - loss: 0.7905 - val_accuracy: 0.5325 - val_loss: 2.0077\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7501 - loss: 0.7900 - val_accuracy: 0.5379 - val_loss: 2.0042\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7491 - loss: 0.7894 - val_accuracy: 0.5384 - val_loss: 2.0024\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7497 - loss: 0.7888 - val_accuracy: 0.5415 - val_loss: 2.0014\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7491 - loss: 0.7883 - val_accuracy: 0.5395 - val_loss: 1.9963\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7507 - loss: 0.7878 - val_accuracy: 0.5417 - val_loss: 1.9931\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7519 - loss: 0.7873 - val_accuracy: 0.5410 - val_loss: 1.9900\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7517 - loss: 0.7869 - val_accuracy: 0.5389 - val_loss: 1.9930\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7528 - loss: 0.7864 - val_accuracy: 0.5335 - val_loss: 1.9895\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7540 - loss: 0.7859 - val_accuracy: 0.5390 - val_loss: 1.9823\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7536 - loss: 0.7855 - val_accuracy: 0.5399 - val_loss: 1.9784\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7535 - loss: 0.7851 - val_accuracy: 0.5399 - val_loss: 1.9753\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7541 - loss: 0.7847 - val_accuracy: 0.5398 - val_loss: 1.9761\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7536 - loss: 0.7843 - val_accuracy: 0.5399 - val_loss: 1.9733\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7535 - loss: 0.7839 - val_accuracy: 0.5399 - val_loss: 1.9678\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7529 - loss: 0.7835 - val_accuracy: 0.5400 - val_loss: 1.9667\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7534 - loss: 0.7832 - val_accuracy: 0.5407 - val_loss: 1.9645\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7534 - loss: 0.7828 - val_accuracy: 0.5408 - val_loss: 1.9589\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.7825 - val_accuracy: 0.5408 - val_loss: 1.9621\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7503 - loss: 0.7822 - val_accuracy: 0.5408 - val_loss: 1.9548\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7508 - loss: 0.7818 - val_accuracy: 0.5408 - val_loss: 1.9508\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7471 - loss: 0.7815 - val_accuracy: 0.5402 - val_loss: 1.9494\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7477 - loss: 0.7812 - val_accuracy: 0.5408 - val_loss: 1.9516\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7467 - loss: 0.7809 - val_accuracy: 0.5409 - val_loss: 1.9451\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7487 - loss: 0.7807 - val_accuracy: 0.5405 - val_loss: 1.9461\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7450 - loss: 0.7804 - val_accuracy: 0.5405 - val_loss: 1.9463\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7433 - loss: 0.7801 - val_accuracy: 0.5414 - val_loss: 1.9430\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7402 - loss: 0.7799 - val_accuracy: 0.5414 - val_loss: 1.9409\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.7796 - val_accuracy: 0.5441 - val_loss: 1.9396\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.7793 - val_accuracy: 0.5435 - val_loss: 1.9348\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7434 - loss: 0.7791 - val_accuracy: 0.5441 - val_loss: 1.9330\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7458 - loss: 0.7789 - val_accuracy: 0.5434 - val_loss: 1.9345\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7416 - loss: 0.7786 - val_accuracy: 0.5444 - val_loss: 1.9325\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.7784 - val_accuracy: 0.5437 - val_loss: 1.9329\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7396 - loss: 0.7782 - val_accuracy: 0.5446 - val_loss: 1.9256\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.7780 - val_accuracy: 0.5440 - val_loss: 1.9261\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7384 - loss: 0.7778 - val_accuracy: 0.5440 - val_loss: 1.9241\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7392 - loss: 0.7776 - val_accuracy: 0.5440 - val_loss: 1.9200\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7368 - loss: 0.7774 - val_accuracy: 0.5445 - val_loss: 1.9157\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7363 - loss: 0.7772 - val_accuracy: 0.5441 - val_loss: 1.9225\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7356 - loss: 0.7770 - val_accuracy: 0.5441 - val_loss: 1.9196\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7373 - loss: 0.7768 - val_accuracy: 0.5448 - val_loss: 1.9190\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7395 - loss: 0.7766 - val_accuracy: 0.5441 - val_loss: 1.9149\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7341 - loss: 0.7764 - val_accuracy: 0.5441 - val_loss: 1.9148\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7344 - loss: 0.7763 - val_accuracy: 0.5440 - val_loss: 1.9111\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7338 - loss: 0.7761 - val_accuracy: 0.5441 - val_loss: 1.9106\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7342 - loss: 0.7759 - val_accuracy: 0.5441 - val_loss: 1.9106\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7758 - val_accuracy: 0.5442 - val_loss: 1.9119\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7344 - loss: 0.7756 - val_accuracy: 0.5442 - val_loss: 1.9094\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7337 - loss: 0.7755 - val_accuracy: 0.5442 - val_loss: 1.9094\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7337 - loss: 0.7753 - val_accuracy: 0.5442 - val_loss: 1.9113\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7751 - val_accuracy: 0.5443 - val_loss: 1.9029\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7335 - loss: 0.7750 - val_accuracy: 0.5443 - val_loss: 1.9054\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7353 - loss: 0.7749 - val_accuracy: 0.5442 - val_loss: 1.9038\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7335 - loss: 0.7747 - val_accuracy: 0.5443 - val_loss: 1.9042\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7337 - loss: 0.7746 - val_accuracy: 0.5454 - val_loss: 1.9011\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7744 - val_accuracy: 0.5454 - val_loss: 1.9009\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7743 - val_accuracy: 0.5456 - val_loss: 1.9065\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7345 - loss: 0.7742 - val_accuracy: 0.5456 - val_loss: 1.8979\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7346 - loss: 0.7740 - val_accuracy: 0.5468 - val_loss: 1.8965\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7345 - loss: 0.7739 - val_accuracy: 0.5456 - val_loss: 1.8988\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7352 - loss: 0.7738 - val_accuracy: 0.5468 - val_loss: 1.8957\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7737 - val_accuracy: 0.5470 - val_loss: 1.9005\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7346 - loss: 0.7735 - val_accuracy: 0.5470 - val_loss: 1.8960\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7346 - loss: 0.7734 - val_accuracy: 0.5470 - val_loss: 1.8987\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7346 - loss: 0.7733 - val_accuracy: 0.5471 - val_loss: 1.8958\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7346 - loss: 0.7732 - val_accuracy: 0.5470 - val_loss: 1.8969\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7347 - loss: 0.7731 - val_accuracy: 0.5470 - val_loss: 1.8929\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7347 - loss: 0.7729 - val_accuracy: 0.5470 - val_loss: 1.8964\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7346 - loss: 0.7728 - val_accuracy: 0.5471 - val_loss: 1.8942\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7347 - loss: 0.7727 - val_accuracy: 0.5471 - val_loss: 1.8922\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7726 - val_accuracy: 0.5471 - val_loss: 1.8885\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7348 - loss: 0.7725 - val_accuracy: 0.5471 - val_loss: 1.8956\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7347 - loss: 0.7724 - val_accuracy: 0.5471 - val_loss: 1.8914\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7348 - loss: 0.7723 - val_accuracy: 0.5472 - val_loss: 1.8925\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7347 - loss: 0.7722 - val_accuracy: 0.5473 - val_loss: 1.8903\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7346 - loss: 0.7721 - val_accuracy: 0.5472 - val_loss: 1.8884\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7345 - loss: 0.7720 - val_accuracy: 0.5472 - val_loss: 1.8894\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7346 - loss: 0.7719 - val_accuracy: 0.5472 - val_loss: 1.8894\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7344 - loss: 0.7718 - val_accuracy: 0.5473 - val_loss: 1.8859\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7717 - val_accuracy: 0.5472 - val_loss: 1.8864\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7343 - loss: 0.7716 - val_accuracy: 0.5473 - val_loss: 1.8884\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7342 - loss: 0.7715 - val_accuracy: 0.5473 - val_loss: 1.8855\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7341 - loss: 0.7714 - val_accuracy: 0.5473 - val_loss: 1.8840\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7343 - loss: 0.7713 - val_accuracy: 0.5470 - val_loss: 1.8867\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7341 - loss: 0.7712 - val_accuracy: 0.5474 - val_loss: 1.8883\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7342 - loss: 0.7711 - val_accuracy: 0.5475 - val_loss: 1.8849\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7341 - loss: 0.7710 - val_accuracy: 0.5472 - val_loss: 1.8850\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7709 - val_accuracy: 0.5474 - val_loss: 1.8842\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7341 - loss: 0.7708 - val_accuracy: 0.5470 - val_loss: 1.8864\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7343 - loss: 0.7707 - val_accuracy: 0.5474 - val_loss: 1.8855\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7342 - loss: 0.7706 - val_accuracy: 0.5476 - val_loss: 1.8797\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7705 - val_accuracy: 0.5482 - val_loss: 1.8845\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7704 - val_accuracy: 0.5482 - val_loss: 1.8834\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7703 - val_accuracy: 0.5482 - val_loss: 1.8852\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7703 - val_accuracy: 0.5482 - val_loss: 1.8817\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7702 - val_accuracy: 0.5482 - val_loss: 1.8803\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7701 - val_accuracy: 0.5484 - val_loss: 1.8771\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7700 - val_accuracy: 0.5484 - val_loss: 1.8816\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7699 - val_accuracy: 0.5484 - val_loss: 1.8816\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7698 - val_accuracy: 0.5484 - val_loss: 1.8775\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7344 - loss: 0.7697 - val_accuracy: 0.5482 - val_loss: 1.8855\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7358 - loss: 0.7697 - val_accuracy: 0.5484 - val_loss: 1.8798\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7342 - loss: 0.7696 - val_accuracy: 0.5484 - val_loss: 1.8803\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7344 - loss: 0.7695 - val_accuracy: 0.5484 - val_loss: 1.8782\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7694 - val_accuracy: 0.5484 - val_loss: 1.8830\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7693 - val_accuracy: 0.5484 - val_loss: 1.8789\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7343 - loss: 0.7692 - val_accuracy: 0.5484 - val_loss: 1.8822\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7344 - loss: 0.7692 - val_accuracy: 0.5484 - val_loss: 1.8806\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7349 - loss: 0.7691 - val_accuracy: 0.5484 - val_loss: 1.8770\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7353 - loss: 0.7690 - val_accuracy: 0.5485 - val_loss: 1.8766\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7352 - loss: 0.7689 - val_accuracy: 0.5485 - val_loss: 1.8776\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7351 - loss: 0.7689 - val_accuracy: 0.5485 - val_loss: 1.8787\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7351 - loss: 0.7688 - val_accuracy: 0.5484 - val_loss: 1.8812\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7355 - loss: 0.7687 - val_accuracy: 0.5484 - val_loss: 1.8805\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7352 - loss: 0.7686 - val_accuracy: 0.5485 - val_loss: 1.8774\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7362 - loss: 0.7685 - val_accuracy: 0.5485 - val_loss: 1.8787\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7362 - loss: 0.7685 - val_accuracy: 0.5486 - val_loss: 1.8762\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7365 - loss: 0.7684 - val_accuracy: 0.5486 - val_loss: 1.8729\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7369 - loss: 0.7683 - val_accuracy: 0.5486 - val_loss: 1.8768\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7382 - loss: 0.7682 - val_accuracy: 0.5486 - val_loss: 1.8742\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7381 - loss: 0.7682 - val_accuracy: 0.5486 - val_loss: 1.8744\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7376 - loss: 0.7681 - val_accuracy: 0.5486 - val_loss: 1.8781\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7376 - loss: 0.7680 - val_accuracy: 0.5486 - val_loss: 1.8784\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7376 - loss: 0.7679 - val_accuracy: 0.5486 - val_loss: 1.8759\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7376 - loss: 0.7679 - val_accuracy: 0.5486 - val_loss: 1.8754\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7678 - val_accuracy: 0.5486 - val_loss: 1.8752\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7376 - loss: 0.7677 - val_accuracy: 0.5486 - val_loss: 1.8779\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7376 - loss: 0.7677 - val_accuracy: 0.5486 - val_loss: 1.8756\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7676 - val_accuracy: 0.5486 - val_loss: 1.8773\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7376 - loss: 0.7675 - val_accuracy: 0.5487 - val_loss: 1.8740\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7675 - val_accuracy: 0.5487 - val_loss: 1.8736\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7674 - val_accuracy: 0.5487 - val_loss: 1.8724\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7375 - loss: 0.7673 - val_accuracy: 0.5487 - val_loss: 1.8754\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7380 - loss: 0.7672 - val_accuracy: 0.5487 - val_loss: 1.8737\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7672 - val_accuracy: 0.5485 - val_loss: 1.8748\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7383 - loss: 0.7671 - val_accuracy: 0.5487 - val_loss: 1.8731\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7375 - loss: 0.7670 - val_accuracy: 0.5487 - val_loss: 1.8701\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7670 - val_accuracy: 0.5487 - val_loss: 1.8733\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7375 - loss: 0.7669 - val_accuracy: 0.5487 - val_loss: 1.8719\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7668 - val_accuracy: 0.5486 - val_loss: 1.8707\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7668 - val_accuracy: 0.5486 - val_loss: 1.8766\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7667 - val_accuracy: 0.5486 - val_loss: 1.8718\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7377 - loss: 0.7666 - val_accuracy: 0.5486 - val_loss: 1.8740\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7391 - loss: 0.7666 - val_accuracy: 0.5486 - val_loss: 1.8732\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7385 - loss: 0.7665 - val_accuracy: 0.5486 - val_loss: 1.8741\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7374 - loss: 0.7664 - val_accuracy: 0.5486 - val_loss: 1.8705\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7374 - loss: 0.7664 - val_accuracy: 0.5486 - val_loss: 1.8738\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7378 - loss: 0.7663 - val_accuracy: 0.5486 - val_loss: 1.8727\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7377 - loss: 0.7663 - val_accuracy: 0.5486 - val_loss: 1.8674\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7374 - loss: 0.7662 - val_accuracy: 0.5485 - val_loss: 1.8724\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7373 - loss: 0.7661 - val_accuracy: 0.5486 - val_loss: 1.8710\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7374 - loss: 0.7661 - val_accuracy: 0.5485 - val_loss: 1.8725\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7377 - loss: 0.7660 - val_accuracy: 0.5485 - val_loss: 1.8723\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7373 - loss: 0.7659 - val_accuracy: 0.5486 - val_loss: 1.8707\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7395 - loss: 0.7659 - val_accuracy: 0.5486 - val_loss: 1.8719\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7377 - loss: 0.7658 - val_accuracy: 0.5485 - val_loss: 1.8754\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7399 - loss: 0.7657 - val_accuracy: 0.5485 - val_loss: 1.8717\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7379 - loss: 0.7657 - val_accuracy: 0.5486 - val_loss: 1.8739\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7390 - loss: 0.7656 - val_accuracy: 0.5519 - val_loss: 1.8659\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7372 - loss: 0.7656 - val_accuracy: 0.5486 - val_loss: 1.8687\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7388 - loss: 0.7655 - val_accuracy: 0.5486 - val_loss: 1.8660\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7372 - loss: 0.7654 - val_accuracy: 0.5485 - val_loss: 1.8724\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7373 - loss: 0.7654 - val_accuracy: 0.5486 - val_loss: 1.8725\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7379 - loss: 0.7653 - val_accuracy: 0.5485 - val_loss: 1.8743\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7373 - loss: 0.7653 - val_accuracy: 0.5485 - val_loss: 1.8729\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7377 - loss: 0.7652 - val_accuracy: 0.5518 - val_loss: 1.8721\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7396 - loss: 0.7651 - val_accuracy: 0.5518 - val_loss: 1.8726\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7377 - loss: 0.7651 - val_accuracy: 0.5518 - val_loss: 1.8733\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7372 - loss: 0.7650 - val_accuracy: 0.5518 - val_loss: 1.8731\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7374 - loss: 0.7650 - val_accuracy: 0.5518 - val_loss: 1.8690\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7384 - loss: 0.7649 - val_accuracy: 0.5518 - val_loss: 1.8703\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7386 - loss: 0.7648 - val_accuracy: 0.5519 - val_loss: 1.8652\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7387 - loss: 0.7648 - val_accuracy: 0.5519 - val_loss: 1.8648\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7393 - loss: 0.7647 - val_accuracy: 0.5519 - val_loss: 1.8692\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7373 - loss: 0.7647 - val_accuracy: 0.5519 - val_loss: 1.8664\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7400 - loss: 0.7646 - val_accuracy: 0.5519 - val_loss: 1.8664\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7375 - loss: 0.7645 - val_accuracy: 0.5632 - val_loss: 1.8672\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7388 - loss: 0.7645 - val_accuracy: 0.5632 - val_loss: 1.8677\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7426 - loss: 0.7644 - val_accuracy: 0.5632 - val_loss: 1.8672\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7389 - loss: 0.7644 - val_accuracy: 0.5639 - val_loss: 1.8688\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7391 - loss: 0.7643 - val_accuracy: 0.5632 - val_loss: 1.8682\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7406 - loss: 0.7643 - val_accuracy: 0.5633 - val_loss: 1.8663\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7380 - loss: 0.7642 - val_accuracy: 0.5632 - val_loss: 1.8662\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7409 - loss: 0.7641 - val_accuracy: 0.5633 - val_loss: 1.8669\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7391 - loss: 0.7641 - val_accuracy: 0.5633 - val_loss: 1.8668\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.7640 - val_accuracy: 0.5633 - val_loss: 1.8674\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7412 - loss: 0.7640 - val_accuracy: 0.5633 - val_loss: 1.8702\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7400 - loss: 0.7639 - val_accuracy: 0.5640 - val_loss: 1.8680\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7412 - loss: 0.7639 - val_accuracy: 0.5633 - val_loss: 1.8688\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7389 - loss: 0.7638 - val_accuracy: 0.5633 - val_loss: 1.8655\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7417 - loss: 0.7638 - val_accuracy: 0.5633 - val_loss: 1.8653\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7417 - loss: 0.7637 - val_accuracy: 0.5633 - val_loss: 1.8634\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7387 - loss: 0.7636 - val_accuracy: 0.5633 - val_loss: 1.8697\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7419 - loss: 0.7636 - val_accuracy: 0.5633 - val_loss: 1.8691\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.7635 - val_accuracy: 0.5633 - val_loss: 1.8626\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7407 - loss: 0.7635 - val_accuracy: 0.5640 - val_loss: 1.8642\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7408 - loss: 0.7634 - val_accuracy: 0.5633 - val_loss: 1.8690\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7404 - loss: 0.7634 - val_accuracy: 0.5633 - val_loss: 1.8687\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7409 - loss: 0.7633 - val_accuracy: 0.5640 - val_loss: 1.8662\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7421 - loss: 0.7633 - val_accuracy: 0.5633 - val_loss: 1.8684\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7427 - loss: 0.7632 - val_accuracy: 0.5633 - val_loss: 1.8666\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7400 - loss: 0.7632 - val_accuracy: 0.5633 - val_loss: 1.8641\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7397 - loss: 0.7631 - val_accuracy: 0.5633 - val_loss: 1.8684\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7434 - loss: 0.7630 - val_accuracy: 0.5633 - val_loss: 1.8648\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7415 - loss: 0.7630 - val_accuracy: 0.5640 - val_loss: 1.8695\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.7629 - val_accuracy: 0.5633 - val_loss: 1.8645\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7413 - loss: 0.7629 - val_accuracy: 0.5633 - val_loss: 1.8653\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7415 - loss: 0.7628 - val_accuracy: 0.5634 - val_loss: 1.8613\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7435 - loss: 0.7628 - val_accuracy: 0.5633 - val_loss: 1.8655\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7420 - loss: 0.7627 - val_accuracy: 0.5633 - val_loss: 1.8654\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7447 - loss: 0.7627 - val_accuracy: 0.5634 - val_loss: 1.8642\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7448 - loss: 0.7626 - val_accuracy: 0.5633 - val_loss: 1.8627\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7456 - loss: 0.7626 - val_accuracy: 0.5633 - val_loss: 1.8689\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7433 - loss: 0.7625 - val_accuracy: 0.5634 - val_loss: 1.8614\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7411 - loss: 0.7625 - val_accuracy: 0.5633 - val_loss: 1.8670\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7436 - loss: 0.7624 - val_accuracy: 0.5640 - val_loss: 1.8620\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7429 - loss: 0.7624 - val_accuracy: 0.5634 - val_loss: 1.8635\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7424 - loss: 0.7623 - val_accuracy: 0.5634 - val_loss: 1.8603\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7442 - loss: 0.7623 - val_accuracy: 0.5634 - val_loss: 1.8580\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.7622 - val_accuracy: 0.5632 - val_loss: 1.8676\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7432 - loss: 0.7622 - val_accuracy: 0.5634 - val_loss: 1.8635\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7422 - loss: 0.7621 - val_accuracy: 0.5633 - val_loss: 1.8660\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7437 - loss: 0.7621 - val_accuracy: 0.5634 - val_loss: 1.8596\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7449 - loss: 0.7620 - val_accuracy: 0.5634 - val_loss: 1.8583\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7431 - loss: 0.7620 - val_accuracy: 0.5634 - val_loss: 1.8633\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7446 - loss: 0.7619 - val_accuracy: 0.5632 - val_loss: 1.8652\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7478 - loss: 0.7619 - val_accuracy: 0.5633 - val_loss: 1.8660\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7426 - loss: 0.7618 - val_accuracy: 0.5634 - val_loss: 1.8612\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7438 - loss: 0.7618 - val_accuracy: 0.5639 - val_loss: 1.8652\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7504 - loss: 0.7617 - val_accuracy: 0.5634 - val_loss: 1.8651\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7433 - loss: 0.7617 - val_accuracy: 0.5663 - val_loss: 1.8639\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7444 - loss: 0.7616 - val_accuracy: 0.5670 - val_loss: 1.8629\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7473 - loss: 0.7616 - val_accuracy: 0.5634 - val_loss: 1.8622\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7442 - loss: 0.7615 - val_accuracy: 0.5664 - val_loss: 1.8594\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7469 - loss: 0.7615 - val_accuracy: 0.5670 - val_loss: 1.8603\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7479 - loss: 0.7614 - val_accuracy: 0.5664 - val_loss: 1.8568\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7470 - loss: 0.7614 - val_accuracy: 0.5664 - val_loss: 1.8617\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7461 - loss: 0.7613 - val_accuracy: 0.5664 - val_loss: 1.8606\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7468 - loss: 0.7613 - val_accuracy: 0.5668 - val_loss: 1.8601\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7469 - loss: 0.7612 - val_accuracy: 0.5662 - val_loss: 1.8626\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7466 - loss: 0.7612 - val_accuracy: 0.5662 - val_loss: 1.8629\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7481 - loss: 0.7611 - val_accuracy: 0.5662 - val_loss: 1.8641\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7464 - loss: 0.7611 - val_accuracy: 0.5671 - val_loss: 1.8579\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7503 - loss: 0.7610 - val_accuracy: 0.5662 - val_loss: 1.8634\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7470 - loss: 0.7610 - val_accuracy: 0.5682 - val_loss: 1.8601\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7489 - loss: 0.7609 - val_accuracy: 0.5682 - val_loss: 1.8636\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7475 - loss: 0.7609 - val_accuracy: 0.5662 - val_loss: 1.8628\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7460 - loss: 0.7608 - val_accuracy: 0.5689 - val_loss: 1.8599\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7510 - loss: 0.7608 - val_accuracy: 0.5682 - val_loss: 1.8618\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7486 - loss: 0.7607 - val_accuracy: 0.5682 - val_loss: 1.8638\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7469 - loss: 0.7607 - val_accuracy: 0.5684 - val_loss: 1.8582\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7486 - loss: 0.7607 - val_accuracy: 0.5682 - val_loss: 1.8614\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7484 - loss: 0.7606 - val_accuracy: 0.5681 - val_loss: 1.8605\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7468 - loss: 0.7606 - val_accuracy: 0.5690 - val_loss: 1.8588\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7500 - loss: 0.7605 - val_accuracy: 0.5689 - val_loss: 1.8584\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7497 - loss: 0.7605 - val_accuracy: 0.5687 - val_loss: 1.8631\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7525 - loss: 0.7604 - val_accuracy: 0.5681 - val_loss: 1.8651\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7494 - loss: 0.7604 - val_accuracy: 0.5682 - val_loss: 1.8593\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7524 - loss: 0.7603 - val_accuracy: 0.5691 - val_loss: 1.8559\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7484 - loss: 0.7603 - val_accuracy: 0.5687 - val_loss: 1.8637\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 0.7602 - val_accuracy: 0.5689 - val_loss: 1.8597\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 0.7602 - val_accuracy: 0.5689 - val_loss: 1.8561\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7498 - loss: 0.7601 - val_accuracy: 0.5689 - val_loss: 1.8596\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7521 - loss: 0.7601 - val_accuracy: 0.5681 - val_loss: 1.8624\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7518 - loss: 0.7600 - val_accuracy: 0.5681 - val_loss: 1.8619\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7501 - loss: 0.7600 - val_accuracy: 0.5688 - val_loss: 1.8592\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7490 - loss: 0.7600 - val_accuracy: 0.5688 - val_loss: 1.8628\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7531 - loss: 0.7599 - val_accuracy: 0.5688 - val_loss: 1.8596\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7512 - loss: 0.7599 - val_accuracy: 0.5688 - val_loss: 1.8582\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7522 - loss: 0.7598 - val_accuracy: 0.5688 - val_loss: 1.8589\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7529 - loss: 0.7598 - val_accuracy: 0.5681 - val_loss: 1.8608\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7538 - loss: 0.7597 - val_accuracy: 0.5688 - val_loss: 1.8647\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.7597 - val_accuracy: 0.5685 - val_loss: 1.8629\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7576 - loss: 0.7596 - val_accuracy: 0.5681 - val_loss: 1.8606\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7543 - loss: 0.7596 - val_accuracy: 0.5688 - val_loss: 1.8604\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7595 - val_accuracy: 0.5688 - val_loss: 1.8582\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7561 - loss: 0.7595 - val_accuracy: 0.5681 - val_loss: 1.8603\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.7595 - val_accuracy: 0.5681 - val_loss: 1.8612\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7578 - loss: 0.7594 - val_accuracy: 0.5688 - val_loss: 1.8575\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.7594 - val_accuracy: 0.5681 - val_loss: 1.8593\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7576 - loss: 0.7593 - val_accuracy: 0.5688 - val_loss: 1.8549\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7610 - loss: 0.7593 - val_accuracy: 0.5688 - val_loss: 1.8574\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7609 - loss: 0.7592 - val_accuracy: 0.5688 - val_loss: 1.8573\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.7592 - val_accuracy: 0.5688 - val_loss: 1.8565\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7604 - loss: 0.7591 - val_accuracy: 0.5688 - val_loss: 1.8591\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7591 - val_accuracy: 0.5685 - val_loss: 1.8597\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7591 - val_accuracy: 0.5685 - val_loss: 1.8613\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7590 - val_accuracy: 0.5681 - val_loss: 1.8592\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.7590 - val_accuracy: 0.5685 - val_loss: 1.8625\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7589 - val_accuracy: 0.5687 - val_loss: 1.8614\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7616 - loss: 0.7589 - val_accuracy: 0.5687 - val_loss: 1.8583\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7588 - val_accuracy: 0.5688 - val_loss: 1.8567\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7588 - val_accuracy: 0.5685 - val_loss: 1.8620\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7587 - val_accuracy: 0.5685 - val_loss: 1.8613\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7587 - val_accuracy: 0.5685 - val_loss: 1.8617\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7587 - val_accuracy: 0.5685 - val_loss: 1.8615\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7586 - val_accuracy: 0.5688 - val_loss: 1.8550\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7586 - val_accuracy: 0.5688 - val_loss: 1.8554\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7585 - val_accuracy: 0.5685 - val_loss: 1.8568\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7585 - val_accuracy: 0.5688 - val_loss: 1.8583\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7584 - val_accuracy: 0.5685 - val_loss: 1.8583\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7584 - val_accuracy: 0.5685 - val_loss: 1.8587\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7584 - val_accuracy: 0.5681 - val_loss: 1.8637\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7583 - val_accuracy: 0.5674 - val_loss: 1.8568\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7583 - val_accuracy: 0.5685 - val_loss: 1.8589\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7582 - val_accuracy: 0.5681 - val_loss: 1.8622\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7582 - val_accuracy: 0.5679 - val_loss: 1.8617\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7581 - val_accuracy: 0.5674 - val_loss: 1.8582\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7581 - val_accuracy: 0.5681 - val_loss: 1.8575\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7581 - val_accuracy: 0.5681 - val_loss: 1.8577\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7580 - val_accuracy: 0.5682 - val_loss: 1.8580\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7642 - loss: 0.7580 - val_accuracy: 0.5725 - val_loss: 1.8563\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7579 - val_accuracy: 0.5681 - val_loss: 1.8591\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7579 - val_accuracy: 0.5674 - val_loss: 1.8573\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7578 - val_accuracy: 0.5725 - val_loss: 1.8560\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7578 - val_accuracy: 0.5681 - val_loss: 1.8584\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7578 - val_accuracy: 0.5679 - val_loss: 1.8609\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7651 - loss: 0.7577 - val_accuracy: 0.5679 - val_loss: 1.8594\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7577 - val_accuracy: 0.5725 - val_loss: 1.8570\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7576 - val_accuracy: 0.5725 - val_loss: 1.8568\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7576 - val_accuracy: 0.5722 - val_loss: 1.8576\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7576 - val_accuracy: 0.5725 - val_loss: 1.8560\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7575 - val_accuracy: 0.5725 - val_loss: 1.8564\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7645 - loss: 0.7575 - val_accuracy: 0.5679 - val_loss: 1.8590\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7574 - val_accuracy: 0.5726 - val_loss: 1.8558\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7574 - val_accuracy: 0.5722 - val_loss: 1.8557\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7573 - val_accuracy: 0.5674 - val_loss: 1.8589\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7573 - val_accuracy: 0.5722 - val_loss: 1.8587\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7573 - val_accuracy: 0.5722 - val_loss: 1.8575\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7657 - loss: 0.7572 - val_accuracy: 0.5723 - val_loss: 1.8566\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7651 - loss: 0.7572 - val_accuracy: 0.5718 - val_loss: 1.8571\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7571 - val_accuracy: 0.5723 - val_loss: 1.8541\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7627 - loss: 0.7571 - val_accuracy: 0.5723 - val_loss: 1.8611\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7571 - val_accuracy: 0.5722 - val_loss: 1.8591\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7570 - val_accuracy: 0.5725 - val_loss: 1.8558\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7656 - loss: 0.7570 - val_accuracy: 0.5723 - val_loss: 1.8565\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7656 - loss: 0.7569 - val_accuracy: 0.5723 - val_loss: 1.8570\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7654 - loss: 0.7569 - val_accuracy: 0.5723 - val_loss: 1.8569\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7569 - val_accuracy: 0.5723 - val_loss: 1.8567\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7568 - val_accuracy: 0.5728 - val_loss: 1.8509\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7625 - loss: 0.7568 - val_accuracy: 0.5723 - val_loss: 1.8558\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7567 - val_accuracy: 0.5723 - val_loss: 1.8559\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7638 - loss: 0.7567 - val_accuracy: 0.5725 - val_loss: 1.8545\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7567 - val_accuracy: 0.5723 - val_loss: 1.8556\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7566 - val_accuracy: 0.5722 - val_loss: 1.8563\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7566 - val_accuracy: 0.5723 - val_loss: 1.8555\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7565 - val_accuracy: 0.5722 - val_loss: 1.8554\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7565 - val_accuracy: 0.5723 - val_loss: 1.8588\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7565 - val_accuracy: 0.5729 - val_loss: 1.8517\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7564 - val_accuracy: 0.5729 - val_loss: 1.8513\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7564 - val_accuracy: 0.5726 - val_loss: 1.8523\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7563 - val_accuracy: 0.5726 - val_loss: 1.8545\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7563 - val_accuracy: 0.5723 - val_loss: 1.8580\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7651 - loss: 0.7563 - val_accuracy: 0.5724 - val_loss: 1.8572\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7562 - val_accuracy: 0.5726 - val_loss: 1.8544\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7562 - val_accuracy: 0.5726 - val_loss: 1.8539\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7561 - val_accuracy: 0.5726 - val_loss: 1.8532\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7561 - val_accuracy: 0.5725 - val_loss: 1.8548\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7561 - val_accuracy: 0.5723 - val_loss: 1.8552\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7650 - loss: 0.7560 - val_accuracy: 0.5726 - val_loss: 1.8503\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7560 - val_accuracy: 0.5729 - val_loss: 1.8496\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7559 - val_accuracy: 0.5726 - val_loss: 1.8563\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7559 - val_accuracy: 0.5720 - val_loss: 1.8544\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7559 - val_accuracy: 0.5723 - val_loss: 1.8576\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7558 - val_accuracy: 0.5724 - val_loss: 1.8557\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7558 - val_accuracy: 0.5726 - val_loss: 1.8560\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7558 - val_accuracy: 0.5727 - val_loss: 1.8529\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7557 - val_accuracy: 0.5723 - val_loss: 1.8580\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7557 - val_accuracy: 0.5728 - val_loss: 1.8549\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7556 - val_accuracy: 0.5728 - val_loss: 1.8518\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7556 - val_accuracy: 0.5725 - val_loss: 1.8578\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7556 - val_accuracy: 0.5727 - val_loss: 1.8507\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7555 - val_accuracy: 0.5731 - val_loss: 1.8508\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7555 - val_accuracy: 0.5727 - val_loss: 1.8533\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7554 - val_accuracy: 0.5724 - val_loss: 1.8574\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7554 - val_accuracy: 0.5728 - val_loss: 1.8575\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7554 - val_accuracy: 0.5731 - val_loss: 1.8533\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7553 - val_accuracy: 0.5731 - val_loss: 1.8532\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7553 - val_accuracy: 0.5733 - val_loss: 1.8518\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7553 - val_accuracy: 0.5728 - val_loss: 1.8553\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7552 - val_accuracy: 0.5731 - val_loss: 1.8544\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7552 - val_accuracy: 0.5731 - val_loss: 1.8545\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7551 - val_accuracy: 0.5731 - val_loss: 1.8505\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7551 - val_accuracy: 0.5731 - val_loss: 1.8484\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7551 - val_accuracy: 0.5731 - val_loss: 1.8545\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7550 - val_accuracy: 0.5730 - val_loss: 1.8561\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7550 - val_accuracy: 0.5731 - val_loss: 1.8565\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7550 - val_accuracy: 0.5731 - val_loss: 1.8480\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7549 - val_accuracy: 0.5730 - val_loss: 1.8540\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7549 - val_accuracy: 0.5730 - val_loss: 1.8565\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7548 - val_accuracy: 0.5729 - val_loss: 1.8565\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7548 - val_accuracy: 0.5730 - val_loss: 1.8556\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7548 - val_accuracy: 0.5731 - val_loss: 1.8520\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7547 - val_accuracy: 0.5731 - val_loss: 1.8529\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7547 - val_accuracy: 0.5730 - val_loss: 1.8560\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7547 - val_accuracy: 0.5731 - val_loss: 1.8549\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7546 - val_accuracy: 0.5730 - val_loss: 1.8524\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7546 - val_accuracy: 0.5731 - val_loss: 1.8559\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7545 - val_accuracy: 0.5731 - val_loss: 1.8565\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7545 - val_accuracy: 0.5731 - val_loss: 1.8564\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7545 - val_accuracy: 0.5730 - val_loss: 1.8549\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7544 - val_accuracy: 0.5731 - val_loss: 1.8489\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7544 - val_accuracy: 0.5731 - val_loss: 1.8544\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7544 - val_accuracy: 0.5739 - val_loss: 1.8504\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7543 - val_accuracy: 0.5731 - val_loss: 1.8548\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7543 - val_accuracy: 0.5734 - val_loss: 1.8540\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7542 - val_accuracy: 0.5735 - val_loss: 1.8512\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7542 - val_accuracy: 0.5734 - val_loss: 1.8544\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7542 - val_accuracy: 0.5734 - val_loss: 1.8553\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7541 - val_accuracy: 0.5735 - val_loss: 1.8503\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7541 - val_accuracy: 0.5735 - val_loss: 1.8530\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7541 - val_accuracy: 0.5733 - val_loss: 1.8592\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7540 - val_accuracy: 0.5734 - val_loss: 1.8541\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7540 - val_accuracy: 0.5735 - val_loss: 1.8515\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7540 - val_accuracy: 0.5735 - val_loss: 1.8525\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7539 - val_accuracy: 0.5743 - val_loss: 1.8514\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7539 - val_accuracy: 0.5734 - val_loss: 1.8555\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7539 - val_accuracy: 0.5735 - val_loss: 1.8547\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7538 - val_accuracy: 0.5743 - val_loss: 1.8518\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7538 - val_accuracy: 0.5733 - val_loss: 1.8604\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7537 - val_accuracy: 0.5743 - val_loss: 1.8527\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7537 - val_accuracy: 0.5742 - val_loss: 1.8541\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7652 - loss: 0.7537 - val_accuracy: 0.5743 - val_loss: 1.8514\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7536 - val_accuracy: 0.5743 - val_loss: 1.8520\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7536 - val_accuracy: 0.5743 - val_loss: 1.8533\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7536 - val_accuracy: 0.5743 - val_loss: 1.8545\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7535 - val_accuracy: 0.5743 - val_loss: 1.8502\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7535 - val_accuracy: 0.5743 - val_loss: 1.8525\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7652 - loss: 0.7535 - val_accuracy: 0.5742 - val_loss: 1.8570\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7534 - val_accuracy: 0.5743 - val_loss: 1.8544\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7534 - val_accuracy: 0.5743 - val_loss: 1.8539\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7533 - val_accuracy: 0.5742 - val_loss: 1.8568\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7533 - val_accuracy: 0.5743 - val_loss: 1.8555\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7533 - val_accuracy: 0.5742 - val_loss: 1.8547\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7532 - val_accuracy: 0.5742 - val_loss: 1.8552\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7532 - val_accuracy: 0.5743 - val_loss: 1.8479\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7532 - val_accuracy: 0.5743 - val_loss: 1.8523\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7531 - val_accuracy: 0.5743 - val_loss: 1.8505\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7531 - val_accuracy: 0.5743 - val_loss: 1.8531\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7531 - val_accuracy: 0.5743 - val_loss: 1.8544\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7530 - val_accuracy: 0.5743 - val_loss: 1.8533\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7530 - val_accuracy: 0.5743 - val_loss: 1.8538\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7530 - val_accuracy: 0.5743 - val_loss: 1.8542\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7529 - val_accuracy: 0.5744 - val_loss: 1.8540\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7529 - val_accuracy: 0.5742 - val_loss: 1.8570\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7529 - val_accuracy: 0.5745 - val_loss: 1.8495\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7528 - val_accuracy: 0.5744 - val_loss: 1.8512\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7528 - val_accuracy: 0.5744 - val_loss: 1.8509\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7528 - val_accuracy: 0.5744 - val_loss: 1.8561\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7527 - val_accuracy: 0.5744 - val_loss: 1.8507\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7527 - val_accuracy: 0.5745 - val_loss: 1.8500\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7527 - val_accuracy: 0.5744 - val_loss: 1.8488\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7526 - val_accuracy: 0.5744 - val_loss: 1.8530\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7526 - val_accuracy: 0.5745 - val_loss: 1.8537\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7525 - val_accuracy: 0.5745 - val_loss: 1.8502\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7525 - val_accuracy: 0.5744 - val_loss: 1.8543\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7525 - val_accuracy: 0.5743 - val_loss: 1.8529\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7524 - val_accuracy: 0.5744 - val_loss: 1.8523\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7524 - val_accuracy: 0.5743 - val_loss: 1.8541\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7524 - val_accuracy: 0.5744 - val_loss: 1.8537\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7523 - val_accuracy: 0.5746 - val_loss: 1.8483\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7523 - val_accuracy: 0.5744 - val_loss: 1.8545\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7523 - val_accuracy: 0.5745 - val_loss: 1.8486\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7522 - val_accuracy: 0.5743 - val_loss: 1.8535\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7522 - val_accuracy: 0.5744 - val_loss: 1.8489\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7522 - val_accuracy: 0.5743 - val_loss: 1.8515\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7521 - val_accuracy: 0.5744 - val_loss: 1.8537\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7521 - val_accuracy: 0.5743 - val_loss: 1.8558\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7521 - val_accuracy: 0.5744 - val_loss: 1.8534\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7520 - val_accuracy: 0.5743 - val_loss: 1.8572\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7520 - val_accuracy: 0.5744 - val_loss: 1.8532\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7520 - val_accuracy: 0.5743 - val_loss: 1.8545\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7519 - val_accuracy: 0.5745 - val_loss: 1.8520\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7519 - val_accuracy: 0.5744 - val_loss: 1.8512\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7519 - val_accuracy: 0.5742 - val_loss: 1.8576\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7518 - val_accuracy: 0.5743 - val_loss: 1.8549\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7518 - val_accuracy: 0.5743 - val_loss: 1.8525\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.58107\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7518 - val_accuracy: 0.5745 - val_loss: 1.8499\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7517 - val_accuracy: 0.5745 - val_loss: 1.8492\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7517 - val_accuracy: 0.5745 - val_loss: 1.8507\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7517 - val_accuracy: 0.5743 - val_loss: 1.8556\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7516 - val_accuracy: 0.5746 - val_loss: 1.8520\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7516 - val_accuracy: 0.5743 - val_loss: 1.8551\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.58107\n726/726 - 5s - 8ms/step - accuracy: 0.7653 - loss: 0.7516 - val_accuracy: 0.5745 - val_loss: 1.8515\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7515 - val_accuracy: 0.5745 - val_loss: 1.8512\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7515 - val_accuracy: 0.5744 - val_loss: 1.8532\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7515 - val_accuracy: 0.5744 - val_loss: 1.8549\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_8, X_test_8, y_train_8, y_test_8 = train_test_split(\n    X, y, test_size=0.3, random_state=50, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_8, X_val_8, y_train_8, y_val_8 = train_test_split(\n    X_train_8, y_train_8, test_size=0.2, random_state=50, stratify=y_train_8\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_8:\", np.max(X_train_8))\nprint(\"Min value in X_train_8:\", np.min(X_train_8))\n\nX_train_8_scaled = scaler.fit_transform(X_train_8)\n\n# Get the original class distribution\nclass_counts_8 = Counter(y_train_8)\nprint(\"Original class distribution:\", class_counts_8)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_8 = class_counts_8[min(class_counts_8, key=class_counts_8.get)]\ndesired_majority_size_8 = minority_class_size_8 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_8 = {0: desired_majority_size_8, 1: minority_class_size_8}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_8 = RandomUnderSampler(sampling_strategy=sampling_strategy_8, random_state=42)\nX_resampled_8, y_resampled_8 = undersampler_8.fit_resample(X_train_8, y_train_8)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_8))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_8, y_train_resampled_8 = smote.fit_resample(X_resampled_8, y_resampled_8)\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_8))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_8))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T00:47:00.036604Z","iopub.execute_input":"2025-03-07T00:47:00.037122Z","iopub.status.idle":"2025-03-07T00:47:36.448026Z","shell.execute_reply.started":"2025-03-07T00:47:00.037073Z","shell.execute_reply":"2025-03-07T00:47:36.446890Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_8: 2071000000.0\nMin value in X_train_8: -9663668122.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_8 = X_train_resampled_8.reshape(X_train_resampled_8.shape[0], 1, 56)\nX_val_8 = X_val_8.reshape(X_val_8.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_8,  # Features from CICIDS2017\n    y_train_resampled_8,  # Labels from CICIDS2017\n    validation_data=(X_val_8, y_val_8),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T00:47:36.449348Z","iopub.execute_input":"2025-03-07T00:47:36.449751Z","iopub.status.idle":"2025-03-07T01:31:35.866943Z","shell.execute_reply.started":"2025-03-07T00:47:36.449711Z","shell.execute_reply":"2025-03-07T01:31:35.864383Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.58107\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.8448 - val_accuracy: 0.5761 - val_loss: 1.7848\nEpoch 2/500\n\nEpoch 2: val_accuracy improved from 0.58107 to 0.58427, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8366 - val_accuracy: 0.5843 - val_loss: 1.7647\nEpoch 3/500\n\nEpoch 3: val_accuracy improved from 0.58427 to 0.58443, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8316 - val_accuracy: 0.5844 - val_loss: 1.7557\nEpoch 4/500\n\nEpoch 4: val_accuracy improved from 0.58443 to 0.58628, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8276 - val_accuracy: 0.5863 - val_loss: 1.7482\nEpoch 5/500\n\nEpoch 5: val_accuracy improved from 0.58628 to 0.58653, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.8243 - val_accuracy: 0.5865 - val_loss: 1.7390\nEpoch 6/500\n\nEpoch 6: val_accuracy improved from 0.58653 to 0.59137, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.8213 - val_accuracy: 0.5914 - val_loss: 1.7292\nEpoch 7/500\n\nEpoch 7: val_accuracy improved from 0.59137 to 0.59400, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.8186 - val_accuracy: 0.5940 - val_loss: 1.7258\nEpoch 8/500\n\nEpoch 8: val_accuracy improved from 0.59400 to 0.59428, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7730 - loss: 0.8162 - val_accuracy: 0.5943 - val_loss: 1.7173\nEpoch 9/500\n\nEpoch 9: val_accuracy improved from 0.59428 to 0.59438, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7737 - loss: 0.8139 - val_accuracy: 0.5944 - val_loss: 1.7089\nEpoch 10/500\n\nEpoch 10: val_accuracy improved from 0.59438 to 0.60547, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7740 - loss: 0.8119 - val_accuracy: 0.6055 - val_loss: 1.7080\nEpoch 11/500\n\nEpoch 11: val_accuracy improved from 0.60547 to 0.60554, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.8100 - val_accuracy: 0.6055 - val_loss: 1.7048\nEpoch 12/500\n\nEpoch 12: val_accuracy improved from 0.60554 to 0.60574, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.8082 - val_accuracy: 0.6057 - val_loss: 1.7014\nEpoch 13/500\n\nEpoch 13: val_accuracy improved from 0.60574 to 0.60582, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7763 - loss: 0.8066 - val_accuracy: 0.6058 - val_loss: 1.6979\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7763 - loss: 0.8051 - val_accuracy: 0.6043 - val_loss: 1.6992\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7764 - loss: 0.8036 - val_accuracy: 0.6046 - val_loss: 1.6945\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7764 - loss: 0.8023 - val_accuracy: 0.6047 - val_loss: 1.6899\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.8010 - val_accuracy: 0.6043 - val_loss: 1.6885\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7998 - val_accuracy: 0.5992 - val_loss: 1.6919\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7987 - val_accuracy: 0.6048 - val_loss: 1.6877\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7768 - loss: 0.7976 - val_accuracy: 0.5997 - val_loss: 1.6889\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7771 - loss: 0.7967 - val_accuracy: 0.5997 - val_loss: 1.6893\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7957 - val_accuracy: 0.5997 - val_loss: 1.6885\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7948 - val_accuracy: 0.5997 - val_loss: 1.6879\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7764 - loss: 0.7939 - val_accuracy: 0.6054 - val_loss: 1.6866\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7931 - val_accuracy: 0.6000 - val_loss: 1.6883\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7924 - val_accuracy: 0.6003 - val_loss: 1.6858\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7767 - loss: 0.7916 - val_accuracy: 0.5984 - val_loss: 1.6846\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7768 - loss: 0.7909 - val_accuracy: 0.5984 - val_loss: 1.6896\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7768 - loss: 0.7903 - val_accuracy: 0.5982 - val_loss: 1.6869\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7766 - loss: 0.7896 - val_accuracy: 0.5982 - val_loss: 1.6905\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7890 - val_accuracy: 0.5986 - val_loss: 1.6858\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7885 - val_accuracy: 0.5987 - val_loss: 1.6833\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7764 - loss: 0.7879 - val_accuracy: 0.5987 - val_loss: 1.6882\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7874 - val_accuracy: 0.5987 - val_loss: 1.6920\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7869 - val_accuracy: 0.5985 - val_loss: 1.6949\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7864 - val_accuracy: 0.5988 - val_loss: 1.6935\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7859 - val_accuracy: 0.5954 - val_loss: 1.6910\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7765 - loss: 0.7855 - val_accuracy: 0.5989 - val_loss: 1.6930\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7756 - loss: 0.7851 - val_accuracy: 0.5953 - val_loss: 1.6968\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7746 - loss: 0.7847 - val_accuracy: 0.5954 - val_loss: 1.6950\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7744 - loss: 0.7843 - val_accuracy: 0.5953 - val_loss: 1.6991\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7739 - loss: 0.7839 - val_accuracy: 0.5982 - val_loss: 1.6964\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7743 - loss: 0.7835 - val_accuracy: 0.5947 - val_loss: 1.6980\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7740 - loss: 0.7832 - val_accuracy: 0.5988 - val_loss: 1.6959\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7742 - loss: 0.7829 - val_accuracy: 0.5954 - val_loss: 1.6992\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7825 - val_accuracy: 0.5954 - val_loss: 1.7004\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7822 - val_accuracy: 0.5955 - val_loss: 1.6981\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7742 - loss: 0.7819 - val_accuracy: 0.5955 - val_loss: 1.6973\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7738 - loss: 0.7816 - val_accuracy: 0.5955 - val_loss: 1.6988\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7740 - loss: 0.7813 - val_accuracy: 0.5955 - val_loss: 1.7050\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7747 - loss: 0.7811 - val_accuracy: 0.5956 - val_loss: 1.7012\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7808 - val_accuracy: 0.5962 - val_loss: 1.6965\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7806 - val_accuracy: 0.5956 - val_loss: 1.7022\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7742 - loss: 0.7803 - val_accuracy: 0.5958 - val_loss: 1.6975\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7743 - loss: 0.7801 - val_accuracy: 0.5956 - val_loss: 1.6975\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7750 - loss: 0.7798 - val_accuracy: 0.5955 - val_loss: 1.7020\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7796 - val_accuracy: 0.5958 - val_loss: 1.7011\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7794 - val_accuracy: 0.5958 - val_loss: 1.7028\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7768 - loss: 0.7792 - val_accuracy: 0.5958 - val_loss: 1.6997\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7763 - loss: 0.7789 - val_accuracy: 0.5960 - val_loss: 1.7014\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7787 - val_accuracy: 0.5960 - val_loss: 1.6998\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7769 - loss: 0.7785 - val_accuracy: 0.5961 - val_loss: 1.7007\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7783 - val_accuracy: 0.5962 - val_loss: 1.7020\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7773 - loss: 0.7781 - val_accuracy: 0.5962 - val_loss: 1.7075\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7772 - loss: 0.7779 - val_accuracy: 0.5960 - val_loss: 1.7054\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7769 - loss: 0.7777 - val_accuracy: 0.5960 - val_loss: 1.7017\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7776 - val_accuracy: 0.5961 - val_loss: 1.7066\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7774 - val_accuracy: 0.5959 - val_loss: 1.7063\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7772 - val_accuracy: 0.5966 - val_loss: 1.7056\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7773 - loss: 0.7770 - val_accuracy: 0.5966 - val_loss: 1.7087\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7772 - loss: 0.7769 - val_accuracy: 0.5968 - val_loss: 1.7014\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7777 - loss: 0.7767 - val_accuracy: 0.5968 - val_loss: 1.7062\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7765 - val_accuracy: 0.5967 - val_loss: 1.7058\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7764 - val_accuracy: 0.5968 - val_loss: 1.7051\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7762 - val_accuracy: 0.5968 - val_loss: 1.7077\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.7760 - val_accuracy: 0.5968 - val_loss: 1.7061\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7759 - val_accuracy: 0.5968 - val_loss: 1.7061\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7757 - val_accuracy: 0.5969 - val_loss: 1.7016\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7756 - val_accuracy: 0.5967 - val_loss: 1.7055\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7754 - val_accuracy: 0.5968 - val_loss: 1.7045\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7753 - val_accuracy: 0.5967 - val_loss: 1.7056\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7783 - loss: 0.7751 - val_accuracy: 0.5967 - val_loss: 1.7054\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7791 - loss: 0.7750 - val_accuracy: 0.5967 - val_loss: 1.7036\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7786 - loss: 0.7748 - val_accuracy: 0.5967 - val_loss: 1.7048\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7747 - val_accuracy: 0.5967 - val_loss: 1.7080\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7746 - val_accuracy: 0.5967 - val_loss: 1.7029\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7744 - val_accuracy: 0.5967 - val_loss: 1.7053\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7743 - val_accuracy: 0.5967 - val_loss: 1.7060\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7794 - loss: 0.7741 - val_accuracy: 0.5967 - val_loss: 1.7039\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7740 - val_accuracy: 0.5967 - val_loss: 1.7039\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7739 - val_accuracy: 0.5967 - val_loss: 1.7046\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7738 - val_accuracy: 0.5967 - val_loss: 1.7070\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7736 - val_accuracy: 0.5965 - val_loss: 1.7089\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7787 - loss: 0.7735 - val_accuracy: 0.5967 - val_loss: 1.7068\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7790 - loss: 0.7734 - val_accuracy: 0.5967 - val_loss: 1.7072\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7732 - val_accuracy: 0.5970 - val_loss: 1.7031\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7731 - val_accuracy: 0.5963 - val_loss: 1.7080\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7787 - loss: 0.7730 - val_accuracy: 0.5964 - val_loss: 1.7075\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7729 - val_accuracy: 0.5968 - val_loss: 1.7043\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7727 - val_accuracy: 0.5964 - val_loss: 1.7069\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7789 - loss: 0.7726 - val_accuracy: 0.5964 - val_loss: 1.7093\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7725 - val_accuracy: 0.5968 - val_loss: 1.7051\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7724 - val_accuracy: 0.5967 - val_loss: 1.7090\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7786 - loss: 0.7723 - val_accuracy: 0.5968 - val_loss: 1.7036\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7722 - val_accuracy: 0.5965 - val_loss: 1.7039\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7720 - val_accuracy: 0.5964 - val_loss: 1.7089\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.7719 - val_accuracy: 0.5964 - val_loss: 1.7092\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7718 - val_accuracy: 0.5962 - val_loss: 1.7118\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7717 - val_accuracy: 0.5964 - val_loss: 1.7068\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7716 - val_accuracy: 0.5965 - val_loss: 1.7068\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7715 - val_accuracy: 0.5965 - val_loss: 1.7068\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7714 - val_accuracy: 0.5966 - val_loss: 1.7039\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7713 - val_accuracy: 0.5966 - val_loss: 1.7056\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7711 - val_accuracy: 0.5964 - val_loss: 1.7115\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7710 - val_accuracy: 0.5964 - val_loss: 1.7115\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7709 - val_accuracy: 0.5974 - val_loss: 1.7024\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7708 - val_accuracy: 0.5966 - val_loss: 1.7082\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7707 - val_accuracy: 0.5971 - val_loss: 1.7061\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7787 - loss: 0.7706 - val_accuracy: 0.5973 - val_loss: 1.7031\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7792 - loss: 0.7705 - val_accuracy: 0.5971 - val_loss: 1.7045\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7704 - val_accuracy: 0.5973 - val_loss: 1.7051\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7703 - val_accuracy: 0.5971 - val_loss: 1.7065\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7702 - val_accuracy: 0.5973 - val_loss: 1.7064\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7701 - val_accuracy: 0.5967 - val_loss: 1.7061\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7700 - val_accuracy: 0.5973 - val_loss: 1.7079\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60582\n726/726 - 7s - 10ms/step - accuracy: 0.7793 - loss: 0.7699 - val_accuracy: 0.5971 - val_loss: 1.7064\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7698 - val_accuracy: 0.5973 - val_loss: 1.7073\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7697 - val_accuracy: 0.5973 - val_loss: 1.7069\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7793 - loss: 0.7696 - val_accuracy: 0.5974 - val_loss: 1.7083\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7793 - loss: 0.7695 - val_accuracy: 0.5974 - val_loss: 1.7087\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7694 - val_accuracy: 0.6029 - val_loss: 1.7049\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7693 - val_accuracy: 0.5974 - val_loss: 1.7032\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7692 - val_accuracy: 0.5974 - val_loss: 1.7086\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7691 - val_accuracy: 0.5974 - val_loss: 1.7048\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7690 - val_accuracy: 0.5974 - val_loss: 1.7079\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7689 - val_accuracy: 0.5975 - val_loss: 1.7022\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7689 - val_accuracy: 0.5975 - val_loss: 1.7057\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7688 - val_accuracy: 0.5975 - val_loss: 1.7068\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7687 - val_accuracy: 0.5975 - val_loss: 1.7021\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7686 - val_accuracy: 0.5975 - val_loss: 1.7043\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7685 - val_accuracy: 0.5975 - val_loss: 1.7071\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7795 - loss: 0.7684 - val_accuracy: 0.6030 - val_loss: 1.7020\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7683 - val_accuracy: 0.5975 - val_loss: 1.7089\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7682 - val_accuracy: 0.5976 - val_loss: 1.7046\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7681 - val_accuracy: 0.5975 - val_loss: 1.7056\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7680 - val_accuracy: 0.5976 - val_loss: 1.7032\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7679 - val_accuracy: 0.5976 - val_loss: 1.7051\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7679 - val_accuracy: 0.5975 - val_loss: 1.7084\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7678 - val_accuracy: 0.5988 - val_loss: 1.7075\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7797 - loss: 0.7677 - val_accuracy: 0.5988 - val_loss: 1.7107\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7798 - loss: 0.7676 - val_accuracy: 0.5988 - val_loss: 1.7063\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7675 - val_accuracy: 0.5988 - val_loss: 1.7056\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7674 - val_accuracy: 0.5988 - val_loss: 1.7064\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7673 - val_accuracy: 0.5988 - val_loss: 1.7054\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7672 - val_accuracy: 0.5988 - val_loss: 1.7040\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7797 - loss: 0.7672 - val_accuracy: 0.5988 - val_loss: 1.7050\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7671 - val_accuracy: 0.5988 - val_loss: 1.7074\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7670 - val_accuracy: 0.5988 - val_loss: 1.7086\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7669 - val_accuracy: 0.5988 - val_loss: 1.7067\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7668 - val_accuracy: 0.6043 - val_loss: 1.7020\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7798 - loss: 0.7667 - val_accuracy: 0.6043 - val_loss: 1.7060\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7797 - loss: 0.7667 - val_accuracy: 0.5988 - val_loss: 1.7033\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7798 - loss: 0.7666 - val_accuracy: 0.5988 - val_loss: 1.7074\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7798 - loss: 0.7665 - val_accuracy: 0.5988 - val_loss: 1.7060\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7664 - val_accuracy: 0.5988 - val_loss: 1.7074\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7663 - val_accuracy: 0.5990 - val_loss: 1.7074\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7663 - val_accuracy: 0.5990 - val_loss: 1.7032\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7797 - loss: 0.7662 - val_accuracy: 0.6047 - val_loss: 1.7033\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7661 - val_accuracy: 0.5992 - val_loss: 1.7039\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7660 - val_accuracy: 0.5990 - val_loss: 1.7067\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7659 - val_accuracy: 0.6047 - val_loss: 1.7040\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7659 - val_accuracy: 0.5992 - val_loss: 1.7071\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7658 - val_accuracy: 0.6047 - val_loss: 1.7037\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7794 - loss: 0.7657 - val_accuracy: 0.5992 - val_loss: 1.7048\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7656 - val_accuracy: 0.5992 - val_loss: 1.7097\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7656 - val_accuracy: 0.5992 - val_loss: 1.7064\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7655 - val_accuracy: 0.5992 - val_loss: 1.7067\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7654 - val_accuracy: 0.5992 - val_loss: 1.7041\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7653 - val_accuracy: 0.6047 - val_loss: 1.7042\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7794 - loss: 0.7653 - val_accuracy: 0.5994 - val_loss: 1.7059\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7652 - val_accuracy: 0.6049 - val_loss: 1.7055\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7651 - val_accuracy: 0.5994 - val_loss: 1.7083\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7795 - loss: 0.7650 - val_accuracy: 0.5995 - val_loss: 1.7024\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7650 - val_accuracy: 0.6049 - val_loss: 1.7040\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7649 - val_accuracy: 0.5994 - val_loss: 1.7068\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7648 - val_accuracy: 0.5994 - val_loss: 1.7063\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7647 - val_accuracy: 0.5994 - val_loss: 1.7063\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7647 - val_accuracy: 0.6050 - val_loss: 1.7021\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7646 - val_accuracy: 0.5994 - val_loss: 1.7062\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7645 - val_accuracy: 0.5994 - val_loss: 1.7085\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7644 - val_accuracy: 0.6050 - val_loss: 1.7038\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7644 - val_accuracy: 0.5995 - val_loss: 1.7026\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7643 - val_accuracy: 0.5994 - val_loss: 1.7066\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7642 - val_accuracy: 0.6052 - val_loss: 1.7031\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7642 - val_accuracy: 0.5994 - val_loss: 1.7114\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7641 - val_accuracy: 0.5996 - val_loss: 1.7085\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7640 - val_accuracy: 0.6052 - val_loss: 1.7037\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7795 - loss: 0.7640 - val_accuracy: 0.5997 - val_loss: 1.7066\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7639 - val_accuracy: 0.5997 - val_loss: 1.7103\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7638 - val_accuracy: 0.5997 - val_loss: 1.7104\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7637 - val_accuracy: 0.6052 - val_loss: 1.7060\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7637 - val_accuracy: 0.5997 - val_loss: 1.7086\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7636 - val_accuracy: 0.5997 - val_loss: 1.7060\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7795 - loss: 0.7635 - val_accuracy: 0.5998 - val_loss: 1.7059\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7635 - val_accuracy: 0.5998 - val_loss: 1.7090\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7634 - val_accuracy: 0.5997 - val_loss: 1.7073\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7633 - val_accuracy: 0.6053 - val_loss: 1.7041\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7633 - val_accuracy: 0.6053 - val_loss: 1.7032\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7632 - val_accuracy: 0.5999 - val_loss: 1.7065\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7631 - val_accuracy: 0.6053 - val_loss: 1.7048\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7631 - val_accuracy: 0.6054 - val_loss: 1.7053\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7630 - val_accuracy: 0.6054 - val_loss: 1.7061\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7629 - val_accuracy: 0.5999 - val_loss: 1.7066\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7629 - val_accuracy: 0.5999 - val_loss: 1.7050\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7628 - val_accuracy: 0.6054 - val_loss: 1.7059\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7627 - val_accuracy: 0.6054 - val_loss: 1.7063\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7799 - loss: 0.7627 - val_accuracy: 0.5999 - val_loss: 1.7062\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7798 - loss: 0.7626 - val_accuracy: 0.5999 - val_loss: 1.7072\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7799 - loss: 0.7625 - val_accuracy: 0.6054 - val_loss: 1.7039\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7805 - loss: 0.7625 - val_accuracy: 0.6054 - val_loss: 1.7032\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7811 - loss: 0.7624 - val_accuracy: 0.5999 - val_loss: 1.7073\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7812 - loss: 0.7624 - val_accuracy: 0.6055 - val_loss: 1.7030\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7818 - loss: 0.7623 - val_accuracy: 0.6055 - val_loss: 1.7065\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7622 - val_accuracy: 0.6055 - val_loss: 1.7048\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7622 - val_accuracy: 0.6000 - val_loss: 1.7061\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7621 - val_accuracy: 0.6055 - val_loss: 1.7017\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7620 - val_accuracy: 0.6001 - val_loss: 1.7005\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7620 - val_accuracy: 0.6055 - val_loss: 1.7034\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7619 - val_accuracy: 0.6000 - val_loss: 1.7097\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7619 - val_accuracy: 0.6000 - val_loss: 1.7028\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7618 - val_accuracy: 0.6000 - val_loss: 1.7060\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7617 - val_accuracy: 0.6055 - val_loss: 1.7058\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7617 - val_accuracy: 0.6000 - val_loss: 1.7084\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7616 - val_accuracy: 0.6000 - val_loss: 1.7069\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7616 - val_accuracy: 0.6055 - val_loss: 1.7065\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7615 - val_accuracy: 0.6055 - val_loss: 1.7062\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7614 - val_accuracy: 0.6056 - val_loss: 1.7022\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7614 - val_accuracy: 0.6001 - val_loss: 1.7066\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7819 - loss: 0.7613 - val_accuracy: 0.6055 - val_loss: 1.7047\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7612 - val_accuracy: 0.6001 - val_loss: 1.7051\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7612 - val_accuracy: 0.6001 - val_loss: 1.7069\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7819 - loss: 0.7611 - val_accuracy: 0.6055 - val_loss: 1.7048\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7611 - val_accuracy: 0.6001 - val_loss: 1.7066\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7610 - val_accuracy: 0.6001 - val_loss: 1.7087\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7610 - val_accuracy: 0.6000 - val_loss: 1.7087\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7609 - val_accuracy: 0.6000 - val_loss: 1.7087\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7608 - val_accuracy: 0.6001 - val_loss: 1.7041\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7608 - val_accuracy: 0.6056 - val_loss: 1.7057\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7607 - val_accuracy: 0.6001 - val_loss: 1.7058\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7607 - val_accuracy: 0.6055 - val_loss: 1.7051\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7606 - val_accuracy: 0.6055 - val_loss: 1.7045\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7606 - val_accuracy: 0.6055 - val_loss: 1.7089\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7605 - val_accuracy: 0.6055 - val_loss: 1.7025\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7604 - val_accuracy: 0.6055 - val_loss: 1.7061\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7604 - val_accuracy: 0.6055 - val_loss: 1.7061\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7603 - val_accuracy: 0.6001 - val_loss: 1.7071\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7603 - val_accuracy: 0.6055 - val_loss: 1.7038\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7602 - val_accuracy: 0.6055 - val_loss: 1.7088\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7602 - val_accuracy: 0.6055 - val_loss: 1.7054\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7601 - val_accuracy: 0.6056 - val_loss: 1.7035\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7600 - val_accuracy: 0.6055 - val_loss: 1.7087\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7600 - val_accuracy: 0.6000 - val_loss: 1.7086\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7599 - val_accuracy: 0.6057 - val_loss: 1.7034\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7820 - loss: 0.7599 - val_accuracy: 0.6000 - val_loss: 1.7069\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7821 - loss: 0.7598 - val_accuracy: 0.6000 - val_loss: 1.7097\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7598 - val_accuracy: 0.6056 - val_loss: 1.7056\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7597 - val_accuracy: 0.6000 - val_loss: 1.7092\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7597 - val_accuracy: 0.6000 - val_loss: 1.7088\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7822 - loss: 0.7596 - val_accuracy: 0.6055 - val_loss: 1.7079\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7823 - loss: 0.7596 - val_accuracy: 0.6056 - val_loss: 1.7069\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7823 - loss: 0.7595 - val_accuracy: 0.6001 - val_loss: 1.7081\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7823 - loss: 0.7594 - val_accuracy: 0.6057 - val_loss: 1.7059\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7594 - val_accuracy: 0.6002 - val_loss: 1.7083\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7593 - val_accuracy: 0.6057 - val_loss: 1.7051\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7593 - val_accuracy: 0.6057 - val_loss: 1.7030\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7592 - val_accuracy: 0.6058 - val_loss: 1.7013\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7592 - val_accuracy: 0.6056 - val_loss: 1.7097\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7591 - val_accuracy: 0.6057 - val_loss: 1.7048\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7591 - val_accuracy: 0.6057 - val_loss: 1.7045\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60582\n726/726 - 5s - 8ms/step - accuracy: 0.7825 - loss: 0.7590 - val_accuracy: 0.6057 - val_loss: 1.7080\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7590 - val_accuracy: 0.6058 - val_loss: 1.7041\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7589 - val_accuracy: 0.6058 - val_loss: 1.7037\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7589 - val_accuracy: 0.6057 - val_loss: 1.7035\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7588 - val_accuracy: 0.6002 - val_loss: 1.7065\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7588 - val_accuracy: 0.6056 - val_loss: 1.7036\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7825 - loss: 0.7587 - val_accuracy: 0.6056 - val_loss: 1.7075\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7587 - val_accuracy: 0.6056 - val_loss: 1.7046\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7586 - val_accuracy: 0.6056 - val_loss: 1.7103\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7586 - val_accuracy: 0.6057 - val_loss: 1.7071\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7585 - val_accuracy: 0.6057 - val_loss: 1.7063\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7585 - val_accuracy: 0.6002 - val_loss: 1.7086\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60582\n726/726 - 6s - 8ms/step - accuracy: 0.7826 - loss: 0.7584 - val_accuracy: 0.6057 - val_loss: 1.7045\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7584 - val_accuracy: 0.6057 - val_loss: 1.7034\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7583 - val_accuracy: 0.6057 - val_loss: 1.7059\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7583 - val_accuracy: 0.6057 - val_loss: 1.7083\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7582 - val_accuracy: 0.6057 - val_loss: 1.7074\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7582 - val_accuracy: 0.6057 - val_loss: 1.7030\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7581 - val_accuracy: 0.6056 - val_loss: 1.7093\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7581 - val_accuracy: 0.6058 - val_loss: 1.7026\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7580 - val_accuracy: 0.6057 - val_loss: 1.7064\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7580 - val_accuracy: 0.6058 - val_loss: 1.7040\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7579 - val_accuracy: 0.6058 - val_loss: 1.7021\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7579 - val_accuracy: 0.6057 - val_loss: 1.7076\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7578 - val_accuracy: 0.6057 - val_loss: 1.7093\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7578 - val_accuracy: 0.6057 - val_loss: 1.7065\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7577 - val_accuracy: 0.6002 - val_loss: 1.7089\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7577 - val_accuracy: 0.6057 - val_loss: 1.7033\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7576 - val_accuracy: 0.6057 - val_loss: 1.7077\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7576 - val_accuracy: 0.6058 - val_loss: 1.7048\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7575 - val_accuracy: 0.6058 - val_loss: 1.7033\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7575 - val_accuracy: 0.6057 - val_loss: 1.7083\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7574 - val_accuracy: 0.6057 - val_loss: 1.7088\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7574 - val_accuracy: 0.6057 - val_loss: 1.7044\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7573 - val_accuracy: 0.6058 - val_loss: 1.7022\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7573 - val_accuracy: 0.6058 - val_loss: 1.7020\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7572 - val_accuracy: 0.6057 - val_loss: 1.7049\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7572 - val_accuracy: 0.6058 - val_loss: 1.7041\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7571 - val_accuracy: 0.6058 - val_loss: 1.7041\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7571 - val_accuracy: 0.6057 - val_loss: 1.7091\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7570 - val_accuracy: 0.6057 - val_loss: 1.7051\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7570 - val_accuracy: 0.6058 - val_loss: 1.7072\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7570 - val_accuracy: 0.6058 - val_loss: 1.6998\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7569 - val_accuracy: 0.6002 - val_loss: 1.7070\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7569 - val_accuracy: 0.6058 - val_loss: 1.7066\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7568 - val_accuracy: 0.6058 - val_loss: 1.7074\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7568 - val_accuracy: 0.6058 - val_loss: 1.7032\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7567 - val_accuracy: 0.6058 - val_loss: 1.7026\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7826 - loss: 0.7567 - val_accuracy: 0.6058 - val_loss: 1.7024\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7566 - val_accuracy: 0.6057 - val_loss: 1.7064\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7566 - val_accuracy: 0.6057 - val_loss: 1.7050\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7565 - val_accuracy: 0.6057 - val_loss: 1.7066\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7565 - val_accuracy: 0.6057 - val_loss: 1.7064\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7564 - val_accuracy: 0.6057 - val_loss: 1.7070\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60582\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7564 - val_accuracy: 0.6057 - val_loss: 1.7048\nEpoch 335/500\n\nEpoch 335: val_accuracy improved from 0.60582 to 0.61006, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7835 - loss: 0.7564 - val_accuracy: 0.6101 - val_loss: 1.7031\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7563 - val_accuracy: 0.6045 - val_loss: 1.7101\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7828 - loss: 0.7563 - val_accuracy: 0.6057 - val_loss: 1.7044\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7562 - val_accuracy: 0.6058 - val_loss: 1.7037\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7562 - val_accuracy: 0.6058 - val_loss: 1.7017\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7827 - loss: 0.7561 - val_accuracy: 0.6057 - val_loss: 1.7046\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7835 - loss: 0.7561 - val_accuracy: 0.6003 - val_loss: 1.7069\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7560 - val_accuracy: 0.6002 - val_loss: 1.7091\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7560 - val_accuracy: 0.6058 - val_loss: 1.7060\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7842 - loss: 0.7559 - val_accuracy: 0.6057 - val_loss: 1.7050\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7559 - val_accuracy: 0.6003 - val_loss: 1.7065\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7559 - val_accuracy: 0.6057 - val_loss: 1.7081\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7558 - val_accuracy: 0.6100 - val_loss: 1.7092\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61006\n726/726 - 6s - 8ms/step - accuracy: 0.7845 - loss: 0.7558 - val_accuracy: 0.6057 - val_loss: 1.7056\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7845 - loss: 0.7557 - val_accuracy: 0.6058 - val_loss: 1.7035\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7848 - loss: 0.7557 - val_accuracy: 0.6058 - val_loss: 1.7056\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7836 - loss: 0.7556 - val_accuracy: 0.6058 - val_loss: 1.7055\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61006\n726/726 - 5s - 7ms/step - accuracy: 0.7848 - loss: 0.7556 - val_accuracy: 0.5986 - val_loss: 1.7079\nEpoch 353/500\n\nEpoch 353: val_accuracy improved from 0.61006 to 0.61012, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7847 - loss: 0.7556 - val_accuracy: 0.6101 - val_loss: 1.7041\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7834 - loss: 0.7555 - val_accuracy: 0.6084 - val_loss: 1.7067\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7859 - loss: 0.7555 - val_accuracy: 0.6085 - val_loss: 1.7014\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 6s - 9ms/step - accuracy: 0.7853 - loss: 0.7554 - val_accuracy: 0.6042 - val_loss: 1.7060\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7851 - loss: 0.7554 - val_accuracy: 0.6092 - val_loss: 1.7027\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7851 - loss: 0.7553 - val_accuracy: 0.6084 - val_loss: 1.7071\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7846 - loss: 0.7553 - val_accuracy: 0.6086 - val_loss: 1.7072\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7855 - loss: 0.7553 - val_accuracy: 0.6028 - val_loss: 1.7119\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7859 - loss: 0.7552 - val_accuracy: 0.6092 - val_loss: 1.7024\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7552 - val_accuracy: 0.6036 - val_loss: 1.7077\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7864 - loss: 0.7551 - val_accuracy: 0.6050 - val_loss: 1.7049\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7857 - loss: 0.7551 - val_accuracy: 0.6085 - val_loss: 1.7081\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7854 - loss: 0.7550 - val_accuracy: 0.6093 - val_loss: 1.7026\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7550 - val_accuracy: 0.6037 - val_loss: 1.7114\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7855 - loss: 0.7550 - val_accuracy: 0.6093 - val_loss: 1.7035\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7549 - val_accuracy: 0.6093 - val_loss: 1.7034\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7549 - val_accuracy: 0.6091 - val_loss: 1.7080\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7548 - val_accuracy: 0.6093 - val_loss: 1.7050\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7548 - val_accuracy: 0.6037 - val_loss: 1.7083\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7548 - val_accuracy: 0.6093 - val_loss: 1.7025\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7863 - loss: 0.7547 - val_accuracy: 0.6092 - val_loss: 1.7076\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7547 - val_accuracy: 0.6092 - val_loss: 1.7090\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7546 - val_accuracy: 0.6091 - val_loss: 1.7091\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7546 - val_accuracy: 0.6092 - val_loss: 1.7061\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7545 - val_accuracy: 0.6091 - val_loss: 1.7074\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7853 - loss: 0.7545 - val_accuracy: 0.6092 - val_loss: 1.7060\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7545 - val_accuracy: 0.6093 - val_loss: 1.7041\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7544 - val_accuracy: 0.6092 - val_loss: 1.7027\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7544 - val_accuracy: 0.6093 - val_loss: 1.7029\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7869 - loss: 0.7543 - val_accuracy: 0.6036 - val_loss: 1.7111\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7543 - val_accuracy: 0.6092 - val_loss: 1.7029\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7543 - val_accuracy: 0.6092 - val_loss: 1.7098\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7542 - val_accuracy: 0.6092 - val_loss: 1.7068\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7863 - loss: 0.7542 - val_accuracy: 0.6037 - val_loss: 1.7074\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7541 - val_accuracy: 0.6092 - val_loss: 1.7056\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7541 - val_accuracy: 0.6092 - val_loss: 1.7081\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7541 - val_accuracy: 0.6092 - val_loss: 1.7049\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7540 - val_accuracy: 0.6092 - val_loss: 1.7048\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7540 - val_accuracy: 0.6093 - val_loss: 1.7042\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7539 - val_accuracy: 0.6091 - val_loss: 1.7062\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7539 - val_accuracy: 0.6093 - val_loss: 1.7058\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7539 - val_accuracy: 0.6093 - val_loss: 1.7080\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7538 - val_accuracy: 0.6091 - val_loss: 1.7083\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7538 - val_accuracy: 0.6093 - val_loss: 1.7027\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7537 - val_accuracy: 0.6093 - val_loss: 1.7047\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7537 - val_accuracy: 0.6093 - val_loss: 1.7046\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7537 - val_accuracy: 0.6038 - val_loss: 1.7084\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7868 - loss: 0.7536 - val_accuracy: 0.6093 - val_loss: 1.7059\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7869 - loss: 0.7536 - val_accuracy: 0.6038 - val_loss: 1.7067\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7869 - loss: 0.7535 - val_accuracy: 0.6093 - val_loss: 1.7047\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7869 - loss: 0.7535 - val_accuracy: 0.6093 - val_loss: 1.7066\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7871 - loss: 0.7535 - val_accuracy: 0.6093 - val_loss: 1.7077\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7870 - loss: 0.7534 - val_accuracy: 0.6093 - val_loss: 1.7078\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7870 - loss: 0.7534 - val_accuracy: 0.6093 - val_loss: 1.7058\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7870 - loss: 0.7533 - val_accuracy: 0.6093 - val_loss: 1.7052\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7871 - loss: 0.7533 - val_accuracy: 0.6093 - val_loss: 1.7048\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7533 - val_accuracy: 0.6093 - val_loss: 1.7036\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7870 - loss: 0.7532 - val_accuracy: 0.6092 - val_loss: 1.7091\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7871 - loss: 0.7532 - val_accuracy: 0.6037 - val_loss: 1.7115\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7532 - val_accuracy: 0.6093 - val_loss: 1.7052\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7871 - loss: 0.7531 - val_accuracy: 0.6038 - val_loss: 1.7092\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7873 - loss: 0.7531 - val_accuracy: 0.6092 - val_loss: 1.7074\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7870 - loss: 0.7530 - val_accuracy: 0.6097 - val_loss: 1.7027\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7530 - val_accuracy: 0.6093 - val_loss: 1.7061\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7530 - val_accuracy: 0.6093 - val_loss: 1.7067\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7529 - val_accuracy: 0.6093 - val_loss: 1.7072\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7529 - val_accuracy: 0.6093 - val_loss: 1.7084\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7529 - val_accuracy: 0.6093 - val_loss: 1.7053\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7528 - val_accuracy: 0.6093 - val_loss: 1.7080\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7528 - val_accuracy: 0.6092 - val_loss: 1.7056\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7527 - val_accuracy: 0.6093 - val_loss: 1.7066\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7527 - val_accuracy: 0.6093 - val_loss: 1.7053\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7527 - val_accuracy: 0.6093 - val_loss: 1.7074\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7526 - val_accuracy: 0.6093 - val_loss: 1.7061\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7526 - val_accuracy: 0.6093 - val_loss: 1.7044\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7526 - val_accuracy: 0.6092 - val_loss: 1.7092\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7525 - val_accuracy: 0.6092 - val_loss: 1.7075\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7525 - val_accuracy: 0.6093 - val_loss: 1.7067\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7524 - val_accuracy: 0.6095 - val_loss: 1.7045\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7524 - val_accuracy: 0.6093 - val_loss: 1.7078\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7874 - loss: 0.7524 - val_accuracy: 0.6093 - val_loss: 1.7072\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7523 - val_accuracy: 0.6095 - val_loss: 1.7052\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7523 - val_accuracy: 0.6093 - val_loss: 1.7057\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7523 - val_accuracy: 0.6092 - val_loss: 1.7080\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7522 - val_accuracy: 0.6093 - val_loss: 1.7077\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7522 - val_accuracy: 0.6096 - val_loss: 1.7051\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7874 - loss: 0.7522 - val_accuracy: 0.6095 - val_loss: 1.7058\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7521 - val_accuracy: 0.6095 - val_loss: 1.7084\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7521 - val_accuracy: 0.6095 - val_loss: 1.7086\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7520 - val_accuracy: 0.6099 - val_loss: 1.7051\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7520 - val_accuracy: 0.6099 - val_loss: 1.7051\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7520 - val_accuracy: 0.6099 - val_loss: 1.7025\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7879 - loss: 0.7519 - val_accuracy: 0.6099 - val_loss: 1.7055\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7519 - val_accuracy: 0.6045 - val_loss: 1.7052\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7519 - val_accuracy: 0.6099 - val_loss: 1.7027\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7518 - val_accuracy: 0.6099 - val_loss: 1.7092\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7518 - val_accuracy: 0.6099 - val_loss: 1.7056\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7518 - val_accuracy: 0.6099 - val_loss: 1.7046\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7879 - loss: 0.7517 - val_accuracy: 0.6099 - val_loss: 1.7068\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7517 - val_accuracy: 0.6099 - val_loss: 1.7058\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7516 - val_accuracy: 0.6099 - val_loss: 1.7064\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7516 - val_accuracy: 0.6096 - val_loss: 1.7090\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7516 - val_accuracy: 0.6098 - val_loss: 1.7091\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7515 - val_accuracy: 0.6099 - val_loss: 1.7082\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7878 - loss: 0.7515 - val_accuracy: 0.6100 - val_loss: 1.7017\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7515 - val_accuracy: 0.6099 - val_loss: 1.7080\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7514 - val_accuracy: 0.6044 - val_loss: 1.7113\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7514 - val_accuracy: 0.6099 - val_loss: 1.7020\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7514 - val_accuracy: 0.6099 - val_loss: 1.7056\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7513 - val_accuracy: 0.6100 - val_loss: 1.7020\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7513 - val_accuracy: 0.6099 - val_loss: 1.7072\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7513 - val_accuracy: 0.6099 - val_loss: 1.7056\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7512 - val_accuracy: 0.6099 - val_loss: 1.7089\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7512 - val_accuracy: 0.6099 - val_loss: 1.7088\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7512 - val_accuracy: 0.6099 - val_loss: 1.7063\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7511 - val_accuracy: 0.6099 - val_loss: 1.7040\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7511 - val_accuracy: 0.6099 - val_loss: 1.7075\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7511 - val_accuracy: 0.6099 - val_loss: 1.7075\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7510 - val_accuracy: 0.6099 - val_loss: 1.7085\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7510 - val_accuracy: 0.6099 - val_loss: 1.7057\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7509 - val_accuracy: 0.6099 - val_loss: 1.7095\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7509 - val_accuracy: 0.6099 - val_loss: 1.7069\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7509 - val_accuracy: 0.6099 - val_loss: 1.7119\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7509 - val_accuracy: 0.6099 - val_loss: 1.7078\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7508 - val_accuracy: 0.6099 - val_loss: 1.7034\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7508 - val_accuracy: 0.6099 - val_loss: 1.7040\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7507 - val_accuracy: 0.6099 - val_loss: 1.7035\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7507 - val_accuracy: 0.6099 - val_loss: 1.7087\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7881 - loss: 0.7507 - val_accuracy: 0.6099 - val_loss: 1.7059\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7506 - val_accuracy: 0.6100 - val_loss: 1.7053\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7506 - val_accuracy: 0.6100 - val_loss: 1.7048\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7879 - loss: 0.7506 - val_accuracy: 0.6100 - val_loss: 1.7049\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7883 - loss: 0.7505 - val_accuracy: 0.6100 - val_loss: 1.7060\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7505 - val_accuracy: 0.6100 - val_loss: 1.7058\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7878 - loss: 0.7505 - val_accuracy: 0.6100 - val_loss: 1.7048\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7504 - val_accuracy: 0.6099 - val_loss: 1.7075\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7504 - val_accuracy: 0.6099 - val_loss: 1.7084\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7504 - val_accuracy: 0.6100 - val_loss: 1.7054\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7503 - val_accuracy: 0.6099 - val_loss: 1.7092\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7503 - val_accuracy: 0.6099 - val_loss: 1.7063\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7884 - loss: 0.7503 - val_accuracy: 0.6099 - val_loss: 1.7089\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7502 - val_accuracy: 0.6100 - val_loss: 1.7044\nEpoch 495/500\n\nEpoch 495: val_accuracy improved from 0.61012 to 0.61012, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7502 - val_accuracy: 0.6101 - val_loss: 1.7034\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7502 - val_accuracy: 0.6101 - val_loss: 1.7062\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7501 - val_accuracy: 0.6100 - val_loss: 1.7049\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7501 - val_accuracy: 0.6100 - val_loss: 1.7043\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7501 - val_accuracy: 0.6099 - val_loss: 1.7097\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7500 - val_accuracy: 0.6100 - val_loss: 1.7042\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_9, X_test_9, y_train_9, y_test_9 = train_test_split(\n    X, y, test_size=0.3, random_state=51, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_9, X_val_9, y_train_9, y_val_9 = train_test_split(\n    X_train_9, y_train_9, test_size=0.2, random_state=51, stratify=y_train_9\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_9:\", np.max(X_train_9))\nprint(\"Min value in X_train_9:\", np.min(X_train_9))\n\nX_train_9_scaled = scaler.fit_transform(X_train_9)\n\n# Get the original class distribution\nclass_counts_9 = Counter(y_train_9)\nprint(\"Original class distribution:\", class_counts_9)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_9 = class_counts_9[min(class_counts_9, key=class_counts_9.get)]\ndesired_majority_size_9 = minority_class_size_9 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_9 = {0: desired_majority_size_9, 1: minority_class_size_9}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_9 = RandomUnderSampler(sampling_strategy=sampling_strategy_9, random_state=42)\nX_resampled_9, y_resampled_9 = undersampler_9.fit_resample(X_train_9, y_train_9)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_9))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_9, y_train_resampled_9 = smote.fit_resample(X_resampled_9, y_resampled_9)\n\n\n#Verify the class distribution after SMOTE\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_9))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_9))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T01:31:35.870022Z","iopub.execute_input":"2025-03-07T01:31:35.870519Z","iopub.status.idle":"2025-03-07T01:32:14.124270Z","shell.execute_reply.started":"2025-03-07T01:31:35.870459Z","shell.execute_reply":"2025-03-07T01:32:14.123078Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_9: 2071000000.0\nMin value in X_train_9: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_9 = X_train_resampled_9.reshape(X_train_resampled_9.shape[0], 1, 56)\nX_val_9 = X_val_9.reshape(X_val_9.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_9,  # Features from CICIDS2017\n    y_train_resampled_9,  # Labels from CICIDS2017\n    validation_data=(X_val_9, y_val_9),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T01:32:14.125633Z","iopub.execute_input":"2025-03-07T01:32:14.126069Z","iopub.status.idle":"2025-03-07T02:15:23.888357Z","shell.execute_reply.started":"2025-03-07T01:32:14.126030Z","shell.execute_reply":"2025-03-07T02:15:23.885213Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7534 - loss: 1.1401 - val_accuracy: 0.5972 - val_loss: 1.7131\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7536 - loss: 1.1274 - val_accuracy: 0.5972 - val_loss: 1.7057\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7548 - loss: 1.1178 - val_accuracy: 0.5974 - val_loss: 1.6975\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7554 - loss: 1.1093 - val_accuracy: 0.5965 - val_loss: 1.6953\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7541 - loss: 1.1014 - val_accuracy: 0.5950 - val_loss: 1.6883\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7516 - loss: 1.0940 - val_accuracy: 0.6061 - val_loss: 1.6820\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7519 - loss: 1.0870 - val_accuracy: 0.6064 - val_loss: 1.6798\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 1.0804 - val_accuracy: 0.6060 - val_loss: 1.6777\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7520 - loss: 1.0742 - val_accuracy: 0.6060 - val_loss: 1.6761\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7517 - loss: 1.0684 - val_accuracy: 0.6046 - val_loss: 1.6690\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7518 - loss: 1.0629 - val_accuracy: 0.6044 - val_loss: 1.6668\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7521 - loss: 1.0578 - val_accuracy: 0.6032 - val_loss: 1.6671\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7520 - loss: 1.0530 - val_accuracy: 0.6032 - val_loss: 1.6685\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7523 - loss: 1.0485 - val_accuracy: 0.6033 - val_loss: 1.6641\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 1.0442 - val_accuracy: 0.6023 - val_loss: 1.6635\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7520 - loss: 1.0402 - val_accuracy: 0.6014 - val_loss: 1.6679\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7523 - loss: 1.0362 - val_accuracy: 0.6017 - val_loss: 1.6656\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7522 - loss: 1.0324 - val_accuracy: 0.6046 - val_loss: 1.6645\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7539 - loss: 1.0287 - val_accuracy: 0.6011 - val_loss: 1.6656\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7544 - loss: 1.0250 - val_accuracy: 0.6016 - val_loss: 1.6643\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7543 - loss: 1.0214 - val_accuracy: 0.6050 - val_loss: 1.6649\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 1.0178 - val_accuracy: 0.6042 - val_loss: 1.6695\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7566 - loss: 1.0143 - val_accuracy: 0.6033 - val_loss: 1.6650\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7560 - loss: 1.0109 - val_accuracy: 0.6033 - val_loss: 1.6676\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7563 - loss: 1.0075 - val_accuracy: 0.5999 - val_loss: 1.6704\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7561 - loss: 1.0042 - val_accuracy: 0.6033 - val_loss: 1.6687\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 1.0009 - val_accuracy: 0.6032 - val_loss: 1.6664\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.9977 - val_accuracy: 0.6030 - val_loss: 1.6699\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.9945 - val_accuracy: 0.6027 - val_loss: 1.6748\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.9914 - val_accuracy: 0.6029 - val_loss: 1.6713\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7559 - loss: 0.9883 - val_accuracy: 0.6028 - val_loss: 1.6793\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7559 - loss: 0.9852 - val_accuracy: 0.6028 - val_loss: 1.6805\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7559 - loss: 0.9822 - val_accuracy: 0.6024 - val_loss: 1.6793\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7558 - loss: 0.9792 - val_accuracy: 0.6024 - val_loss: 1.6800\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7557 - loss: 0.9763 - val_accuracy: 0.5910 - val_loss: 1.6833\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9734 - val_accuracy: 0.5910 - val_loss: 1.6827\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9705 - val_accuracy: 0.5903 - val_loss: 1.6882\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9677 - val_accuracy: 0.5902 - val_loss: 1.6900\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9649 - val_accuracy: 0.5901 - val_loss: 1.6899\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9621 - val_accuracy: 0.5899 - val_loss: 1.6876\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9594 - val_accuracy: 0.5877 - val_loss: 1.6982\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9567 - val_accuracy: 0.5877 - val_loss: 1.6958\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9541 - val_accuracy: 0.5877 - val_loss: 1.6992\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9515 - val_accuracy: 0.5877 - val_loss: 1.7005\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9489 - val_accuracy: 0.5876 - val_loss: 1.7040\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7554 - loss: 0.9463 - val_accuracy: 0.5874 - val_loss: 1.7051\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7555 - loss: 0.9438 - val_accuracy: 0.5875 - val_loss: 1.7043\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.9413 - val_accuracy: 0.5876 - val_loss: 1.7048\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7553 - loss: 0.9388 - val_accuracy: 0.5876 - val_loss: 1.7105\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7551 - loss: 0.9364 - val_accuracy: 0.5874 - val_loss: 1.7200\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7551 - loss: 0.9340 - val_accuracy: 0.5874 - val_loss: 1.7150\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7551 - loss: 0.9316 - val_accuracy: 0.5874 - val_loss: 1.7155\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7547 - loss: 0.9293 - val_accuracy: 0.5874 - val_loss: 1.7183\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7547 - loss: 0.9271 - val_accuracy: 0.5873 - val_loss: 1.7188\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7549 - loss: 0.9248 - val_accuracy: 0.5878 - val_loss: 1.7208\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7548 - loss: 0.9226 - val_accuracy: 0.5877 - val_loss: 1.7244\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7548 - loss: 0.9204 - val_accuracy: 0.5873 - val_loss: 1.7238\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7565 - loss: 0.9183 - val_accuracy: 0.5725 - val_loss: 1.7270\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7582 - loss: 0.9162 - val_accuracy: 0.5724 - val_loss: 1.7286\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.9142 - val_accuracy: 0.5693 - val_loss: 1.7306\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.9122 - val_accuracy: 0.5693 - val_loss: 1.7326\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.9102 - val_accuracy: 0.5693 - val_loss: 1.7323\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7582 - loss: 0.9083 - val_accuracy: 0.5693 - val_loss: 1.7350\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7578 - loss: 0.9064 - val_accuracy: 0.5686 - val_loss: 1.7337\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7570 - loss: 0.9046 - val_accuracy: 0.5682 - val_loss: 1.7432\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.9028 - val_accuracy: 0.5682 - val_loss: 1.7339\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.9011 - val_accuracy: 0.5681 - val_loss: 1.7406\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.8994 - val_accuracy: 0.5681 - val_loss: 1.7435\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.8977 - val_accuracy: 0.5681 - val_loss: 1.7455\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.8961 - val_accuracy: 0.5681 - val_loss: 1.7419\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7568 - loss: 0.8945 - val_accuracy: 0.5681 - val_loss: 1.7459\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.8930 - val_accuracy: 0.5681 - val_loss: 1.7442\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7568 - loss: 0.8916 - val_accuracy: 0.5681 - val_loss: 1.7455\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7550 - loss: 0.8902 - val_accuracy: 0.5680 - val_loss: 1.7511\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7542 - loss: 0.8888 - val_accuracy: 0.5679 - val_loss: 1.7520\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7540 - loss: 0.8875 - val_accuracy: 0.5679 - val_loss: 1.7500\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7539 - loss: 0.8862 - val_accuracy: 0.5679 - val_loss: 1.7567\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7538 - loss: 0.8850 - val_accuracy: 0.5679 - val_loss: 1.7521\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7538 - loss: 0.8838 - val_accuracy: 0.5679 - val_loss: 1.7483\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7538 - loss: 0.8827 - val_accuracy: 0.5678 - val_loss: 1.7548\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7539 - loss: 0.8816 - val_accuracy: 0.5678 - val_loss: 1.7541\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7548 - loss: 0.8806 - val_accuracy: 0.5677 - val_loss: 1.7560\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.8796 - val_accuracy: 0.5679 - val_loss: 1.7567\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.8787 - val_accuracy: 0.5678 - val_loss: 1.7582\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.8778 - val_accuracy: 0.5678 - val_loss: 1.7566\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.8770 - val_accuracy: 0.5679 - val_loss: 1.7554\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7563 - loss: 0.8762 - val_accuracy: 0.5678 - val_loss: 1.7557\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7563 - loss: 0.8755 - val_accuracy: 0.5679 - val_loss: 1.7588\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7564 - loss: 0.8747 - val_accuracy: 0.5678 - val_loss: 1.7607\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.8741 - val_accuracy: 0.5673 - val_loss: 1.7587\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7567 - loss: 0.8734 - val_accuracy: 0.5683 - val_loss: 1.7579\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8728 - val_accuracy: 0.5683 - val_loss: 1.7592\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8722 - val_accuracy: 0.5688 - val_loss: 1.7551\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8717 - val_accuracy: 0.5683 - val_loss: 1.7598\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8712 - val_accuracy: 0.5710 - val_loss: 1.7586\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7570 - loss: 0.8707 - val_accuracy: 0.5705 - val_loss: 1.7572\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8702 - val_accuracy: 0.5705 - val_loss: 1.7578\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8698 - val_accuracy: 0.5705 - val_loss: 1.7618\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8694 - val_accuracy: 0.5708 - val_loss: 1.7552\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8690 - val_accuracy: 0.5708 - val_loss: 1.7590\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.8686 - val_accuracy: 0.5713 - val_loss: 1.7570\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.8682 - val_accuracy: 0.5707 - val_loss: 1.7616\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.8679 - val_accuracy: 0.5708 - val_loss: 1.7570\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.8675 - val_accuracy: 0.5713 - val_loss: 1.7568\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.8672 - val_accuracy: 0.5708 - val_loss: 1.7594\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.8669 - val_accuracy: 0.5714 - val_loss: 1.7565\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.8666 - val_accuracy: 0.5714 - val_loss: 1.7536\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.8663 - val_accuracy: 0.5714 - val_loss: 1.7530\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8660 - val_accuracy: 0.5714 - val_loss: 1.7535\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8657 - val_accuracy: 0.5714 - val_loss: 1.7580\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8654 - val_accuracy: 0.5714 - val_loss: 1.7511\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8652 - val_accuracy: 0.5715 - val_loss: 1.7515\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8649 - val_accuracy: 0.5714 - val_loss: 1.7531\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8646 - val_accuracy: 0.5714 - val_loss: 1.7518\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7569 - loss: 0.8644 - val_accuracy: 0.5714 - val_loss: 1.7575\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7567 - loss: 0.8641 - val_accuracy: 0.5714 - val_loss: 1.7528\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7566 - loss: 0.8639 - val_accuracy: 0.5713 - val_loss: 1.7495\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7565 - loss: 0.8637 - val_accuracy: 0.5713 - val_loss: 1.7501\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7564 - loss: 0.8634 - val_accuracy: 0.5714 - val_loss: 1.7491\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7563 - loss: 0.8632 - val_accuracy: 0.5714 - val_loss: 1.7479\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7564 - loss: 0.8630 - val_accuracy: 0.5714 - val_loss: 1.7541\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7562 - loss: 0.8628 - val_accuracy: 0.5714 - val_loss: 1.7477\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7563 - loss: 0.8626 - val_accuracy: 0.5714 - val_loss: 1.7473\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7564 - loss: 0.8624 - val_accuracy: 0.5713 - val_loss: 1.7521\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.8622 - val_accuracy: 0.5713 - val_loss: 1.7521\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7577 - loss: 0.8620 - val_accuracy: 0.5713 - val_loss: 1.7508\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7580 - loss: 0.8618 - val_accuracy: 0.5714 - val_loss: 1.7466\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7584 - loss: 0.8616 - val_accuracy: 0.5714 - val_loss: 1.7452\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.8614 - val_accuracy: 0.5713 - val_loss: 1.7472\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.8612 - val_accuracy: 0.5714 - val_loss: 1.7449\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.8610 - val_accuracy: 0.5714 - val_loss: 1.7471\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.8609 - val_accuracy: 0.5713 - val_loss: 1.7467\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8607 - val_accuracy: 0.5715 - val_loss: 1.7469\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8605 - val_accuracy: 0.5716 - val_loss: 1.7418\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8603 - val_accuracy: 0.5716 - val_loss: 1.7394\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8602 - val_accuracy: 0.5716 - val_loss: 1.7449\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8600 - val_accuracy: 0.5716 - val_loss: 1.7461\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8598 - val_accuracy: 0.5716 - val_loss: 1.7445\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8597 - val_accuracy: 0.5716 - val_loss: 1.7471\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8595 - val_accuracy: 0.5720 - val_loss: 1.7401\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.8594 - val_accuracy: 0.5720 - val_loss: 1.7391\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.8592 - val_accuracy: 0.5716 - val_loss: 1.7401\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.8591 - val_accuracy: 0.5720 - val_loss: 1.7417\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8589 - val_accuracy: 0.5720 - val_loss: 1.7407\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8588 - val_accuracy: 0.5720 - val_loss: 1.7457\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8586 - val_accuracy: 0.5720 - val_loss: 1.7390\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8585 - val_accuracy: 0.5720 - val_loss: 1.7403\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8583 - val_accuracy: 0.5720 - val_loss: 1.7368\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.8582 - val_accuracy: 0.5719 - val_loss: 1.7434\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.8580 - val_accuracy: 0.5720 - val_loss: 1.7407\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8579 - val_accuracy: 0.5719 - val_loss: 1.7427\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8578 - val_accuracy: 0.5720 - val_loss: 1.7379\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8576 - val_accuracy: 0.5720 - val_loss: 1.7379\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8575 - val_accuracy: 0.5720 - val_loss: 1.7375\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8574 - val_accuracy: 0.5720 - val_loss: 1.7372\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8572 - val_accuracy: 0.5720 - val_loss: 1.7404\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8571 - val_accuracy: 0.5720 - val_loss: 1.7338\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8570 - val_accuracy: 0.5719 - val_loss: 1.7422\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8568 - val_accuracy: 0.5720 - val_loss: 1.7354\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8567 - val_accuracy: 0.5719 - val_loss: 1.7399\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8566 - val_accuracy: 0.5719 - val_loss: 1.7380\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8565 - val_accuracy: 0.5720 - val_loss: 1.7422\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8563 - val_accuracy: 0.5720 - val_loss: 1.7398\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8562 - val_accuracy: 0.5721 - val_loss: 1.7391\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8561 - val_accuracy: 0.5721 - val_loss: 1.7370\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8560 - val_accuracy: 0.5725 - val_loss: 1.7322\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8559 - val_accuracy: 0.5725 - val_loss: 1.7380\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8557 - val_accuracy: 0.5725 - val_loss: 1.7348\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8556 - val_accuracy: 0.5723 - val_loss: 1.7386\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8555 - val_accuracy: 0.5723 - val_loss: 1.7333\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7596 - loss: 0.8554 - val_accuracy: 0.5723 - val_loss: 1.7373\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8553 - val_accuracy: 0.5723 - val_loss: 1.7362\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8552 - val_accuracy: 0.5723 - val_loss: 1.7375\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8551 - val_accuracy: 0.5718 - val_loss: 1.7337\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8549 - val_accuracy: 0.5723 - val_loss: 1.7328\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8548 - val_accuracy: 0.5723 - val_loss: 1.7346\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7598 - loss: 0.8547 - val_accuracy: 0.5718 - val_loss: 1.7321\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7598 - loss: 0.8546 - val_accuracy: 0.5718 - val_loss: 1.7317\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8545 - val_accuracy: 0.5718 - val_loss: 1.7340\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8544 - val_accuracy: 0.5718 - val_loss: 1.7386\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8543 - val_accuracy: 0.5719 - val_loss: 1.7326\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8542 - val_accuracy: 0.5719 - val_loss: 1.7321\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8541 - val_accuracy: 0.5719 - val_loss: 1.7285\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8540 - val_accuracy: 0.5719 - val_loss: 1.7269\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8539 - val_accuracy: 0.5718 - val_loss: 1.7347\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8538 - val_accuracy: 0.5718 - val_loss: 1.7317\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8537 - val_accuracy: 0.5718 - val_loss: 1.7353\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8536 - val_accuracy: 0.5719 - val_loss: 1.7277\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8535 - val_accuracy: 0.5718 - val_loss: 1.7327\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8534 - val_accuracy: 0.5721 - val_loss: 1.7264\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8533 - val_accuracy: 0.5718 - val_loss: 1.7332\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8532 - val_accuracy: 0.5720 - val_loss: 1.7309\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8531 - val_accuracy: 0.5720 - val_loss: 1.7290\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7598 - loss: 0.8530 - val_accuracy: 0.5718 - val_loss: 1.7351\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7598 - loss: 0.8529 - val_accuracy: 0.5720 - val_loss: 1.7324\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7597 - loss: 0.8528 - val_accuracy: 0.5720 - val_loss: 1.7320\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8527 - val_accuracy: 0.5720 - val_loss: 1.7324\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8526 - val_accuracy: 0.5732 - val_loss: 1.7267\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8525 - val_accuracy: 0.5731 - val_loss: 1.7269\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8524 - val_accuracy: 0.5731 - val_loss: 1.7302\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8523 - val_accuracy: 0.5731 - val_loss: 1.7270\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7594 - loss: 0.8522 - val_accuracy: 0.5731 - val_loss: 1.7280\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.8521 - val_accuracy: 0.5731 - val_loss: 1.7276\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8520 - val_accuracy: 0.5731 - val_loss: 1.7280\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8519 - val_accuracy: 0.5653 - val_loss: 1.7274\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.8518 - val_accuracy: 0.5653 - val_loss: 1.7285\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.8518 - val_accuracy: 0.5653 - val_loss: 1.7319\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7585 - loss: 0.8517 - val_accuracy: 0.5653 - val_loss: 1.7288\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7585 - loss: 0.8516 - val_accuracy: 0.5653 - val_loss: 1.7296\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7584 - loss: 0.8515 - val_accuracy: 0.5653 - val_loss: 1.7268\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8514 - val_accuracy: 0.5653 - val_loss: 1.7305\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7584 - loss: 0.8513 - val_accuracy: 0.5653 - val_loss: 1.7279\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7584 - loss: 0.8512 - val_accuracy: 0.5653 - val_loss: 1.7265\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8511 - val_accuracy: 0.5653 - val_loss: 1.7278\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7584 - loss: 0.8510 - val_accuracy: 0.5653 - val_loss: 1.7260\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7584 - loss: 0.8510 - val_accuracy: 0.5653 - val_loss: 1.7258\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7585 - loss: 0.8509 - val_accuracy: 0.5598 - val_loss: 1.7296\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7585 - loss: 0.8508 - val_accuracy: 0.5598 - val_loss: 1.7265\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7585 - loss: 0.8507 - val_accuracy: 0.5653 - val_loss: 1.7240\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7585 - loss: 0.8506 - val_accuracy: 0.5598 - val_loss: 1.7281\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8505 - val_accuracy: 0.5653 - val_loss: 1.7231\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8505 - val_accuracy: 0.5598 - val_loss: 1.7302\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8504 - val_accuracy: 0.5598 - val_loss: 1.7257\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8503 - val_accuracy: 0.5653 - val_loss: 1.7234\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8502 - val_accuracy: 0.5598 - val_loss: 1.7336\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8501 - val_accuracy: 0.5598 - val_loss: 1.7291\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8500 - val_accuracy: 0.5653 - val_loss: 1.7236\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8500 - val_accuracy: 0.5598 - val_loss: 1.7293\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8499 - val_accuracy: 0.5598 - val_loss: 1.7272\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8498 - val_accuracy: 0.5598 - val_loss: 1.7225\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8497 - val_accuracy: 0.5653 - val_loss: 1.7233\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8496 - val_accuracy: 0.5666 - val_loss: 1.7246\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8496 - val_accuracy: 0.5598 - val_loss: 1.7291\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8495 - val_accuracy: 0.5666 - val_loss: 1.7248\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8494 - val_accuracy: 0.5666 - val_loss: 1.7257\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8493 - val_accuracy: 0.5666 - val_loss: 1.7261\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8492 - val_accuracy: 0.5611 - val_loss: 1.7274\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8492 - val_accuracy: 0.5666 - val_loss: 1.7213\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8491 - val_accuracy: 0.5611 - val_loss: 1.7232\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.8490 - val_accuracy: 0.5611 - val_loss: 1.7235\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8489 - val_accuracy: 0.5666 - val_loss: 1.7240\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8488 - val_accuracy: 0.5611 - val_loss: 1.7248\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8488 - val_accuracy: 0.5611 - val_loss: 1.7232\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8487 - val_accuracy: 0.5611 - val_loss: 1.7180\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8486 - val_accuracy: 0.5611 - val_loss: 1.7240\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8485 - val_accuracy: 0.5611 - val_loss: 1.7207\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8485 - val_accuracy: 0.5611 - val_loss: 1.7247\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8484 - val_accuracy: 0.5611 - val_loss: 1.7263\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8483 - val_accuracy: 0.5611 - val_loss: 1.7254\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8482 - val_accuracy: 0.5611 - val_loss: 1.7240\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8482 - val_accuracy: 0.5611 - val_loss: 1.7243\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8481 - val_accuracy: 0.5611 - val_loss: 1.7235\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.8480 - val_accuracy: 0.5611 - val_loss: 1.7203\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8479 - val_accuracy: 0.5611 - val_loss: 1.7224\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8479 - val_accuracy: 0.5611 - val_loss: 1.7224\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8478 - val_accuracy: 0.5611 - val_loss: 1.7263\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8477 - val_accuracy: 0.5611 - val_loss: 1.7247\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8476 - val_accuracy: 0.5611 - val_loss: 1.7185\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.8476 - val_accuracy: 0.5611 - val_loss: 1.7215\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8475 - val_accuracy: 0.5611 - val_loss: 1.7274\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8474 - val_accuracy: 0.5611 - val_loss: 1.7250\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8474 - val_accuracy: 0.5611 - val_loss: 1.7206\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.61012\n726/726 - 6s - 9ms/step - accuracy: 0.7587 - loss: 0.8473 - val_accuracy: 0.5611 - val_loss: 1.7210\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8472 - val_accuracy: 0.5611 - val_loss: 1.7220\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.8471 - val_accuracy: 0.5611 - val_loss: 1.7224\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8471 - val_accuracy: 0.5611 - val_loss: 1.7227\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8470 - val_accuracy: 0.5611 - val_loss: 1.7205\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8469 - val_accuracy: 0.5600 - val_loss: 1.7251\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8469 - val_accuracy: 0.5666 - val_loss: 1.7211\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8468 - val_accuracy: 0.5611 - val_loss: 1.7280\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8467 - val_accuracy: 0.5611 - val_loss: 1.7217\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8467 - val_accuracy: 0.5611 - val_loss: 1.7223\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8466 - val_accuracy: 0.5605 - val_loss: 1.7193\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.8465 - val_accuracy: 0.5600 - val_loss: 1.7256\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8465 - val_accuracy: 0.5616 - val_loss: 1.7155\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8464 - val_accuracy: 0.5616 - val_loss: 1.7195\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7586 - loss: 0.8463 - val_accuracy: 0.5600 - val_loss: 1.7228\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8463 - val_accuracy: 0.5600 - val_loss: 1.7247\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8462 - val_accuracy: 0.5605 - val_loss: 1.7236\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.8461 - val_accuracy: 0.5605 - val_loss: 1.7216\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.8461 - val_accuracy: 0.5593 - val_loss: 1.7201\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.8460 - val_accuracy: 0.5593 - val_loss: 1.7216\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.8459 - val_accuracy: 0.5593 - val_loss: 1.7192\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.8459 - val_accuracy: 0.5593 - val_loss: 1.7167\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8458 - val_accuracy: 0.5593 - val_loss: 1.7258\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8457 - val_accuracy: 0.5594 - val_loss: 1.7201\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8457 - val_accuracy: 0.5594 - val_loss: 1.7185\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8456 - val_accuracy: 0.5594 - val_loss: 1.7258\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7599 - loss: 0.8455 - val_accuracy: 0.5594 - val_loss: 1.7180\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8455 - val_accuracy: 0.5594 - val_loss: 1.7226\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8454 - val_accuracy: 0.5594 - val_loss: 1.7184\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8453 - val_accuracy: 0.5594 - val_loss: 1.7213\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8453 - val_accuracy: 0.5594 - val_loss: 1.7193\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8452 - val_accuracy: 0.5594 - val_loss: 1.7237\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8451 - val_accuracy: 0.5594 - val_loss: 1.7213\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7601 - loss: 0.8451 - val_accuracy: 0.5592 - val_loss: 1.7241\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8450 - val_accuracy: 0.5594 - val_loss: 1.7203\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8450 - val_accuracy: 0.5594 - val_loss: 1.7191\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.8449 - val_accuracy: 0.5594 - val_loss: 1.7169\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8448 - val_accuracy: 0.5592 - val_loss: 1.7219\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8448 - val_accuracy: 0.5596 - val_loss: 1.7151\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.8447 - val_accuracy: 0.5596 - val_loss: 1.7179\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8446 - val_accuracy: 0.5595 - val_loss: 1.7196\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.8446 - val_accuracy: 0.5596 - val_loss: 1.7187\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8445 - val_accuracy: 0.5596 - val_loss: 1.7177\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8445 - val_accuracy: 0.5595 - val_loss: 1.7218\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8444 - val_accuracy: 0.5596 - val_loss: 1.7175\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.8443 - val_accuracy: 0.5597 - val_loss: 1.7177\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7601 - loss: 0.8443 - val_accuracy: 0.5597 - val_loss: 1.7130\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.8442 - val_accuracy: 0.5595 - val_loss: 1.7231\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.8442 - val_accuracy: 0.5597 - val_loss: 1.7163\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.8441 - val_accuracy: 0.5597 - val_loss: 1.7162\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.8440 - val_accuracy: 0.5597 - val_loss: 1.7160\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.8440 - val_accuracy: 0.5597 - val_loss: 1.7170\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.8439 - val_accuracy: 0.5596 - val_loss: 1.7204\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.8439 - val_accuracy: 0.5597 - val_loss: 1.7183\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.8438 - val_accuracy: 0.5598 - val_loss: 1.7133\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.8437 - val_accuracy: 0.5597 - val_loss: 1.7179\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7606 - loss: 0.8437 - val_accuracy: 0.5596 - val_loss: 1.7133\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.8436 - val_accuracy: 0.5597 - val_loss: 1.7181\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7604 - loss: 0.8436 - val_accuracy: 0.5597 - val_loss: 1.7150\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.8435 - val_accuracy: 0.5598 - val_loss: 1.7121\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7607 - loss: 0.8434 - val_accuracy: 0.5596 - val_loss: 1.7199\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7609 - loss: 0.8434 - val_accuracy: 0.5596 - val_loss: 1.7186\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7609 - loss: 0.8433 - val_accuracy: 0.5597 - val_loss: 1.7160\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.8433 - val_accuracy: 0.5596 - val_loss: 1.7188\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7607 - loss: 0.8432 - val_accuracy: 0.5596 - val_loss: 1.7156\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8432 - val_accuracy: 0.5596 - val_loss: 1.7186\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8431 - val_accuracy: 0.5596 - val_loss: 1.7182\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8430 - val_accuracy: 0.5596 - val_loss: 1.7161\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7610 - loss: 0.8430 - val_accuracy: 0.5596 - val_loss: 1.7129\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8429 - val_accuracy: 0.5595 - val_loss: 1.7213\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8429 - val_accuracy: 0.5595 - val_loss: 1.7183\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7611 - loss: 0.8428 - val_accuracy: 0.5596 - val_loss: 1.7152\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8428 - val_accuracy: 0.5596 - val_loss: 1.7131\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8427 - val_accuracy: 0.5595 - val_loss: 1.7159\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8426 - val_accuracy: 0.5596 - val_loss: 1.7134\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8426 - val_accuracy: 0.5595 - val_loss: 1.7190\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8425 - val_accuracy: 0.5596 - val_loss: 1.7157\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8425 - val_accuracy: 0.5596 - val_loss: 1.7169\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8424 - val_accuracy: 0.5595 - val_loss: 1.7168\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8424 - val_accuracy: 0.5596 - val_loss: 1.7138\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8423 - val_accuracy: 0.5595 - val_loss: 1.7152\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8423 - val_accuracy: 0.5597 - val_loss: 1.7098\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8422 - val_accuracy: 0.5596 - val_loss: 1.7104\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8421 - val_accuracy: 0.5595 - val_loss: 1.7194\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8421 - val_accuracy: 0.5596 - val_loss: 1.7146\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8420 - val_accuracy: 0.5637 - val_loss: 1.7132\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8420 - val_accuracy: 0.5637 - val_loss: 1.7157\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8419 - val_accuracy: 0.5639 - val_loss: 1.7140\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8419 - val_accuracy: 0.5639 - val_loss: 1.7147\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8418 - val_accuracy: 0.5639 - val_loss: 1.7166\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8418 - val_accuracy: 0.5639 - val_loss: 1.7168\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8417 - val_accuracy: 0.5639 - val_loss: 1.7181\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8417 - val_accuracy: 0.5639 - val_loss: 1.7192\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8416 - val_accuracy: 0.5639 - val_loss: 1.7159\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.8415 - val_accuracy: 0.5639 - val_loss: 1.7141\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8415 - val_accuracy: 0.5639 - val_loss: 1.7194\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8414 - val_accuracy: 0.5639 - val_loss: 1.7118\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7612 - loss: 0.8414 - val_accuracy: 0.5639 - val_loss: 1.7135\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.8413 - val_accuracy: 0.5639 - val_loss: 1.7158\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.8413 - val_accuracy: 0.5639 - val_loss: 1.7131\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.8412 - val_accuracy: 0.5639 - val_loss: 1.7123\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.8412 - val_accuracy: 0.5639 - val_loss: 1.7120\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7617 - loss: 0.8411 - val_accuracy: 0.5639 - val_loss: 1.7178\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.8411 - val_accuracy: 0.5639 - val_loss: 1.7169\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8410 - val_accuracy: 0.5639 - val_loss: 1.7105\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7614 - loss: 0.8410 - val_accuracy: 0.5639 - val_loss: 1.7130\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7616 - loss: 0.8409 - val_accuracy: 0.5639 - val_loss: 1.7164\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8409 - val_accuracy: 0.5639 - val_loss: 1.7203\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7617 - loss: 0.8408 - val_accuracy: 0.5639 - val_loss: 1.7148\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8408 - val_accuracy: 0.5639 - val_loss: 1.7163\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8407 - val_accuracy: 0.5639 - val_loss: 1.7183\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.8407 - val_accuracy: 0.5639 - val_loss: 1.7180\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7617 - loss: 0.8406 - val_accuracy: 0.5639 - val_loss: 1.7144\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8406 - val_accuracy: 0.5640 - val_loss: 1.7129\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8405 - val_accuracy: 0.5639 - val_loss: 1.7132\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8405 - val_accuracy: 0.5640 - val_loss: 1.7130\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8404 - val_accuracy: 0.5640 - val_loss: 1.7175\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8404 - val_accuracy: 0.5640 - val_loss: 1.7165\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8403 - val_accuracy: 0.5637 - val_loss: 1.7130\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8403 - val_accuracy: 0.5637 - val_loss: 1.7144\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8402 - val_accuracy: 0.5637 - val_loss: 1.7140\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8402 - val_accuracy: 0.5637 - val_loss: 1.7172\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8401 - val_accuracy: 0.5637 - val_loss: 1.7123\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8401 - val_accuracy: 0.5637 - val_loss: 1.7181\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8400 - val_accuracy: 0.5636 - val_loss: 1.7183\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8400 - val_accuracy: 0.5637 - val_loss: 1.7157\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8399 - val_accuracy: 0.5637 - val_loss: 1.7171\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7617 - loss: 0.8399 - val_accuracy: 0.5637 - val_loss: 1.7138\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8398 - val_accuracy: 0.5637 - val_loss: 1.7120\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8398 - val_accuracy: 0.5637 - val_loss: 1.7094\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8397 - val_accuracy: 0.5637 - val_loss: 1.7150\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8397 - val_accuracy: 0.5636 - val_loss: 1.7130\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8396 - val_accuracy: 0.5637 - val_loss: 1.7126\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8396 - val_accuracy: 0.5637 - val_loss: 1.7139\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8395 - val_accuracy: 0.5636 - val_loss: 1.7151\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8395 - val_accuracy: 0.5636 - val_loss: 1.7182\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8394 - val_accuracy: 0.5636 - val_loss: 1.7135\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8394 - val_accuracy: 0.5637 - val_loss: 1.7101\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8393 - val_accuracy: 0.5637 - val_loss: 1.7129\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8393 - val_accuracy: 0.5636 - val_loss: 1.7140\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8393 - val_accuracy: 0.5636 - val_loss: 1.7153\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8392 - val_accuracy: 0.5636 - val_loss: 1.7152\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8392 - val_accuracy: 0.5637 - val_loss: 1.7118\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8391 - val_accuracy: 0.5636 - val_loss: 1.7178\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8391 - val_accuracy: 0.5636 - val_loss: 1.7146\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8390 - val_accuracy: 0.5636 - val_loss: 1.7168\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8390 - val_accuracy: 0.5636 - val_loss: 1.7107\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8389 - val_accuracy: 0.5637 - val_loss: 1.7132\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.8389 - val_accuracy: 0.5636 - val_loss: 1.7123\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.8388 - val_accuracy: 0.5636 - val_loss: 1.7129\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.8388 - val_accuracy: 0.5632 - val_loss: 1.7164\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8387 - val_accuracy: 0.5636 - val_loss: 1.7157\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7618 - loss: 0.8387 - val_accuracy: 0.5632 - val_loss: 1.7154\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8387 - val_accuracy: 0.5636 - val_loss: 1.7137\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8386 - val_accuracy: 0.5632 - val_loss: 1.7157\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.8386 - val_accuracy: 0.5636 - val_loss: 1.7092\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8385 - val_accuracy: 0.5635 - val_loss: 1.7133\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8385 - val_accuracy: 0.5635 - val_loss: 1.7151\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.8384 - val_accuracy: 0.5633 - val_loss: 1.7130\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8384 - val_accuracy: 0.5636 - val_loss: 1.7099\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.8383 - val_accuracy: 0.5635 - val_loss: 1.7132\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.8383 - val_accuracy: 0.5633 - val_loss: 1.7148\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.8382 - val_accuracy: 0.5632 - val_loss: 1.7144\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.8382 - val_accuracy: 0.5632 - val_loss: 1.7180\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.8382 - val_accuracy: 0.5631 - val_loss: 1.7161\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.8381 - val_accuracy: 0.5632 - val_loss: 1.7133\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7620 - loss: 0.8381 - val_accuracy: 0.5631 - val_loss: 1.7146\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.8380 - val_accuracy: 0.5635 - val_loss: 1.7083\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.8380 - val_accuracy: 0.5631 - val_loss: 1.7150\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.8379 - val_accuracy: 0.5624 - val_loss: 1.7145\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.8379 - val_accuracy: 0.5632 - val_loss: 1.7092\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.8378 - val_accuracy: 0.5624 - val_loss: 1.7141\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.8378 - val_accuracy: 0.5624 - val_loss: 1.7175\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8378 - val_accuracy: 0.5624 - val_loss: 1.7156\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8377 - val_accuracy: 0.5625 - val_loss: 1.7150\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8377 - val_accuracy: 0.5625 - val_loss: 1.7104\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8376 - val_accuracy: 0.5625 - val_loss: 1.7142\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.8376 - val_accuracy: 0.5625 - val_loss: 1.7093\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8375 - val_accuracy: 0.5625 - val_loss: 1.7123\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8375 - val_accuracy: 0.5625 - val_loss: 1.7098\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8375 - val_accuracy: 0.5625 - val_loss: 1.7134\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8374 - val_accuracy: 0.5625 - val_loss: 1.7155\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8374 - val_accuracy: 0.5625 - val_loss: 1.7144\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.8373 - val_accuracy: 0.5625 - val_loss: 1.7132\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8373 - val_accuracy: 0.5625 - val_loss: 1.7181\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8372 - val_accuracy: 0.5625 - val_loss: 1.7167\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8372 - val_accuracy: 0.5625 - val_loss: 1.7157\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8372 - val_accuracy: 0.5625 - val_loss: 1.7127\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8371 - val_accuracy: 0.5625 - val_loss: 1.7180\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.8371 - val_accuracy: 0.5625 - val_loss: 1.7131\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8370 - val_accuracy: 0.5625 - val_loss: 1.7143\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8370 - val_accuracy: 0.5625 - val_loss: 1.7099\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8369 - val_accuracy: 0.5625 - val_loss: 1.7081\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8369 - val_accuracy: 0.5625 - val_loss: 1.7129\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8369 - val_accuracy: 0.5625 - val_loss: 1.7115\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8368 - val_accuracy: 0.5625 - val_loss: 1.7160\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8368 - val_accuracy: 0.5625 - val_loss: 1.7163\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8367 - val_accuracy: 0.5625 - val_loss: 1.7109\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8367 - val_accuracy: 0.5625 - val_loss: 1.7151\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8367 - val_accuracy: 0.5625 - val_loss: 1.7165\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8366 - val_accuracy: 0.5625 - val_loss: 1.7118\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8366 - val_accuracy: 0.5625 - val_loss: 1.7108\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8365 - val_accuracy: 0.5625 - val_loss: 1.7115\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8365 - val_accuracy: 0.5625 - val_loss: 1.7131\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8365 - val_accuracy: 0.5625 - val_loss: 1.7111\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8364 - val_accuracy: 0.5625 - val_loss: 1.7109\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8364 - val_accuracy: 0.5625 - val_loss: 1.7132\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8363 - val_accuracy: 0.5625 - val_loss: 1.7136\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8363 - val_accuracy: 0.5625 - val_loss: 1.7164\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8363 - val_accuracy: 0.5625 - val_loss: 1.7134\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8362 - val_accuracy: 0.5625 - val_loss: 1.7095\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8362 - val_accuracy: 0.5625 - val_loss: 1.7133\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8361 - val_accuracy: 0.5625 - val_loss: 1.7122\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8361 - val_accuracy: 0.5625 - val_loss: 1.7103\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7652 - loss: 0.8361 - val_accuracy: 0.5625 - val_loss: 1.7076\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8360 - val_accuracy: 0.5625 - val_loss: 1.7095\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8360 - val_accuracy: 0.5625 - val_loss: 1.7137\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8359 - val_accuracy: 0.5625 - val_loss: 1.7123\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8359 - val_accuracy: 0.5625 - val_loss: 1.7159\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8359 - val_accuracy: 0.5625 - val_loss: 1.7132\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8358 - val_accuracy: 0.5625 - val_loss: 1.7163\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8358 - val_accuracy: 0.5625 - val_loss: 1.7139\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8357 - val_accuracy: 0.5625 - val_loss: 1.7128\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8357 - val_accuracy: 0.5625 - val_loss: 1.7092\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8357 - val_accuracy: 0.5625 - val_loss: 1.7125\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8356 - val_accuracy: 0.5625 - val_loss: 1.7101\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8356 - val_accuracy: 0.5625 - val_loss: 1.7152\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8355 - val_accuracy: 0.5625 - val_loss: 1.7139\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8355 - val_accuracy: 0.5625 - val_loss: 1.7085\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8355 - val_accuracy: 0.5625 - val_loss: 1.7152\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8354 - val_accuracy: 0.5625 - val_loss: 1.7140\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8354 - val_accuracy: 0.5625 - val_loss: 1.7129\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8354 - val_accuracy: 0.5625 - val_loss: 1.7171\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.8353 - val_accuracy: 0.5625 - val_loss: 1.7127\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.8353 - val_accuracy: 0.5625 - val_loss: 1.7126\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8352 - val_accuracy: 0.5625 - val_loss: 1.7136\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8352 - val_accuracy: 0.5625 - val_loss: 1.7148\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.8352 - val_accuracy: 0.5625 - val_loss: 1.7099\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(\n    X, y, test_size=0.3, random_state=52, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_10, X_val_10, y_train_10, y_val_10 = train_test_split(\n    X_train_10, y_train_10, test_size=0.2, random_state=52, stratify=y_train_10\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_10:\", np.max(X_train_10))\nprint(\"Min value in X_train_10:\", np.min(X_train_10))\n\nX_train_10_scaled = scaler.fit_transform(X_train_10)\n\n# Get the original class distribution\nclass_counts_10 = Counter(y_train_10)\nprint(\"Original class distribution:\", class_counts_10)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_10 = class_counts_10[min(class_counts_10, key=class_counts_10.get)]\ndesired_majority_size_10 = minority_class_size_10 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_10 = {0: desired_majority_size_10, 1: minority_class_size_10}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_10 = RandomUnderSampler(sampling_strategy=sampling_strategy_10, random_state=42)\nX_resampled_10, y_resampled_10 = undersampler_10.fit_resample(X_train_10, y_train_10)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_10))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_10, y_train_resampled_10 = smote.fit_resample(X_resampled_10, y_resampled_10)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_10))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_10))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:15:23.896380Z","iopub.execute_input":"2025-03-07T02:15:23.896888Z","iopub.status.idle":"2025-03-07T02:16:01.799427Z","shell.execute_reply.started":"2025-03-07T02:15:23.896840Z","shell.execute_reply":"2025-03-07T02:16:01.798315Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_10: 2071000000.0\nMin value in X_train_10: -6442447920.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_10 = X_train_resampled_10.reshape(X_train_resampled_10.shape[0], 1, 56)\nX_val_10 = X_val_10.reshape(X_val_10.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_10,  # Features from CICIDS2017\n    y_train_resampled_10,  # Labels from CICIDS2017\n    validation_data=(X_val_10, y_val_10),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:16:01.805591Z","iopub.execute_input":"2025-03-07T02:16:01.806018Z","iopub.status.idle":"2025-03-07T02:58:57.673133Z","execution_failed":"2025-03-07T05:54:25.147Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7861 - loss: 0.7223 - val_accuracy: 0.5682 - val_loss: 1.5804\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7922 - loss: 0.7147 - val_accuracy: 0.5878 - val_loss: 1.5821\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.7120 - val_accuracy: 0.5890 - val_loss: 1.5847\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.7099 - val_accuracy: 0.5890 - val_loss: 1.5936\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.7081 - val_accuracy: 0.5888 - val_loss: 1.5983\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.7065 - val_accuracy: 0.6012 - val_loss: 1.5991\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.7051 - val_accuracy: 0.6010 - val_loss: 1.6003\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.7038 - val_accuracy: 0.5887 - val_loss: 1.6034\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.7026 - val_accuracy: 0.5996 - val_loss: 1.6044\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.7015 - val_accuracy: 0.5999 - val_loss: 1.6051\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.7005 - val_accuracy: 0.5992 - val_loss: 1.6075\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6995 - val_accuracy: 0.6001 - val_loss: 1.6056\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6986 - val_accuracy: 0.6001 - val_loss: 1.6077\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6978 - val_accuracy: 0.6001 - val_loss: 1.6054\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6971 - val_accuracy: 0.5999 - val_loss: 1.6069\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6963 - val_accuracy: 0.6005 - val_loss: 1.6045\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6957 - val_accuracy: 0.5997 - val_loss: 1.6045\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6950 - val_accuracy: 0.6004 - val_loss: 1.6039\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6944 - val_accuracy: 0.6004 - val_loss: 1.6067\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.6938 - val_accuracy: 0.6005 - val_loss: 1.6031\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6933 - val_accuracy: 0.6004 - val_loss: 1.6087\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6927 - val_accuracy: 0.6004 - val_loss: 1.6091\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6922 - val_accuracy: 0.6004 - val_loss: 1.6022\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6918 - val_accuracy: 0.6009 - val_loss: 1.5985\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6913 - val_accuracy: 0.6006 - val_loss: 1.6026\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6909 - val_accuracy: 0.6010 - val_loss: 1.6012\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6904 - val_accuracy: 0.6009 - val_loss: 1.6001\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6900 - val_accuracy: 0.6009 - val_loss: 1.5997\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6896 - val_accuracy: 0.6010 - val_loss: 1.5997\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6893 - val_accuracy: 0.6021 - val_loss: 1.6000\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6889 - val_accuracy: 0.6021 - val_loss: 1.5985\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6886 - val_accuracy: 0.6007 - val_loss: 1.6022\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6882 - val_accuracy: 0.6019 - val_loss: 1.5957\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6879 - val_accuracy: 0.6018 - val_loss: 1.5997\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6876 - val_accuracy: 0.6018 - val_loss: 1.6000\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.61012\n726/726 - 6s - 9ms/step - accuracy: 0.8069 - loss: 0.6873 - val_accuracy: 0.6018 - val_loss: 1.6006\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8069 - loss: 0.6870 - val_accuracy: 0.6018 - val_loss: 1.5982\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8071 - loss: 0.6867 - val_accuracy: 0.6018 - val_loss: 1.5964\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8073 - loss: 0.6864 - val_accuracy: 0.6013 - val_loss: 1.5951\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8074 - loss: 0.6862 - val_accuracy: 0.6014 - val_loss: 1.5949\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8074 - loss: 0.6859 - val_accuracy: 0.6013 - val_loss: 1.5964\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8074 - loss: 0.6856 - val_accuracy: 0.6013 - val_loss: 1.5996\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8074 - loss: 0.6854 - val_accuracy: 0.6015 - val_loss: 1.5971\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8075 - loss: 0.6851 - val_accuracy: 0.6016 - val_loss: 1.5969\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8071 - loss: 0.6849 - val_accuracy: 0.6025 - val_loss: 1.5948\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8074 - loss: 0.6847 - val_accuracy: 0.6024 - val_loss: 1.5966\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8072 - loss: 0.6845 - val_accuracy: 0.6025 - val_loss: 1.5951\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8064 - loss: 0.6842 - val_accuracy: 0.6033 - val_loss: 1.5987\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8064 - loss: 0.6840 - val_accuracy: 0.6033 - val_loss: 1.5969\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8067 - loss: 0.6838 - val_accuracy: 0.5991 - val_loss: 1.5943\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6836 - val_accuracy: 0.6033 - val_loss: 1.5983\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6834 - val_accuracy: 0.6033 - val_loss: 1.5955\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6832 - val_accuracy: 0.5991 - val_loss: 1.5957\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8033 - loss: 0.6830 - val_accuracy: 0.5991 - val_loss: 1.5966\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6828 - val_accuracy: 0.6034 - val_loss: 1.5957\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8046 - loss: 0.6827 - val_accuracy: 0.5991 - val_loss: 1.6002\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6825 - val_accuracy: 0.5991 - val_loss: 1.5940\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6823 - val_accuracy: 0.5991 - val_loss: 1.5968\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8028 - loss: 0.6821 - val_accuracy: 0.5992 - val_loss: 1.5948\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8029 - loss: 0.6820 - val_accuracy: 0.5992 - val_loss: 1.5949\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8029 - loss: 0.6818 - val_accuracy: 0.5992 - val_loss: 1.5994\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6816 - val_accuracy: 0.5988 - val_loss: 1.6008\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6815 - val_accuracy: 0.5997 - val_loss: 1.5957\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6813 - val_accuracy: 0.5997 - val_loss: 1.5966\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6811 - val_accuracy: 0.5998 - val_loss: 1.5904\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6810 - val_accuracy: 0.5998 - val_loss: 1.5970\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6808 - val_accuracy: 0.5997 - val_loss: 1.5982\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6807 - val_accuracy: 0.5998 - val_loss: 1.5957\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8032 - loss: 0.6806 - val_accuracy: 0.5998 - val_loss: 1.5997\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6804 - val_accuracy: 0.5999 - val_loss: 1.5930\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6803 - val_accuracy: 0.5999 - val_loss: 1.5952\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8039 - loss: 0.6801 - val_accuracy: 0.5999 - val_loss: 1.5945\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8039 - loss: 0.6800 - val_accuracy: 0.6004 - val_loss: 1.5924\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8042 - loss: 0.6798 - val_accuracy: 0.5998 - val_loss: 1.5971\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8043 - loss: 0.6797 - val_accuracy: 0.6004 - val_loss: 1.5971\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6796 - val_accuracy: 0.6004 - val_loss: 1.5948\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6795 - val_accuracy: 0.6005 - val_loss: 1.5904\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6793 - val_accuracy: 0.6004 - val_loss: 1.5931\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6792 - val_accuracy: 0.6005 - val_loss: 1.5956\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6791 - val_accuracy: 0.6005 - val_loss: 1.5958\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6790 - val_accuracy: 0.6006 - val_loss: 1.5931\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8048 - loss: 0.6788 - val_accuracy: 0.6002 - val_loss: 1.5958\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8049 - loss: 0.6787 - val_accuracy: 0.6005 - val_loss: 1.5914\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8048 - loss: 0.6786 - val_accuracy: 0.6002 - val_loss: 1.5960\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6785 - val_accuracy: 0.6002 - val_loss: 1.5969\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6784 - val_accuracy: 0.6002 - val_loss: 1.5963\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6782 - val_accuracy: 0.6002 - val_loss: 1.5955\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6781 - val_accuracy: 0.6002 - val_loss: 1.5908\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6780 - val_accuracy: 0.6004 - val_loss: 1.5906\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6779 - val_accuracy: 0.6002 - val_loss: 1.5946\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6778 - val_accuracy: 0.6002 - val_loss: 1.5958\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6777 - val_accuracy: 0.6004 - val_loss: 1.5928\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6776 - val_accuracy: 0.6004 - val_loss: 1.5941\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6775 - val_accuracy: 0.6004 - val_loss: 1.5952\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8051 - loss: 0.6774 - val_accuracy: 0.6003 - val_loss: 1.5961\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6773 - val_accuracy: 0.6004 - val_loss: 1.5950\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6772 - val_accuracy: 0.6005 - val_loss: 1.5933\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6771 - val_accuracy: 0.6002 - val_loss: 1.5952\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.6770 - val_accuracy: 0.6005 - val_loss: 1.5926\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6768 - val_accuracy: 0.6005 - val_loss: 1.5938\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8051 - loss: 0.6767 - val_accuracy: 0.6005 - val_loss: 1.5909\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6766 - val_accuracy: 0.6003 - val_loss: 1.5951\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6766 - val_accuracy: 0.6005 - val_loss: 1.5931\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6765 - val_accuracy: 0.6004 - val_loss: 1.5951\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6764 - val_accuracy: 0.6005 - val_loss: 1.5933\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6763 - val_accuracy: 0.6005 - val_loss: 1.5961\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8051 - loss: 0.6762 - val_accuracy: 0.6005 - val_loss: 1.5949\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6761 - val_accuracy: 0.6004 - val_loss: 1.5983\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6760 - val_accuracy: 0.6004 - val_loss: 1.5955\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6759 - val_accuracy: 0.6004 - val_loss: 1.5951\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6758 - val_accuracy: 0.6004 - val_loss: 1.5958\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6757 - val_accuracy: 0.6005 - val_loss: 1.5942\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6756 - val_accuracy: 0.6004 - val_loss: 1.5990\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6755 - val_accuracy: 0.6005 - val_loss: 1.5935\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6754 - val_accuracy: 0.6005 - val_loss: 1.5926\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6753 - val_accuracy: 0.6005 - val_loss: 1.5917\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6753 - val_accuracy: 0.6005 - val_loss: 1.5909\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6752 - val_accuracy: 0.6005 - val_loss: 1.5959\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6751 - val_accuracy: 0.6005 - val_loss: 1.5958\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6750 - val_accuracy: 0.6000 - val_loss: 1.5962\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6749 - val_accuracy: 0.6005 - val_loss: 1.5917\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6748 - val_accuracy: 0.5999 - val_loss: 1.5952\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6748 - val_accuracy: 0.5999 - val_loss: 1.5975\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6747 - val_accuracy: 0.5999 - val_loss: 1.5963\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6746 - val_accuracy: 0.6000 - val_loss: 1.5944\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6745 - val_accuracy: 0.6000 - val_loss: 1.5987\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6744 - val_accuracy: 0.6000 - val_loss: 1.5952\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6743 - val_accuracy: 0.6000 - val_loss: 1.5970\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6743 - val_accuracy: 0.6001 - val_loss: 1.5928\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6742 - val_accuracy: 0.6000 - val_loss: 1.5959\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6741 - val_accuracy: 0.6001 - val_loss: 1.5921\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6740 - val_accuracy: 0.5999 - val_loss: 1.5947\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6740 - val_accuracy: 0.5971 - val_loss: 1.5947\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6739 - val_accuracy: 0.5970 - val_loss: 1.5983\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6738 - val_accuracy: 0.6000 - val_loss: 1.5902\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6737 - val_accuracy: 0.5970 - val_loss: 1.5968\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6736 - val_accuracy: 0.5971 - val_loss: 1.5937\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6736 - val_accuracy: 0.5971 - val_loss: 1.5970\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6735 - val_accuracy: 0.5971 - val_loss: 1.5962\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6734 - val_accuracy: 0.5970 - val_loss: 1.5949\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6733 - val_accuracy: 0.5974 - val_loss: 1.5965\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6733 - val_accuracy: 0.5974 - val_loss: 1.5937\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6732 - val_accuracy: 0.5975 - val_loss: 1.5926\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6731 - val_accuracy: 0.5970 - val_loss: 1.5986\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6731 - val_accuracy: 0.5970 - val_loss: 1.5981\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6730 - val_accuracy: 0.5971 - val_loss: 1.5948\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8056 - loss: 0.6729 - val_accuracy: 0.5971 - val_loss: 1.5986\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6728 - val_accuracy: 0.5971 - val_loss: 1.5938\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6728 - val_accuracy: 0.5970 - val_loss: 1.5951\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6727 - val_accuracy: 0.5970 - val_loss: 1.5981\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6726 - val_accuracy: 0.5971 - val_loss: 1.5913\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6726 - val_accuracy: 0.5970 - val_loss: 1.5969\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6725 - val_accuracy: 0.5970 - val_loss: 1.5976\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6724 - val_accuracy: 0.5971 - val_loss: 1.5964\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8056 - loss: 0.6724 - val_accuracy: 0.5971 - val_loss: 1.5946\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6723 - val_accuracy: 0.5970 - val_loss: 1.5973\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8055 - loss: 0.6722 - val_accuracy: 0.5971 - val_loss: 1.5970\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6722 - val_accuracy: 0.5971 - val_loss: 1.5944\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8056 - loss: 0.6721 - val_accuracy: 0.5970 - val_loss: 1.5966\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8056 - loss: 0.6720 - val_accuracy: 0.5970 - val_loss: 1.5943\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6720 - val_accuracy: 0.5970 - val_loss: 1.5968\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6719 - val_accuracy: 0.5971 - val_loss: 1.5977\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8056 - loss: 0.6718 - val_accuracy: 0.5969 - val_loss: 1.6011\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6718 - val_accuracy: 0.5970 - val_loss: 1.5912\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6717 - val_accuracy: 0.5972 - val_loss: 1.5925\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6716 - val_accuracy: 0.5969 - val_loss: 1.5965\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6716 - val_accuracy: 0.5975 - val_loss: 1.5934\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6715 - val_accuracy: 0.5971 - val_loss: 1.6020\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8055 - loss: 0.6714 - val_accuracy: 0.5971 - val_loss: 1.6023\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6714 - val_accuracy: 0.5974 - val_loss: 1.5984\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6713 - val_accuracy: 0.5974 - val_loss: 1.5976\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6712 - val_accuracy: 0.5972 - val_loss: 1.6011\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8048 - loss: 0.6712 - val_accuracy: 0.5974 - val_loss: 1.5987\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8048 - loss: 0.6711 - val_accuracy: 0.5974 - val_loss: 1.5973\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6711 - val_accuracy: 0.5974 - val_loss: 1.5970\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8046 - loss: 0.6710 - val_accuracy: 0.5974 - val_loss: 1.5986\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6709 - val_accuracy: 0.5975 - val_loss: 1.5949\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6709 - val_accuracy: 0.5974 - val_loss: 1.5963\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8049 - loss: 0.6708 - val_accuracy: 0.5975 - val_loss: 1.5948\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8054 - loss: 0.6708 - val_accuracy: 0.5974 - val_loss: 1.6009\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8053 - loss: 0.6707 - val_accuracy: 0.5976 - val_loss: 1.5946\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8050 - loss: 0.6706 - val_accuracy: 0.5975 - val_loss: 1.5942\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6706 - val_accuracy: 0.5975 - val_loss: 1.5983\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8049 - loss: 0.6705 - val_accuracy: 0.5975 - val_loss: 1.5976\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6705 - val_accuracy: 0.5976 - val_loss: 1.5953\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8042 - loss: 0.6704 - val_accuracy: 0.5974 - val_loss: 1.6006\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8052 - loss: 0.6703 - val_accuracy: 0.5975 - val_loss: 1.5988\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8043 - loss: 0.6703 - val_accuracy: 0.5976 - val_loss: 1.5974\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8049 - loss: 0.6702 - val_accuracy: 0.5975 - val_loss: 1.5967\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8042 - loss: 0.6702 - val_accuracy: 0.5976 - val_loss: 1.5948\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8047 - loss: 0.6701 - val_accuracy: 0.5975 - val_loss: 1.5981\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8046 - loss: 0.6701 - val_accuracy: 0.5990 - val_loss: 1.5970\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.6700 - val_accuracy: 0.5975 - val_loss: 1.5975\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8047 - loss: 0.6699 - val_accuracy: 0.5974 - val_loss: 1.5987\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8046 - loss: 0.6699 - val_accuracy: 0.5975 - val_loss: 1.5970\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.6698 - val_accuracy: 0.5973 - val_loss: 1.5947\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6698 - val_accuracy: 0.5974 - val_loss: 1.5981\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8041 - loss: 0.6697 - val_accuracy: 0.5990 - val_loss: 1.5929\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8043 - loss: 0.6697 - val_accuracy: 0.5973 - val_loss: 1.6001\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8040 - loss: 0.6696 - val_accuracy: 0.5988 - val_loss: 1.5977\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8041 - loss: 0.6696 - val_accuracy: 0.5970 - val_loss: 1.6010\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8043 - loss: 0.6695 - val_accuracy: 0.5988 - val_loss: 1.5969\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8042 - loss: 0.6694 - val_accuracy: 0.5971 - val_loss: 1.5987\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8042 - loss: 0.6694 - val_accuracy: 0.5984 - val_loss: 1.5973\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6693 - val_accuracy: 0.5986 - val_loss: 1.5952\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8044 - loss: 0.6693 - val_accuracy: 0.5984 - val_loss: 1.5952\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8042 - loss: 0.6692 - val_accuracy: 0.5986 - val_loss: 1.5958\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8038 - loss: 0.6692 - val_accuracy: 0.5984 - val_loss: 1.5985\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8046 - loss: 0.6691 - val_accuracy: 0.5983 - val_loss: 1.5998\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6691 - val_accuracy: 0.5969 - val_loss: 1.6019\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8043 - loss: 0.6690 - val_accuracy: 0.5984 - val_loss: 1.5977\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8039 - loss: 0.6690 - val_accuracy: 0.5984 - val_loss: 1.5955\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8033 - loss: 0.6689 - val_accuracy: 0.5984 - val_loss: 1.6011\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6689 - val_accuracy: 0.5983 - val_loss: 1.5998\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8038 - loss: 0.6688 - val_accuracy: 0.5986 - val_loss: 1.5930\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8041 - loss: 0.6687 - val_accuracy: 0.5984 - val_loss: 1.5987\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6687 - val_accuracy: 0.5984 - val_loss: 1.5942\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8038 - loss: 0.6686 - val_accuracy: 0.5984 - val_loss: 1.6004\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6686 - val_accuracy: 0.5983 - val_loss: 1.6008\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8032 - loss: 0.6685 - val_accuracy: 0.5986 - val_loss: 1.5947\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8031 - loss: 0.6685 - val_accuracy: 0.5984 - val_loss: 1.5986\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8031 - loss: 0.6684 - val_accuracy: 0.5983 - val_loss: 1.5962\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6684 - val_accuracy: 0.5985 - val_loss: 1.5977\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8033 - loss: 0.6683 - val_accuracy: 0.5985 - val_loss: 1.5971\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8039 - loss: 0.6683 - val_accuracy: 0.5985 - val_loss: 1.5994\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8028 - loss: 0.6682 - val_accuracy: 0.5986 - val_loss: 1.5979\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8029 - loss: 0.6682 - val_accuracy: 0.5986 - val_loss: 1.5970\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8027 - loss: 0.6681 - val_accuracy: 0.5986 - val_loss: 1.5983\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8032 - loss: 0.6681 - val_accuracy: 0.5985 - val_loss: 1.6019\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8028 - loss: 0.6680 - val_accuracy: 0.5983 - val_loss: 1.5991\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8024 - loss: 0.6680 - val_accuracy: 0.5984 - val_loss: 1.5974\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6679 - val_accuracy: 0.5985 - val_loss: 1.5948\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8039 - loss: 0.6679 - val_accuracy: 0.5986 - val_loss: 1.5969\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8032 - loss: 0.6679 - val_accuracy: 0.5986 - val_loss: 1.5992\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8019 - loss: 0.6678 - val_accuracy: 0.5984 - val_loss: 1.5990\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6678 - val_accuracy: 0.5982 - val_loss: 1.6009\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6677 - val_accuracy: 0.5983 - val_loss: 1.5978\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.6677 - val_accuracy: 0.5986 - val_loss: 1.5996\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8024 - loss: 0.6676 - val_accuracy: 0.5983 - val_loss: 1.6015\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8028 - loss: 0.6676 - val_accuracy: 0.5982 - val_loss: 1.6024\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8019 - loss: 0.6675 - val_accuracy: 0.5984 - val_loss: 1.6015\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6675 - val_accuracy: 0.5985 - val_loss: 1.6000\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.6674 - val_accuracy: 0.5983 - val_loss: 1.5986\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8016 - loss: 0.6674 - val_accuracy: 0.5984 - val_loss: 1.6015\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6673 - val_accuracy: 0.5983 - val_loss: 1.5964\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6673 - val_accuracy: 0.5983 - val_loss: 1.5973\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6672 - val_accuracy: 0.5982 - val_loss: 1.5977\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6672 - val_accuracy: 0.5983 - val_loss: 1.5979\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.6671 - val_accuracy: 0.5982 - val_loss: 1.6023\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6671 - val_accuracy: 0.5983 - val_loss: 1.6011\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.6671 - val_accuracy: 0.5983 - val_loss: 1.5988\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6670 - val_accuracy: 0.5983 - val_loss: 1.5982\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6670 - val_accuracy: 0.5983 - val_loss: 1.6010\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6669 - val_accuracy: 0.5983 - val_loss: 1.5978\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.6669 - val_accuracy: 0.5983 - val_loss: 1.6024\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6668 - val_accuracy: 0.5983 - val_loss: 1.5980\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6668 - val_accuracy: 0.5982 - val_loss: 1.6021\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.6667 - val_accuracy: 0.5984 - val_loss: 1.5998\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6667 - val_accuracy: 0.5982 - val_loss: 1.6022\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.6666 - val_accuracy: 0.5983 - val_loss: 1.5971\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.6666 - val_accuracy: 0.5982 - val_loss: 1.6003\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6666 - val_accuracy: 0.5983 - val_loss: 1.5952\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6665 - val_accuracy: 0.5983 - val_loss: 1.6017\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.6665 - val_accuracy: 0.5981 - val_loss: 1.6025\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8023 - loss: 0.6664 - val_accuracy: 0.5983 - val_loss: 1.5999\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6664 - val_accuracy: 0.5983 - val_loss: 1.6000\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6663 - val_accuracy: 0.5981 - val_loss: 1.6006\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6663 - val_accuracy: 0.5983 - val_loss: 1.5978\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6663 - val_accuracy: 0.5981 - val_loss: 1.6007\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6662 - val_accuracy: 0.5983 - val_loss: 1.5986\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8029 - loss: 0.6662 - val_accuracy: 0.5981 - val_loss: 1.6012\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6661 - val_accuracy: 0.5983 - val_loss: 1.5985\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6661 - val_accuracy: 0.5981 - val_loss: 1.5980\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6660 - val_accuracy: 0.5981 - val_loss: 1.6029\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.6660 - val_accuracy: 0.5981 - val_loss: 1.6029\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6660 - val_accuracy: 0.5984 - val_loss: 1.5988\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6659 - val_accuracy: 0.5981 - val_loss: 1.6026\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6659 - val_accuracy: 0.5981 - val_loss: 1.5990\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6658 - val_accuracy: 0.5981 - val_loss: 1.5989\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6658 - val_accuracy: 0.5981 - val_loss: 1.6022\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6657 - val_accuracy: 0.5983 - val_loss: 1.5990\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8015 - loss: 0.6657 - val_accuracy: 0.5980 - val_loss: 1.6059\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6657 - val_accuracy: 0.5981 - val_loss: 1.6034\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8016 - loss: 0.6656 - val_accuracy: 0.5981 - val_loss: 1.6029\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6656 - val_accuracy: 0.5981 - val_loss: 1.5999\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8019 - loss: 0.6655 - val_accuracy: 0.5981 - val_loss: 1.5996\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6655 - val_accuracy: 0.5981 - val_loss: 1.6005\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8023 - loss: 0.6655 - val_accuracy: 0.5981 - val_loss: 1.6002\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6654 - val_accuracy: 0.5981 - val_loss: 1.6017\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8016 - loss: 0.6654 - val_accuracy: 0.5981 - val_loss: 1.6003\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6653 - val_accuracy: 0.5981 - val_loss: 1.6011\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8024 - loss: 0.6653 - val_accuracy: 0.5983 - val_loss: 1.6000\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6653 - val_accuracy: 0.5983 - val_loss: 1.5996\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6652 - val_accuracy: 0.5981 - val_loss: 1.5987\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6652 - val_accuracy: 0.5981 - val_loss: 1.6041\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6651 - val_accuracy: 0.5981 - val_loss: 1.6033\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6651 - val_accuracy: 0.5981 - val_loss: 1.6032\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6651 - val_accuracy: 0.5981 - val_loss: 1.6004\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6650 - val_accuracy: 0.5983 - val_loss: 1.5987\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.6650 - val_accuracy: 0.5981 - val_loss: 1.6013\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6649 - val_accuracy: 0.5983 - val_loss: 1.6005\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6649 - val_accuracy: 0.5981 - val_loss: 1.6020\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6649 - val_accuracy: 0.5981 - val_loss: 1.6023\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6648 - val_accuracy: 0.5980 - val_loss: 1.6027\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6648 - val_accuracy: 0.5981 - val_loss: 1.6006\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6647 - val_accuracy: 0.5981 - val_loss: 1.6046\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6647 - val_accuracy: 0.5981 - val_loss: 1.6025\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6647 - val_accuracy: 0.5981 - val_loss: 1.6052\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6646 - val_accuracy: 0.5983 - val_loss: 1.6011\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6646 - val_accuracy: 0.5983 - val_loss: 1.6057\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.6646 - val_accuracy: 0.5981 - val_loss: 1.5981\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6645 - val_accuracy: 0.5981 - val_loss: 1.6033\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8015 - loss: 0.6645 - val_accuracy: 0.5983 - val_loss: 1.6036\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8019 - loss: 0.6644 - val_accuracy: 0.5982 - val_loss: 1.6031\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8016 - loss: 0.6644 - val_accuracy: 0.5983 - val_loss: 1.6038\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8015 - loss: 0.6644 - val_accuracy: 0.5981 - val_loss: 1.6036\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6643 - val_accuracy: 0.5982 - val_loss: 1.6016\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6643 - val_accuracy: 0.5981 - val_loss: 1.6003\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6643 - val_accuracy: 0.5982 - val_loss: 1.5999\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6642 - val_accuracy: 0.5981 - val_loss: 1.6032\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6642 - val_accuracy: 0.5982 - val_loss: 1.6051\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6641 - val_accuracy: 0.5982 - val_loss: 1.6036\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6641 - val_accuracy: 0.5982 - val_loss: 1.6015\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6641 - val_accuracy: 0.5981 - val_loss: 1.6065\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6640 - val_accuracy: 0.5983 - val_loss: 1.6026\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6640 - val_accuracy: 0.5982 - val_loss: 1.6029\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6640 - val_accuracy: 0.5982 - val_loss: 1.5998\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6639 - val_accuracy: 0.5981 - val_loss: 1.6038\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6639 - val_accuracy: 0.5983 - val_loss: 1.6014\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6638 - val_accuracy: 0.5982 - val_loss: 1.6029\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6638 - val_accuracy: 0.5981 - val_loss: 1.6056\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6638 - val_accuracy: 0.5982 - val_loss: 1.6037\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6637 - val_accuracy: 0.5982 - val_loss: 1.6035\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6637 - val_accuracy: 0.5983 - val_loss: 1.6045\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6637 - val_accuracy: 0.5980 - val_loss: 1.6071\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6636 - val_accuracy: 0.5982 - val_loss: 1.6030\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6636 - val_accuracy: 0.5983 - val_loss: 1.5997\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6636 - val_accuracy: 0.5983 - val_loss: 1.6035\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6635 - val_accuracy: 0.5982 - val_loss: 1.6078\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6635 - val_accuracy: 0.5982 - val_loss: 1.6037\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6635 - val_accuracy: 0.5983 - val_loss: 1.6025\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6634 - val_accuracy: 0.5981 - val_loss: 1.6034\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6634 - val_accuracy: 0.5983 - val_loss: 1.6001\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6634 - val_accuracy: 0.5982 - val_loss: 1.6051\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6633 - val_accuracy: 0.5982 - val_loss: 1.6003\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6633 - val_accuracy: 0.5983 - val_loss: 1.6031\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6632 - val_accuracy: 0.5982 - val_loss: 1.6041\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6632 - val_accuracy: 0.5981 - val_loss: 1.6056\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6632 - val_accuracy: 0.5982 - val_loss: 1.6025\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8010 - loss: 0.6631 - val_accuracy: 0.5981 - val_loss: 1.6030\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6631 - val_accuracy: 0.5981 - val_loss: 1.6039\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6631 - val_accuracy: 0.5981 - val_loss: 1.6038\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6630 - val_accuracy: 0.5978 - val_loss: 1.6079\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6630 - val_accuracy: 0.5982 - val_loss: 1.6013\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6630 - val_accuracy: 0.5981 - val_loss: 1.6015\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6629 - val_accuracy: 0.5981 - val_loss: 1.6039\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6629 - val_accuracy: 0.5982 - val_loss: 1.6051\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6629 - val_accuracy: 0.5981 - val_loss: 1.6035\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 10s - 14ms/step - accuracy: 0.8010 - loss: 0.6628 - val_accuracy: 0.5981 - val_loss: 1.6016\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6628 - val_accuracy: 0.5981 - val_loss: 1.6017\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6628 - val_accuracy: 0.5981 - val_loss: 1.6032\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6627 - val_accuracy: 0.5981 - val_loss: 1.6029\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6627 - val_accuracy: 0.5982 - val_loss: 1.6024\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6627 - val_accuracy: 0.5982 - val_loss: 1.6011\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6626 - val_accuracy: 0.5983 - val_loss: 1.6088\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6626 - val_accuracy: 0.5982 - val_loss: 1.6010\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6626 - val_accuracy: 0.5983 - val_loss: 1.6061\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6625 - val_accuracy: 0.5983 - val_loss: 1.6030\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6625 - val_accuracy: 0.5983 - val_loss: 1.6053\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6625 - val_accuracy: 0.5984 - val_loss: 1.6037\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6624 - val_accuracy: 0.5983 - val_loss: 1.6060\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6624 - val_accuracy: 0.5983 - val_loss: 1.6037\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6624 - val_accuracy: 0.5983 - val_loss: 1.6060\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6623 - val_accuracy: 0.5985 - val_loss: 1.6024\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6623 - val_accuracy: 0.5984 - val_loss: 1.6037\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6623 - val_accuracy: 0.5984 - val_loss: 1.6020\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6622 - val_accuracy: 0.5984 - val_loss: 1.6054\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6622 - val_accuracy: 0.5984 - val_loss: 1.6045\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6622 - val_accuracy: 0.5985 - val_loss: 1.6037\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6621 - val_accuracy: 0.5985 - val_loss: 1.6025\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6621 - val_accuracy: 0.5985 - val_loss: 1.6039\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6621 - val_accuracy: 0.5985 - val_loss: 1.6050\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6620 - val_accuracy: 0.5985 - val_loss: 1.6029\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6620 - val_accuracy: 0.5984 - val_loss: 1.6065\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6620 - val_accuracy: 0.5984 - val_loss: 1.6072\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6620 - val_accuracy: 0.5985 - val_loss: 1.6053\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6619 - val_accuracy: 0.5984 - val_loss: 1.6086\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6619 - val_accuracy: 0.5984 - val_loss: 1.6053\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6619 - val_accuracy: 0.5985 - val_loss: 1.6007\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6618 - val_accuracy: 0.5985 - val_loss: 1.6055\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6618 - val_accuracy: 0.5984 - val_loss: 1.6069\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6618 - val_accuracy: 0.5985 - val_loss: 1.6019\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6617 - val_accuracy: 0.5984 - val_loss: 1.6073\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6617 - val_accuracy: 0.5985 - val_loss: 1.6040\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6617 - val_accuracy: 0.5985 - val_loss: 1.6035\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6616 - val_accuracy: 0.5985 - val_loss: 1.6004\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6616 - val_accuracy: 0.5985 - val_loss: 1.6050\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6616 - val_accuracy: 0.5985 - val_loss: 1.6025\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6616 - val_accuracy: 0.5985 - val_loss: 1.6052\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6615 - val_accuracy: 0.5985 - val_loss: 1.6079\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6615 - val_accuracy: 0.5984 - val_loss: 1.6091\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6615 - val_accuracy: 0.5984 - val_loss: 1.6070\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6614 - val_accuracy: 0.5985 - val_loss: 1.6057\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6614 - val_accuracy: 0.5984 - val_loss: 1.6094\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6614 - val_accuracy: 0.5985 - val_loss: 1.6032\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6613 - val_accuracy: 0.5985 - val_loss: 1.6057\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6613 - val_accuracy: 0.5984 - val_loss: 1.6075\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6613 - val_accuracy: 0.5985 - val_loss: 1.6081\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6612 - val_accuracy: 0.5985 - val_loss: 1.6066\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6612 - val_accuracy: 0.5985 - val_loss: 1.6046\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6612 - val_accuracy: 0.5985 - val_loss: 1.6049\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6612 - val_accuracy: 0.5985 - val_loss: 1.6069\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6611 - val_accuracy: 0.5984 - val_loss: 1.6079\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6611 - val_accuracy: 0.5984 - val_loss: 1.6074\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6611 - val_accuracy: 0.5984 - val_loss: 1.6051\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6610 - val_accuracy: 0.5984 - val_loss: 1.6092\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6610 - val_accuracy: 0.5984 - val_loss: 1.6122\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6610 - val_accuracy: 0.5985 - val_loss: 1.6037\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6609 - val_accuracy: 0.5984 - val_loss: 1.6106\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6609 - val_accuracy: 0.5984 - val_loss: 1.6080\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6609 - val_accuracy: 0.5984 - val_loss: 1.6086\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6609 - val_accuracy: 0.5984 - val_loss: 1.6084\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6608 - val_accuracy: 0.5984 - val_loss: 1.6070\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6608 - val_accuracy: 0.5984 - val_loss: 1.6078\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6608 - val_accuracy: 0.5986 - val_loss: 1.6034\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6607 - val_accuracy: 0.5984 - val_loss: 1.6067\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6607 - val_accuracy: 0.5984 - val_loss: 1.6089\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6607 - val_accuracy: 0.5986 - val_loss: 1.6056\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6607 - val_accuracy: 0.5985 - val_loss: 1.6101\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6606 - val_accuracy: 0.5985 - val_loss: 1.6065\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6606 - val_accuracy: 0.5985 - val_loss: 1.6097\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6606 - val_accuracy: 0.5986 - val_loss: 1.6076\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6605 - val_accuracy: 0.5986 - val_loss: 1.6062\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6605 - val_accuracy: 0.5988 - val_loss: 1.6036\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6605 - val_accuracy: 0.5986 - val_loss: 1.6089\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6605 - val_accuracy: 0.5987 - val_loss: 1.6077\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6604 - val_accuracy: 0.5986 - val_loss: 1.6090\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6604 - val_accuracy: 0.5987 - val_loss: 1.6060\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6604 - val_accuracy: 0.5988 - val_loss: 1.6032\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6603 - val_accuracy: 0.5986 - val_loss: 1.6083\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6603 - val_accuracy: 0.5988 - val_loss: 1.6058\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6603 - val_accuracy: 0.5987 - val_loss: 1.6066\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6603 - val_accuracy: 0.5986 - val_loss: 1.6097\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6602 - val_accuracy: 0.5986 - val_loss: 1.6084\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6602 - val_accuracy: 0.5987 - val_loss: 1.6104\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6602 - val_accuracy: 0.5987 - val_loss: 1.6100\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6601 - val_accuracy: 0.5988 - val_loss: 1.6067\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6601 - val_accuracy: 0.5987 - val_loss: 1.6105\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6601 - val_accuracy: 0.5986 - val_loss: 1.6132\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6601 - val_accuracy: 0.5987 - val_loss: 1.6063\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6600 - val_accuracy: 0.5987 - val_loss: 1.6093\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6600 - val_accuracy: 0.5988 - val_loss: 1.6052\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6600 - val_accuracy: 0.5987 - val_loss: 1.6092\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6599 - val_accuracy: 0.5987 - val_loss: 1.6099\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6599 - val_accuracy: 0.5986 - val_loss: 1.6086\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6599 - val_accuracy: 0.5987 - val_loss: 1.6129\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6599 - val_accuracy: 0.5988 - val_loss: 1.6058\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6598 - val_accuracy: 0.5988 - val_loss: 1.6087\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6598 - val_accuracy: 0.5987 - val_loss: 1.6083\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6598 - val_accuracy: 0.5988 - val_loss: 1.6057\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6598 - val_accuracy: 0.5988 - val_loss: 1.6083\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6597 - val_accuracy: 0.5988 - val_loss: 1.6079\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6597 - val_accuracy: 0.5987 - val_loss: 1.6116\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6597 - val_accuracy: 0.5988 - val_loss: 1.6097\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6596 - val_accuracy: 0.5987 - val_loss: 1.6100\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6596 - val_accuracy: 0.5988 - val_loss: 1.6065\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6596 - val_accuracy: 0.5987 - val_loss: 1.6073\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6596 - val_accuracy: 0.5988 - val_loss: 1.6061\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6595 - val_accuracy: 0.5987 - val_loss: 1.6104\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6595 - val_accuracy: 0.5988 - val_loss: 1.6082\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6595 - val_accuracy: 0.5988 - val_loss: 1.6085\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6595 - val_accuracy: 0.5988 - val_loss: 1.6057\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6594 - val_accuracy: 0.5988 - val_loss: 1.6082\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6594 - val_accuracy: 0.5988 - val_loss: 1.6095\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6594 - val_accuracy: 0.5987 - val_loss: 1.6113\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6593 - val_accuracy: 0.5987 - val_loss: 1.6068\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6593 - val_accuracy: 0.5988 - val_loss: 1.6088\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6593 - val_accuracy: 0.5988 - val_loss: 1.6074\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6593 - val_accuracy: 0.5988 - val_loss: 1.6076\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6592 - val_accuracy: 0.5987 - val_loss: 1.6099\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6592 - val_accuracy: 0.5998 - val_loss: 1.6099\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6592 - val_accuracy: 0.5988 - val_loss: 1.6097\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6592 - val_accuracy: 0.6000 - val_loss: 1.6059\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6591 - val_accuracy: 0.5998 - val_loss: 1.6080\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6591 - val_accuracy: 0.6000 - val_loss: 1.6068\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6591 - val_accuracy: 0.6000 - val_loss: 1.6069\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6591 - val_accuracy: 0.6000 - val_loss: 1.6113\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6590 - val_accuracy: 0.6000 - val_loss: 1.6090\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6590 - val_accuracy: 0.6000 - val_loss: 1.6059\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6590 - val_accuracy: 0.6000 - val_loss: 1.6099\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6590 - val_accuracy: 0.6000 - val_loss: 1.6096\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6589 - val_accuracy: 0.6000 - val_loss: 1.6108\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6589 - val_accuracy: 0.6000 - val_loss: 1.6085\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6589 - val_accuracy: 0.5998 - val_loss: 1.6157\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6589 - val_accuracy: 0.6000 - val_loss: 1.6083\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6588 - val_accuracy: 0.6029 - val_loss: 1.6072\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6588 - val_accuracy: 0.6000 - val_loss: 1.6115\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6588 - val_accuracy: 0.6000 - val_loss: 1.6098\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8014 - loss: 0.6587 - val_accuracy: 0.6029 - val_loss: 1.6058\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6587 - val_accuracy: 0.6000 - val_loss: 1.6086\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_11, X_test_11, y_train_11, y_test_11 = train_test_split(\n    X, y, test_size=0.3, random_state=53, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_11, X_val_11, y_train_11, y_val_11 = train_test_split(\n    X_train_11, y_train_11, test_size=0.2, random_state=53, stratify=y_train_11\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_11:\", np.max(X_train_11))\nprint(\"Min value in X_train_11:\", np.min(X_train_11))\n\nX_train_11_scaled = scaler.fit_transform(X_train_11)\n\n# Get the original class distribution\nclass_counts_11 = Counter(y_train_11)\nprint(\"Original class distribution:\", class_counts_11)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_11 = class_counts_11[min(class_counts_11, key=class_counts_11.get)]\ndesired_majority_size_11 = minority_class_size_11 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_11 = {0: desired_majority_size_11, 1: minority_class_size_11}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_11 = RandomUnderSampler(sampling_strategy=sampling_strategy_11, random_state=42)\nX_resampled_11, y_resampled_11 = undersampler_11.fit_resample(X_train_11, y_train_11)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_11))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_11, y_train_resampled_11 = smote.fit_resample(X_resampled_11, y_resampled_11)\n\n\n#Verify the class distribution after SMOTE\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_11))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_11))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:58:57.679474Z","iopub.execute_input":"2025-03-07T02:58:57.679859Z","iopub.status.idle":"2025-03-07T02:59:35.416746Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_11: 2071000000.0\nMin value in X_train_11: -6442447920.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_11 = X_train_resampled_11.reshape(X_train_resampled_11.shape[0], 1, 56)\nX_val_11 = X_val_11.reshape(X_val_11.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_11,  # Features from CICIDS2017\n    y_train_resampled_11,  # Labels from CICIDS2017\n    validation_data=(X_val_11, y_val_11),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:59:35.420527Z","iopub.execute_input":"2025-03-07T02:59:35.420812Z","iopub.status.idle":"2025-03-07T03:42:44.733367Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7521 - val_accuracy: 0.5857 - val_loss: 1.6345\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7862 - loss: 0.7452 - val_accuracy: 0.5857 - val_loss: 1.6345\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7862 - loss: 0.7436 - val_accuracy: 0.5856 - val_loss: 1.6419\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7861 - loss: 0.7422 - val_accuracy: 0.5856 - val_loss: 1.6478\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7861 - loss: 0.7410 - val_accuracy: 0.5859 - val_loss: 1.6485\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7861 - loss: 0.7398 - val_accuracy: 0.5859 - val_loss: 1.6513\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7861 - loss: 0.7387 - val_accuracy: 0.5859 - val_loss: 1.6518\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7861 - loss: 0.7377 - val_accuracy: 0.5859 - val_loss: 1.6567\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7860 - loss: 0.7368 - val_accuracy: 0.5856 - val_loss: 1.6624\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7860 - loss: 0.7358 - val_accuracy: 0.5856 - val_loss: 1.6639\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7859 - loss: 0.7350 - val_accuracy: 0.5856 - val_loss: 1.6613\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7341 - val_accuracy: 0.5854 - val_loss: 1.6644\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7333 - val_accuracy: 0.5857 - val_loss: 1.6641\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7326 - val_accuracy: 0.5845 - val_loss: 1.6676\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7318 - val_accuracy: 0.5845 - val_loss: 1.6673\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7311 - val_accuracy: 0.5954 - val_loss: 1.6684\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7304 - val_accuracy: 0.5954 - val_loss: 1.6699\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7298 - val_accuracy: 0.5954 - val_loss: 1.6707\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7898 - loss: 0.7292 - val_accuracy: 0.5954 - val_loss: 1.6707\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7285 - val_accuracy: 0.5954 - val_loss: 1.6760\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7279 - val_accuracy: 0.5957 - val_loss: 1.6704\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7274 - val_accuracy: 0.5957 - val_loss: 1.6711\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7268 - val_accuracy: 0.5954 - val_loss: 1.6747\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7263 - val_accuracy: 0.5956 - val_loss: 1.6774\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7912 - loss: 0.7257 - val_accuracy: 0.5956 - val_loss: 1.6739\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7927 - loss: 0.7252 - val_accuracy: 0.5984 - val_loss: 1.6710\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7247 - val_accuracy: 0.5984 - val_loss: 1.6759\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7242 - val_accuracy: 0.5984 - val_loss: 1.6721\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7238 - val_accuracy: 0.5985 - val_loss: 1.6766\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7233 - val_accuracy: 0.5985 - val_loss: 1.6706\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7229 - val_accuracy: 0.5984 - val_loss: 1.6748\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7224 - val_accuracy: 0.5984 - val_loss: 1.6781\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7220 - val_accuracy: 0.5976 - val_loss: 1.6775\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7216 - val_accuracy: 0.5985 - val_loss: 1.6790\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7212 - val_accuracy: 0.5985 - val_loss: 1.6779\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7208 - val_accuracy: 0.5985 - val_loss: 1.6775\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7204 - val_accuracy: 0.5985 - val_loss: 1.6806\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7201 - val_accuracy: 0.5985 - val_loss: 1.6759\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7197 - val_accuracy: 0.5979 - val_loss: 1.6772\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7193 - val_accuracy: 0.5986 - val_loss: 1.6753\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7190 - val_accuracy: 0.5980 - val_loss: 1.6776\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7187 - val_accuracy: 0.5985 - val_loss: 1.6772\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7183 - val_accuracy: 0.5978 - val_loss: 1.6781\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.61012\n726/726 - 7s - 10ms/step - accuracy: 0.7943 - loss: 0.7180 - val_accuracy: 0.5977 - val_loss: 1.6832\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7177 - val_accuracy: 0.5976 - val_loss: 1.6825\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7174 - val_accuracy: 0.5976 - val_loss: 1.6819\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7171 - val_accuracy: 0.5976 - val_loss: 1.6835\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7168 - val_accuracy: 0.5976 - val_loss: 1.6761\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7165 - val_accuracy: 0.5984 - val_loss: 1.6811\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7163 - val_accuracy: 0.5976 - val_loss: 1.6863\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7160 - val_accuracy: 0.5976 - val_loss: 1.6818\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7157 - val_accuracy: 0.5976 - val_loss: 1.6851\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7155 - val_accuracy: 0.5970 - val_loss: 1.6840\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7152 - val_accuracy: 0.5975 - val_loss: 1.6811\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7149 - val_accuracy: 0.5969 - val_loss: 1.6823\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7147 - val_accuracy: 0.5969 - val_loss: 1.6814\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7145 - val_accuracy: 0.5969 - val_loss: 1.6815\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7142 - val_accuracy: 0.5969 - val_loss: 1.6826\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7140 - val_accuracy: 0.5972 - val_loss: 1.6818\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7138 - val_accuracy: 0.5972 - val_loss: 1.6825\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7135 - val_accuracy: 0.5971 - val_loss: 1.6847\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7133 - val_accuracy: 0.5971 - val_loss: 1.6844\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7131 - val_accuracy: 0.5971 - val_loss: 1.6881\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7129 - val_accuracy: 0.5972 - val_loss: 1.6850\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7127 - val_accuracy: 0.5980 - val_loss: 1.6819\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7125 - val_accuracy: 0.5970 - val_loss: 1.6859\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7123 - val_accuracy: 0.5969 - val_loss: 1.6872\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7121 - val_accuracy: 0.5969 - val_loss: 1.6864\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7119 - val_accuracy: 0.5970 - val_loss: 1.6854\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7117 - val_accuracy: 0.5969 - val_loss: 1.6863\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7115 - val_accuracy: 0.5969 - val_loss: 1.6876\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7113 - val_accuracy: 0.5969 - val_loss: 1.6867\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7111 - val_accuracy: 0.5969 - val_loss: 1.6871\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7109 - val_accuracy: 0.5969 - val_loss: 1.6882\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7108 - val_accuracy: 0.5969 - val_loss: 1.6861\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7106 - val_accuracy: 0.5978 - val_loss: 1.6825\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7104 - val_accuracy: 0.5969 - val_loss: 1.6851\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7944 - loss: 0.7102 - val_accuracy: 0.5969 - val_loss: 1.6873\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7101 - val_accuracy: 0.5969 - val_loss: 1.6875\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7943 - loss: 0.7099 - val_accuracy: 0.5969 - val_loss: 1.6915\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7097 - val_accuracy: 0.5984 - val_loss: 1.6856\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7096 - val_accuracy: 0.5984 - val_loss: 1.6905\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7094 - val_accuracy: 0.5992 - val_loss: 1.6846\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7959 - loss: 0.7093 - val_accuracy: 0.5984 - val_loss: 1.6878\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7091 - val_accuracy: 0.5984 - val_loss: 1.6897\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7959 - loss: 0.7089 - val_accuracy: 0.5991 - val_loss: 1.6874\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7959 - loss: 0.7088 - val_accuracy: 0.5984 - val_loss: 1.6901\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7086 - val_accuracy: 0.5992 - val_loss: 1.6919\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7085 - val_accuracy: 0.5983 - val_loss: 1.6922\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7083 - val_accuracy: 0.5983 - val_loss: 1.6893\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7082 - val_accuracy: 0.5991 - val_loss: 1.6886\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7080 - val_accuracy: 0.5991 - val_loss: 1.6909\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7079 - val_accuracy: 0.5983 - val_loss: 1.6912\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7077 - val_accuracy: 0.5992 - val_loss: 1.6865\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7076 - val_accuracy: 0.5983 - val_loss: 1.6915\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7074 - val_accuracy: 0.5983 - val_loss: 1.6919\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7073 - val_accuracy: 0.5991 - val_loss: 1.6897\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7072 - val_accuracy: 0.5991 - val_loss: 1.6916\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7070 - val_accuracy: 0.5991 - val_loss: 1.6913\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7960 - loss: 0.7069 - val_accuracy: 0.5982 - val_loss: 1.6945\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7068 - val_accuracy: 0.5991 - val_loss: 1.6917\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.7066 - val_accuracy: 0.5982 - val_loss: 1.6936\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.7065 - val_accuracy: 0.5982 - val_loss: 1.6937\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7063 - val_accuracy: 0.5982 - val_loss: 1.6943\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7062 - val_accuracy: 0.5992 - val_loss: 1.6926\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7061 - val_accuracy: 0.5982 - val_loss: 1.6966\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7974 - loss: 0.7060 - val_accuracy: 0.5992 - val_loss: 1.6913\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7973 - loss: 0.7058 - val_accuracy: 0.5983 - val_loss: 1.6952\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.7057 - val_accuracy: 0.5983 - val_loss: 1.6944\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.7056 - val_accuracy: 0.5984 - val_loss: 1.6950\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7055 - val_accuracy: 0.5984 - val_loss: 1.6987\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7053 - val_accuracy: 0.5991 - val_loss: 1.6945\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7980 - loss: 0.7052 - val_accuracy: 0.5984 - val_loss: 1.6921\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7051 - val_accuracy: 0.5992 - val_loss: 1.6948\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7050 - val_accuracy: 0.5983 - val_loss: 1.6983\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7048 - val_accuracy: 0.5984 - val_loss: 1.6980\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7047 - val_accuracy: 0.5984 - val_loss: 1.6951\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7046 - val_accuracy: 0.5984 - val_loss: 1.6949\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7045 - val_accuracy: 0.5992 - val_loss: 1.6944\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7044 - val_accuracy: 0.5994 - val_loss: 1.6937\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7042 - val_accuracy: 0.5992 - val_loss: 1.6961\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7041 - val_accuracy: 0.5993 - val_loss: 1.6957\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7040 - val_accuracy: 0.5994 - val_loss: 1.6936\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7039 - val_accuracy: 0.5992 - val_loss: 1.6995\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7980 - loss: 0.7038 - val_accuracy: 0.5992 - val_loss: 1.6966\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7037 - val_accuracy: 0.5984 - val_loss: 1.6990\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7036 - val_accuracy: 0.5992 - val_loss: 1.6977\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7035 - val_accuracy: 0.5983 - val_loss: 1.7010\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7033 - val_accuracy: 0.5984 - val_loss: 1.6980\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7032 - val_accuracy: 0.5984 - val_loss: 1.7006\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7980 - loss: 0.7031 - val_accuracy: 0.5984 - val_loss: 1.6999\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7030 - val_accuracy: 0.5982 - val_loss: 1.7014\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7029 - val_accuracy: 0.5982 - val_loss: 1.7030\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7028 - val_accuracy: 0.5990 - val_loss: 1.7023\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7027 - val_accuracy: 0.5990 - val_loss: 1.7018\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.7026 - val_accuracy: 0.5990 - val_loss: 1.6968\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7025 - val_accuracy: 0.5982 - val_loss: 1.7007\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7024 - val_accuracy: 0.5990 - val_loss: 1.6958\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7023 - val_accuracy: 0.5982 - val_loss: 1.7014\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.7022 - val_accuracy: 0.5982 - val_loss: 1.6993\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7021 - val_accuracy: 0.5983 - val_loss: 1.6984\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7020 - val_accuracy: 0.5985 - val_loss: 1.7012\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7019 - val_accuracy: 0.5986 - val_loss: 1.6978\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7018 - val_accuracy: 0.5985 - val_loss: 1.6983\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7017 - val_accuracy: 0.5986 - val_loss: 1.6995\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7016 - val_accuracy: 0.5976 - val_loss: 1.7034\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7015 - val_accuracy: 0.5977 - val_loss: 1.7014\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7014 - val_accuracy: 0.5977 - val_loss: 1.7000\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7013 - val_accuracy: 0.5976 - val_loss: 1.7004\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7012 - val_accuracy: 0.5985 - val_loss: 1.6991\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7011 - val_accuracy: 0.5986 - val_loss: 1.6980\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7010 - val_accuracy: 0.5985 - val_loss: 1.7009\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7009 - val_accuracy: 0.5985 - val_loss: 1.7003\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7008 - val_accuracy: 0.5984 - val_loss: 1.7001\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7007 - val_accuracy: 0.5976 - val_loss: 1.7024\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7006 - val_accuracy: 0.5982 - val_loss: 1.7028\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7005 - val_accuracy: 0.5983 - val_loss: 1.7005\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7004 - val_accuracy: 0.5983 - val_loss: 1.7006\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7003 - val_accuracy: 0.5983 - val_loss: 1.6979\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7003 - val_accuracy: 0.5982 - val_loss: 1.7028\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7002 - val_accuracy: 0.5973 - val_loss: 1.7052\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7001 - val_accuracy: 0.5972 - val_loss: 1.7042\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7000 - val_accuracy: 0.5981 - val_loss: 1.7040\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6999 - val_accuracy: 0.5981 - val_loss: 1.7025\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6998 - val_accuracy: 0.5963 - val_loss: 1.7059\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6997 - val_accuracy: 0.5962 - val_loss: 1.7054\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6996 - val_accuracy: 0.5979 - val_loss: 1.7019\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6995 - val_accuracy: 0.5963 - val_loss: 1.7038\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6994 - val_accuracy: 0.5971 - val_loss: 1.7040\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6994 - val_accuracy: 0.5973 - val_loss: 1.7042\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6993 - val_accuracy: 0.5962 - val_loss: 1.7029\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6992 - val_accuracy: 0.5971 - val_loss: 1.7045\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6991 - val_accuracy: 0.5962 - val_loss: 1.7059\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6990 - val_accuracy: 0.5961 - val_loss: 1.7101\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7994 - loss: 0.6989 - val_accuracy: 0.5970 - val_loss: 1.7043\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6988 - val_accuracy: 0.5970 - val_loss: 1.7056\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6988 - val_accuracy: 0.5970 - val_loss: 1.7058\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6987 - val_accuracy: 0.5961 - val_loss: 1.7071\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6986 - val_accuracy: 0.5970 - val_loss: 1.7041\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6985 - val_accuracy: 0.5962 - val_loss: 1.7059\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7994 - loss: 0.6984 - val_accuracy: 0.5961 - val_loss: 1.7078\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6984 - val_accuracy: 0.5961 - val_loss: 1.7104\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6983 - val_accuracy: 0.5970 - val_loss: 1.7043\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6982 - val_accuracy: 0.5970 - val_loss: 1.7046\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6981 - val_accuracy: 0.5992 - val_loss: 1.7021\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6980 - val_accuracy: 0.5983 - val_loss: 1.7052\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7995 - loss: 0.6979 - val_accuracy: 0.5984 - val_loss: 1.7025\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6979 - val_accuracy: 0.5983 - val_loss: 1.7072\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6978 - val_accuracy: 0.5970 - val_loss: 1.7065\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6977 - val_accuracy: 0.5964 - val_loss: 1.7080\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6976 - val_accuracy: 0.5984 - val_loss: 1.7077\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6975 - val_accuracy: 0.5955 - val_loss: 1.7087\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6975 - val_accuracy: 0.5976 - val_loss: 1.7088\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6974 - val_accuracy: 0.5964 - val_loss: 1.7080\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6973 - val_accuracy: 0.5985 - val_loss: 1.7062\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6972 - val_accuracy: 0.5977 - val_loss: 1.7071\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6972 - val_accuracy: 0.5985 - val_loss: 1.7060\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6971 - val_accuracy: 0.5955 - val_loss: 1.7074\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6970 - val_accuracy: 0.5976 - val_loss: 1.7104\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6969 - val_accuracy: 0.5985 - val_loss: 1.7078\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6969 - val_accuracy: 0.5977 - val_loss: 1.7075\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6968 - val_accuracy: 0.5983 - val_loss: 1.7102\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6967 - val_accuracy: 0.5985 - val_loss: 1.7104\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6966 - val_accuracy: 0.5985 - val_loss: 1.7063\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6966 - val_accuracy: 0.5984 - val_loss: 1.7088\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6965 - val_accuracy: 0.5984 - val_loss: 1.7053\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6964 - val_accuracy: 0.5984 - val_loss: 1.7095\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6963 - val_accuracy: 0.5984 - val_loss: 1.7089\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6963 - val_accuracy: 0.5976 - val_loss: 1.7090\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6962 - val_accuracy: 0.5985 - val_loss: 1.7069\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6961 - val_accuracy: 0.5976 - val_loss: 1.7105\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6961 - val_accuracy: 0.5976 - val_loss: 1.7099\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6960 - val_accuracy: 0.5984 - val_loss: 1.7096\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6959 - val_accuracy: 0.5984 - val_loss: 1.7109\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6958 - val_accuracy: 0.5984 - val_loss: 1.7105\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6958 - val_accuracy: 0.5984 - val_loss: 1.7101\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6957 - val_accuracy: 0.5976 - val_loss: 1.7106\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6956 - val_accuracy: 0.5974 - val_loss: 1.7112\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6956 - val_accuracy: 0.5982 - val_loss: 1.7084\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6955 - val_accuracy: 0.5974 - val_loss: 1.7122\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6954 - val_accuracy: 0.5982 - val_loss: 1.7109\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6953 - val_accuracy: 0.5974 - val_loss: 1.7095\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6953 - val_accuracy: 0.5982 - val_loss: 1.7106\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6952 - val_accuracy: 0.5974 - val_loss: 1.7148\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6951 - val_accuracy: 0.5982 - val_loss: 1.7123\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6951 - val_accuracy: 0.5982 - val_loss: 1.7143\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6950 - val_accuracy: 0.5974 - val_loss: 1.7133\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6949 - val_accuracy: 0.5982 - val_loss: 1.7109\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6949 - val_accuracy: 0.5982 - val_loss: 1.7132\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6948 - val_accuracy: 0.5982 - val_loss: 1.7087\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6947 - val_accuracy: 0.5982 - val_loss: 1.7099\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6947 - val_accuracy: 0.5982 - val_loss: 1.7107\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6946 - val_accuracy: 0.5982 - val_loss: 1.7089\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6945 - val_accuracy: 0.5973 - val_loss: 1.7169\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7993 - loss: 0.6945 - val_accuracy: 0.5982 - val_loss: 1.7120\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6944 - val_accuracy: 0.5982 - val_loss: 1.7116\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.61012\n726/726 - 7s - 10ms/step - accuracy: 0.7993 - loss: 0.6943 - val_accuracy: 0.5982 - val_loss: 1.7104\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.61012\n726/726 - 7s - 9ms/step - accuracy: 0.7993 - loss: 0.6943 - val_accuracy: 0.5982 - val_loss: 1.7109\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6942 - val_accuracy: 0.5973 - val_loss: 1.7143\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6941 - val_accuracy: 0.5982 - val_loss: 1.7147\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6941 - val_accuracy: 0.5974 - val_loss: 1.7124\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6940 - val_accuracy: 0.5982 - val_loss: 1.7136\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6940 - val_accuracy: 0.5974 - val_loss: 1.7148\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6939 - val_accuracy: 0.5982 - val_loss: 1.7134\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7993 - loss: 0.6938 - val_accuracy: 0.5973 - val_loss: 1.7146\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7993 - loss: 0.6938 - val_accuracy: 0.5981 - val_loss: 1.7158\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6937 - val_accuracy: 0.5982 - val_loss: 1.7144\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6936 - val_accuracy: 0.5982 - val_loss: 1.7116\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6936 - val_accuracy: 0.5982 - val_loss: 1.7114\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6935 - val_accuracy: 0.5982 - val_loss: 1.7124\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6935 - val_accuracy: 0.5981 - val_loss: 1.7146\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6934 - val_accuracy: 0.5982 - val_loss: 1.7145\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6933 - val_accuracy: 0.5981 - val_loss: 1.7132\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6933 - val_accuracy: 0.5982 - val_loss: 1.7136\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6932 - val_accuracy: 0.5982 - val_loss: 1.7127\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6931 - val_accuracy: 0.5981 - val_loss: 1.7160\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6931 - val_accuracy: 0.5982 - val_loss: 1.7101\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6930 - val_accuracy: 0.5973 - val_loss: 1.7155\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6930 - val_accuracy: 0.5972 - val_loss: 1.7169\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6929 - val_accuracy: 0.5970 - val_loss: 1.7190\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6928 - val_accuracy: 0.5981 - val_loss: 1.7156\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6928 - val_accuracy: 0.5970 - val_loss: 1.7182\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6927 - val_accuracy: 0.5970 - val_loss: 1.7180\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6927 - val_accuracy: 0.5978 - val_loss: 1.7150\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6926 - val_accuracy: 0.5970 - val_loss: 1.7170\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6925 - val_accuracy: 0.5970 - val_loss: 1.7190\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6925 - val_accuracy: 0.5978 - val_loss: 1.7159\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6924 - val_accuracy: 0.5978 - val_loss: 1.7137\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6924 - val_accuracy: 0.5970 - val_loss: 1.7213\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6923 - val_accuracy: 0.5978 - val_loss: 1.7148\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6923 - val_accuracy: 0.5970 - val_loss: 1.7190\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6922 - val_accuracy: 0.5962 - val_loss: 1.7195\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6921 - val_accuracy: 0.5970 - val_loss: 1.7190\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6921 - val_accuracy: 0.5962 - val_loss: 1.7203\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6920 - val_accuracy: 0.5962 - val_loss: 1.7203\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6920 - val_accuracy: 0.5970 - val_loss: 1.7147\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6919 - val_accuracy: 0.5970 - val_loss: 1.7156\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7995 - loss: 0.6919 - val_accuracy: 0.5970 - val_loss: 1.7183\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6918 - val_accuracy: 0.5970 - val_loss: 1.7167\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6917 - val_accuracy: 0.5970 - val_loss: 1.7182\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6917 - val_accuracy: 0.5970 - val_loss: 1.7174\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6916 - val_accuracy: 0.5962 - val_loss: 1.7195\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6916 - val_accuracy: 0.5962 - val_loss: 1.7213\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.6915 - val_accuracy: 0.5976 - val_loss: 1.7163\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6915 - val_accuracy: 0.5976 - val_loss: 1.7182\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6914 - val_accuracy: 0.5970 - val_loss: 1.7211\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6914 - val_accuracy: 0.5970 - val_loss: 1.7197\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6913 - val_accuracy: 0.5976 - val_loss: 1.7183\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6912 - val_accuracy: 0.5962 - val_loss: 1.7209\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.6912 - val_accuracy: 0.5962 - val_loss: 1.7236\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7994 - loss: 0.6911 - val_accuracy: 0.5986 - val_loss: 1.7190\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6911 - val_accuracy: 0.5976 - val_loss: 1.7178\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.6910 - val_accuracy: 0.5976 - val_loss: 1.7200\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.6910 - val_accuracy: 0.5970 - val_loss: 1.7194\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6909 - val_accuracy: 0.5976 - val_loss: 1.7216\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.6909 - val_accuracy: 0.5962 - val_loss: 1.7225\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7994 - loss: 0.6908 - val_accuracy: 0.5976 - val_loss: 1.7215\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6908 - val_accuracy: 0.5986 - val_loss: 1.7188\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6907 - val_accuracy: 0.5962 - val_loss: 1.7232\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6907 - val_accuracy: 0.5962 - val_loss: 1.7219\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6906 - val_accuracy: 0.5976 - val_loss: 1.7218\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7995 - loss: 0.6905 - val_accuracy: 0.5976 - val_loss: 1.7228\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6905 - val_accuracy: 0.5976 - val_loss: 1.7203\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6904 - val_accuracy: 0.5962 - val_loss: 1.7230\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6904 - val_accuracy: 0.5976 - val_loss: 1.7214\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6903 - val_accuracy: 0.5977 - val_loss: 1.7209\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6903 - val_accuracy: 0.5987 - val_loss: 1.7193\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7994 - loss: 0.6902 - val_accuracy: 0.5962 - val_loss: 1.7256\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6902 - val_accuracy: 0.5987 - val_loss: 1.7196\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6901 - val_accuracy: 0.5976 - val_loss: 1.7221\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6901 - val_accuracy: 0.5987 - val_loss: 1.7230\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6900 - val_accuracy: 0.5986 - val_loss: 1.7234\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6900 - val_accuracy: 0.5962 - val_loss: 1.7285\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6899 - val_accuracy: 0.5986 - val_loss: 1.7242\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6899 - val_accuracy: 0.5962 - val_loss: 1.7250\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6898 - val_accuracy: 0.5987 - val_loss: 1.7218\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6898 - val_accuracy: 0.5985 - val_loss: 1.7258\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6897 - val_accuracy: 0.5985 - val_loss: 1.7218\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6897 - val_accuracy: 0.5960 - val_loss: 1.7276\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6896 - val_accuracy: 0.5985 - val_loss: 1.7217\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6896 - val_accuracy: 0.5985 - val_loss: 1.7243\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6895 - val_accuracy: 0.5985 - val_loss: 1.7202\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6895 - val_accuracy: 0.5985 - val_loss: 1.7210\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6894 - val_accuracy: 0.5966 - val_loss: 1.7288\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6894 - val_accuracy: 0.5985 - val_loss: 1.7231\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6893 - val_accuracy: 0.5985 - val_loss: 1.7244\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6893 - val_accuracy: 0.5966 - val_loss: 1.7290\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6892 - val_accuracy: 0.5985 - val_loss: 1.7248\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6892 - val_accuracy: 0.5986 - val_loss: 1.7202\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6891 - val_accuracy: 0.5977 - val_loss: 1.7277\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6891 - val_accuracy: 0.5986 - val_loss: 1.7207\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6890 - val_accuracy: 0.5985 - val_loss: 1.7245\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6890 - val_accuracy: 0.5985 - val_loss: 1.7229\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6889 - val_accuracy: 0.5976 - val_loss: 1.7263\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6889 - val_accuracy: 0.5985 - val_loss: 1.7253\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6888 - val_accuracy: 0.5986 - val_loss: 1.7249\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6888 - val_accuracy: 0.5985 - val_loss: 1.7263\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6887 - val_accuracy: 0.5985 - val_loss: 1.7269\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6887 - val_accuracy: 0.5986 - val_loss: 1.7223\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6887 - val_accuracy: 0.5977 - val_loss: 1.7271\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6886 - val_accuracy: 0.5986 - val_loss: 1.7244\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6886 - val_accuracy: 0.5985 - val_loss: 1.7250\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6885 - val_accuracy: 0.5981 - val_loss: 1.7278\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6885 - val_accuracy: 0.5980 - val_loss: 1.7306\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6884 - val_accuracy: 0.5988 - val_loss: 1.7257\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6884 - val_accuracy: 0.5989 - val_loss: 1.7277\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6883 - val_accuracy: 0.5981 - val_loss: 1.7296\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6883 - val_accuracy: 0.5988 - val_loss: 1.7305\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6882 - val_accuracy: 0.5981 - val_loss: 1.7280\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6882 - val_accuracy: 0.5988 - val_loss: 1.7298\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6881 - val_accuracy: 0.5989 - val_loss: 1.7278\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8003 - loss: 0.6881 - val_accuracy: 0.5989 - val_loss: 1.7262\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6881 - val_accuracy: 0.5991 - val_loss: 1.7242\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6880 - val_accuracy: 0.5989 - val_loss: 1.7273\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6880 - val_accuracy: 0.5990 - val_loss: 1.7261\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6879 - val_accuracy: 0.5989 - val_loss: 1.7282\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6879 - val_accuracy: 0.5989 - val_loss: 1.7269\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6878 - val_accuracy: 0.5989 - val_loss: 1.7303\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6878 - val_accuracy: 0.5981 - val_loss: 1.7265\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6877 - val_accuracy: 0.5989 - val_loss: 1.7277\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6877 - val_accuracy: 0.5981 - val_loss: 1.7268\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6876 - val_accuracy: 0.5990 - val_loss: 1.7291\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6876 - val_accuracy: 0.5989 - val_loss: 1.7253\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6876 - val_accuracy: 0.5981 - val_loss: 1.7297\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6875 - val_accuracy: 0.5989 - val_loss: 1.7249\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6875 - val_accuracy: 0.5981 - val_loss: 1.7302\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6874 - val_accuracy: 0.5991 - val_loss: 1.7263\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6874 - val_accuracy: 0.5990 - val_loss: 1.7269\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6873 - val_accuracy: 0.5982 - val_loss: 1.7326\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6873 - val_accuracy: 0.5990 - val_loss: 1.7289\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6873 - val_accuracy: 0.5990 - val_loss: 1.7273\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6872 - val_accuracy: 0.5990 - val_loss: 1.7305\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6872 - val_accuracy: 0.5991 - val_loss: 1.7299\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6871 - val_accuracy: 0.5981 - val_loss: 1.7302\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6871 - val_accuracy: 0.5981 - val_loss: 1.7294\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6870 - val_accuracy: 0.5989 - val_loss: 1.7302\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6870 - val_accuracy: 0.5989 - val_loss: 1.7322\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6869 - val_accuracy: 0.5980 - val_loss: 1.7300\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6869 - val_accuracy: 0.5989 - val_loss: 1.7313\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6869 - val_accuracy: 0.5989 - val_loss: 1.7322\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6868 - val_accuracy: 0.5980 - val_loss: 1.7319\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6868 - val_accuracy: 0.5989 - val_loss: 1.7317\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6867 - val_accuracy: 0.5989 - val_loss: 1.7271\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8001 - loss: 0.6867 - val_accuracy: 0.5989 - val_loss: 1.7292\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6867 - val_accuracy: 0.5989 - val_loss: 1.7313\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6866 - val_accuracy: 0.5989 - val_loss: 1.7289\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6866 - val_accuracy: 0.5989 - val_loss: 1.7323\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6865 - val_accuracy: 0.5989 - val_loss: 1.7298\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6865 - val_accuracy: 0.5990 - val_loss: 1.7281\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6864 - val_accuracy: 0.5980 - val_loss: 1.7310\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6864 - val_accuracy: 0.5991 - val_loss: 1.7305\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6864 - val_accuracy: 0.5989 - val_loss: 1.7330\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6863 - val_accuracy: 0.5969 - val_loss: 1.7334\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6863 - val_accuracy: 0.5981 - val_loss: 1.7323\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6862 - val_accuracy: 0.5990 - val_loss: 1.7303\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6862 - val_accuracy: 0.5989 - val_loss: 1.7286\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6862 - val_accuracy: 0.5978 - val_loss: 1.7329\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6861 - val_accuracy: 0.5978 - val_loss: 1.7318\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8000 - loss: 0.6861 - val_accuracy: 0.5978 - val_loss: 1.7296\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6860 - val_accuracy: 0.5978 - val_loss: 1.7318\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6860 - val_accuracy: 0.5979 - val_loss: 1.7296\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6860 - val_accuracy: 0.5978 - val_loss: 1.7341\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6859 - val_accuracy: 0.5970 - val_loss: 1.7324\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6859 - val_accuracy: 0.5971 - val_loss: 1.7339\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6858 - val_accuracy: 0.5978 - val_loss: 1.7310\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6858 - val_accuracy: 0.5979 - val_loss: 1.7313\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6858 - val_accuracy: 0.5978 - val_loss: 1.7333\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6857 - val_accuracy: 0.5979 - val_loss: 1.7338\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6857 - val_accuracy: 0.5969 - val_loss: 1.7361\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6856 - val_accuracy: 0.5978 - val_loss: 1.7307\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6856 - val_accuracy: 0.5978 - val_loss: 1.7346\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6856 - val_accuracy: 0.5977 - val_loss: 1.7353\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6855 - val_accuracy: 0.5978 - val_loss: 1.7337\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6855 - val_accuracy: 0.5969 - val_loss: 1.7351\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6854 - val_accuracy: 0.5978 - val_loss: 1.7305\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6854 - val_accuracy: 0.5971 - val_loss: 1.7335\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6854 - val_accuracy: 0.5979 - val_loss: 1.7327\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6853 - val_accuracy: 0.5978 - val_loss: 1.7324\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6853 - val_accuracy: 0.5947 - val_loss: 1.7368\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6852 - val_accuracy: 0.5978 - val_loss: 1.7325\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6852 - val_accuracy: 0.5945 - val_loss: 1.7322\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6852 - val_accuracy: 0.5948 - val_loss: 1.7298\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.6851 - val_accuracy: 0.5947 - val_loss: 1.7362\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6851 - val_accuracy: 0.5945 - val_loss: 1.7364\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.6851 - val_accuracy: 0.5977 - val_loss: 1.7341\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6850 - val_accuracy: 0.5947 - val_loss: 1.7332\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7975 - loss: 0.6850 - val_accuracy: 0.5945 - val_loss: 1.7369\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6849 - val_accuracy: 0.5937 - val_loss: 1.7378\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.6849 - val_accuracy: 0.5937 - val_loss: 1.7344\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7978 - loss: 0.6849 - val_accuracy: 0.5947 - val_loss: 1.7330\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6848 - val_accuracy: 0.5947 - val_loss: 1.7328\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7978 - loss: 0.6848 - val_accuracy: 0.5947 - val_loss: 1.7347\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6847 - val_accuracy: 0.5946 - val_loss: 1.7320\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6847 - val_accuracy: 0.5946 - val_loss: 1.7325\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.6847 - val_accuracy: 0.5936 - val_loss: 1.7404\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7982 - loss: 0.6846 - val_accuracy: 0.5946 - val_loss: 1.7374\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6846 - val_accuracy: 0.5945 - val_loss: 1.7353\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.6846 - val_accuracy: 0.5946 - val_loss: 1.7359\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7978 - loss: 0.6845 - val_accuracy: 0.5944 - val_loss: 1.7363\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.6845 - val_accuracy: 0.5947 - val_loss: 1.7376\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7982 - loss: 0.6845 - val_accuracy: 0.5936 - val_loss: 1.7404\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.6844 - val_accuracy: 0.5936 - val_loss: 1.7379\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.6844 - val_accuracy: 0.5946 - val_loss: 1.7342\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.6843 - val_accuracy: 0.5946 - val_loss: 1.7403\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6843 - val_accuracy: 0.5936 - val_loss: 1.7376\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.6843 - val_accuracy: 0.5945 - val_loss: 1.7353\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.6842 - val_accuracy: 0.5946 - val_loss: 1.7388\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.6842 - val_accuracy: 0.5946 - val_loss: 1.7363\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6842 - val_accuracy: 0.5944 - val_loss: 1.7388\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6841 - val_accuracy: 0.5937 - val_loss: 1.7402\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.6841 - val_accuracy: 0.5946 - val_loss: 1.7368\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.6841 - val_accuracy: 0.5946 - val_loss: 1.7352\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.6840 - val_accuracy: 0.5945 - val_loss: 1.7364\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.6840 - val_accuracy: 0.5936 - val_loss: 1.7438\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.6839 - val_accuracy: 0.5937 - val_loss: 1.7436\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7982 - loss: 0.6839 - val_accuracy: 0.5947 - val_loss: 1.7360\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6839 - val_accuracy: 0.5945 - val_loss: 1.7382\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6838 - val_accuracy: 0.5945 - val_loss: 1.7399\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6838 - val_accuracy: 0.5947 - val_loss: 1.7374\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6838 - val_accuracy: 0.5946 - val_loss: 1.7399\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6837 - val_accuracy: 0.5945 - val_loss: 1.7366\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6837 - val_accuracy: 0.5948 - val_loss: 1.7366\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6837 - val_accuracy: 0.5942 - val_loss: 1.7390\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.6836 - val_accuracy: 0.5944 - val_loss: 1.7392\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.6836 - val_accuracy: 0.5945 - val_loss: 1.7383\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6836 - val_accuracy: 0.5946 - val_loss: 1.7386\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6835 - val_accuracy: 0.5933 - val_loss: 1.7408\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7978 - loss: 0.6835 - val_accuracy: 0.5943 - val_loss: 1.7391\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6835 - val_accuracy: 0.5942 - val_loss: 1.7420\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.6834 - val_accuracy: 0.5948 - val_loss: 1.7392\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6834 - val_accuracy: 0.5986 - val_loss: 1.7366\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6834 - val_accuracy: 0.5949 - val_loss: 1.7357\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6833 - val_accuracy: 0.5932 - val_loss: 1.7436\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6833 - val_accuracy: 0.5985 - val_loss: 1.7411\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6833 - val_accuracy: 0.5992 - val_loss: 1.7387\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6832 - val_accuracy: 0.5990 - val_loss: 1.7393\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6832 - val_accuracy: 0.5992 - val_loss: 1.7398\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6831 - val_accuracy: 0.5991 - val_loss: 1.7378\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6831 - val_accuracy: 0.5991 - val_loss: 1.7389\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6831 - val_accuracy: 0.5977 - val_loss: 1.7460\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.6830 - val_accuracy: 0.5991 - val_loss: 1.7386\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6830 - val_accuracy: 0.5990 - val_loss: 1.7415\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6830 - val_accuracy: 0.5991 - val_loss: 1.7386\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6829 - val_accuracy: 0.5992 - val_loss: 1.7385\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6829 - val_accuracy: 0.5989 - val_loss: 1.7406\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6829 - val_accuracy: 0.5986 - val_loss: 1.7419\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6828 - val_accuracy: 0.5990 - val_loss: 1.7429\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6828 - val_accuracy: 0.5990 - val_loss: 1.7419\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.6828 - val_accuracy: 0.5990 - val_loss: 1.7394\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.6827 - val_accuracy: 0.5991 - val_loss: 1.7403\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6827 - val_accuracy: 0.5984 - val_loss: 1.7434\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6827 - val_accuracy: 0.5991 - val_loss: 1.7398\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.6826 - val_accuracy: 0.5992 - val_loss: 1.7418\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7995 - loss: 0.6826 - val_accuracy: 0.5991 - val_loss: 1.7447\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.6826 - val_accuracy: 0.5991 - val_loss: 1.7386\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6826 - val_accuracy: 0.5991 - val_loss: 1.7441\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6825 - val_accuracy: 0.5991 - val_loss: 1.7427\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6825 - val_accuracy: 0.5991 - val_loss: 1.7438\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6825 - val_accuracy: 0.5991 - val_loss: 1.7409\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6824 - val_accuracy: 0.5993 - val_loss: 1.7377\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_12, X_test_12, y_train_12, y_test_12 = train_test_split(\n    X, y, test_size=0.3, random_state=54, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_12, X_val_12, y_train_12, y_val_12 = train_test_split(\n    X_train_12, y_train_12, test_size=0.2, random_state=54, stratify=y_train_12\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_12:\", np.max(X_train_12))\nprint(\"Min value in X_train_12:\", np.min(X_train_12))\n\nX_train_12_scaled = scaler.fit_transform(X_train_12)\n\n# Get the original class distribution\nclass_counts_12 = Counter(y_train_12)\nprint(\"Original class distribution:\", class_counts_12)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_12 = class_counts_12[min(class_counts_12, key=class_counts_12.get)]\ndesired_majority_size_12 = minority_class_size_12 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_12 = {0: desired_majority_size_12, 1: minority_class_size_12}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_12 = RandomUnderSampler(sampling_strategy=sampling_strategy_12, random_state=42)\nX_resampled_12, y_resampled_12 = undersampler_12.fit_resample(X_train_12, y_train_12)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_12))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_12, y_train_resampled_12 = smote.fit_resample(X_resampled_12, y_resampled_12)\n\n\n#Verify the class distribution after SMOTE\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_12))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_12))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:42:44.738209Z","iopub.execute_input":"2025-03-07T03:42:44.738523Z","iopub.status.idle":"2025-03-07T03:43:21.384999Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_12: 2071000000.0\nMin value in X_train_12: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_12 = X_train_resampled_12.reshape(X_train_resampled_12.shape[0], 1, 56)\nX_val_12 = X_val_12.reshape(X_val_12.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_12,  # Features from CICIDS2017\n    y_train_resampled_12,  # Labels from CICIDS2017\n    validation_data=(X_val_12, y_val_12),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:43:21.386439Z","iopub.execute_input":"2025-03-07T03:43:21.386864Z","iopub.status.idle":"2025-03-07T04:25:46.005613Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7747 - loss: 0.8298 - val_accuracy: 0.6025 - val_loss: 1.8043\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.61012\n726/726 - 7s - 9ms/step - accuracy: 0.7741 - loss: 0.8224 - val_accuracy: 0.6023 - val_loss: 1.8000\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7739 - loss: 0.8174 - val_accuracy: 0.6035 - val_loss: 1.7951\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.8129 - val_accuracy: 0.6036 - val_loss: 1.7878\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.8089 - val_accuracy: 0.6041 - val_loss: 1.7852\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.8051 - val_accuracy: 0.6033 - val_loss: 1.7821\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.8016 - val_accuracy: 0.6037 - val_loss: 1.7734\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7982 - val_accuracy: 0.6040 - val_loss: 1.7685\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7730 - loss: 0.7952 - val_accuracy: 0.6037 - val_loss: 1.7657\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.7923 - val_accuracy: 0.6019 - val_loss: 1.7644\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7716 - loss: 0.7897 - val_accuracy: 0.5971 - val_loss: 1.7606\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7872 - val_accuracy: 0.5972 - val_loss: 1.7528\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7850 - val_accuracy: 0.5971 - val_loss: 1.7517\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7829 - val_accuracy: 0.5974 - val_loss: 1.7479\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7809 - val_accuracy: 0.5970 - val_loss: 1.7441\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7706 - loss: 0.7791 - val_accuracy: 0.5972 - val_loss: 1.7392\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.7774 - val_accuracy: 0.5971 - val_loss: 1.7383\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.7758 - val_accuracy: 0.5980 - val_loss: 1.7327\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7728 - loss: 0.7743 - val_accuracy: 0.6023 - val_loss: 1.7305\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7769 - loss: 0.7729 - val_accuracy: 0.6009 - val_loss: 1.7289\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7768 - loss: 0.7715 - val_accuracy: 0.6011 - val_loss: 1.7222\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7703 - val_accuracy: 0.6014 - val_loss: 1.7166\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7771 - loss: 0.7690 - val_accuracy: 0.6013 - val_loss: 1.7174\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7678 - val_accuracy: 0.6012 - val_loss: 1.7139\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7667 - val_accuracy: 0.6013 - val_loss: 1.7130\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7854 - loss: 0.7656 - val_accuracy: 0.6012 - val_loss: 1.7124\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7646 - val_accuracy: 0.6058 - val_loss: 1.7060\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7636 - val_accuracy: 0.6057 - val_loss: 1.7016\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7861 - loss: 0.7626 - val_accuracy: 0.6059 - val_loss: 1.7006\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7617 - val_accuracy: 0.6059 - val_loss: 1.7014\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7869 - loss: 0.7608 - val_accuracy: 0.6058 - val_loss: 1.6964\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7863 - loss: 0.7600 - val_accuracy: 0.6061 - val_loss: 1.6944\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7863 - loss: 0.7591 - val_accuracy: 0.6071 - val_loss: 1.6926\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7583 - val_accuracy: 0.6074 - val_loss: 1.6875\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7576 - val_accuracy: 0.6072 - val_loss: 1.6880\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7568 - val_accuracy: 0.6063 - val_loss: 1.6855\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7561 - val_accuracy: 0.6071 - val_loss: 1.6843\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7870 - loss: 0.7554 - val_accuracy: 0.6071 - val_loss: 1.6835\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7869 - loss: 0.7548 - val_accuracy: 0.6077 - val_loss: 1.6796\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7541 - val_accuracy: 0.6077 - val_loss: 1.6826\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7535 - val_accuracy: 0.6077 - val_loss: 1.6815\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7871 - loss: 0.7529 - val_accuracy: 0.6077 - val_loss: 1.6793\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7864 - loss: 0.7523 - val_accuracy: 0.6077 - val_loss: 1.6757\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7517 - val_accuracy: 0.6079 - val_loss: 1.6757\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7512 - val_accuracy: 0.6036 - val_loss: 1.6760\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7507 - val_accuracy: 0.6036 - val_loss: 1.6735\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7501 - val_accuracy: 0.6035 - val_loss: 1.6720\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7496 - val_accuracy: 0.6034 - val_loss: 1.6730\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7491 - val_accuracy: 0.6032 - val_loss: 1.6702\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7487 - val_accuracy: 0.6032 - val_loss: 1.6693\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7482 - val_accuracy: 0.6032 - val_loss: 1.6685\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7478 - val_accuracy: 0.6033 - val_loss: 1.6679\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7473 - val_accuracy: 0.6033 - val_loss: 1.6686\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7469 - val_accuracy: 0.6032 - val_loss: 1.6688\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7465 - val_accuracy: 0.6033 - val_loss: 1.6653\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7461 - val_accuracy: 0.6032 - val_loss: 1.6665\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7457 - val_accuracy: 0.6032 - val_loss: 1.6664\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7453 - val_accuracy: 0.6032 - val_loss: 1.6641\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7449 - val_accuracy: 0.6034 - val_loss: 1.6639\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7446 - val_accuracy: 0.6034 - val_loss: 1.6630\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7442 - val_accuracy: 0.6034 - val_loss: 1.6635\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7439 - val_accuracy: 0.6067 - val_loss: 1.6605\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7910 - loss: 0.7435 - val_accuracy: 0.6062 - val_loss: 1.6641\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7929 - loss: 0.7432 - val_accuracy: 0.6065 - val_loss: 1.6604\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7930 - loss: 0.7429 - val_accuracy: 0.6067 - val_loss: 1.6560\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7934 - loss: 0.7425 - val_accuracy: 0.6062 - val_loss: 1.6565\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7934 - loss: 0.7422 - val_accuracy: 0.6064 - val_loss: 1.6551\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7419 - val_accuracy: 0.6062 - val_loss: 1.6556\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7930 - loss: 0.7416 - val_accuracy: 0.6062 - val_loss: 1.6554\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7414 - val_accuracy: 0.6061 - val_loss: 1.6577\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7411 - val_accuracy: 0.6066 - val_loss: 1.6597\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7408 - val_accuracy: 0.6066 - val_loss: 1.6557\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7405 - val_accuracy: 0.6066 - val_loss: 1.6542\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7403 - val_accuracy: 0.6066 - val_loss: 1.6530\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7400 - val_accuracy: 0.6067 - val_loss: 1.6536\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7398 - val_accuracy: 0.6067 - val_loss: 1.6552\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7395 - val_accuracy: 0.6065 - val_loss: 1.6519\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7935 - loss: 0.7393 - val_accuracy: 0.6065 - val_loss: 1.6524\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7936 - loss: 0.7390 - val_accuracy: 0.6065 - val_loss: 1.6552\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7936 - loss: 0.7388 - val_accuracy: 0.6067 - val_loss: 1.6553\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7936 - loss: 0.7386 - val_accuracy: 0.6067 - val_loss: 1.6531\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7936 - loss: 0.7383 - val_accuracy: 0.6067 - val_loss: 1.6506\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7937 - loss: 0.7381 - val_accuracy: 0.6066 - val_loss: 1.6491\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7379 - val_accuracy: 0.6066 - val_loss: 1.6537\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7377 - val_accuracy: 0.6066 - val_loss: 1.6493\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7375 - val_accuracy: 0.6067 - val_loss: 1.6500\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7373 - val_accuracy: 0.6067 - val_loss: 1.6515\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7371 - val_accuracy: 0.6066 - val_loss: 1.6518\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7369 - val_accuracy: 0.6066 - val_loss: 1.6519\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7367 - val_accuracy: 0.6067 - val_loss: 1.6501\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7365 - val_accuracy: 0.6066 - val_loss: 1.6477\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7363 - val_accuracy: 0.6066 - val_loss: 1.6505\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7361 - val_accuracy: 0.6066 - val_loss: 1.6481\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7359 - val_accuracy: 0.6065 - val_loss: 1.6482\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7358 - val_accuracy: 0.6066 - val_loss: 1.6517\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7937 - loss: 0.7356 - val_accuracy: 0.6065 - val_loss: 1.6498\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7354 - val_accuracy: 0.6065 - val_loss: 1.6508\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7352 - val_accuracy: 0.6066 - val_loss: 1.6475\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7940 - loss: 0.7351 - val_accuracy: 0.6066 - val_loss: 1.6473\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7349 - val_accuracy: 0.6066 - val_loss: 1.6460\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7347 - val_accuracy: 0.6065 - val_loss: 1.6513\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7346 - val_accuracy: 0.6065 - val_loss: 1.6502\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7941 - loss: 0.7344 - val_accuracy: 0.6065 - val_loss: 1.6472\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7343 - val_accuracy: 0.6066 - val_loss: 1.6480\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7341 - val_accuracy: 0.6065 - val_loss: 1.6497\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7340 - val_accuracy: 0.6066 - val_loss: 1.6465\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7338 - val_accuracy: 0.6066 - val_loss: 1.6467\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7337 - val_accuracy: 0.6065 - val_loss: 1.6463\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7335 - val_accuracy: 0.6065 - val_loss: 1.6517\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7334 - val_accuracy: 0.6065 - val_loss: 1.6435\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7332 - val_accuracy: 0.6065 - val_loss: 1.6463\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7331 - val_accuracy: 0.6065 - val_loss: 1.6448\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7329 - val_accuracy: 0.6064 - val_loss: 1.6511\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7942 - loss: 0.7328 - val_accuracy: 0.6066 - val_loss: 1.6433\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7327 - val_accuracy: 0.6066 - val_loss: 1.6424\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7325 - val_accuracy: 0.6064 - val_loss: 1.6469\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7324 - val_accuracy: 0.6065 - val_loss: 1.6452\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7323 - val_accuracy: 0.6064 - val_loss: 1.6482\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7321 - val_accuracy: 0.6065 - val_loss: 1.6430\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7320 - val_accuracy: 0.6064 - val_loss: 1.6475\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7319 - val_accuracy: 0.6064 - val_loss: 1.6498\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7318 - val_accuracy: 0.6064 - val_loss: 1.6440\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7316 - val_accuracy: 0.6063 - val_loss: 1.6453\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7315 - val_accuracy: 0.6063 - val_loss: 1.6465\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7314 - val_accuracy: 0.6064 - val_loss: 1.6435\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7313 - val_accuracy: 0.6063 - val_loss: 1.6463\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7312 - val_accuracy: 0.6063 - val_loss: 1.6452\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7310 - val_accuracy: 0.6063 - val_loss: 1.6392\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7309 - val_accuracy: 0.6063 - val_loss: 1.6462\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7308 - val_accuracy: 0.6063 - val_loss: 1.6454\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7307 - val_accuracy: 0.6063 - val_loss: 1.6470\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7306 - val_accuracy: 0.6063 - val_loss: 1.6425\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7305 - val_accuracy: 0.6065 - val_loss: 1.6429\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7303 - val_accuracy: 0.6063 - val_loss: 1.6449\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7302 - val_accuracy: 0.6063 - val_loss: 1.6441\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7301 - val_accuracy: 0.6065 - val_loss: 1.6406\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7300 - val_accuracy: 0.6065 - val_loss: 1.6396\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7299 - val_accuracy: 0.6065 - val_loss: 1.6422\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7298 - val_accuracy: 0.6063 - val_loss: 1.6448\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7297 - val_accuracy: 0.6065 - val_loss: 1.6438\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7296 - val_accuracy: 0.6063 - val_loss: 1.6480\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7295 - val_accuracy: 0.6066 - val_loss: 1.6398\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7294 - val_accuracy: 0.6064 - val_loss: 1.6458\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7293 - val_accuracy: 0.6065 - val_loss: 1.6437\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7292 - val_accuracy: 0.6068 - val_loss: 1.6404\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7922 - loss: 0.7291 - val_accuracy: 0.6066 - val_loss: 1.6434\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7290 - val_accuracy: 0.6066 - val_loss: 1.6441\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7289 - val_accuracy: 0.6066 - val_loss: 1.6427\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7288 - val_accuracy: 0.6071 - val_loss: 1.6420\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7287 - val_accuracy: 0.6066 - val_loss: 1.6434\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7911 - loss: 0.7286 - val_accuracy: 0.6070 - val_loss: 1.6420\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7930 - loss: 0.7285 - val_accuracy: 0.6071 - val_loss: 1.6413\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7284 - val_accuracy: 0.6070 - val_loss: 1.6449\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7283 - val_accuracy: 0.6070 - val_loss: 1.6460\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7282 - val_accuracy: 0.6070 - val_loss: 1.6425\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7281 - val_accuracy: 0.6071 - val_loss: 1.6398\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7280 - val_accuracy: 0.6071 - val_loss: 1.6407\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7279 - val_accuracy: 0.6070 - val_loss: 1.6436\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7278 - val_accuracy: 0.6070 - val_loss: 1.6493\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7277 - val_accuracy: 0.6070 - val_loss: 1.6438\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7276 - val_accuracy: 0.6070 - val_loss: 1.6470\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7276 - val_accuracy: 0.6070 - val_loss: 1.6438\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7275 - val_accuracy: 0.6070 - val_loss: 1.6446\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7274 - val_accuracy: 0.6070 - val_loss: 1.6438\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7273 - val_accuracy: 0.6070 - val_loss: 1.6427\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7272 - val_accuracy: 0.6070 - val_loss: 1.6434\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7271 - val_accuracy: 0.6070 - val_loss: 1.6425\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7270 - val_accuracy: 0.6070 - val_loss: 1.6419\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7269 - val_accuracy: 0.6070 - val_loss: 1.6446\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7269 - val_accuracy: 0.6070 - val_loss: 1.6466\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7268 - val_accuracy: 0.6070 - val_loss: 1.6436\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7267 - val_accuracy: 0.6070 - val_loss: 1.6412\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7266 - val_accuracy: 0.6070 - val_loss: 1.6434\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7265 - val_accuracy: 0.6072 - val_loss: 1.6409\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7264 - val_accuracy: 0.6070 - val_loss: 1.6432\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7264 - val_accuracy: 0.6070 - val_loss: 1.6408\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7263 - val_accuracy: 0.6070 - val_loss: 1.6400\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7262 - val_accuracy: 0.6072 - val_loss: 1.6432\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7261 - val_accuracy: 0.6072 - val_loss: 1.6433\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7260 - val_accuracy: 0.6072 - val_loss: 1.6460\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7260 - val_accuracy: 0.6075 - val_loss: 1.6408\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7259 - val_accuracy: 0.6072 - val_loss: 1.6473\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7258 - val_accuracy: 0.6075 - val_loss: 1.6431\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7257 - val_accuracy: 0.6075 - val_loss: 1.6455\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7256 - val_accuracy: 0.6078 - val_loss: 1.6423\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7256 - val_accuracy: 0.6075 - val_loss: 1.6470\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7255 - val_accuracy: 0.6077 - val_loss: 1.6430\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7254 - val_accuracy: 0.6075 - val_loss: 1.6450\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7253 - val_accuracy: 0.6075 - val_loss: 1.6480\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7253 - val_accuracy: 0.6075 - val_loss: 1.6430\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7252 - val_accuracy: 0.6075 - val_loss: 1.6456\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7251 - val_accuracy: 0.6077 - val_loss: 1.6414\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7250 - val_accuracy: 0.6075 - val_loss: 1.6429\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7250 - val_accuracy: 0.6064 - val_loss: 1.6454\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7249 - val_accuracy: 0.6066 - val_loss: 1.6442\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7248 - val_accuracy: 0.6066 - val_loss: 1.6458\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7247 - val_accuracy: 0.6064 - val_loss: 1.6476\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7247 - val_accuracy: 0.6077 - val_loss: 1.6438\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7246 - val_accuracy: 0.6077 - val_loss: 1.6409\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7245 - val_accuracy: 0.6066 - val_loss: 1.6463\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7244 - val_accuracy: 0.6064 - val_loss: 1.6449\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7244 - val_accuracy: 0.6066 - val_loss: 1.6472\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7243 - val_accuracy: 0.6067 - val_loss: 1.6409\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7242 - val_accuracy: 0.6066 - val_loss: 1.6440\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7242 - val_accuracy: 0.6066 - val_loss: 1.6424\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7241 - val_accuracy: 0.6066 - val_loss: 1.6437\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7240 - val_accuracy: 0.6066 - val_loss: 1.6427\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7239 - val_accuracy: 0.6066 - val_loss: 1.6426\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7239 - val_accuracy: 0.6066 - val_loss: 1.6407\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7238 - val_accuracy: 0.6066 - val_loss: 1.6413\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7237 - val_accuracy: 0.6067 - val_loss: 1.6453\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7237 - val_accuracy: 0.6066 - val_loss: 1.6447\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7236 - val_accuracy: 0.6066 - val_loss: 1.6476\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7235 - val_accuracy: 0.6066 - val_loss: 1.6429\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7877 - loss: 0.7235 - val_accuracy: 0.6066 - val_loss: 1.6413\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7234 - val_accuracy: 0.6066 - val_loss: 1.6442\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7233 - val_accuracy: 0.6067 - val_loss: 1.6423\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7233 - val_accuracy: 0.6066 - val_loss: 1.6453\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7232 - val_accuracy: 0.6066 - val_loss: 1.6460\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7231 - val_accuracy: 0.6069 - val_loss: 1.6442\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7231 - val_accuracy: 0.6067 - val_loss: 1.6439\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7230 - val_accuracy: 0.6067 - val_loss: 1.6440\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7229 - val_accuracy: 0.6067 - val_loss: 1.6442\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7229 - val_accuracy: 0.6067 - val_loss: 1.6466\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7228 - val_accuracy: 0.6067 - val_loss: 1.6447\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7227 - val_accuracy: 0.6068 - val_loss: 1.6431\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7227 - val_accuracy: 0.6067 - val_loss: 1.6437\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7226 - val_accuracy: 0.6069 - val_loss: 1.6453\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7225 - val_accuracy: 0.6069 - val_loss: 1.6461\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7225 - val_accuracy: 0.6069 - val_loss: 1.6439\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7224 - val_accuracy: 0.6067 - val_loss: 1.6450\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7223 - val_accuracy: 0.6067 - val_loss: 1.6459\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7223 - val_accuracy: 0.6067 - val_loss: 1.6447\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7222 - val_accuracy: 0.6067 - val_loss: 1.6446\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7222 - val_accuracy: 0.6067 - val_loss: 1.6453\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7221 - val_accuracy: 0.6067 - val_loss: 1.6455\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7220 - val_accuracy: 0.6068 - val_loss: 1.6460\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7220 - val_accuracy: 0.6068 - val_loss: 1.6448\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7219 - val_accuracy: 0.6069 - val_loss: 1.6444\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7218 - val_accuracy: 0.6068 - val_loss: 1.6447\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7218 - val_accuracy: 0.6069 - val_loss: 1.6422\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7217 - val_accuracy: 0.6068 - val_loss: 1.6422\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7217 - val_accuracy: 0.6066 - val_loss: 1.6463\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7216 - val_accuracy: 0.6067 - val_loss: 1.6474\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7215 - val_accuracy: 0.6068 - val_loss: 1.6475\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7215 - val_accuracy: 0.6069 - val_loss: 1.6440\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7214 - val_accuracy: 0.6068 - val_loss: 1.6457\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7214 - val_accuracy: 0.6066 - val_loss: 1.6471\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7213 - val_accuracy: 0.6066 - val_loss: 1.6456\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7212 - val_accuracy: 0.6066 - val_loss: 1.6452\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7212 - val_accuracy: 0.6066 - val_loss: 1.6456\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7211 - val_accuracy: 0.6066 - val_loss: 1.6465\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7211 - val_accuracy: 0.6066 - val_loss: 1.6487\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7210 - val_accuracy: 0.6067 - val_loss: 1.6464\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7210 - val_accuracy: 0.6066 - val_loss: 1.6444\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7209 - val_accuracy: 0.6066 - val_loss: 1.6426\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7208 - val_accuracy: 0.6066 - val_loss: 1.6475\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7208 - val_accuracy: 0.6067 - val_loss: 1.6468\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7207 - val_accuracy: 0.6068 - val_loss: 1.6453\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7207 - val_accuracy: 0.6068 - val_loss: 1.6475\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7206 - val_accuracy: 0.6066 - val_loss: 1.6491\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7206 - val_accuracy: 0.6067 - val_loss: 1.6450\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7205 - val_accuracy: 0.6066 - val_loss: 1.6474\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7204 - val_accuracy: 0.6068 - val_loss: 1.6452\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7204 - val_accuracy: 0.6066 - val_loss: 1.6486\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7203 - val_accuracy: 0.6067 - val_loss: 1.6490\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7203 - val_accuracy: 0.6066 - val_loss: 1.6470\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7202 - val_accuracy: 0.6066 - val_loss: 1.6473\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7202 - val_accuracy: 0.6068 - val_loss: 1.6487\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7201 - val_accuracy: 0.6068 - val_loss: 1.6462\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7200 - val_accuracy: 0.6066 - val_loss: 1.6477\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7200 - val_accuracy: 0.6068 - val_loss: 1.6482\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7199 - val_accuracy: 0.6066 - val_loss: 1.6469\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7199 - val_accuracy: 0.6067 - val_loss: 1.6527\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7198 - val_accuracy: 0.6066 - val_loss: 1.6481\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7198 - val_accuracy: 0.6066 - val_loss: 1.6476\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7197 - val_accuracy: 0.6067 - val_loss: 1.6448\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7197 - val_accuracy: 0.6068 - val_loss: 1.6486\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7196 - val_accuracy: 0.6065 - val_loss: 1.6487\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7196 - val_accuracy: 0.6065 - val_loss: 1.6489\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7195 - val_accuracy: 0.6068 - val_loss: 1.6478\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7195 - val_accuracy: 0.6068 - val_loss: 1.6437\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7194 - val_accuracy: 0.6066 - val_loss: 1.6448\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7193 - val_accuracy: 0.6066 - val_loss: 1.6475\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7193 - val_accuracy: 0.6066 - val_loss: 1.6519\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7192 - val_accuracy: 0.6067 - val_loss: 1.6498\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7192 - val_accuracy: 0.6068 - val_loss: 1.6444\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7191 - val_accuracy: 0.6068 - val_loss: 1.6515\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7899 - loss: 0.7191 - val_accuracy: 0.6066 - val_loss: 1.6471\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7190 - val_accuracy: 0.6068 - val_loss: 1.6467\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7190 - val_accuracy: 0.6068 - val_loss: 1.6493\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7189 - val_accuracy: 0.6068 - val_loss: 1.6469\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7189 - val_accuracy: 0.6067 - val_loss: 1.6478\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7188 - val_accuracy: 0.6068 - val_loss: 1.6498\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7188 - val_accuracy: 0.6068 - val_loss: 1.6469\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7187 - val_accuracy: 0.6068 - val_loss: 1.6448\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7187 - val_accuracy: 0.6068 - val_loss: 1.6474\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7186 - val_accuracy: 0.6067 - val_loss: 1.6526\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7186 - val_accuracy: 0.6067 - val_loss: 1.6493\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7185 - val_accuracy: 0.6068 - val_loss: 1.6470\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7185 - val_accuracy: 0.6067 - val_loss: 1.6499\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7184 - val_accuracy: 0.6066 - val_loss: 1.6495\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7184 - val_accuracy: 0.6066 - val_loss: 1.6507\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7183 - val_accuracy: 0.6067 - val_loss: 1.6505\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7183 - val_accuracy: 0.6067 - val_loss: 1.6504\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7182 - val_accuracy: 0.6067 - val_loss: 1.6477\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7182 - val_accuracy: 0.6066 - val_loss: 1.6503\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7181 - val_accuracy: 0.6067 - val_loss: 1.6491\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7181 - val_accuracy: 0.6066 - val_loss: 1.6500\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7180 - val_accuracy: 0.6067 - val_loss: 1.6480\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7180 - val_accuracy: 0.6067 - val_loss: 1.6481\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7179 - val_accuracy: 0.6067 - val_loss: 1.6505\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7179 - val_accuracy: 0.6066 - val_loss: 1.6479\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7178 - val_accuracy: 0.6067 - val_loss: 1.6511\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7178 - val_accuracy: 0.6067 - val_loss: 1.6476\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7177 - val_accuracy: 0.6065 - val_loss: 1.6513\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7177 - val_accuracy: 0.6067 - val_loss: 1.6431\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7176 - val_accuracy: 0.6067 - val_loss: 1.6485\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7176 - val_accuracy: 0.6066 - val_loss: 1.6520\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7175 - val_accuracy: 0.6067 - val_loss: 1.6489\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7899 - loss: 0.7175 - val_accuracy: 0.6066 - val_loss: 1.6495\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7174 - val_accuracy: 0.6067 - val_loss: 1.6515\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7174 - val_accuracy: 0.6067 - val_loss: 1.6506\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7173 - val_accuracy: 0.6067 - val_loss: 1.6479\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7173 - val_accuracy: 0.6067 - val_loss: 1.6480\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7173 - val_accuracy: 0.6067 - val_loss: 1.6474\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7172 - val_accuracy: 0.6054 - val_loss: 1.6510\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7172 - val_accuracy: 0.6067 - val_loss: 1.6495\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7171 - val_accuracy: 0.6067 - val_loss: 1.6499\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7171 - val_accuracy: 0.6067 - val_loss: 1.6507\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7170 - val_accuracy: 0.6067 - val_loss: 1.6491\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7899 - loss: 0.7170 - val_accuracy: 0.6054 - val_loss: 1.6508\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7169 - val_accuracy: 0.6067 - val_loss: 1.6509\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7169 - val_accuracy: 0.6067 - val_loss: 1.6495\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7900 - loss: 0.7168 - val_accuracy: 0.6056 - val_loss: 1.6485\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7168 - val_accuracy: 0.6048 - val_loss: 1.6497\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7167 - val_accuracy: 0.6056 - val_loss: 1.6508\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7167 - val_accuracy: 0.6067 - val_loss: 1.6490\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7166 - val_accuracy: 0.6054 - val_loss: 1.6504\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7902 - loss: 0.7166 - val_accuracy: 0.6054 - val_loss: 1.6466\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7166 - val_accuracy: 0.6056 - val_loss: 1.6528\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7165 - val_accuracy: 0.6056 - val_loss: 1.6520\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7165 - val_accuracy: 0.6057 - val_loss: 1.6504\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7164 - val_accuracy: 0.6046 - val_loss: 1.6516\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7164 - val_accuracy: 0.6078 - val_loss: 1.6491\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7163 - val_accuracy: 0.6065 - val_loss: 1.6491\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7163 - val_accuracy: 0.6066 - val_loss: 1.6520\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7900 - loss: 0.7162 - val_accuracy: 0.6065 - val_loss: 1.6511\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7162 - val_accuracy: 0.6066 - val_loss: 1.6510\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7161 - val_accuracy: 0.6058 - val_loss: 1.6507\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7902 - loss: 0.7161 - val_accuracy: 0.6056 - val_loss: 1.6550\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7161 - val_accuracy: 0.6058 - val_loss: 1.6481\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7160 - val_accuracy: 0.6056 - val_loss: 1.6493\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7900 - loss: 0.7160 - val_accuracy: 0.6056 - val_loss: 1.6509\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7159 - val_accuracy: 0.6056 - val_loss: 1.6526\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7159 - val_accuracy: 0.6058 - val_loss: 1.6510\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7158 - val_accuracy: 0.6056 - val_loss: 1.6505\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7158 - val_accuracy: 0.6058 - val_loss: 1.6481\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7904 - loss: 0.7158 - val_accuracy: 0.6060 - val_loss: 1.6511\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7894 - loss: 0.7157 - val_accuracy: 0.6063 - val_loss: 1.6498\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7157 - val_accuracy: 0.6063 - val_loss: 1.6518\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7156 - val_accuracy: 0.6063 - val_loss: 1.6486\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7156 - val_accuracy: 0.6061 - val_loss: 1.6540\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7155 - val_accuracy: 0.6063 - val_loss: 1.6485\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7903 - loss: 0.7155 - val_accuracy: 0.6061 - val_loss: 1.6535\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7155 - val_accuracy: 0.6063 - val_loss: 1.6490\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7902 - loss: 0.7154 - val_accuracy: 0.6063 - val_loss: 1.6500\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7154 - val_accuracy: 0.6063 - val_loss: 1.6497\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7153 - val_accuracy: 0.6063 - val_loss: 1.6522\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7153 - val_accuracy: 0.6063 - val_loss: 1.6526\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7903 - loss: 0.7152 - val_accuracy: 0.6063 - val_loss: 1.6521\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7152 - val_accuracy: 0.6063 - val_loss: 1.6506\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7152 - val_accuracy: 0.6061 - val_loss: 1.6536\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7151 - val_accuracy: 0.6062 - val_loss: 1.6526\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7904 - loss: 0.7151 - val_accuracy: 0.6061 - val_loss: 1.6507\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7150 - val_accuracy: 0.6060 - val_loss: 1.6572\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7150 - val_accuracy: 0.6063 - val_loss: 1.6511\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7149 - val_accuracy: 0.6062 - val_loss: 1.6510\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7149 - val_accuracy: 0.6063 - val_loss: 1.6506\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7906 - loss: 0.7149 - val_accuracy: 0.6061 - val_loss: 1.6525\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7148 - val_accuracy: 0.6062 - val_loss: 1.6526\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7148 - val_accuracy: 0.6061 - val_loss: 1.6505\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7147 - val_accuracy: 0.6062 - val_loss: 1.6520\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7903 - loss: 0.7147 - val_accuracy: 0.6060 - val_loss: 1.6532\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7147 - val_accuracy: 0.6060 - val_loss: 1.6534\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7146 - val_accuracy: 0.6062 - val_loss: 1.6546\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7907 - loss: 0.7146 - val_accuracy: 0.6062 - val_loss: 1.6501\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7902 - loss: 0.7145 - val_accuracy: 0.6062 - val_loss: 1.6527\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7905 - loss: 0.7145 - val_accuracy: 0.6061 - val_loss: 1.6530\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7144 - val_accuracy: 0.6060 - val_loss: 1.6508\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7901 - loss: 0.7144 - val_accuracy: 0.6060 - val_loss: 1.6548\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7902 - loss: 0.7144 - val_accuracy: 0.6062 - val_loss: 1.6573\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7906 - loss: 0.7143 - val_accuracy: 0.6060 - val_loss: 1.6546\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7143 - val_accuracy: 0.6062 - val_loss: 1.6551\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7906 - loss: 0.7142 - val_accuracy: 0.6060 - val_loss: 1.6577\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7895 - loss: 0.7142 - val_accuracy: 0.6062 - val_loss: 1.6556\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7142 - val_accuracy: 0.6062 - val_loss: 1.6513\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7141 - val_accuracy: 0.6062 - val_loss: 1.6544\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7141 - val_accuracy: 0.6060 - val_loss: 1.6499\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7140 - val_accuracy: 0.6062 - val_loss: 1.6501\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7140 - val_accuracy: 0.6060 - val_loss: 1.6547\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7140 - val_accuracy: 0.6060 - val_loss: 1.6504\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7139 - val_accuracy: 0.6059 - val_loss: 1.6585\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7139 - val_accuracy: 0.6060 - val_loss: 1.6512\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7138 - val_accuracy: 0.6061 - val_loss: 1.6517\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7138 - val_accuracy: 0.6062 - val_loss: 1.6545\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7138 - val_accuracy: 0.6062 - val_loss: 1.6521\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7137 - val_accuracy: 0.6061 - val_loss: 1.6544\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7137 - val_accuracy: 0.6062 - val_loss: 1.6539\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7136 - val_accuracy: 0.6059 - val_loss: 1.6566\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7136 - val_accuracy: 0.6061 - val_loss: 1.6535\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7889 - loss: 0.7136 - val_accuracy: 0.6062 - val_loss: 1.6520\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7135 - val_accuracy: 0.6060 - val_loss: 1.6557\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7135 - val_accuracy: 0.6061 - val_loss: 1.6529\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7134 - val_accuracy: 0.6059 - val_loss: 1.6562\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7134 - val_accuracy: 0.6060 - val_loss: 1.6558\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7134 - val_accuracy: 0.6061 - val_loss: 1.6504\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7133 - val_accuracy: 0.6061 - val_loss: 1.6579\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7892 - loss: 0.7133 - val_accuracy: 0.6062 - val_loss: 1.6571\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7133 - val_accuracy: 0.6061 - val_loss: 1.6575\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7132 - val_accuracy: 0.6059 - val_loss: 1.6549\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7132 - val_accuracy: 0.6062 - val_loss: 1.6519\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.7131 - val_accuracy: 0.6059 - val_loss: 1.6559\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7131 - val_accuracy: 0.6059 - val_loss: 1.6544\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7131 - val_accuracy: 0.6062 - val_loss: 1.6503\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7130 - val_accuracy: 0.6059 - val_loss: 1.6573\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7130 - val_accuracy: 0.6061 - val_loss: 1.6566\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7130 - val_accuracy: 0.6059 - val_loss: 1.6566\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7885 - loss: 0.7129 - val_accuracy: 0.6062 - val_loss: 1.6515\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7129 - val_accuracy: 0.6059 - val_loss: 1.6545\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7128 - val_accuracy: 0.6061 - val_loss: 1.6583\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7128 - val_accuracy: 0.6062 - val_loss: 1.6482\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7884 - loss: 0.7128 - val_accuracy: 0.6059 - val_loss: 1.6562\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7885 - loss: 0.7127 - val_accuracy: 0.6059 - val_loss: 1.6550\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7127 - val_accuracy: 0.6061 - val_loss: 1.6546\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7127 - val_accuracy: 0.6059 - val_loss: 1.6569\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7126 - val_accuracy: 0.6059 - val_loss: 1.6612\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7126 - val_accuracy: 0.6062 - val_loss: 1.6527\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7125 - val_accuracy: 0.6059 - val_loss: 1.6527\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7125 - val_accuracy: 0.6059 - val_loss: 1.6578\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7125 - val_accuracy: 0.6062 - val_loss: 1.6534\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7124 - val_accuracy: 0.6059 - val_loss: 1.6568\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7124 - val_accuracy: 0.6062 - val_loss: 1.6531\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7124 - val_accuracy: 0.6062 - val_loss: 1.6541\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7123 - val_accuracy: 0.6059 - val_loss: 1.6600\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7123 - val_accuracy: 0.6061 - val_loss: 1.6548\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7883 - loss: 0.7123 - val_accuracy: 0.6062 - val_loss: 1.6551\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7122 - val_accuracy: 0.6061 - val_loss: 1.6553\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7122 - val_accuracy: 0.6062 - val_loss: 1.6547\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7121 - val_accuracy: 0.6059 - val_loss: 1.6560\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7121 - val_accuracy: 0.6058 - val_loss: 1.6587\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7121 - val_accuracy: 0.6061 - val_loss: 1.6573\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7120 - val_accuracy: 0.6061 - val_loss: 1.6563\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7120 - val_accuracy: 0.6058 - val_loss: 1.6574\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7120 - val_accuracy: 0.6062 - val_loss: 1.6549\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7119 - val_accuracy: 0.6062 - val_loss: 1.6536\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7119 - val_accuracy: 0.6062 - val_loss: 1.6551\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7119 - val_accuracy: 0.6058 - val_loss: 1.6583\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7118 - val_accuracy: 0.6058 - val_loss: 1.6560\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7118 - val_accuracy: 0.6058 - val_loss: 1.6596\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7118 - val_accuracy: 0.6058 - val_loss: 1.6567\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7117 - val_accuracy: 0.6058 - val_loss: 1.6551\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7117 - val_accuracy: 0.6058 - val_loss: 1.6565\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7116 - val_accuracy: 0.6058 - val_loss: 1.6542\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7116 - val_accuracy: 0.6058 - val_loss: 1.6548\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7116 - val_accuracy: 0.6058 - val_loss: 1.6538\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7115 - val_accuracy: 0.6058 - val_loss: 1.6579\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7115 - val_accuracy: 0.6058 - val_loss: 1.6531\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7115 - val_accuracy: 0.6058 - val_loss: 1.6549\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7114 - val_accuracy: 0.6058 - val_loss: 1.6593\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7114 - val_accuracy: 0.6058 - val_loss: 1.6551\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7114 - val_accuracy: 0.6058 - val_loss: 1.6558\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7113 - val_accuracy: 0.6058 - val_loss: 1.6572\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7113 - val_accuracy: 0.6058 - val_loss: 1.6577\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7113 - val_accuracy: 0.6058 - val_loss: 1.6571\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7112 - val_accuracy: 0.6058 - val_loss: 1.6548\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7112 - val_accuracy: 0.6058 - val_loss: 1.6565\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7112 - val_accuracy: 0.6058 - val_loss: 1.6579\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7111 - val_accuracy: 0.6058 - val_loss: 1.6578\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7111 - val_accuracy: 0.6057 - val_loss: 1.6615\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7111 - val_accuracy: 0.6058 - val_loss: 1.6548\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7110 - val_accuracy: 0.6058 - val_loss: 1.6607\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7110 - val_accuracy: 0.6058 - val_loss: 1.6561\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7110 - val_accuracy: 0.6058 - val_loss: 1.6582\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7882 - loss: 0.7109 - val_accuracy: 0.6056 - val_loss: 1.6636\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7109 - val_accuracy: 0.6058 - val_loss: 1.6580\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7109 - val_accuracy: 0.6058 - val_loss: 1.6565\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7108 - val_accuracy: 0.6057 - val_loss: 1.6588\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7108 - val_accuracy: 0.6057 - val_loss: 1.6558\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7108 - val_accuracy: 0.6057 - val_loss: 1.6553\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7107 - val_accuracy: 0.6057 - val_loss: 1.6593\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7107 - val_accuracy: 0.6057 - val_loss: 1.6594\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7106 - val_accuracy: 0.6058 - val_loss: 1.6559\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7106 - val_accuracy: 0.6057 - val_loss: 1.6565\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7106 - val_accuracy: 0.6056 - val_loss: 1.6597\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7105 - val_accuracy: 0.6059 - val_loss: 1.6560\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7105 - val_accuracy: 0.6057 - val_loss: 1.6587\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7105 - val_accuracy: 0.6057 - val_loss: 1.6580\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7105 - val_accuracy: 0.6056 - val_loss: 1.6641\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7104 - val_accuracy: 0.6057 - val_loss: 1.6602\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_13, X_test_13, y_train_13, y_test_13 = train_test_split(\n    X, y, test_size=0.3, random_state=55, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_13, X_val_13, y_train_13, y_val_13 = train_test_split(\n    X_train_13, y_train_13, test_size=0.2, random_state=55, stratify=y_train_13\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_13:\", np.max(X_train_13))\nprint(\"Min value in X_train_13:\", np.min(X_train_13))\n\nX_train_13_scaled = scaler.fit_transform(X_train_13)\n\n# Get the original class distribution\nclass_counts_13 = Counter(y_train_13)\nprint(\"Original class distribution:\", class_counts_13)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_13 = class_counts_13[min(class_counts_13, key=class_counts_13.get)]\ndesired_majority_size_13 = minority_class_size_13 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_13 = {0: desired_majority_size_13, 1: minority_class_size_13}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_13 = RandomUnderSampler(sampling_strategy=sampling_strategy_13, random_state=42)\nX_resampled_13, y_resampled_13 = undersampler_13.fit_resample(X_train_13, y_train_13)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_13))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_13, y_train_resampled_13 = smote.fit_resample(X_resampled_13, y_resampled_13)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_13))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_13))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T04:25:46.007705Z","iopub.execute_input":"2025-03-07T04:25:46.008179Z","iopub.status.idle":"2025-03-07T04:26:23.074935Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_13: 2071000000.0\nMin value in X_train_13: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_13 = X_train_resampled_13.reshape(X_train_resampled_13.shape[0], 1, 56)\nX_val_13 = X_val_13.reshape(X_val_13.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_13,  # Features from CICIDS2017\n    y_train_resampled_13,  # Labels from CICIDS2017\n    validation_data=(X_val_13, y_val_13),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T04:26:23.075833Z","iopub.execute_input":"2025-03-07T04:26:23.076136Z","iopub.status.idle":"2025-03-07T05:09:53.886183Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.8193 - val_accuracy: 0.6043 - val_loss: 1.6614\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.8171 - val_accuracy: 0.6032 - val_loss: 1.6647\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7671 - loss: 0.8158 - val_accuracy: 0.6034 - val_loss: 1.6656\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7672 - loss: 0.8147 - val_accuracy: 0.6034 - val_loss: 1.6681\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7672 - loss: 0.8137 - val_accuracy: 0.6034 - val_loss: 1.6661\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.8129 - val_accuracy: 0.6034 - val_loss: 1.6706\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7686 - loss: 0.8120 - val_accuracy: 0.6027 - val_loss: 1.6752\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7692 - loss: 0.8113 - val_accuracy: 0.6040 - val_loss: 1.6726\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7696 - loss: 0.8105 - val_accuracy: 0.6040 - val_loss: 1.6759\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.8098 - val_accuracy: 0.6040 - val_loss: 1.6799\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.8091 - val_accuracy: 0.6053 - val_loss: 1.6757\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.8085 - val_accuracy: 0.6053 - val_loss: 1.6760\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.8079 - val_accuracy: 0.6052 - val_loss: 1.6781\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7711 - loss: 0.8073 - val_accuracy: 0.6051 - val_loss: 1.6837\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7715 - loss: 0.8067 - val_accuracy: 0.6052 - val_loss: 1.6846\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7713 - loss: 0.8062 - val_accuracy: 0.6052 - val_loss: 1.6823\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.8056 - val_accuracy: 0.6052 - val_loss: 1.6831\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.8051 - val_accuracy: 0.6063 - val_loss: 1.6864\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7711 - loss: 0.8046 - val_accuracy: 0.6064 - val_loss: 1.6817\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7715 - loss: 0.8041 - val_accuracy: 0.6063 - val_loss: 1.6850\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.8036 - val_accuracy: 0.6020 - val_loss: 1.6859\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7700 - loss: 0.8032 - val_accuracy: 0.6068 - val_loss: 1.6843\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7712 - loss: 0.8027 - val_accuracy: 0.6068 - val_loss: 1.6828\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7712 - loss: 0.8023 - val_accuracy: 0.6074 - val_loss: 1.6845\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.8018 - val_accuracy: 0.6074 - val_loss: 1.6865\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.8014 - val_accuracy: 0.6067 - val_loss: 1.6916\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7697 - loss: 0.8010 - val_accuracy: 0.6074 - val_loss: 1.6845\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.8006 - val_accuracy: 0.6070 - val_loss: 1.6878\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.8002 - val_accuracy: 0.6079 - val_loss: 1.6828\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.7998 - val_accuracy: 0.6071 - val_loss: 1.6871\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.7994 - val_accuracy: 0.6071 - val_loss: 1.6879\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7711 - loss: 0.7991 - val_accuracy: 0.6025 - val_loss: 1.6878\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7704 - loss: 0.7987 - val_accuracy: 0.6071 - val_loss: 1.6895\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7705 - loss: 0.7984 - val_accuracy: 0.6025 - val_loss: 1.6873\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7699 - loss: 0.7980 - val_accuracy: 0.6069 - val_loss: 1.6921\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7714 - loss: 0.7976 - val_accuracy: 0.6025 - val_loss: 1.6900\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7698 - loss: 0.7973 - val_accuracy: 0.6069 - val_loss: 1.6947\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7970 - val_accuracy: 0.6080 - val_loss: 1.6904\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7711 - loss: 0.7966 - val_accuracy: 0.6080 - val_loss: 1.6907\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7963 - val_accuracy: 0.6080 - val_loss: 1.6911\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7693 - loss: 0.7960 - val_accuracy: 0.6080 - val_loss: 1.6904\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7717 - loss: 0.7957 - val_accuracy: 0.6079 - val_loss: 1.6920\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7719 - loss: 0.7954 - val_accuracy: 0.6077 - val_loss: 1.6932\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7703 - loss: 0.7951 - val_accuracy: 0.6080 - val_loss: 1.6916\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7715 - loss: 0.7948 - val_accuracy: 0.6075 - val_loss: 1.6963\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7716 - loss: 0.7945 - val_accuracy: 0.6079 - val_loss: 1.6911\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7717 - loss: 0.7942 - val_accuracy: 0.6076 - val_loss: 1.6904\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7720 - loss: 0.7939 - val_accuracy: 0.6084 - val_loss: 1.6901\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7719 - loss: 0.7936 - val_accuracy: 0.6077 - val_loss: 1.6912\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7718 - loss: 0.7933 - val_accuracy: 0.6033 - val_loss: 1.6919\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7719 - loss: 0.7930 - val_accuracy: 0.6078 - val_loss: 1.6941\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7718 - loss: 0.7927 - val_accuracy: 0.6078 - val_loss: 1.6939\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7721 - loss: 0.7925 - val_accuracy: 0.6087 - val_loss: 1.6919\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.7922 - val_accuracy: 0.6077 - val_loss: 1.6962\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7723 - loss: 0.7919 - val_accuracy: 0.6041 - val_loss: 1.6937\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7722 - loss: 0.7917 - val_accuracy: 0.6085 - val_loss: 1.6935\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7725 - loss: 0.7914 - val_accuracy: 0.6077 - val_loss: 1.6976\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7724 - loss: 0.7912 - val_accuracy: 0.6077 - val_loss: 1.6962\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7725 - loss: 0.7909 - val_accuracy: 0.6077 - val_loss: 1.6968\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7728 - loss: 0.7906 - val_accuracy: 0.6082 - val_loss: 1.6929\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7730 - loss: 0.7904 - val_accuracy: 0.6089 - val_loss: 1.6929\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7728 - loss: 0.7901 - val_accuracy: 0.6086 - val_loss: 1.6961\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7723 - loss: 0.7899 - val_accuracy: 0.6089 - val_loss: 1.6933\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7731 - loss: 0.7897 - val_accuracy: 0.6044 - val_loss: 1.6964\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7705 - loss: 0.7894 - val_accuracy: 0.6080 - val_loss: 1.6978\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7892 - val_accuracy: 0.6089 - val_loss: 1.6943\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7718 - loss: 0.7889 - val_accuracy: 0.6089 - val_loss: 1.6932\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7887 - val_accuracy: 0.6092 - val_loss: 1.6902\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7732 - loss: 0.7885 - val_accuracy: 0.6089 - val_loss: 1.6970\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7726 - loss: 0.7882 - val_accuracy: 0.6089 - val_loss: 1.6950\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7880 - val_accuracy: 0.6088 - val_loss: 1.6946\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7720 - loss: 0.7878 - val_accuracy: 0.6086 - val_loss: 1.6935\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7730 - loss: 0.7876 - val_accuracy: 0.6077 - val_loss: 1.6958\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7729 - loss: 0.7873 - val_accuracy: 0.6075 - val_loss: 1.6948\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7871 - val_accuracy: 0.6075 - val_loss: 1.7016\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7726 - loss: 0.7869 - val_accuracy: 0.6075 - val_loss: 1.7005\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7726 - loss: 0.7867 - val_accuracy: 0.6076 - val_loss: 1.6954\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7730 - loss: 0.7865 - val_accuracy: 0.6075 - val_loss: 1.6987\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7728 - loss: 0.7863 - val_accuracy: 0.6076 - val_loss: 1.6952\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7861 - val_accuracy: 0.6077 - val_loss: 1.6995\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.7858 - val_accuracy: 0.6077 - val_loss: 1.6973\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.7856 - val_accuracy: 0.6077 - val_loss: 1.6984\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.7854 - val_accuracy: 0.6078 - val_loss: 1.6975\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7852 - val_accuracy: 0.6077 - val_loss: 1.6977\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7850 - val_accuracy: 0.6077 - val_loss: 1.6969\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7725 - loss: 0.7848 - val_accuracy: 0.6078 - val_loss: 1.6959\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7846 - val_accuracy: 0.6077 - val_loss: 1.6971\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.7844 - val_accuracy: 0.6078 - val_loss: 1.6979\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7733 - loss: 0.7842 - val_accuracy: 0.6077 - val_loss: 1.7007\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7731 - loss: 0.7840 - val_accuracy: 0.6077 - val_loss: 1.7009\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7737 - loss: 0.7838 - val_accuracy: 0.6079 - val_loss: 1.6981\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7737 - loss: 0.7837 - val_accuracy: 0.6081 - val_loss: 1.6963\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7739 - loss: 0.7835 - val_accuracy: 0.6081 - val_loss: 1.6964\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7833 - val_accuracy: 0.6080 - val_loss: 1.6988\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7831 - val_accuracy: 0.6080 - val_loss: 1.7008\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7829 - val_accuracy: 0.6080 - val_loss: 1.7021\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7827 - val_accuracy: 0.6083 - val_loss: 1.6999\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7825 - val_accuracy: 0.6093 - val_loss: 1.6976\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7727 - loss: 0.7824 - val_accuracy: 0.6093 - val_loss: 1.7008\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7735 - loss: 0.7822 - val_accuracy: 0.6093 - val_loss: 1.7007\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7820 - val_accuracy: 0.6094 - val_loss: 1.6988\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7738 - loss: 0.7818 - val_accuracy: 0.6093 - val_loss: 1.7024\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7816 - val_accuracy: 0.6093 - val_loss: 1.7011\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7815 - val_accuracy: 0.6093 - val_loss: 1.7017\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7734 - loss: 0.7813 - val_accuracy: 0.6093 - val_loss: 1.7032\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7811 - val_accuracy: 0.6088 - val_loss: 1.7034\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7736 - loss: 0.7809 - val_accuracy: 0.6089 - val_loss: 1.6995\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7741 - loss: 0.7808 - val_accuracy: 0.6088 - val_loss: 1.7055\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7737 - loss: 0.7806 - val_accuracy: 0.6088 - val_loss: 1.7017\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7743 - loss: 0.7804 - val_accuracy: 0.6089 - val_loss: 1.7007\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7741 - loss: 0.7803 - val_accuracy: 0.6057 - val_loss: 1.7055\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7751 - loss: 0.7801 - val_accuracy: 0.6058 - val_loss: 1.7022\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7799 - val_accuracy: 0.6057 - val_loss: 1.7038\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7748 - loss: 0.7798 - val_accuracy: 0.6057 - val_loss: 1.7057\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7751 - loss: 0.7796 - val_accuracy: 0.6058 - val_loss: 1.6999\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7751 - loss: 0.7794 - val_accuracy: 0.6057 - val_loss: 1.7045\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7749 - loss: 0.7793 - val_accuracy: 0.6058 - val_loss: 1.7045\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7751 - loss: 0.7791 - val_accuracy: 0.6057 - val_loss: 1.7042\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7790 - val_accuracy: 0.6056 - val_loss: 1.7039\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7788 - val_accuracy: 0.6056 - val_loss: 1.7080\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7750 - loss: 0.7786 - val_accuracy: 0.6058 - val_loss: 1.7034\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7754 - loss: 0.7785 - val_accuracy: 0.6056 - val_loss: 1.7082\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7783 - val_accuracy: 0.6058 - val_loss: 1.7027\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7782 - val_accuracy: 0.6058 - val_loss: 1.7052\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7754 - loss: 0.7780 - val_accuracy: 0.6055 - val_loss: 1.7104\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7779 - val_accuracy: 0.6056 - val_loss: 1.7040\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7751 - loss: 0.7777 - val_accuracy: 0.6055 - val_loss: 1.7081\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7776 - val_accuracy: 0.6055 - val_loss: 1.7046\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7744 - loss: 0.7774 - val_accuracy: 0.6043 - val_loss: 1.7112\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7773 - val_accuracy: 0.6043 - val_loss: 1.7085\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7771 - val_accuracy: 0.6042 - val_loss: 1.7076\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7770 - val_accuracy: 0.6042 - val_loss: 1.7091\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7768 - val_accuracy: 0.6044 - val_loss: 1.7048\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7748 - loss: 0.7767 - val_accuracy: 0.6045 - val_loss: 1.7055\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7765 - val_accuracy: 0.6045 - val_loss: 1.7070\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7764 - val_accuracy: 0.6044 - val_loss: 1.7087\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7752 - loss: 0.7763 - val_accuracy: 0.6045 - val_loss: 1.7085\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7761 - val_accuracy: 0.6044 - val_loss: 1.7067\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7752 - loss: 0.7760 - val_accuracy: 0.6044 - val_loss: 1.7100\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7758 - val_accuracy: 0.6045 - val_loss: 1.7095\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7757 - val_accuracy: 0.6044 - val_loss: 1.7124\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7752 - loss: 0.7756 - val_accuracy: 0.6046 - val_loss: 1.7058\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7751 - loss: 0.7754 - val_accuracy: 0.6044 - val_loss: 1.7118\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7752 - loss: 0.7753 - val_accuracy: 0.6045 - val_loss: 1.7075\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7752 - val_accuracy: 0.6045 - val_loss: 1.7089\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7750 - val_accuracy: 0.6045 - val_loss: 1.7082\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7752 - loss: 0.7749 - val_accuracy: 0.6044 - val_loss: 1.7114\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7748 - val_accuracy: 0.6045 - val_loss: 1.7098\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7746 - val_accuracy: 0.6045 - val_loss: 1.7132\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7753 - loss: 0.7745 - val_accuracy: 0.6049 - val_loss: 1.7077\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7754 - loss: 0.7744 - val_accuracy: 0.6044 - val_loss: 1.7124\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7742 - val_accuracy: 0.6043 - val_loss: 1.7154\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7741 - val_accuracy: 0.6043 - val_loss: 1.7133\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7740 - val_accuracy: 0.6047 - val_loss: 1.7118\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7738 - val_accuracy: 0.6047 - val_loss: 1.7132\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7737 - val_accuracy: 0.6047 - val_loss: 1.7128\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7736 - val_accuracy: 0.6048 - val_loss: 1.7089\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7735 - val_accuracy: 0.6042 - val_loss: 1.7114\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7757 - loss: 0.7733 - val_accuracy: 0.6042 - val_loss: 1.7115\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7732 - val_accuracy: 0.6042 - val_loss: 1.7104\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7731 - val_accuracy: 0.6042 - val_loss: 1.7105\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7730 - val_accuracy: 0.6040 - val_loss: 1.7133\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7728 - val_accuracy: 0.6039 - val_loss: 1.7171\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7758 - loss: 0.7727 - val_accuracy: 0.6040 - val_loss: 1.7110\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7759 - loss: 0.7726 - val_accuracy: 0.6040 - val_loss: 1.7114\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7725 - val_accuracy: 0.6040 - val_loss: 1.7146\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7724 - val_accuracy: 0.6040 - val_loss: 1.7151\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7722 - val_accuracy: 0.6040 - val_loss: 1.7154\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7721 - val_accuracy: 0.6041 - val_loss: 1.7138\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7720 - val_accuracy: 0.6040 - val_loss: 1.7140\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7759 - loss: 0.7719 - val_accuracy: 0.6041 - val_loss: 1.7148\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7718 - val_accuracy: 0.6039 - val_loss: 1.7209\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7717 - val_accuracy: 0.6041 - val_loss: 1.7135\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7715 - val_accuracy: 0.6041 - val_loss: 1.7111\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7714 - val_accuracy: 0.6039 - val_loss: 1.7179\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7713 - val_accuracy: 0.6040 - val_loss: 1.7171\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7712 - val_accuracy: 0.6039 - val_loss: 1.7147\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7711 - val_accuracy: 0.6039 - val_loss: 1.7174\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7710 - val_accuracy: 0.6040 - val_loss: 1.7144\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7709 - val_accuracy: 0.6038 - val_loss: 1.7178\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7708 - val_accuracy: 0.6038 - val_loss: 1.7146\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7706 - val_accuracy: 0.6038 - val_loss: 1.7166\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7759 - loss: 0.7705 - val_accuracy: 0.6039 - val_loss: 1.7162\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7704 - val_accuracy: 0.6039 - val_loss: 1.7174\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7703 - val_accuracy: 0.6038 - val_loss: 1.7200\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7702 - val_accuracy: 0.6038 - val_loss: 1.7184\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7701 - val_accuracy: 0.6038 - val_loss: 1.7173\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7700 - val_accuracy: 0.6038 - val_loss: 1.7168\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7759 - loss: 0.7699 - val_accuracy: 0.6038 - val_loss: 1.7211\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7698 - val_accuracy: 0.6037 - val_loss: 1.7216\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7697 - val_accuracy: 0.6037 - val_loss: 1.7193\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7696 - val_accuracy: 0.6037 - val_loss: 1.7169\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7761 - loss: 0.7695 - val_accuracy: 0.6037 - val_loss: 1.7207\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7694 - val_accuracy: 0.6038 - val_loss: 1.7164\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7761 - loss: 0.7693 - val_accuracy: 0.6037 - val_loss: 1.7207\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7692 - val_accuracy: 0.6038 - val_loss: 1.7209\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7691 - val_accuracy: 0.6038 - val_loss: 1.7186\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7690 - val_accuracy: 0.6037 - val_loss: 1.7229\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7689 - val_accuracy: 0.6036 - val_loss: 1.7232\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7688 - val_accuracy: 0.6037 - val_loss: 1.7217\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7687 - val_accuracy: 0.6036 - val_loss: 1.7252\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7686 - val_accuracy: 0.6038 - val_loss: 1.7187\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7685 - val_accuracy: 0.6038 - val_loss: 1.7200\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7684 - val_accuracy: 0.6037 - val_loss: 1.7235\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7683 - val_accuracy: 0.6037 - val_loss: 1.7233\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7682 - val_accuracy: 0.6040 - val_loss: 1.7223\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7681 - val_accuracy: 0.6039 - val_loss: 1.7220\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7680 - val_accuracy: 0.6039 - val_loss: 1.7214\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7679 - val_accuracy: 0.6039 - val_loss: 1.7246\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7678 - val_accuracy: 0.6039 - val_loss: 1.7249\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7677 - val_accuracy: 0.6039 - val_loss: 1.7238\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7676 - val_accuracy: 0.6040 - val_loss: 1.7209\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7675 - val_accuracy: 0.6038 - val_loss: 1.7256\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7765 - loss: 0.7674 - val_accuracy: 0.6040 - val_loss: 1.7246\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7673 - val_accuracy: 0.6040 - val_loss: 1.7226\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7672 - val_accuracy: 0.6040 - val_loss: 1.7237\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7671 - val_accuracy: 0.6040 - val_loss: 1.7259\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7670 - val_accuracy: 0.6040 - val_loss: 1.7263\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7670 - val_accuracy: 0.6041 - val_loss: 1.7229\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7767 - loss: 0.7669 - val_accuracy: 0.6040 - val_loss: 1.7261\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7668 - val_accuracy: 0.6038 - val_loss: 1.7262\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7667 - val_accuracy: 0.6041 - val_loss: 1.7234\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7666 - val_accuracy: 0.6041 - val_loss: 1.7243\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7665 - val_accuracy: 0.6038 - val_loss: 1.7267\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7664 - val_accuracy: 0.6041 - val_loss: 1.7277\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7766 - loss: 0.7663 - val_accuracy: 0.6040 - val_loss: 1.7247\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7662 - val_accuracy: 0.6042 - val_loss: 1.7243\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7662 - val_accuracy: 0.6040 - val_loss: 1.7295\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7661 - val_accuracy: 0.6042 - val_loss: 1.7253\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7660 - val_accuracy: 0.6042 - val_loss: 1.7243\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7659 - val_accuracy: 0.6042 - val_loss: 1.7262\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7766 - loss: 0.7658 - val_accuracy: 0.6042 - val_loss: 1.7271\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7657 - val_accuracy: 0.6042 - val_loss: 1.7266\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7656 - val_accuracy: 0.6041 - val_loss: 1.7288\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7656 - val_accuracy: 0.6042 - val_loss: 1.7279\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7655 - val_accuracy: 0.6042 - val_loss: 1.7298\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7654 - val_accuracy: 0.6043 - val_loss: 1.7289\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7766 - loss: 0.7653 - val_accuracy: 0.6042 - val_loss: 1.7301\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7652 - val_accuracy: 0.6042 - val_loss: 1.7296\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7651 - val_accuracy: 0.6043 - val_loss: 1.7286\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7651 - val_accuracy: 0.6043 - val_loss: 1.7271\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7650 - val_accuracy: 0.6043 - val_loss: 1.7309\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7649 - val_accuracy: 0.6043 - val_loss: 1.7317\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7766 - loss: 0.7648 - val_accuracy: 0.6043 - val_loss: 1.7294\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7647 - val_accuracy: 0.6042 - val_loss: 1.7316\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7647 - val_accuracy: 0.6043 - val_loss: 1.7313\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7646 - val_accuracy: 0.6042 - val_loss: 1.7324\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7645 - val_accuracy: 0.6043 - val_loss: 1.7300\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7644 - val_accuracy: 0.6042 - val_loss: 1.7329\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7766 - loss: 0.7643 - val_accuracy: 0.6043 - val_loss: 1.7320\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7643 - val_accuracy: 0.6043 - val_loss: 1.7294\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7642 - val_accuracy: 0.6041 - val_loss: 1.7326\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7641 - val_accuracy: 0.6042 - val_loss: 1.7313\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7640 - val_accuracy: 0.6041 - val_loss: 1.7332\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7639 - val_accuracy: 0.6042 - val_loss: 1.7293\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7766 - loss: 0.7639 - val_accuracy: 0.6042 - val_loss: 1.7327\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7638 - val_accuracy: 0.6042 - val_loss: 1.7321\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7637 - val_accuracy: 0.6042 - val_loss: 1.7290\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7636 - val_accuracy: 0.6042 - val_loss: 1.7345\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7636 - val_accuracy: 0.6042 - val_loss: 1.7299\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7635 - val_accuracy: 0.6042 - val_loss: 1.7306\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7634 - val_accuracy: 0.6042 - val_loss: 1.7342\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7633 - val_accuracy: 0.6042 - val_loss: 1.7329\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7633 - val_accuracy: 0.6042 - val_loss: 1.7323\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7632 - val_accuracy: 0.6042 - val_loss: 1.7331\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7631 - val_accuracy: 0.6042 - val_loss: 1.7346\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7630 - val_accuracy: 0.6042 - val_loss: 1.7375\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7630 - val_accuracy: 0.6042 - val_loss: 1.7385\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7629 - val_accuracy: 0.6042 - val_loss: 1.7338\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7628 - val_accuracy: 0.6042 - val_loss: 1.7389\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7628 - val_accuracy: 0.6042 - val_loss: 1.7345\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7627 - val_accuracy: 0.6042 - val_loss: 1.7332\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7769 - loss: 0.7626 - val_accuracy: 0.6042 - val_loss: 1.7334\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7773 - loss: 0.7625 - val_accuracy: 0.6042 - val_loss: 1.7348\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7777 - loss: 0.7625 - val_accuracy: 0.6041 - val_loss: 1.7371\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7624 - val_accuracy: 0.6042 - val_loss: 1.7339\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7623 - val_accuracy: 0.6041 - val_loss: 1.7362\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7623 - val_accuracy: 0.6042 - val_loss: 1.7376\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7622 - val_accuracy: 0.6041 - val_loss: 1.7382\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7621 - val_accuracy: 0.6041 - val_loss: 1.7359\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7778 - loss: 0.7621 - val_accuracy: 0.6041 - val_loss: 1.7382\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7620 - val_accuracy: 0.6041 - val_loss: 1.7357\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7619 - val_accuracy: 0.6041 - val_loss: 1.7388\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7619 - val_accuracy: 0.6043 - val_loss: 1.7394\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7618 - val_accuracy: 0.6041 - val_loss: 1.7407\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7617 - val_accuracy: 0.6041 - val_loss: 1.7389\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7778 - loss: 0.7616 - val_accuracy: 0.6041 - val_loss: 1.7399\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7616 - val_accuracy: 0.6043 - val_loss: 1.7394\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7615 - val_accuracy: 0.6041 - val_loss: 1.7378\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7614 - val_accuracy: 0.6043 - val_loss: 1.7374\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7614 - val_accuracy: 0.6044 - val_loss: 1.7364\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7613 - val_accuracy: 0.6045 - val_loss: 1.7362\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7778 - loss: 0.7613 - val_accuracy: 0.6045 - val_loss: 1.7386\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7612 - val_accuracy: 0.6044 - val_loss: 1.7393\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7611 - val_accuracy: 0.6044 - val_loss: 1.7418\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7611 - val_accuracy: 0.6044 - val_loss: 1.7417\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7610 - val_accuracy: 0.6045 - val_loss: 1.7411\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7609 - val_accuracy: 0.6044 - val_loss: 1.7433\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7778 - loss: 0.7609 - val_accuracy: 0.6043 - val_loss: 1.7415\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7608 - val_accuracy: 0.6045 - val_loss: 1.7395\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7607 - val_accuracy: 0.6045 - val_loss: 1.7405\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7607 - val_accuracy: 0.6044 - val_loss: 1.7400\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7606 - val_accuracy: 0.6044 - val_loss: 1.7426\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7605 - val_accuracy: 0.6044 - val_loss: 1.7406\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7779 - loss: 0.7605 - val_accuracy: 0.6044 - val_loss: 1.7398\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7604 - val_accuracy: 0.6044 - val_loss: 1.7382\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7604 - val_accuracy: 0.6044 - val_loss: 1.7390\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7603 - val_accuracy: 0.6045 - val_loss: 1.7415\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7602 - val_accuracy: 0.6043 - val_loss: 1.7422\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7602 - val_accuracy: 0.6043 - val_loss: 1.7424\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7779 - loss: 0.7601 - val_accuracy: 0.6043 - val_loss: 1.7449\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7600 - val_accuracy: 0.6043 - val_loss: 1.7430\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7600 - val_accuracy: 0.6043 - val_loss: 1.7437\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7599 - val_accuracy: 0.6044 - val_loss: 1.7413\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7599 - val_accuracy: 0.6043 - val_loss: 1.7442\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7598 - val_accuracy: 0.6043 - val_loss: 1.7447\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7598 - val_accuracy: 0.6043 - val_loss: 1.7463\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7597 - val_accuracy: 0.6043 - val_loss: 1.7475\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7596 - val_accuracy: 0.6044 - val_loss: 1.7435\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7596 - val_accuracy: 0.6044 - val_loss: 1.7450\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7595 - val_accuracy: 0.6044 - val_loss: 1.7446\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7595 - val_accuracy: 0.6043 - val_loss: 1.7470\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7594 - val_accuracy: 0.6042 - val_loss: 1.7478\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.7593 - val_accuracy: 0.6043 - val_loss: 1.7466\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7593 - val_accuracy: 0.6042 - val_loss: 1.7487\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7592 - val_accuracy: 0.6044 - val_loss: 1.7436\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7592 - val_accuracy: 0.6039 - val_loss: 1.7488\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7591 - val_accuracy: 0.6044 - val_loss: 1.7450\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7590 - val_accuracy: 0.6040 - val_loss: 1.7483\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7590 - val_accuracy: 0.6043 - val_loss: 1.7502\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7589 - val_accuracy: 0.6043 - val_loss: 1.7474\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7589 - val_accuracy: 0.6043 - val_loss: 1.7458\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7588 - val_accuracy: 0.6040 - val_loss: 1.7475\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7588 - val_accuracy: 0.6042 - val_loss: 1.7480\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7587 - val_accuracy: 0.6039 - val_loss: 1.7468\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7781 - loss: 0.7587 - val_accuracy: 0.6039 - val_loss: 1.7482\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7586 - val_accuracy: 0.6040 - val_loss: 1.7484\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7585 - val_accuracy: 0.6039 - val_loss: 1.7488\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7585 - val_accuracy: 0.6036 - val_loss: 1.7460\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7584 - val_accuracy: 0.6036 - val_loss: 1.7492\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7584 - val_accuracy: 0.6036 - val_loss: 1.7486\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7583 - val_accuracy: 0.6037 - val_loss: 1.7493\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7583 - val_accuracy: 0.6036 - val_loss: 1.7515\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7582 - val_accuracy: 0.6036 - val_loss: 1.7530\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7582 - val_accuracy: 0.6036 - val_loss: 1.7520\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7581 - val_accuracy: 0.6036 - val_loss: 1.7498\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7581 - val_accuracy: 0.6036 - val_loss: 1.7521\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7580 - val_accuracy: 0.6036 - val_loss: 1.7507\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7579 - val_accuracy: 0.6037 - val_loss: 1.7542\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7579 - val_accuracy: 0.6037 - val_loss: 1.7508\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7578 - val_accuracy: 0.6037 - val_loss: 1.7508\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7578 - val_accuracy: 0.6037 - val_loss: 1.7521\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7577 - val_accuracy: 0.6036 - val_loss: 1.7527\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7577 - val_accuracy: 0.6037 - val_loss: 1.7491\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7781 - loss: 0.7576 - val_accuracy: 0.6037 - val_loss: 1.7496\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7576 - val_accuracy: 0.6037 - val_loss: 1.7523\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7575 - val_accuracy: 0.6037 - val_loss: 1.7475\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7575 - val_accuracy: 0.6037 - val_loss: 1.7523\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7574 - val_accuracy: 0.6037 - val_loss: 1.7501\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7574 - val_accuracy: 0.6037 - val_loss: 1.7540\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7781 - loss: 0.7573 - val_accuracy: 0.6037 - val_loss: 1.7534\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7573 - val_accuracy: 0.6037 - val_loss: 1.7559\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7572 - val_accuracy: 0.6037 - val_loss: 1.7556\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7572 - val_accuracy: 0.6037 - val_loss: 1.7562\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7571 - val_accuracy: 0.6037 - val_loss: 1.7544\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7571 - val_accuracy: 0.6037 - val_loss: 1.7530\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7570 - val_accuracy: 0.6037 - val_loss: 1.7516\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7570 - val_accuracy: 0.6037 - val_loss: 1.7541\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7569 - val_accuracy: 0.6037 - val_loss: 1.7513\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7569 - val_accuracy: 0.6037 - val_loss: 1.7532\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7568 - val_accuracy: 0.6036 - val_loss: 1.7550\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7568 - val_accuracy: 0.6036 - val_loss: 1.7573\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7567 - val_accuracy: 0.6037 - val_loss: 1.7492\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7567 - val_accuracy: 0.6036 - val_loss: 1.7547\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7566 - val_accuracy: 0.6036 - val_loss: 1.7513\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7566 - val_accuracy: 0.6036 - val_loss: 1.7565\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7565 - val_accuracy: 0.6036 - val_loss: 1.7541\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7565 - val_accuracy: 0.6036 - val_loss: 1.7549\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7564 - val_accuracy: 0.6036 - val_loss: 1.7576\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7564 - val_accuracy: 0.6036 - val_loss: 1.7578\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7563 - val_accuracy: 0.6036 - val_loss: 1.7548\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7563 - val_accuracy: 0.6035 - val_loss: 1.7571\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7563 - val_accuracy: 0.6035 - val_loss: 1.7579\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7562 - val_accuracy: 0.6035 - val_loss: 1.7572\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7562 - val_accuracy: 0.6035 - val_loss: 1.7541\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7561 - val_accuracy: 0.6035 - val_loss: 1.7552\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7561 - val_accuracy: 0.6035 - val_loss: 1.7545\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7560 - val_accuracy: 0.6035 - val_loss: 1.7580\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7560 - val_accuracy: 0.6034 - val_loss: 1.7614\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7559 - val_accuracy: 0.6035 - val_loss: 1.7602\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7559 - val_accuracy: 0.6033 - val_loss: 1.7555\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7558 - val_accuracy: 0.6035 - val_loss: 1.7573\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7558 - val_accuracy: 0.6035 - val_loss: 1.7578\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7557 - val_accuracy: 0.6035 - val_loss: 1.7614\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7557 - val_accuracy: 0.6035 - val_loss: 1.7566\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7557 - val_accuracy: 0.6035 - val_loss: 1.7600\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7556 - val_accuracy: 0.6035 - val_loss: 1.7602\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7782 - loss: 0.7556 - val_accuracy: 0.6035 - val_loss: 1.7626\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7555 - val_accuracy: 0.6035 - val_loss: 1.7585\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7555 - val_accuracy: 0.6035 - val_loss: 1.7585\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7554 - val_accuracy: 0.6033 - val_loss: 1.7587\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7554 - val_accuracy: 0.6035 - val_loss: 1.7577\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7553 - val_accuracy: 0.6034 - val_loss: 1.7598\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7553 - val_accuracy: 0.6035 - val_loss: 1.7586\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7552 - val_accuracy: 0.6035 - val_loss: 1.7615\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7552 - val_accuracy: 0.6035 - val_loss: 1.7636\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7552 - val_accuracy: 0.6035 - val_loss: 1.7602\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7551 - val_accuracy: 0.6034 - val_loss: 1.7632\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7551 - val_accuracy: 0.6034 - val_loss: 1.7588\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7550 - val_accuracy: 0.6035 - val_loss: 1.7641\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7550 - val_accuracy: 0.6034 - val_loss: 1.7615\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7549 - val_accuracy: 0.6036 - val_loss: 1.7622\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7549 - val_accuracy: 0.6036 - val_loss: 1.7578\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7549 - val_accuracy: 0.6036 - val_loss: 1.7597\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7548 - val_accuracy: 0.6036 - val_loss: 1.7651\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7548 - val_accuracy: 0.6036 - val_loss: 1.7613\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7547 - val_accuracy: 0.6036 - val_loss: 1.7615\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7547 - val_accuracy: 0.6036 - val_loss: 1.7635\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7546 - val_accuracy: 0.6036 - val_loss: 1.7657\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7546 - val_accuracy: 0.6036 - val_loss: 1.7645\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7546 - val_accuracy: 0.6036 - val_loss: 1.7647\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7545 - val_accuracy: 0.6036 - val_loss: 1.7595\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7780 - loss: 0.7545 - val_accuracy: 0.6036 - val_loss: 1.7643\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7544 - val_accuracy: 0.6035 - val_loss: 1.7621\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7544 - val_accuracy: 0.6034 - val_loss: 1.7640\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7543 - val_accuracy: 0.6036 - val_loss: 1.7659\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7543 - val_accuracy: 0.6035 - val_loss: 1.7652\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7543 - val_accuracy: 0.6036 - val_loss: 1.7643\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7781 - loss: 0.7542 - val_accuracy: 0.6036 - val_loss: 1.7685\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7542 - val_accuracy: 0.6035 - val_loss: 1.7649\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7541 - val_accuracy: 0.6036 - val_loss: 1.7684\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7541 - val_accuracy: 0.6034 - val_loss: 1.7682\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7541 - val_accuracy: 0.6035 - val_loss: 1.7643\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7540 - val_accuracy: 0.6036 - val_loss: 1.7636\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7540 - val_accuracy: 0.6035 - val_loss: 1.7633\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7539 - val_accuracy: 0.6036 - val_loss: 1.7618\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7539 - val_accuracy: 0.6035 - val_loss: 1.7660\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7539 - val_accuracy: 0.6036 - val_loss: 1.7685\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7538 - val_accuracy: 0.6036 - val_loss: 1.7671\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7538 - val_accuracy: 0.6035 - val_loss: 1.7669\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7537 - val_accuracy: 0.6035 - val_loss: 1.7650\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7537 - val_accuracy: 0.6035 - val_loss: 1.7672\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7537 - val_accuracy: 0.6033 - val_loss: 1.7708\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7536 - val_accuracy: 0.6036 - val_loss: 1.7671\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7536 - val_accuracy: 0.6035 - val_loss: 1.7662\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7535 - val_accuracy: 0.6036 - val_loss: 1.7681\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7535 - val_accuracy: 0.6037 - val_loss: 1.7655\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7779 - loss: 0.7535 - val_accuracy: 0.6039 - val_loss: 1.7665\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7534 - val_accuracy: 0.6037 - val_loss: 1.7663\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7534 - val_accuracy: 0.6035 - val_loss: 1.7705\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7533 - val_accuracy: 0.6039 - val_loss: 1.7674\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7533 - val_accuracy: 0.6039 - val_loss: 1.7697\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7533 - val_accuracy: 0.6039 - val_loss: 1.7665\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7532 - val_accuracy: 0.6037 - val_loss: 1.7666\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7532 - val_accuracy: 0.6037 - val_loss: 1.7675\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7531 - val_accuracy: 0.6037 - val_loss: 1.7721\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7531 - val_accuracy: 0.6034 - val_loss: 1.7689\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7531 - val_accuracy: 0.6034 - val_loss: 1.7720\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7530 - val_accuracy: 0.6036 - val_loss: 1.7699\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7530 - val_accuracy: 0.6037 - val_loss: 1.7658\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7530 - val_accuracy: 0.6034 - val_loss: 1.7731\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7529 - val_accuracy: 0.6034 - val_loss: 1.7708\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7529 - val_accuracy: 0.6039 - val_loss: 1.7687\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7528 - val_accuracy: 0.6037 - val_loss: 1.7728\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7779 - loss: 0.7528 - val_accuracy: 0.6035 - val_loss: 1.7741\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7528 - val_accuracy: 0.6037 - val_loss: 1.7724\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7527 - val_accuracy: 0.6034 - val_loss: 1.7711\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7527 - val_accuracy: 0.6034 - val_loss: 1.7716\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7527 - val_accuracy: 0.6035 - val_loss: 1.7722\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7526 - val_accuracy: 0.6039 - val_loss: 1.7713\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7526 - val_accuracy: 0.6036 - val_loss: 1.7676\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7782 - loss: 0.7526 - val_accuracy: 0.6034 - val_loss: 1.7710\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7780 - loss: 0.7525 - val_accuracy: 0.6035 - val_loss: 1.7759\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7783 - loss: 0.7525 - val_accuracy: 0.6035 - val_loss: 1.7710\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7524 - val_accuracy: 0.6037 - val_loss: 1.7699\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7524 - val_accuracy: 0.6034 - val_loss: 1.7747\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7524 - val_accuracy: 0.6034 - val_loss: 1.7726\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7781 - loss: 0.7523 - val_accuracy: 0.6035 - val_loss: 1.7707\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7523 - val_accuracy: 0.6038 - val_loss: 1.7686\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7523 - val_accuracy: 0.6034 - val_loss: 1.7720\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7783 - loss: 0.7522 - val_accuracy: 0.6035 - val_loss: 1.7699\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7522 - val_accuracy: 0.6034 - val_loss: 1.7745\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7522 - val_accuracy: 0.6037 - val_loss: 1.7749\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7786 - loss: 0.7521 - val_accuracy: 0.6037 - val_loss: 1.7732\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7787 - loss: 0.7521 - val_accuracy: 0.6034 - val_loss: 1.7766\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7787 - loss: 0.7520 - val_accuracy: 0.6034 - val_loss: 1.7771\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7520 - val_accuracy: 0.6036 - val_loss: 1.7727\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7788 - loss: 0.7520 - val_accuracy: 0.6034 - val_loss: 1.7765\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7519 - val_accuracy: 0.6035 - val_loss: 1.7739\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7519 - val_accuracy: 0.6034 - val_loss: 1.7790\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7789 - loss: 0.7519 - val_accuracy: 0.6034 - val_loss: 1.7763\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7518 - val_accuracy: 0.6035 - val_loss: 1.7761\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7518 - val_accuracy: 0.6035 - val_loss: 1.7737\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7518 - val_accuracy: 0.6035 - val_loss: 1.7735\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7517 - val_accuracy: 0.6036 - val_loss: 1.7732\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7787 - loss: 0.7517 - val_accuracy: 0.6034 - val_loss: 1.7829\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7789 - loss: 0.7517 - val_accuracy: 0.6036 - val_loss: 1.7778\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7516 - val_accuracy: 0.6034 - val_loss: 1.7781\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7516 - val_accuracy: 0.6035 - val_loss: 1.7787\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7790 - loss: 0.7516 - val_accuracy: 0.6034 - val_loss: 1.7788\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_14, X_test_14, y_train_14, y_test_14 = train_test_split(\n    X, y, test_size=0.3, random_state=56, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_14, X_val_14, y_train_14, y_val_14 = train_test_split(\n    X_train_14, y_train_14, test_size=0.2, random_state=56, stratify=y_train_14\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_14:\", np.max(X_train_14))\nprint(\"Min value in X_train_14:\", np.min(X_train_14))\n\nX_train_14_scaled = scaler.fit_transform(X_train_14)\n\n# Get the original class distribution\nclass_counts_14 = Counter(y_train_14)\nprint(\"Original class distribution:\", class_counts_14)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_14 = class_counts_14[min(class_counts_14, key=class_counts_14.get)]\ndesired_majority_size_14 = minority_class_size_14 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_14 = {0: desired_majority_size_14, 1: minority_class_size_14}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_14 = RandomUnderSampler(sampling_strategy=sampling_strategy_14, random_state=42)\nX_resampled_14, y_resampled_14 = undersampler_14.fit_resample(X_train_14, y_train_14)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_14))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_14, y_train_resampled_14 = smote.fit_resample(X_resampled_14, y_resampled_14)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_14))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_14))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T05:09:53.887864Z","iopub.execute_input":"2025-03-07T05:09:53.888267Z","iopub.status.idle":"2025-03-07T05:10:36.002081Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_14: 2071000000.0\nMin value in X_train_14: -6442447920.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_14 = X_train_resampled_14.reshape(X_train_resampled_14.shape[0], 1, 56)\nX_val_14 = X_val_14.reshape(X_val_14.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_14,  # Features from CICIDS2017\n    y_train_resampled_14,  # Labels from CICIDS2017\n    validation_data=(X_val_14, y_val_14),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T05:10:36.003241Z","iopub.execute_input":"2025-03-07T05:10:36.003546Z","iopub.status.idle":"2025-03-07T05:53:34.330416Z","execution_failed":"2025-03-07T05:54:25.148Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7565 - val_accuracy: 0.6053 - val_loss: 1.7111\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7477 - val_accuracy: 0.6056 - val_loss: 1.6993\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7429 - val_accuracy: 0.6055 - val_loss: 1.6982\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7391 - val_accuracy: 0.6055 - val_loss: 1.6973\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7358 - val_accuracy: 0.6052 - val_loss: 1.6958\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7327 - val_accuracy: 0.6051 - val_loss: 1.6961\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7832 - loss: 0.7299 - val_accuracy: 0.6058 - val_loss: 1.6966\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7273 - val_accuracy: 0.6058 - val_loss: 1.7009\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7249 - val_accuracy: 0.6058 - val_loss: 1.6974\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7227 - val_accuracy: 0.6058 - val_loss: 1.6980\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7207 - val_accuracy: 0.6058 - val_loss: 1.7013\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7835 - loss: 0.7189 - val_accuracy: 0.6058 - val_loss: 1.7016\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.61012\n726/726 - 7s - 10ms/step - accuracy: 0.7836 - loss: 0.7172 - val_accuracy: 0.6059 - val_loss: 1.6977\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7912 - loss: 0.7157 - val_accuracy: 0.6059 - val_loss: 1.6966\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7949 - loss: 0.7143 - val_accuracy: 0.6059 - val_loss: 1.7018\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7949 - loss: 0.7130 - val_accuracy: 0.6059 - val_loss: 1.7056\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7118 - val_accuracy: 0.6058 - val_loss: 1.7036\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7107 - val_accuracy: 0.6046 - val_loss: 1.7095\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7097 - val_accuracy: 0.6046 - val_loss: 1.7052\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7088 - val_accuracy: 0.6046 - val_loss: 1.7050\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7080 - val_accuracy: 0.6046 - val_loss: 1.7065\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7072 - val_accuracy: 0.6046 - val_loss: 1.7075\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7065 - val_accuracy: 0.6045 - val_loss: 1.7078\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7059 - val_accuracy: 0.6045 - val_loss: 1.7079\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.7053 - val_accuracy: 0.6046 - val_loss: 1.7113\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.7047 - val_accuracy: 0.6046 - val_loss: 1.7063\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.7042 - val_accuracy: 0.6046 - val_loss: 1.7064\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.7037 - val_accuracy: 0.6046 - val_loss: 1.7060\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.7032 - val_accuracy: 0.6046 - val_loss: 1.7079\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.7028 - val_accuracy: 0.6046 - val_loss: 1.7072\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.7023 - val_accuracy: 0.6046 - val_loss: 1.7033\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.7019 - val_accuracy: 0.6046 - val_loss: 1.7050\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.7015 - val_accuracy: 0.6052 - val_loss: 1.7045\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7012 - val_accuracy: 0.6051 - val_loss: 1.7062\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.7008 - val_accuracy: 0.6051 - val_loss: 1.7059\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7005 - val_accuracy: 0.6051 - val_loss: 1.7002\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.7002 - val_accuracy: 0.6051 - val_loss: 1.7062\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6998 - val_accuracy: 0.6051 - val_loss: 1.7062\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6995 - val_accuracy: 0.6051 - val_loss: 1.7038\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6992 - val_accuracy: 0.6051 - val_loss: 1.7052\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6990 - val_accuracy: 0.6051 - val_loss: 1.7035\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7961 - loss: 0.6987 - val_accuracy: 0.6051 - val_loss: 1.7063\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6984 - val_accuracy: 0.6051 - val_loss: 1.7052\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6982 - val_accuracy: 0.6052 - val_loss: 1.7048\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6979 - val_accuracy: 0.6052 - val_loss: 1.7002\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6977 - val_accuracy: 0.6052 - val_loss: 1.7010\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6975 - val_accuracy: 0.6052 - val_loss: 1.7005\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6972 - val_accuracy: 0.6053 - val_loss: 1.7004\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6970 - val_accuracy: 0.6053 - val_loss: 1.6997\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6968 - val_accuracy: 0.6053 - val_loss: 1.6992\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6966 - val_accuracy: 0.6053 - val_loss: 1.7014\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6964 - val_accuracy: 0.6053 - val_loss: 1.6995\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6962 - val_accuracy: 0.6051 - val_loss: 1.7015\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6960 - val_accuracy: 0.6051 - val_loss: 1.7004\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6958 - val_accuracy: 0.6053 - val_loss: 1.7001\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6956 - val_accuracy: 0.6051 - val_loss: 1.6996\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6955 - val_accuracy: 0.6048 - val_loss: 1.7029\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6953 - val_accuracy: 0.6050 - val_loss: 1.6960\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6951 - val_accuracy: 0.6048 - val_loss: 1.6998\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6950 - val_accuracy: 0.6052 - val_loss: 1.6998\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7962 - loss: 0.6948 - val_accuracy: 0.6052 - val_loss: 1.6994\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7962 - loss: 0.6947 - val_accuracy: 0.6052 - val_loss: 1.7015\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.6945 - val_accuracy: 0.6055 - val_loss: 1.6968\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.6944 - val_accuracy: 0.6054 - val_loss: 1.6977\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7963 - loss: 0.6942 - val_accuracy: 0.6054 - val_loss: 1.6980\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6941 - val_accuracy: 0.6052 - val_loss: 1.6989\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6939 - val_accuracy: 0.6054 - val_loss: 1.6962\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6938 - val_accuracy: 0.6054 - val_loss: 1.6989\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6937 - val_accuracy: 0.6052 - val_loss: 1.7045\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6935 - val_accuracy: 0.6052 - val_loss: 1.6990\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6934 - val_accuracy: 0.6052 - val_loss: 1.6990\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6933 - val_accuracy: 0.6052 - val_loss: 1.7005\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6932 - val_accuracy: 0.6052 - val_loss: 1.6990\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6930 - val_accuracy: 0.6052 - val_loss: 1.6990\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6929 - val_accuracy: 0.6052 - val_loss: 1.6969\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6928 - val_accuracy: 0.6052 - val_loss: 1.7005\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6927 - val_accuracy: 0.6052 - val_loss: 1.6993\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6926 - val_accuracy: 0.6052 - val_loss: 1.6997\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6925 - val_accuracy: 0.6052 - val_loss: 1.6972\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6924 - val_accuracy: 0.6052 - val_loss: 1.6983\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6923 - val_accuracy: 0.6055 - val_loss: 1.6984\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7964 - loss: 0.6921 - val_accuracy: 0.6052 - val_loss: 1.6993\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6920 - val_accuracy: 0.6052 - val_loss: 1.6963\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6919 - val_accuracy: 0.6052 - val_loss: 1.6989\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6918 - val_accuracy: 0.6055 - val_loss: 1.6935\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6917 - val_accuracy: 0.6052 - val_loss: 1.7003\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6916 - val_accuracy: 0.6052 - val_loss: 1.6975\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7964 - loss: 0.6915 - val_accuracy: 0.6051 - val_loss: 1.6998\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6914 - val_accuracy: 0.6051 - val_loss: 1.6996\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6914 - val_accuracy: 0.6051 - val_loss: 1.6993\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6913 - val_accuracy: 0.6051 - val_loss: 1.7003\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6912 - val_accuracy: 0.6051 - val_loss: 1.7010\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6911 - val_accuracy: 0.6051 - val_loss: 1.6977\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7965 - loss: 0.6910 - val_accuracy: 0.6051 - val_loss: 1.7031\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6909 - val_accuracy: 0.6052 - val_loss: 1.6997\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.6908 - val_accuracy: 0.6051 - val_loss: 1.7010\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6907 - val_accuracy: 0.6052 - val_loss: 1.7005\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7964 - loss: 0.6907 - val_accuracy: 0.6052 - val_loss: 1.6992\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7965 - loss: 0.6906 - val_accuracy: 0.6053 - val_loss: 1.6991\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.6905 - val_accuracy: 0.6052 - val_loss: 1.7001\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6904 - val_accuracy: 0.6054 - val_loss: 1.6978\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6903 - val_accuracy: 0.6054 - val_loss: 1.7013\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6903 - val_accuracy: 0.6054 - val_loss: 1.7019\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6902 - val_accuracy: 0.6054 - val_loss: 1.6997\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6901 - val_accuracy: 0.6055 - val_loss: 1.6990\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6900 - val_accuracy: 0.6056 - val_loss: 1.6995\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7968 - loss: 0.6899 - val_accuracy: 0.6054 - val_loss: 1.7036\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6899 - val_accuracy: 0.6054 - val_loss: 1.7051\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7968 - loss: 0.6898 - val_accuracy: 0.6056 - val_loss: 1.7019\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.6897 - val_accuracy: 0.6057 - val_loss: 1.6997\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.6897 - val_accuracy: 0.6056 - val_loss: 1.7005\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.6896 - val_accuracy: 0.6057 - val_loss: 1.6987\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.7968 - loss: 0.6895 - val_accuracy: 0.6054 - val_loss: 1.7013\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6894 - val_accuracy: 0.6056 - val_loss: 1.7017\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6894 - val_accuracy: 0.6054 - val_loss: 1.7005\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6893 - val_accuracy: 0.6059 - val_loss: 1.6959\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7985 - loss: 0.6892 - val_accuracy: 0.6056 - val_loss: 1.6992\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6892 - val_accuracy: 0.6056 - val_loss: 1.7005\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6891 - val_accuracy: 0.6056 - val_loss: 1.7013\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6890 - val_accuracy: 0.6056 - val_loss: 1.7027\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7983 - loss: 0.6890 - val_accuracy: 0.6058 - val_loss: 1.6984\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.6889 - val_accuracy: 0.6056 - val_loss: 1.7011\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.6888 - val_accuracy: 0.6057 - val_loss: 1.7006\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7984 - loss: 0.6888 - val_accuracy: 0.6057 - val_loss: 1.6995\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.7994 - loss: 0.6887 - val_accuracy: 0.6054 - val_loss: 1.7044\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6887 - val_accuracy: 0.6056 - val_loss: 1.7019\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.6886 - val_accuracy: 0.6055 - val_loss: 1.7036\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7999 - loss: 0.6885 - val_accuracy: 0.6055 - val_loss: 1.6993\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6885 - val_accuracy: 0.6056 - val_loss: 1.7019\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7998 - loss: 0.6884 - val_accuracy: 0.6054 - val_loss: 1.7055\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6883 - val_accuracy: 0.6055 - val_loss: 1.7050\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6883 - val_accuracy: 0.6056 - val_loss: 1.7025\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6882 - val_accuracy: 0.6055 - val_loss: 1.7063\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6882 - val_accuracy: 0.6055 - val_loss: 1.7033\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6881 - val_accuracy: 0.6055 - val_loss: 1.7040\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6881 - val_accuracy: 0.6056 - val_loss: 1.7053\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6880 - val_accuracy: 0.6056 - val_loss: 1.7033\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8006 - loss: 0.6879 - val_accuracy: 0.6056 - val_loss: 1.7002\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6879 - val_accuracy: 0.6056 - val_loss: 1.7033\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8001 - loss: 0.6878 - val_accuracy: 0.6056 - val_loss: 1.7027\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6878 - val_accuracy: 0.6056 - val_loss: 1.7036\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6877 - val_accuracy: 0.6055 - val_loss: 1.7072\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6877 - val_accuracy: 0.6056 - val_loss: 1.7033\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6876 - val_accuracy: 0.6056 - val_loss: 1.7047\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6875 - val_accuracy: 0.6055 - val_loss: 1.7055\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6875 - val_accuracy: 0.6056 - val_loss: 1.7040\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6874 - val_accuracy: 0.6056 - val_loss: 1.7047\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6874 - val_accuracy: 0.6056 - val_loss: 1.7043\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6873 - val_accuracy: 0.6056 - val_loss: 1.7030\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6873 - val_accuracy: 0.6056 - val_loss: 1.7032\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6872 - val_accuracy: 0.6056 - val_loss: 1.7043\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6872 - val_accuracy: 0.6056 - val_loss: 1.7045\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6871 - val_accuracy: 0.6056 - val_loss: 1.7027\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6871 - val_accuracy: 0.6056 - val_loss: 1.7064\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6870 - val_accuracy: 0.6057 - val_loss: 1.7043\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6870 - val_accuracy: 0.6058 - val_loss: 1.7033\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6869 - val_accuracy: 0.6058 - val_loss: 1.7043\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6869 - val_accuracy: 0.6057 - val_loss: 1.7030\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6868 - val_accuracy: 0.6058 - val_loss: 1.7047\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6868 - val_accuracy: 0.6057 - val_loss: 1.7021\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6867 - val_accuracy: 0.6058 - val_loss: 1.7037\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6867 - val_accuracy: 0.6057 - val_loss: 1.7057\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6866 - val_accuracy: 0.6056 - val_loss: 1.7086\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6866 - val_accuracy: 0.6060 - val_loss: 1.7045\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6865 - val_accuracy: 0.6058 - val_loss: 1.7007\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6865 - val_accuracy: 0.6056 - val_loss: 1.7073\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6865 - val_accuracy: 0.6057 - val_loss: 1.7069\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6864 - val_accuracy: 0.6060 - val_loss: 1.7044\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6864 - val_accuracy: 0.6058 - val_loss: 1.7049\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6863 - val_accuracy: 0.6058 - val_loss: 1.7047\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6863 - val_accuracy: 0.6058 - val_loss: 1.7061\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6862 - val_accuracy: 0.6060 - val_loss: 1.7022\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6862 - val_accuracy: 0.6058 - val_loss: 1.7062\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6861 - val_accuracy: 0.6058 - val_loss: 1.7029\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6861 - val_accuracy: 0.6058 - val_loss: 1.7048\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6860 - val_accuracy: 0.6058 - val_loss: 1.7053\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6860 - val_accuracy: 0.6060 - val_loss: 1.7054\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6860 - val_accuracy: 0.6058 - val_loss: 1.7057\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6859 - val_accuracy: 0.6058 - val_loss: 1.7082\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6859 - val_accuracy: 0.6058 - val_loss: 1.7061\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6858 - val_accuracy: 0.6058 - val_loss: 1.7003\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6858 - val_accuracy: 0.6060 - val_loss: 1.7032\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6857 - val_accuracy: 0.6058 - val_loss: 1.7049\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6857 - val_accuracy: 0.6058 - val_loss: 1.7084\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6857 - val_accuracy: 0.6058 - val_loss: 1.7052\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6856 - val_accuracy: 0.6058 - val_loss: 1.7055\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6856 - val_accuracy: 0.6057 - val_loss: 1.7067\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6855 - val_accuracy: 0.6058 - val_loss: 1.7047\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6855 - val_accuracy: 0.6058 - val_loss: 1.7050\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6854 - val_accuracy: 0.6057 - val_loss: 1.7078\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6854 - val_accuracy: 0.6058 - val_loss: 1.7046\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6854 - val_accuracy: 0.6059 - val_loss: 1.7073\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6853 - val_accuracy: 0.6059 - val_loss: 1.7057\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6853 - val_accuracy: 0.6056 - val_loss: 1.7088\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6852 - val_accuracy: 0.6057 - val_loss: 1.7071\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6852 - val_accuracy: 0.6057 - val_loss: 1.7078\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6852 - val_accuracy: 0.6057 - val_loss: 1.7052\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6851 - val_accuracy: 0.6057 - val_loss: 1.7059\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6851 - val_accuracy: 0.6057 - val_loss: 1.7077\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6850 - val_accuracy: 0.6059 - val_loss: 1.7049\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6850 - val_accuracy: 0.6056 - val_loss: 1.7111\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6850 - val_accuracy: 0.6057 - val_loss: 1.7062\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6849 - val_accuracy: 0.6056 - val_loss: 1.7101\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.6849 - val_accuracy: 0.6057 - val_loss: 1.7054\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6849 - val_accuracy: 0.6057 - val_loss: 1.7058\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6848 - val_accuracy: 0.6057 - val_loss: 1.7074\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6848 - val_accuracy: 0.6059 - val_loss: 1.7084\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6847 - val_accuracy: 0.6047 - val_loss: 1.7094\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6847 - val_accuracy: 0.6059 - val_loss: 1.7052\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6847 - val_accuracy: 0.6047 - val_loss: 1.7096\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6846 - val_accuracy: 0.6047 - val_loss: 1.7083\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6846 - val_accuracy: 0.6056 - val_loss: 1.7074\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6846 - val_accuracy: 0.6049 - val_loss: 1.7067\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6845 - val_accuracy: 0.6049 - val_loss: 1.7034\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8010 - loss: 0.6845 - val_accuracy: 0.6047 - val_loss: 1.7077\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6844 - val_accuracy: 0.6047 - val_loss: 1.7096\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8009 - loss: 0.6844 - val_accuracy: 0.6047 - val_loss: 1.7066\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6844 - val_accuracy: 0.6047 - val_loss: 1.7090\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6843 - val_accuracy: 0.6047 - val_loss: 1.7065\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6843 - val_accuracy: 0.6048 - val_loss: 1.7080\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6843 - val_accuracy: 0.6047 - val_loss: 1.7074\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6842 - val_accuracy: 0.6045 - val_loss: 1.7096\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6842 - val_accuracy: 0.6045 - val_loss: 1.7112\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6841 - val_accuracy: 0.6047 - val_loss: 1.7073\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6841 - val_accuracy: 0.6047 - val_loss: 1.7082\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6841 - val_accuracy: 0.6046 - val_loss: 1.7127\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6840 - val_accuracy: 0.6047 - val_loss: 1.7095\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6840 - val_accuracy: 0.6047 - val_loss: 1.7089\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8008 - loss: 0.6840 - val_accuracy: 0.6047 - val_loss: 1.7063\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6839 - val_accuracy: 0.6047 - val_loss: 1.7095\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6839 - val_accuracy: 0.6048 - val_loss: 1.7100\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6839 - val_accuracy: 0.6048 - val_loss: 1.7084\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6838 - val_accuracy: 0.6047 - val_loss: 1.7059\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6838 - val_accuracy: 0.6047 - val_loss: 1.7110\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6838 - val_accuracy: 0.6047 - val_loss: 1.7102\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6837 - val_accuracy: 0.6047 - val_loss: 1.7083\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6837 - val_accuracy: 0.6046 - val_loss: 1.7103\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6837 - val_accuracy: 0.6047 - val_loss: 1.7104\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6836 - val_accuracy: 0.6047 - val_loss: 1.7141\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6836 - val_accuracy: 0.6046 - val_loss: 1.7088\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8008 - loss: 0.6836 - val_accuracy: 0.6049 - val_loss: 1.7071\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6835 - val_accuracy: 0.6047 - val_loss: 1.7084\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6835 - val_accuracy: 0.6049 - val_loss: 1.7071\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6835 - val_accuracy: 0.6046 - val_loss: 1.7126\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6834 - val_accuracy: 0.6049 - val_loss: 1.7083\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6834 - val_accuracy: 0.6047 - val_loss: 1.7090\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6834 - val_accuracy: 0.6047 - val_loss: 1.7091\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6833 - val_accuracy: 0.6047 - val_loss: 1.7102\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6833 - val_accuracy: 0.6046 - val_loss: 1.7138\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6833 - val_accuracy: 0.6046 - val_loss: 1.7089\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6832 - val_accuracy: 0.6046 - val_loss: 1.7089\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6832 - val_accuracy: 0.6047 - val_loss: 1.7124\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.6832 - val_accuracy: 0.6049 - val_loss: 1.7070\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6831 - val_accuracy: 0.6046 - val_loss: 1.7126\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6831 - val_accuracy: 0.6047 - val_loss: 1.7108\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6831 - val_accuracy: 0.6049 - val_loss: 1.7115\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6830 - val_accuracy: 0.6049 - val_loss: 1.7093\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6830 - val_accuracy: 0.6049 - val_loss: 1.7073\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6830 - val_accuracy: 0.6047 - val_loss: 1.7108\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6830 - val_accuracy: 0.6045 - val_loss: 1.7118\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6829 - val_accuracy: 0.6045 - val_loss: 1.7101\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6829 - val_accuracy: 0.6045 - val_loss: 1.7087\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6829 - val_accuracy: 0.6044 - val_loss: 1.7112\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6828 - val_accuracy: 0.6048 - val_loss: 1.7074\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6828 - val_accuracy: 0.6046 - val_loss: 1.7109\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6828 - val_accuracy: 0.6046 - val_loss: 1.7095\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6827 - val_accuracy: 0.6045 - val_loss: 1.7127\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6827 - val_accuracy: 0.6044 - val_loss: 1.7116\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6827 - val_accuracy: 0.6047 - val_loss: 1.7105\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6826 - val_accuracy: 0.6045 - val_loss: 1.7113\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6826 - val_accuracy: 0.6047 - val_loss: 1.7065\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6826 - val_accuracy: 0.6047 - val_loss: 1.7084\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6826 - val_accuracy: 0.6045 - val_loss: 1.7084\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6825 - val_accuracy: 0.6045 - val_loss: 1.7105\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.6825 - val_accuracy: 0.6047 - val_loss: 1.7083\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6825 - val_accuracy: 0.6046 - val_loss: 1.7101\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6824 - val_accuracy: 0.6047 - val_loss: 1.7089\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6824 - val_accuracy: 0.6044 - val_loss: 1.7104\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6824 - val_accuracy: 0.6047 - val_loss: 1.7097\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6823 - val_accuracy: 0.6044 - val_loss: 1.7112\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6823 - val_accuracy: 0.6045 - val_loss: 1.7120\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6823 - val_accuracy: 0.6044 - val_loss: 1.7117\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6823 - val_accuracy: 0.6043 - val_loss: 1.7148\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.61012\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.6822 - val_accuracy: 0.6043 - val_loss: 1.7117\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6822 - val_accuracy: 0.6045 - val_loss: 1.7073\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6822 - val_accuracy: 0.6045 - val_loss: 1.7108\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6821 - val_accuracy: 0.6047 - val_loss: 1.7078\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6821 - val_accuracy: 0.6047 - val_loss: 1.7119\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6821 - val_accuracy: 0.6043 - val_loss: 1.7129\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6821 - val_accuracy: 0.6048 - val_loss: 1.7065\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.6820 - val_accuracy: 0.6044 - val_loss: 1.7116\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6820 - val_accuracy: 0.6043 - val_loss: 1.7123\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6820 - val_accuracy: 0.6044 - val_loss: 1.7096\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6819 - val_accuracy: 0.6043 - val_loss: 1.7115\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6819 - val_accuracy: 0.6043 - val_loss: 1.7121\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6819 - val_accuracy: 0.6043 - val_loss: 1.7129\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6819 - val_accuracy: 0.6047 - val_loss: 1.7102\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6818 - val_accuracy: 0.6046 - val_loss: 1.7090\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6818 - val_accuracy: 0.6014 - val_loss: 1.7120\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6818 - val_accuracy: 0.6043 - val_loss: 1.7117\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6817 - val_accuracy: 0.6043 - val_loss: 1.7154\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6817 - val_accuracy: 0.6043 - val_loss: 1.7127\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6817 - val_accuracy: 0.6043 - val_loss: 1.7118\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6817 - val_accuracy: 0.6012 - val_loss: 1.7144\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6816 - val_accuracy: 0.6047 - val_loss: 1.7093\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6816 - val_accuracy: 0.6043 - val_loss: 1.7148\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6816 - val_accuracy: 0.6016 - val_loss: 1.7121\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6816 - val_accuracy: 0.6041 - val_loss: 1.7152\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6815 - val_accuracy: 0.6043 - val_loss: 1.7122\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6815 - val_accuracy: 0.6048 - val_loss: 1.7066\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6815 - val_accuracy: 0.6012 - val_loss: 1.7135\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6814 - val_accuracy: 0.6012 - val_loss: 1.7153\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6814 - val_accuracy: 0.6045 - val_loss: 1.7116\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6814 - val_accuracy: 0.6044 - val_loss: 1.7114\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6814 - val_accuracy: 0.6047 - val_loss: 1.7103\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6813 - val_accuracy: 0.6042 - val_loss: 1.7119\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6813 - val_accuracy: 0.6012 - val_loss: 1.7135\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6813 - val_accuracy: 0.6017 - val_loss: 1.7121\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6813 - val_accuracy: 0.6017 - val_loss: 1.7122\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6812 - val_accuracy: 0.6047 - val_loss: 1.7105\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6812 - val_accuracy: 0.6016 - val_loss: 1.7131\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6812 - val_accuracy: 0.6012 - val_loss: 1.7131\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6812 - val_accuracy: 0.6012 - val_loss: 1.7152\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6811 - val_accuracy: 0.6046 - val_loss: 1.7122\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6811 - val_accuracy: 0.6012 - val_loss: 1.7141\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6811 - val_accuracy: 0.6013 - val_loss: 1.7152\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6811 - val_accuracy: 0.6012 - val_loss: 1.7143\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6810 - val_accuracy: 0.6018 - val_loss: 1.7088\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6810 - val_accuracy: 0.6014 - val_loss: 1.7144\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6810 - val_accuracy: 0.6019 - val_loss: 1.7095\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6810 - val_accuracy: 0.6012 - val_loss: 1.7156\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6809 - val_accuracy: 0.6017 - val_loss: 1.7138\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6809 - val_accuracy: 0.6015 - val_loss: 1.7154\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6809 - val_accuracy: 0.6019 - val_loss: 1.7094\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6808 - val_accuracy: 0.6015 - val_loss: 1.7133\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6808 - val_accuracy: 0.6017 - val_loss: 1.7141\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6808 - val_accuracy: 0.6017 - val_loss: 1.7139\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6808 - val_accuracy: 0.6017 - val_loss: 1.7150\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6807 - val_accuracy: 0.6017 - val_loss: 1.7157\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6807 - val_accuracy: 0.6017 - val_loss: 1.7133\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6807 - val_accuracy: 0.6017 - val_loss: 1.7157\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6807 - val_accuracy: 0.6015 - val_loss: 1.7140\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6806 - val_accuracy: 0.6018 - val_loss: 1.7146\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6806 - val_accuracy: 0.6017 - val_loss: 1.7112\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6806 - val_accuracy: 0.6017 - val_loss: 1.7156\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6806 - val_accuracy: 0.6018 - val_loss: 1.7137\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6805 - val_accuracy: 0.6015 - val_loss: 1.7166\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6805 - val_accuracy: 0.6017 - val_loss: 1.7146\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6805 - val_accuracy: 0.6017 - val_loss: 1.7150\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6805 - val_accuracy: 0.6018 - val_loss: 1.7121\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6804 - val_accuracy: 0.6015 - val_loss: 1.7131\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6804 - val_accuracy: 0.6018 - val_loss: 1.7124\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6804 - val_accuracy: 0.6017 - val_loss: 1.7146\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6804 - val_accuracy: 0.6017 - val_loss: 1.7121\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6804 - val_accuracy: 0.6015 - val_loss: 1.7167\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6803 - val_accuracy: 0.6017 - val_loss: 1.7144\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6803 - val_accuracy: 0.6018 - val_loss: 1.7128\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6803 - val_accuracy: 0.6017 - val_loss: 1.7127\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6803 - val_accuracy: 0.6017 - val_loss: 1.7124\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6802 - val_accuracy: 0.6015 - val_loss: 1.7154\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6802 - val_accuracy: 0.6017 - val_loss: 1.7123\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6802 - val_accuracy: 0.6013 - val_loss: 1.7161\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6802 - val_accuracy: 0.6015 - val_loss: 1.7150\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6801 - val_accuracy: 0.6013 - val_loss: 1.7167\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6801 - val_accuracy: 0.6016 - val_loss: 1.7119\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6801 - val_accuracy: 0.6015 - val_loss: 1.7155\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6801 - val_accuracy: 0.6012 - val_loss: 1.7194\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6800 - val_accuracy: 0.6013 - val_loss: 1.7162\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6800 - val_accuracy: 0.6015 - val_loss: 1.7110\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6800 - val_accuracy: 0.6014 - val_loss: 1.7148\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8005 - loss: 0.6800 - val_accuracy: 0.6015 - val_loss: 1.7149\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6799 - val_accuracy: 0.6015 - val_loss: 1.7138\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6799 - val_accuracy: 0.6015 - val_loss: 1.7152\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6799 - val_accuracy: 0.6013 - val_loss: 1.7150\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6799 - val_accuracy: 0.6015 - val_loss: 1.7138\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6799 - val_accuracy: 0.6016 - val_loss: 1.7128\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6798 - val_accuracy: 0.6015 - val_loss: 1.7146\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6798 - val_accuracy: 0.6012 - val_loss: 1.7162\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6798 - val_accuracy: 0.6015 - val_loss: 1.7155\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6798 - val_accuracy: 0.6016 - val_loss: 1.7127\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6797 - val_accuracy: 0.6014 - val_loss: 1.7165\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6797 - val_accuracy: 0.6016 - val_loss: 1.7137\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8004 - loss: 0.6797 - val_accuracy: 0.6014 - val_loss: 1.7158\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6797 - val_accuracy: 0.6014 - val_loss: 1.7171\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6796 - val_accuracy: 0.6014 - val_loss: 1.7174\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6796 - val_accuracy: 0.6015 - val_loss: 1.7155\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6796 - val_accuracy: 0.6014 - val_loss: 1.7178\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6796 - val_accuracy: 0.6014 - val_loss: 1.7143\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6796 - val_accuracy: 0.6014 - val_loss: 1.7157\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6795 - val_accuracy: 0.6012 - val_loss: 1.7158\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6795 - val_accuracy: 0.6010 - val_loss: 1.7167\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6795 - val_accuracy: 0.6012 - val_loss: 1.7153\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6795 - val_accuracy: 0.6010 - val_loss: 1.7177\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6794 - val_accuracy: 0.6012 - val_loss: 1.7162\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6794 - val_accuracy: 0.6010 - val_loss: 1.7197\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6794 - val_accuracy: 0.6010 - val_loss: 1.7158\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6794 - val_accuracy: 0.6012 - val_loss: 1.7156\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6794 - val_accuracy: 0.6012 - val_loss: 1.7139\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8003 - loss: 0.6793 - val_accuracy: 0.6010 - val_loss: 1.7147\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6793 - val_accuracy: 0.6010 - val_loss: 1.7188\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6793 - val_accuracy: 0.6012 - val_loss: 1.7135\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6793 - val_accuracy: 0.6012 - val_loss: 1.7159\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6792 - val_accuracy: 0.6012 - val_loss: 1.7136\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6792 - val_accuracy: 0.6010 - val_loss: 1.7155\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6792 - val_accuracy: 0.6012 - val_loss: 1.7192\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6792 - val_accuracy: 0.6012 - val_loss: 1.7169\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6791 - val_accuracy: 0.6012 - val_loss: 1.7170\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6791 - val_accuracy: 0.6013 - val_loss: 1.7136\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6791 - val_accuracy: 0.6010 - val_loss: 1.7186\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6791 - val_accuracy: 0.6013 - val_loss: 1.7129\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6791 - val_accuracy: 0.6012 - val_loss: 1.7163\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8003 - loss: 0.6790 - val_accuracy: 0.6012 - val_loss: 1.7163\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6790 - val_accuracy: 0.6011 - val_loss: 1.7188\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6790 - val_accuracy: 0.6012 - val_loss: 1.7150\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6790 - val_accuracy: 0.6012 - val_loss: 1.7150\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6790 - val_accuracy: 0.6010 - val_loss: 1.7167\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6789 - val_accuracy: 0.6012 - val_loss: 1.7183\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6789 - val_accuracy: 0.6009 - val_loss: 1.7182\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6789 - val_accuracy: 0.6012 - val_loss: 1.7175\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6789 - val_accuracy: 0.6012 - val_loss: 1.7194\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6788 - val_accuracy: 0.6010 - val_loss: 1.7149\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6788 - val_accuracy: 0.6011 - val_loss: 1.7156\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6788 - val_accuracy: 0.6011 - val_loss: 1.7173\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6788 - val_accuracy: 0.6011 - val_loss: 1.7177\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6788 - val_accuracy: 0.6011 - val_loss: 1.7191\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6787 - val_accuracy: 0.6012 - val_loss: 1.7170\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6787 - val_accuracy: 0.6011 - val_loss: 1.7190\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6787 - val_accuracy: 0.6011 - val_loss: 1.7162\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6787 - val_accuracy: 0.6011 - val_loss: 1.7181\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6787 - val_accuracy: 0.6013 - val_loss: 1.7141\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6786 - val_accuracy: 0.6009 - val_loss: 1.7192\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6786 - val_accuracy: 0.6009 - val_loss: 1.7180\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6786 - val_accuracy: 0.6012 - val_loss: 1.7178\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6786 - val_accuracy: 0.6012 - val_loss: 1.7163\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6786 - val_accuracy: 0.6012 - val_loss: 1.7178\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6785 - val_accuracy: 0.6012 - val_loss: 1.7185\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6785 - val_accuracy: 0.6012 - val_loss: 1.7154\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6785 - val_accuracy: 0.6012 - val_loss: 1.7179\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6785 - val_accuracy: 0.6008 - val_loss: 1.7220\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6784 - val_accuracy: 0.6010 - val_loss: 1.7171\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6784 - val_accuracy: 0.6012 - val_loss: 1.7186\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6784 - val_accuracy: 0.6012 - val_loss: 1.7180\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6784 - val_accuracy: 0.6012 - val_loss: 1.7155\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6784 - val_accuracy: 0.6010 - val_loss: 1.7197\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6783 - val_accuracy: 0.6012 - val_loss: 1.7211\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6783 - val_accuracy: 0.6012 - val_loss: 1.7221\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6783 - val_accuracy: 0.6012 - val_loss: 1.7188\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6783 - val_accuracy: 0.6012 - val_loss: 1.7197\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6783 - val_accuracy: 0.6008 - val_loss: 1.7195\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6782 - val_accuracy: 0.6012 - val_loss: 1.7183\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6782 - val_accuracy: 0.6012 - val_loss: 1.7136\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6782 - val_accuracy: 0.6010 - val_loss: 1.7184\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6782 - val_accuracy: 0.6012 - val_loss: 1.7189\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6782 - val_accuracy: 0.6012 - val_loss: 1.7172\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6781 - val_accuracy: 0.6012 - val_loss: 1.7174\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6781 - val_accuracy: 0.6010 - val_loss: 1.7198\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6781 - val_accuracy: 0.6012 - val_loss: 1.7195\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6781 - val_accuracy: 0.6012 - val_loss: 1.7185\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6781 - val_accuracy: 0.6010 - val_loss: 1.7205\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6780 - val_accuracy: 0.6012 - val_loss: 1.7191\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6780 - val_accuracy: 0.6012 - val_loss: 1.7148\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6780 - val_accuracy: 0.6012 - val_loss: 1.7175\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.61012\n726/726 - 5s - 8ms/step - accuracy: 0.8003 - loss: 0.6780 - val_accuracy: 0.6012 - val_loss: 1.7182\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6780 - val_accuracy: 0.6010 - val_loss: 1.7184\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6779 - val_accuracy: 0.6012 - val_loss: 1.7151\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6779 - val_accuracy: 0.6012 - val_loss: 1.7204\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6779 - val_accuracy: 0.6012 - val_loss: 1.7191\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6779 - val_accuracy: 0.6007 - val_loss: 1.7234\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6779 - val_accuracy: 0.6012 - val_loss: 1.7193\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6778 - val_accuracy: 0.6012 - val_loss: 1.7189\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6778 - val_accuracy: 0.6012 - val_loss: 1.7173\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6778 - val_accuracy: 0.6012 - val_loss: 1.7181\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6778 - val_accuracy: 0.6012 - val_loss: 1.7184\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6778 - val_accuracy: 0.6012 - val_loss: 1.7202\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6777 - val_accuracy: 0.6012 - val_loss: 1.7145\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6777 - val_accuracy: 0.6012 - val_loss: 1.7192\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6777 - val_accuracy: 0.6012 - val_loss: 1.7198\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6777 - val_accuracy: 0.6007 - val_loss: 1.7236\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6777 - val_accuracy: 0.6012 - val_loss: 1.7196\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6776 - val_accuracy: 0.6012 - val_loss: 1.7206\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6776 - val_accuracy: 0.6012 - val_loss: 1.7198\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6776 - val_accuracy: 0.6012 - val_loss: 1.7154\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6776 - val_accuracy: 0.6012 - val_loss: 1.7175\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6776 - val_accuracy: 0.6012 - val_loss: 1.7187\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6775 - val_accuracy: 0.6007 - val_loss: 1.7192\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6775 - val_accuracy: 0.6012 - val_loss: 1.7173\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6775 - val_accuracy: 0.6012 - val_loss: 1.7213\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6775 - val_accuracy: 0.6012 - val_loss: 1.7171\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6775 - val_accuracy: 0.6011 - val_loss: 1.7241\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6775 - val_accuracy: 0.6011 - val_loss: 1.7215\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6774 - val_accuracy: 0.6012 - val_loss: 1.7183\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6774 - val_accuracy: 0.6012 - val_loss: 1.7184\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6774 - val_accuracy: 0.6011 - val_loss: 1.7212\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8003 - loss: 0.6774 - val_accuracy: 0.6011 - val_loss: 1.7212\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6774 - val_accuracy: 0.6012 - val_loss: 1.7196\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6773 - val_accuracy: 0.6011 - val_loss: 1.7168\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6773 - val_accuracy: 0.6012 - val_loss: 1.7188\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6773 - val_accuracy: 0.6012 - val_loss: 1.7176\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6773 - val_accuracy: 0.6012 - val_loss: 1.7203\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.61012\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6773 - val_accuracy: 0.6011 - val_loss: 1.7237\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_15, X_test_15, y_train_15, y_test_15 = train_test_split(\n    X, y, test_size=0.3, random_state=57, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_15, X_val_15, y_train_15, y_val_15 = train_test_split(\n    X_train_15, y_train_15, test_size=0.2, random_state=57, stratify=y_train_15\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_15:\", np.max(X_train_15))\nprint(\"Min value in X_train_15:\", np.min(X_train_15))\n\nX_train_15_scaled = scaler.fit_transform(X_train_15)\n\n# Get the original class distribution\nclass_counts_15 = Counter(y_train_15)\nprint(\"Original class distribution:\", class_counts_15)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_15 = class_counts_15[min(class_counts_15, key=class_counts_15.get)]\ndesired_majority_size_15 = minority_class_size_15 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_15 = {0: desired_majority_size_15, 1: minority_class_size_15}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_15 = RandomUnderSampler(sampling_strategy=sampling_strategy_15, random_state=42)\nX_resampled_15, y_resampled_15 = undersampler_15.fit_resample(X_train_15, y_train_15)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_15))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_15, y_train_resampled_15 = smote.fit_resample(X_resampled_15, y_resampled_15)\n\n\n#Verify the class distribution after SMOTE\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_15))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_15))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T08:24:30.074184Z","iopub.execute_input":"2025-03-07T08:24:30.074768Z","iopub.status.idle":"2025-03-07T08:25:04.949056Z","shell.execute_reply.started":"2025-03-07T08:24:30.074728Z","shell.execute_reply":"2025-03-07T08:25:04.948007Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_15: 2071000000.0\nMin value in X_train_15: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_15 = X_train_resampled_15.reshape(X_train_resampled_15.shape[0], 1, 56)\nX_val_15 = X_val_15.reshape(X_val_15.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_15,  # Features from CICIDS2017\n    y_train_resampled_15,  # Labels from CICIDS2017\n    validation_data=(X_val_15, y_val_15),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T08:25:04.950377Z","iopub.execute_input":"2025-03-07T08:25:04.950789Z","iopub.status.idle":"2025-03-07T09:10:33.586783Z","shell.execute_reply.started":"2025-03-07T08:25:04.950743Z","shell.execute_reply":"2025-03-07T09:10:33.585076Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy improved from -inf to 0.60427, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 8s - 12ms/step - accuracy: 0.7671 - loss: 0.7930 - val_accuracy: 0.6043 - val_loss: 1.7298\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7669 - loss: 0.7892 - val_accuracy: 0.6037 - val_loss: 1.7404\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7670 - loss: 0.7874 - val_accuracy: 0.6032 - val_loss: 1.7514\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.7860 - val_accuracy: 0.6032 - val_loss: 1.7543\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.7849 - val_accuracy: 0.6029 - val_loss: 1.7660\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.7838 - val_accuracy: 0.6028 - val_loss: 1.7705\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.7829 - val_accuracy: 0.6012 - val_loss: 1.7813\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7674 - loss: 0.7820 - val_accuracy: 0.5968 - val_loss: 1.7846\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7812 - val_accuracy: 0.5966 - val_loss: 1.7908\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7804 - val_accuracy: 0.5966 - val_loss: 1.7953\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7797 - val_accuracy: 0.5964 - val_loss: 1.8031\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7790 - val_accuracy: 0.5959 - val_loss: 1.8083\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7783 - val_accuracy: 0.5960 - val_loss: 1.8102\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7777 - val_accuracy: 0.5954 - val_loss: 1.8158\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7650 - loss: 0.7771 - val_accuracy: 0.5954 - val_loss: 1.8144\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7765 - val_accuracy: 0.5950 - val_loss: 1.8234\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7759 - val_accuracy: 0.5950 - val_loss: 1.8231\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7754 - val_accuracy: 0.5943 - val_loss: 1.8222\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7749 - val_accuracy: 0.5941 - val_loss: 1.8297\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7744 - val_accuracy: 0.5941 - val_loss: 1.8352\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7658 - loss: 0.7739 - val_accuracy: 0.5944 - val_loss: 1.8373\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7734 - val_accuracy: 0.5962 - val_loss: 1.8342\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7730 - val_accuracy: 0.5962 - val_loss: 1.8402\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7660 - loss: 0.7726 - val_accuracy: 0.5962 - val_loss: 1.8382\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.7721 - val_accuracy: 0.5952 - val_loss: 1.8429\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7717 - val_accuracy: 0.5951 - val_loss: 1.8463\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7677 - loss: 0.7713 - val_accuracy: 0.5951 - val_loss: 1.8477\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7693 - loss: 0.7709 - val_accuracy: 0.5978 - val_loss: 1.8475\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7706 - loss: 0.7705 - val_accuracy: 0.5977 - val_loss: 1.8488\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7702 - val_accuracy: 0.5976 - val_loss: 1.8521\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7698 - val_accuracy: 0.5975 - val_loss: 1.8526\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7694 - val_accuracy: 0.5969 - val_loss: 1.8541\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7709 - loss: 0.7691 - val_accuracy: 0.5968 - val_loss: 1.8530\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7688 - val_accuracy: 0.5969 - val_loss: 1.8565\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7684 - val_accuracy: 0.5968 - val_loss: 1.8600\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7681 - val_accuracy: 0.5969 - val_loss: 1.8591\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7678 - val_accuracy: 0.5971 - val_loss: 1.8627\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7675 - val_accuracy: 0.5967 - val_loss: 1.8581\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7709 - loss: 0.7672 - val_accuracy: 0.5968 - val_loss: 1.8585\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7669 - val_accuracy: 0.5965 - val_loss: 1.8686\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7666 - val_accuracy: 0.5966 - val_loss: 1.8629\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.7708 - loss: 0.7663 - val_accuracy: 0.5967 - val_loss: 1.8661\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7708 - loss: 0.7661 - val_accuracy: 0.5966 - val_loss: 1.8626\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7708 - loss: 0.7658 - val_accuracy: 0.5966 - val_loss: 1.8675\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.7708 - loss: 0.7655 - val_accuracy: 0.5968 - val_loss: 1.8681\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7710 - loss: 0.7653 - val_accuracy: 0.5967 - val_loss: 1.8680\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7703 - loss: 0.7650 - val_accuracy: 0.5957 - val_loss: 1.8676\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7648 - val_accuracy: 0.5956 - val_loss: 1.8657\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7645 - val_accuracy: 0.5956 - val_loss: 1.8715\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7643 - val_accuracy: 0.5955 - val_loss: 1.8704\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7708 - loss: 0.7640 - val_accuracy: 0.5955 - val_loss: 1.8676\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7638 - val_accuracy: 0.5954 - val_loss: 1.8728\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7709 - loss: 0.7636 - val_accuracy: 0.5951 - val_loss: 1.8721\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7634 - val_accuracy: 0.5951 - val_loss: 1.8720\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7631 - val_accuracy: 0.5951 - val_loss: 1.8718\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7706 - loss: 0.7629 - val_accuracy: 0.5941 - val_loss: 1.8776\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7708 - loss: 0.7627 - val_accuracy: 0.5940 - val_loss: 1.8754\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7625 - val_accuracy: 0.5940 - val_loss: 1.8794\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7703 - loss: 0.7623 - val_accuracy: 0.5940 - val_loss: 1.8756\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7708 - loss: 0.7621 - val_accuracy: 0.5942 - val_loss: 1.8758\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7706 - loss: 0.7619 - val_accuracy: 0.5941 - val_loss: 1.8776\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7707 - loss: 0.7617 - val_accuracy: 0.5940 - val_loss: 1.8780\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7700 - loss: 0.7615 - val_accuracy: 0.5941 - val_loss: 1.8785\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7704 - loss: 0.7613 - val_accuracy: 0.5940 - val_loss: 1.8798\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7700 - loss: 0.7611 - val_accuracy: 0.5941 - val_loss: 1.8786\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7697 - loss: 0.7609 - val_accuracy: 0.5940 - val_loss: 1.8777\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7681 - loss: 0.7607 - val_accuracy: 0.5927 - val_loss: 1.8823\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7687 - loss: 0.7606 - val_accuracy: 0.5928 - val_loss: 1.8808\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7674 - loss: 0.7604 - val_accuracy: 0.5926 - val_loss: 1.8806\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7602 - val_accuracy: 0.5926 - val_loss: 1.8826\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.7600 - val_accuracy: 0.5923 - val_loss: 1.8868\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7599 - val_accuracy: 0.5923 - val_loss: 1.8855\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7597 - val_accuracy: 0.5924 - val_loss: 1.8826\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7650 - loss: 0.7595 - val_accuracy: 0.5925 - val_loss: 1.8833\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7593 - val_accuracy: 0.5924 - val_loss: 1.8865\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7649 - loss: 0.7592 - val_accuracy: 0.5925 - val_loss: 1.8820\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7648 - loss: 0.7590 - val_accuracy: 0.5827 - val_loss: 1.8845\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7589 - val_accuracy: 0.5826 - val_loss: 1.8864\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7643 - loss: 0.7587 - val_accuracy: 0.5823 - val_loss: 1.8863\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7646 - loss: 0.7585 - val_accuracy: 0.5830 - val_loss: 1.8816\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7647 - loss: 0.7584 - val_accuracy: 0.5824 - val_loss: 1.8872\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7582 - val_accuracy: 0.5823 - val_loss: 1.8864\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7647 - loss: 0.7581 - val_accuracy: 0.5820 - val_loss: 1.8895\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7579 - val_accuracy: 0.5820 - val_loss: 1.8910\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7642 - loss: 0.7578 - val_accuracy: 0.5824 - val_loss: 1.8881\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7576 - val_accuracy: 0.5820 - val_loss: 1.8912\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7645 - loss: 0.7575 - val_accuracy: 0.5819 - val_loss: 1.8950\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7649 - loss: 0.7574 - val_accuracy: 0.5820 - val_loss: 1.8922\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7572 - val_accuracy: 0.5823 - val_loss: 1.8914\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7571 - val_accuracy: 0.5824 - val_loss: 1.8918\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7647 - loss: 0.7569 - val_accuracy: 0.5823 - val_loss: 1.8945\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7643 - loss: 0.7568 - val_accuracy: 0.5823 - val_loss: 1.8950\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7646 - loss: 0.7567 - val_accuracy: 0.5823 - val_loss: 1.8962\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7565 - val_accuracy: 0.5820 - val_loss: 1.8935\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7642 - loss: 0.7564 - val_accuracy: 0.5824 - val_loss: 1.8939\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7643 - loss: 0.7563 - val_accuracy: 0.5823 - val_loss: 1.8943\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7561 - val_accuracy: 0.5820 - val_loss: 1.8970\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7645 - loss: 0.7560 - val_accuracy: 0.5823 - val_loss: 1.8959\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7646 - loss: 0.7559 - val_accuracy: 0.5822 - val_loss: 1.8976\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7558 - val_accuracy: 0.5823 - val_loss: 1.9007\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7655 - loss: 0.7556 - val_accuracy: 0.5822 - val_loss: 1.8987\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7651 - loss: 0.7555 - val_accuracy: 0.5823 - val_loss: 1.9005\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7651 - loss: 0.7554 - val_accuracy: 0.5821 - val_loss: 1.8998\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7553 - val_accuracy: 0.5821 - val_loss: 1.9015\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7552 - val_accuracy: 0.5821 - val_loss: 1.8976\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7550 - val_accuracy: 0.5821 - val_loss: 1.9011\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7549 - val_accuracy: 0.5792 - val_loss: 1.9029\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7548 - val_accuracy: 0.5807 - val_loss: 1.9026\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7657 - loss: 0.7547 - val_accuracy: 0.5793 - val_loss: 1.8982\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7654 - loss: 0.7546 - val_accuracy: 0.5787 - val_loss: 1.9057\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7545 - val_accuracy: 0.5807 - val_loss: 1.9022\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7544 - val_accuracy: 0.5801 - val_loss: 1.9049\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7542 - val_accuracy: 0.5800 - val_loss: 1.9029\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7541 - val_accuracy: 0.5801 - val_loss: 1.9081\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7660 - loss: 0.7540 - val_accuracy: 0.5800 - val_loss: 1.9086\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7539 - val_accuracy: 0.5801 - val_loss: 1.9112\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7538 - val_accuracy: 0.5801 - val_loss: 1.9052\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7537 - val_accuracy: 0.5800 - val_loss: 1.9072\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7536 - val_accuracy: 0.5801 - val_loss: 1.9051\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7535 - val_accuracy: 0.5801 - val_loss: 1.9046\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7655 - loss: 0.7534 - val_accuracy: 0.5801 - val_loss: 1.9072\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7533 - val_accuracy: 0.5801 - val_loss: 1.9100\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7532 - val_accuracy: 0.5801 - val_loss: 1.9058\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7531 - val_accuracy: 0.5801 - val_loss: 1.9093\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7530 - val_accuracy: 0.5801 - val_loss: 1.9113\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7529 - val_accuracy: 0.5801 - val_loss: 1.9114\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7528 - val_accuracy: 0.5801 - val_loss: 1.9112\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7647 - loss: 0.7527 - val_accuracy: 0.5801 - val_loss: 1.9087\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7526 - val_accuracy: 0.5801 - val_loss: 1.9139\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7525 - val_accuracy: 0.5800 - val_loss: 1.9107\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7524 - val_accuracy: 0.5799 - val_loss: 1.9118\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7523 - val_accuracy: 0.5796 - val_loss: 1.9102\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7522 - val_accuracy: 0.5796 - val_loss: 1.9120\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7646 - loss: 0.7521 - val_accuracy: 0.5797 - val_loss: 1.9143\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7521 - val_accuracy: 0.5796 - val_loss: 1.9119\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7520 - val_accuracy: 0.5797 - val_loss: 1.9153\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7519 - val_accuracy: 0.5797 - val_loss: 1.9139\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7518 - val_accuracy: 0.5797 - val_loss: 1.9126\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7517 - val_accuracy: 0.5795 - val_loss: 1.9126\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7652 - loss: 0.7516 - val_accuracy: 0.5794 - val_loss: 1.9181\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7515 - val_accuracy: 0.5794 - val_loss: 1.9164\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7514 - val_accuracy: 0.5795 - val_loss: 1.9163\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7514 - val_accuracy: 0.5794 - val_loss: 1.9188\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7513 - val_accuracy: 0.5795 - val_loss: 1.9173\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7647 - loss: 0.7512 - val_accuracy: 0.5796 - val_loss: 1.9171\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7511 - val_accuracy: 0.5795 - val_loss: 1.9169\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7510 - val_accuracy: 0.5794 - val_loss: 1.9157\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7509 - val_accuracy: 0.5795 - val_loss: 1.9169\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7509 - val_accuracy: 0.5795 - val_loss: 1.9159\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7508 - val_accuracy: 0.5795 - val_loss: 1.9190\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7507 - val_accuracy: 0.5795 - val_loss: 1.9189\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7651 - loss: 0.7506 - val_accuracy: 0.5794 - val_loss: 1.9191\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7644 - loss: 0.7505 - val_accuracy: 0.5795 - val_loss: 1.9175\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7647 - loss: 0.7504 - val_accuracy: 0.5795 - val_loss: 1.9213\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7504 - val_accuracy: 0.5794 - val_loss: 1.9174\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7654 - loss: 0.7503 - val_accuracy: 0.5794 - val_loss: 1.9231\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7502 - val_accuracy: 0.5795 - val_loss: 1.9184\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7640 - loss: 0.7501 - val_accuracy: 0.5796 - val_loss: 1.9220\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7501 - val_accuracy: 0.5793 - val_loss: 1.9229\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7500 - val_accuracy: 0.5797 - val_loss: 1.9220\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7643 - loss: 0.7499 - val_accuracy: 0.5794 - val_loss: 1.9240\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7498 - val_accuracy: 0.5795 - val_loss: 1.9193\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7498 - val_accuracy: 0.5795 - val_loss: 1.9255\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7640 - loss: 0.7497 - val_accuracy: 0.5794 - val_loss: 1.9221\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7628 - loss: 0.7496 - val_accuracy: 0.5795 - val_loss: 1.9248\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7633 - loss: 0.7496 - val_accuracy: 0.5794 - val_loss: 1.9257\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7628 - loss: 0.7495 - val_accuracy: 0.5796 - val_loss: 1.9226\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7631 - loss: 0.7494 - val_accuracy: 0.5794 - val_loss: 1.9244\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7627 - loss: 0.7493 - val_accuracy: 0.5794 - val_loss: 1.9241\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7622 - loss: 0.7493 - val_accuracy: 0.5796 - val_loss: 1.9201\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7628 - loss: 0.7492 - val_accuracy: 0.5795 - val_loss: 1.9233\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7627 - loss: 0.7491 - val_accuracy: 0.5794 - val_loss: 1.9265\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7491 - val_accuracy: 0.5796 - val_loss: 1.9255\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7490 - val_accuracy: 0.5794 - val_loss: 1.9280\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7489 - val_accuracy: 0.5795 - val_loss: 1.9261\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7622 - loss: 0.7489 - val_accuracy: 0.5795 - val_loss: 1.9246\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7488 - val_accuracy: 0.5792 - val_loss: 1.9307\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7628 - loss: 0.7487 - val_accuracy: 0.5792 - val_loss: 1.9284\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7487 - val_accuracy: 0.5790 - val_loss: 1.9294\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7486 - val_accuracy: 0.5796 - val_loss: 1.9231\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7485 - val_accuracy: 0.5791 - val_loss: 1.9291\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7619 - loss: 0.7485 - val_accuracy: 0.5791 - val_loss: 1.9294\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7484 - val_accuracy: 0.5789 - val_loss: 1.9274\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7483 - val_accuracy: 0.5789 - val_loss: 1.9290\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7620 - loss: 0.7483 - val_accuracy: 0.5791 - val_loss: 1.9302\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7482 - val_accuracy: 0.5791 - val_loss: 1.9303\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7481 - val_accuracy: 0.5825 - val_loss: 1.9260\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7637 - loss: 0.7481 - val_accuracy: 0.5789 - val_loss: 1.9303\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7480 - val_accuracy: 0.5790 - val_loss: 1.9306\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7480 - val_accuracy: 0.5788 - val_loss: 1.9365\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7479 - val_accuracy: 0.5789 - val_loss: 1.9328\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7478 - val_accuracy: 0.5823 - val_loss: 1.9321\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7478 - val_accuracy: 0.5786 - val_loss: 1.9304\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7625 - loss: 0.7477 - val_accuracy: 0.5786 - val_loss: 1.9320\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7476 - val_accuracy: 0.5789 - val_loss: 1.9344\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7634 - loss: 0.7476 - val_accuracy: 0.5787 - val_loss: 1.9342\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7475 - val_accuracy: 0.5788 - val_loss: 1.9335\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7475 - val_accuracy: 0.5787 - val_loss: 1.9323\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7474 - val_accuracy: 0.5787 - val_loss: 1.9350\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7474 - val_accuracy: 0.5788 - val_loss: 1.9320\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7637 - loss: 0.7473 - val_accuracy: 0.5786 - val_loss: 1.9338\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7626 - loss: 0.7472 - val_accuracy: 0.5824 - val_loss: 1.9332\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7637 - loss: 0.7472 - val_accuracy: 0.5823 - val_loss: 1.9341\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7471 - val_accuracy: 0.5822 - val_loss: 1.9357\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7471 - val_accuracy: 0.5822 - val_loss: 1.9371\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7470 - val_accuracy: 0.5823 - val_loss: 1.9364\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7654 - loss: 0.7470 - val_accuracy: 0.5787 - val_loss: 1.9363\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7634 - loss: 0.7469 - val_accuracy: 0.5822 - val_loss: 1.9378\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7468 - val_accuracy: 0.5822 - val_loss: 1.9372\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7641 - loss: 0.7468 - val_accuracy: 0.5788 - val_loss: 1.9394\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7467 - val_accuracy: 0.5788 - val_loss: 1.9402\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7467 - val_accuracy: 0.5801 - val_loss: 1.9348\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7466 - val_accuracy: 0.5812 - val_loss: 1.9434\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7466 - val_accuracy: 0.5824 - val_loss: 1.9375\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7465 - val_accuracy: 0.5789 - val_loss: 1.9376\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7465 - val_accuracy: 0.5835 - val_loss: 1.9362\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7464 - val_accuracy: 0.5788 - val_loss: 1.9396\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7464 - val_accuracy: 0.5815 - val_loss: 1.9414\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7463 - val_accuracy: 0.5778 - val_loss: 1.9387\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7463 - val_accuracy: 0.5836 - val_loss: 1.9380\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7462 - val_accuracy: 0.5837 - val_loss: 1.9367\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7661 - loss: 0.7461 - val_accuracy: 0.5836 - val_loss: 1.9413\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7649 - loss: 0.7461 - val_accuracy: 0.5818 - val_loss: 1.9392\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7460 - val_accuracy: 0.5826 - val_loss: 1.9406\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7657 - loss: 0.7460 - val_accuracy: 0.5799 - val_loss: 1.9409\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7459 - val_accuracy: 0.5825 - val_loss: 1.9432\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7459 - val_accuracy: 0.5827 - val_loss: 1.9428\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7658 - loss: 0.7458 - val_accuracy: 0.5825 - val_loss: 1.9429\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7458 - val_accuracy: 0.5827 - val_loss: 1.9436\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7457 - val_accuracy: 0.5826 - val_loss: 1.9448\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7457 - val_accuracy: 0.5827 - val_loss: 1.9413\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7456 - val_accuracy: 0.5818 - val_loss: 1.9440\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.7456 - val_accuracy: 0.5825 - val_loss: 1.9424\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7455 - val_accuracy: 0.5835 - val_loss: 1.9388\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.7455 - val_accuracy: 0.5825 - val_loss: 1.9396\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7652 - loss: 0.7454 - val_accuracy: 0.5819 - val_loss: 1.9430\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7454 - val_accuracy: 0.5825 - val_loss: 1.9474\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7453 - val_accuracy: 0.5826 - val_loss: 1.9399\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.7453 - val_accuracy: 0.5825 - val_loss: 1.9432\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7453 - val_accuracy: 0.5818 - val_loss: 1.9445\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7452 - val_accuracy: 0.5807 - val_loss: 1.9479\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7664 - loss: 0.7452 - val_accuracy: 0.5809 - val_loss: 1.9430\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7451 - val_accuracy: 0.5817 - val_loss: 1.9452\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7657 - loss: 0.7451 - val_accuracy: 0.5819 - val_loss: 1.9384\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7659 - loss: 0.7450 - val_accuracy: 0.5815 - val_loss: 1.9460\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7658 - loss: 0.7450 - val_accuracy: 0.5815 - val_loss: 1.9464\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7657 - loss: 0.7449 - val_accuracy: 0.5817 - val_loss: 1.9462\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7449 - val_accuracy: 0.5817 - val_loss: 1.9440\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7669 - loss: 0.7448 - val_accuracy: 0.5808 - val_loss: 1.9450\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7448 - val_accuracy: 0.5807 - val_loss: 1.9515\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7659 - loss: 0.7447 - val_accuracy: 0.5816 - val_loss: 1.9453\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7447 - val_accuracy: 0.5808 - val_loss: 1.9443\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7446 - val_accuracy: 0.5807 - val_loss: 1.9478\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7656 - loss: 0.7446 - val_accuracy: 0.5816 - val_loss: 1.9459\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7654 - loss: 0.7446 - val_accuracy: 0.5817 - val_loss: 1.9486\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7664 - loss: 0.7445 - val_accuracy: 0.5809 - val_loss: 1.9499\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7659 - loss: 0.7445 - val_accuracy: 0.5808 - val_loss: 1.9476\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7649 - loss: 0.7444 - val_accuracy: 0.5817 - val_loss: 1.9490\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7663 - loss: 0.7444 - val_accuracy: 0.5818 - val_loss: 1.9457\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7661 - loss: 0.7443 - val_accuracy: 0.5808 - val_loss: 1.9455\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7443 - val_accuracy: 0.5817 - val_loss: 1.9448\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7650 - loss: 0.7442 - val_accuracy: 0.5818 - val_loss: 1.9439\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7658 - loss: 0.7442 - val_accuracy: 0.5818 - val_loss: 1.9497\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7442 - val_accuracy: 0.5816 - val_loss: 1.9518\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7652 - loss: 0.7441 - val_accuracy: 0.5809 - val_loss: 1.9465\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7441 - val_accuracy: 0.5808 - val_loss: 1.9503\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7659 - loss: 0.7440 - val_accuracy: 0.5816 - val_loss: 1.9475\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7653 - loss: 0.7440 - val_accuracy: 0.5808 - val_loss: 1.9475\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7653 - loss: 0.7439 - val_accuracy: 0.5810 - val_loss: 1.9504\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7660 - loss: 0.7439 - val_accuracy: 0.5808 - val_loss: 1.9499\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7439 - val_accuracy: 0.5808 - val_loss: 1.9524\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7438 - val_accuracy: 0.5808 - val_loss: 1.9496\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7653 - loss: 0.7438 - val_accuracy: 0.5808 - val_loss: 1.9496\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7661 - loss: 0.7437 - val_accuracy: 0.5808 - val_loss: 1.9518\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7650 - loss: 0.7437 - val_accuracy: 0.5809 - val_loss: 1.9481\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7436 - val_accuracy: 0.5808 - val_loss: 1.9520\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.7436 - val_accuracy: 0.5816 - val_loss: 1.9522\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7653 - loss: 0.7436 - val_accuracy: 0.5810 - val_loss: 1.9522\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7655 - loss: 0.7435 - val_accuracy: 0.5817 - val_loss: 1.9482\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7435 - val_accuracy: 0.5810 - val_loss: 1.9488\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7434 - val_accuracy: 0.5810 - val_loss: 1.9512\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7658 - loss: 0.7434 - val_accuracy: 0.5808 - val_loss: 1.9551\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7434 - val_accuracy: 0.5809 - val_loss: 1.9533\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7433 - val_accuracy: 0.5809 - val_loss: 1.9549\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7433 - val_accuracy: 0.5808 - val_loss: 1.9560\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7432 - val_accuracy: 0.5808 - val_loss: 1.9539\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7640 - loss: 0.7432 - val_accuracy: 0.5808 - val_loss: 1.9540\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7650 - loss: 0.7432 - val_accuracy: 0.5808 - val_loss: 1.9520\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7431 - val_accuracy: 0.5817 - val_loss: 1.9492\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7431 - val_accuracy: 0.5808 - val_loss: 1.9525\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7430 - val_accuracy: 0.5808 - val_loss: 1.9556\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7430 - val_accuracy: 0.5809 - val_loss: 1.9535\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7648 - loss: 0.7430 - val_accuracy: 0.5808 - val_loss: 1.9550\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7429 - val_accuracy: 0.5809 - val_loss: 1.9515\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7429 - val_accuracy: 0.5809 - val_loss: 1.9542\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7647 - loss: 0.7428 - val_accuracy: 0.5808 - val_loss: 1.9554\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7428 - val_accuracy: 0.5810 - val_loss: 1.9558\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7428 - val_accuracy: 0.5809 - val_loss: 1.9544\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7427 - val_accuracy: 0.5810 - val_loss: 1.9545\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7656 - loss: 0.7427 - val_accuracy: 0.5808 - val_loss: 1.9568\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7426 - val_accuracy: 0.5808 - val_loss: 1.9567\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7426 - val_accuracy: 0.5808 - val_loss: 1.9559\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7426 - val_accuracy: 0.5810 - val_loss: 1.9555\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7648 - loss: 0.7425 - val_accuracy: 0.5806 - val_loss: 1.9584\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7642 - loss: 0.7425 - val_accuracy: 0.5810 - val_loss: 1.9549\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7424 - val_accuracy: 0.5807 - val_loss: 1.9617\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7644 - loss: 0.7424 - val_accuracy: 0.5810 - val_loss: 1.9574\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7424 - val_accuracy: 0.5809 - val_loss: 1.9560\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7423 - val_accuracy: 0.5809 - val_loss: 1.9554\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7423 - val_accuracy: 0.5809 - val_loss: 1.9521\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7642 - loss: 0.7423 - val_accuracy: 0.5809 - val_loss: 1.9582\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7422 - val_accuracy: 0.5808 - val_loss: 1.9611\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7651 - loss: 0.7422 - val_accuracy: 0.5809 - val_loss: 1.9581\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7421 - val_accuracy: 0.5809 - val_loss: 1.9565\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7421 - val_accuracy: 0.5808 - val_loss: 1.9617\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7421 - val_accuracy: 0.5809 - val_loss: 1.9558\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7649 - loss: 0.7420 - val_accuracy: 0.5808 - val_loss: 1.9618\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7420 - val_accuracy: 0.5809 - val_loss: 1.9579\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7420 - val_accuracy: 0.5809 - val_loss: 1.9597\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7419 - val_accuracy: 0.5749 - val_loss: 1.9577\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7419 - val_accuracy: 0.5809 - val_loss: 1.9563\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7418 - val_accuracy: 0.5808 - val_loss: 1.9591\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7649 - loss: 0.7418 - val_accuracy: 0.5808 - val_loss: 1.9594\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7418 - val_accuracy: 0.5809 - val_loss: 1.9563\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7417 - val_accuracy: 0.5789 - val_loss: 1.9614\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7643 - loss: 0.7417 - val_accuracy: 0.5787 - val_loss: 1.9601\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7417 - val_accuracy: 0.5791 - val_loss: 1.9576\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7416 - val_accuracy: 0.5790 - val_loss: 1.9586\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7639 - loss: 0.7416 - val_accuracy: 0.5789 - val_loss: 1.9636\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7416 - val_accuracy: 0.5787 - val_loss: 1.9588\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7415 - val_accuracy: 0.5789 - val_loss: 1.9621\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7415 - val_accuracy: 0.5788 - val_loss: 1.9658\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7646 - loss: 0.7415 - val_accuracy: 0.5787 - val_loss: 1.9629\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7641 - loss: 0.7414 - val_accuracy: 0.5788 - val_loss: 1.9602\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7643 - loss: 0.7414 - val_accuracy: 0.5789 - val_loss: 1.9611\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7413 - val_accuracy: 0.5787 - val_loss: 1.9623\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7644 - loss: 0.7413 - val_accuracy: 0.5787 - val_loss: 1.9636\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7413 - val_accuracy: 0.5788 - val_loss: 1.9606\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7412 - val_accuracy: 0.5789 - val_loss: 1.9624\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7412 - val_accuracy: 0.5786 - val_loss: 1.9631\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7638 - loss: 0.7412 - val_accuracy: 0.5789 - val_loss: 1.9608\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7411 - val_accuracy: 0.5789 - val_loss: 1.9615\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7411 - val_accuracy: 0.5787 - val_loss: 1.9642\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7411 - val_accuracy: 0.5784 - val_loss: 1.9667\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7642 - loss: 0.7410 - val_accuracy: 0.5786 - val_loss: 1.9613\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7410 - val_accuracy: 0.5785 - val_loss: 1.9651\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7410 - val_accuracy: 0.5785 - val_loss: 1.9631\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7409 - val_accuracy: 0.5786 - val_loss: 1.9637\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7409 - val_accuracy: 0.5785 - val_loss: 1.9628\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7409 - val_accuracy: 0.5786 - val_loss: 1.9627\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7408 - val_accuracy: 0.5786 - val_loss: 1.9626\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7408 - val_accuracy: 0.5786 - val_loss: 1.9653\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7408 - val_accuracy: 0.5784 - val_loss: 1.9654\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7407 - val_accuracy: 0.5745 - val_loss: 1.9632\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7407 - val_accuracy: 0.5744 - val_loss: 1.9667\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7407 - val_accuracy: 0.5783 - val_loss: 1.9667\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7406 - val_accuracy: 0.5785 - val_loss: 1.9668\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7406 - val_accuracy: 0.5745 - val_loss: 1.9621\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7406 - val_accuracy: 0.5745 - val_loss: 1.9614\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7612 - loss: 0.7405 - val_accuracy: 0.5785 - val_loss: 1.9667\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7405 - val_accuracy: 0.5784 - val_loss: 1.9669\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7405 - val_accuracy: 0.5744 - val_loss: 1.9661\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7404 - val_accuracy: 0.5746 - val_loss: 1.9647\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7609 - loss: 0.7404 - val_accuracy: 0.5787 - val_loss: 1.9647\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7635 - loss: 0.7404 - val_accuracy: 0.5785 - val_loss: 1.9649\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7630 - loss: 0.7403 - val_accuracy: 0.5744 - val_loss: 1.9676\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7607 - loss: 0.7403 - val_accuracy: 0.5744 - val_loss: 1.9693\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7610 - loss: 0.7403 - val_accuracy: 0.5787 - val_loss: 1.9661\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7402 - val_accuracy: 0.5743 - val_loss: 1.9678\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.7402 - val_accuracy: 0.5743 - val_loss: 1.9721\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7402 - val_accuracy: 0.5786 - val_loss: 1.9675\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7620 - loss: 0.7401 - val_accuracy: 0.5744 - val_loss: 1.9678\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7609 - loss: 0.7401 - val_accuracy: 0.5789 - val_loss: 1.9724\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.7401 - val_accuracy: 0.5784 - val_loss: 1.9704\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7612 - loss: 0.7400 - val_accuracy: 0.5784 - val_loss: 1.9705\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7614 - loss: 0.7400 - val_accuracy: 0.5744 - val_loss: 1.9685\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7622 - loss: 0.7400 - val_accuracy: 0.5744 - val_loss: 1.9695\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7597 - loss: 0.7399 - val_accuracy: 0.5743 - val_loss: 1.9713\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7399 - val_accuracy: 0.5745 - val_loss: 1.9698\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7399 - val_accuracy: 0.5744 - val_loss: 1.9658\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7614 - loss: 0.7398 - val_accuracy: 0.5784 - val_loss: 1.9681\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.7398 - val_accuracy: 0.5815 - val_loss: 1.9667\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7616 - loss: 0.7398 - val_accuracy: 0.5744 - val_loss: 1.9683\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7397 - val_accuracy: 0.5744 - val_loss: 1.9690\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7397 - val_accuracy: 0.5774 - val_loss: 1.9699\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7397 - val_accuracy: 0.5775 - val_loss: 1.9687\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7396 - val_accuracy: 0.5745 - val_loss: 1.9695\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7612 - loss: 0.7396 - val_accuracy: 0.5745 - val_loss: 1.9679\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7396 - val_accuracy: 0.5773 - val_loss: 1.9700\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7639 - loss: 0.7395 - val_accuracy: 0.5743 - val_loss: 1.9712\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7606 - loss: 0.7395 - val_accuracy: 0.5745 - val_loss: 1.9728\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7395 - val_accuracy: 0.5745 - val_loss: 1.9675\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7608 - loss: 0.7395 - val_accuracy: 0.5770 - val_loss: 1.9739\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7394 - val_accuracy: 0.5774 - val_loss: 1.9701\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7394 - val_accuracy: 0.5773 - val_loss: 1.9717\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7394 - val_accuracy: 0.5774 - val_loss: 1.9699\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7640 - loss: 0.7393 - val_accuracy: 0.5774 - val_loss: 1.9725\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7393 - val_accuracy: 0.5773 - val_loss: 1.9729\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7627 - loss: 0.7393 - val_accuracy: 0.5774 - val_loss: 1.9682\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7636 - loss: 0.7392 - val_accuracy: 0.5773 - val_loss: 1.9714\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7392 - val_accuracy: 0.5775 - val_loss: 1.9698\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7621 - loss: 0.7392 - val_accuracy: 0.5769 - val_loss: 1.9748\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7391 - val_accuracy: 0.5775 - val_loss: 1.9741\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7391 - val_accuracy: 0.5776 - val_loss: 1.9706\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7391 - val_accuracy: 0.5774 - val_loss: 1.9719\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7391 - val_accuracy: 0.5774 - val_loss: 1.9730\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7390 - val_accuracy: 0.5775 - val_loss: 1.9779\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7630 - loss: 0.7390 - val_accuracy: 0.5773 - val_loss: 1.9736\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7390 - val_accuracy: 0.5774 - val_loss: 1.9717\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7389 - val_accuracy: 0.5774 - val_loss: 1.9729\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7389 - val_accuracy: 0.5774 - val_loss: 1.9721\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7636 - loss: 0.7389 - val_accuracy: 0.5770 - val_loss: 1.9748\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7388 - val_accuracy: 0.5779 - val_loss: 1.9745\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7388 - val_accuracy: 0.5773 - val_loss: 1.9748\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7388 - val_accuracy: 0.5774 - val_loss: 1.9723\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7387 - val_accuracy: 0.5773 - val_loss: 1.9752\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7387 - val_accuracy: 0.5774 - val_loss: 1.9742\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7387 - val_accuracy: 0.5774 - val_loss: 1.9747\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7387 - val_accuracy: 0.5776 - val_loss: 1.9707\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7386 - val_accuracy: 0.5770 - val_loss: 1.9757\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7626 - loss: 0.7386 - val_accuracy: 0.5774 - val_loss: 1.9745\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7386 - val_accuracy: 0.5776 - val_loss: 1.9752\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7639 - loss: 0.7385 - val_accuracy: 0.5774 - val_loss: 1.9721\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7385 - val_accuracy: 0.5774 - val_loss: 1.9729\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7385 - val_accuracy: 0.5774 - val_loss: 1.9735\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7384 - val_accuracy: 0.5775 - val_loss: 1.9767\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7637 - loss: 0.7384 - val_accuracy: 0.5774 - val_loss: 1.9731\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7629 - loss: 0.7384 - val_accuracy: 0.5779 - val_loss: 1.9753\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7384 - val_accuracy: 0.5770 - val_loss: 1.9781\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7628 - loss: 0.7383 - val_accuracy: 0.5779 - val_loss: 1.9770\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7638 - loss: 0.7383 - val_accuracy: 0.5775 - val_loss: 1.9758\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7627 - loss: 0.7383 - val_accuracy: 0.5776 - val_loss: 1.9755\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7382 - val_accuracy: 0.5775 - val_loss: 1.9796\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7382 - val_accuracy: 0.5774 - val_loss: 1.9774\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7382 - val_accuracy: 0.5770 - val_loss: 1.9816\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7382 - val_accuracy: 0.5770 - val_loss: 1.9766\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7381 - val_accuracy: 0.5774 - val_loss: 1.9791\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7381 - val_accuracy: 0.5776 - val_loss: 1.9800\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7381 - val_accuracy: 0.5774 - val_loss: 1.9757\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7380 - val_accuracy: 0.5774 - val_loss: 1.9758\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7380 - val_accuracy: 0.5774 - val_loss: 1.9748\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7642 - loss: 0.7380 - val_accuracy: 0.5775 - val_loss: 1.9777\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7380 - val_accuracy: 0.5775 - val_loss: 1.9784\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7640 - loss: 0.7379 - val_accuracy: 0.5775 - val_loss: 1.9784\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7379 - val_accuracy: 0.5779 - val_loss: 1.9778\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7633 - loss: 0.7379 - val_accuracy: 0.5770 - val_loss: 1.9792\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7629 - loss: 0.7378 - val_accuracy: 0.5775 - val_loss: 1.9781\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7634 - loss: 0.7378 - val_accuracy: 0.5779 - val_loss: 1.9792\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7629 - loss: 0.7378 - val_accuracy: 0.5775 - val_loss: 1.9810\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7636 - loss: 0.7378 - val_accuracy: 0.5770 - val_loss: 1.9797\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7630 - loss: 0.7377 - val_accuracy: 0.5770 - val_loss: 1.9797\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7377 - val_accuracy: 0.5775 - val_loss: 1.9773\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7377 - val_accuracy: 0.5779 - val_loss: 1.9794\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7376 - val_accuracy: 0.5770 - val_loss: 1.9765\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7630 - loss: 0.7376 - val_accuracy: 0.5770 - val_loss: 1.9783\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7636 - loss: 0.7376 - val_accuracy: 0.5770 - val_loss: 1.9775\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7635 - loss: 0.7376 - val_accuracy: 0.5770 - val_loss: 1.9783\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7375 - val_accuracy: 0.5774 - val_loss: 1.9779\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7375 - val_accuracy: 0.5776 - val_loss: 1.9846\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7637 - loss: 0.7375 - val_accuracy: 0.5775 - val_loss: 1.9802\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7630 - loss: 0.7374 - val_accuracy: 0.5776 - val_loss: 1.9787\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7630 - loss: 0.7374 - val_accuracy: 0.5777 - val_loss: 1.9784\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7631 - loss: 0.7374 - val_accuracy: 0.5779 - val_loss: 1.9783\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7632 - loss: 0.7374 - val_accuracy: 0.5776 - val_loss: 1.9793\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7633 - loss: 0.7373 - val_accuracy: 0.5776 - val_loss: 1.9844\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7645 - loss: 0.7373 - val_accuracy: 0.5779 - val_loss: 1.9803\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7373 - val_accuracy: 0.5779 - val_loss: 1.9799\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7372 - val_accuracy: 0.5776 - val_loss: 1.9833\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7372 - val_accuracy: 0.5770 - val_loss: 1.9818\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7372 - val_accuracy: 0.5770 - val_loss: 1.9825\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7630 - loss: 0.7372 - val_accuracy: 0.5774 - val_loss: 1.9796\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7371 - val_accuracy: 0.5771 - val_loss: 1.9784\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7371 - val_accuracy: 0.5771 - val_loss: 1.9807\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7371 - val_accuracy: 0.5775 - val_loss: 1.9802\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7371 - val_accuracy: 0.5776 - val_loss: 1.9820\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7370 - val_accuracy: 0.5780 - val_loss: 1.9788\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7638 - loss: 0.7370 - val_accuracy: 0.5775 - val_loss: 1.9831\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7370 - val_accuracy: 0.5774 - val_loss: 1.9783\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7369 - val_accuracy: 0.5778 - val_loss: 1.9817\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7641 - loss: 0.7369 - val_accuracy: 0.5776 - val_loss: 1.9813\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7369 - val_accuracy: 0.5776 - val_loss: 1.9821\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7369 - val_accuracy: 0.5774 - val_loss: 1.9799\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7368 - val_accuracy: 0.5772 - val_loss: 1.9813\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7643 - loss: 0.7368 - val_accuracy: 0.5779 - val_loss: 1.9812\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7368 - val_accuracy: 0.5778 - val_loss: 1.9840\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7640 - loss: 0.7367 - val_accuracy: 0.5775 - val_loss: 1.9864\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7367 - val_accuracy: 0.5779 - val_loss: 1.9816\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7367 - val_accuracy: 0.5774 - val_loss: 1.9795\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7367 - val_accuracy: 0.5777 - val_loss: 1.9822\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7632 - loss: 0.7366 - val_accuracy: 0.5770 - val_loss: 1.9812\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7366 - val_accuracy: 0.5777 - val_loss: 1.9804\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7366 - val_accuracy: 0.5776 - val_loss: 1.9815\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7366 - val_accuracy: 0.5777 - val_loss: 1.9838\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7365 - val_accuracy: 0.5775 - val_loss: 1.9869\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7634 - loss: 0.7365 - val_accuracy: 0.5776 - val_loss: 1.9853\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7631 - loss: 0.7365 - val_accuracy: 0.5771 - val_loss: 1.9866\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7365 - val_accuracy: 0.5781 - val_loss: 1.9791\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7635 - loss: 0.7364 - val_accuracy: 0.5779 - val_loss: 1.9848\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7364 - val_accuracy: 0.5777 - val_loss: 1.9840\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7633 - loss: 0.7364 - val_accuracy: 0.5777 - val_loss: 1.9840\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(\n    X, y, test_size=0.3, random_state=58, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_16, X_val_16, y_train_16, y_val_16 = train_test_split(\n    X_train_16, y_train_16, test_size=0.2, random_state=58, stratify=y_train_16\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_16:\", np.max(X_train_16))\nprint(\"Min value in X_train_16:\", np.min(X_train_16))\n\nX_train_16_scaled = scaler.fit_transform(X_train_16)\n\n# Get the original class distribution\nclass_counts_16 = Counter(y_train_16)\nprint(\"Original class distribution:\", class_counts_16)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_16 = class_counts_16[min(class_counts_16, key=class_counts_16.get)]\ndesired_majority_size_16 = minority_class_size_16 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_16 = {0: desired_majority_size_16, 1: minority_class_size_16}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_16 = RandomUnderSampler(sampling_strategy=sampling_strategy_16, random_state=42)\nX_resampled_16, y_resampled_16 = undersampler_16.fit_resample(X_train_16, y_train_16)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_16))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_16, y_train_resampled_16 = smote.fit_resample(X_resampled_16, y_resampled_16)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_16))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_16))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T09:10:33.591083Z","iopub.execute_input":"2025-03-07T09:10:33.591503Z","iopub.status.idle":"2025-03-07T09:11:09.503252Z","shell.execute_reply.started":"2025-03-07T09:10:33.591468Z","shell.execute_reply":"2025-03-07T09:11:09.501716Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_16: 2071000000.0\nMin value in X_train_16: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_16 = X_train_resampled_16.reshape(X_train_resampled_16.shape[0], 1, 56)\nX_val_16 = X_val_16.reshape(X_val_16.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_16,  # Features from CICIDS2017\n    y_train_resampled_16,  # Labels from CICIDS2017\n    validation_data=(X_val_16, y_val_16),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T09:42:39.132102Z","iopub.execute_input":"2025-03-07T09:42:39.132603Z","iopub.status.idle":"2025-03-07T10:28:22.879590Z","shell.execute_reply.started":"2025-03-07T09:42:39.132566Z","shell.execute_reply":"2025-03-07T10:28:22.877793Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7628 - loss: 0.8509 - val_accuracy: 0.5778 - val_loss: 1.9546\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7684 - loss: 0.8392 - val_accuracy: 0.5783 - val_loss: 1.9325\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7668 - loss: 0.8316 - val_accuracy: 0.5803 - val_loss: 1.9084\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7664 - loss: 0.8255 - val_accuracy: 0.5815 - val_loss: 1.8920\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7661 - loss: 0.8205 - val_accuracy: 0.5828 - val_loss: 1.8688\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7662 - loss: 0.8163 - val_accuracy: 0.5773 - val_loss: 1.8545\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7654 - loss: 0.8127 - val_accuracy: 0.5779 - val_loss: 1.8361\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7618 - loss: 0.8094 - val_accuracy: 0.5787 - val_loss: 1.8206\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7650 - loss: 0.8065 - val_accuracy: 0.5789 - val_loss: 1.8063\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7664 - loss: 0.8038 - val_accuracy: 0.5767 - val_loss: 1.7947\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7665 - loss: 0.8013 - val_accuracy: 0.5769 - val_loss: 1.7810\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7667 - loss: 0.7990 - val_accuracy: 0.5780 - val_loss: 1.7704\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7671 - loss: 0.7969 - val_accuracy: 0.5787 - val_loss: 1.7564\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7669 - loss: 0.7950 - val_accuracy: 0.5784 - val_loss: 1.7498\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7706 - loss: 0.7932 - val_accuracy: 0.5891 - val_loss: 1.7387\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7722 - loss: 0.7915 - val_accuracy: 0.5891 - val_loss: 1.7312\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7732 - loss: 0.7899 - val_accuracy: 0.5900 - val_loss: 1.7247\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7729 - loss: 0.7883 - val_accuracy: 0.5903 - val_loss: 1.7153\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7735 - loss: 0.7869 - val_accuracy: 0.5902 - val_loss: 1.7128\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7746 - loss: 0.7856 - val_accuracy: 0.5920 - val_loss: 1.7012\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7743 - loss: 0.7843 - val_accuracy: 0.5919 - val_loss: 1.6996\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7747 - loss: 0.7830 - val_accuracy: 0.5926 - val_loss: 1.6931\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7745 - loss: 0.7819 - val_accuracy: 0.5931 - val_loss: 1.6895\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7745 - loss: 0.7807 - val_accuracy: 0.5930 - val_loss: 1.6893\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7746 - loss: 0.7796 - val_accuracy: 0.5958 - val_loss: 1.6897\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7747 - loss: 0.7786 - val_accuracy: 0.5959 - val_loss: 1.6803\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7747 - loss: 0.7776 - val_accuracy: 0.5958 - val_loss: 1.6800\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7750 - loss: 0.7766 - val_accuracy: 0.5959 - val_loss: 1.6773\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7752 - loss: 0.7757 - val_accuracy: 0.5963 - val_loss: 1.6746\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7756 - loss: 0.7748 - val_accuracy: 0.5962 - val_loss: 1.6724\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7739 - val_accuracy: 0.5960 - val_loss: 1.6712\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7731 - val_accuracy: 0.5960 - val_loss: 1.6709\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7722 - val_accuracy: 0.5961 - val_loss: 1.6687\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7756 - loss: 0.7715 - val_accuracy: 0.5967 - val_loss: 1.6670\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7707 - val_accuracy: 0.5967 - val_loss: 1.6645\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7699 - val_accuracy: 0.5966 - val_loss: 1.6680\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7692 - val_accuracy: 0.5969 - val_loss: 1.6663\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7685 - val_accuracy: 0.5969 - val_loss: 1.6627\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7766 - loss: 0.7678 - val_accuracy: 0.5969 - val_loss: 1.6622\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7770 - loss: 0.7672 - val_accuracy: 0.5969 - val_loss: 1.6615\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7771 - loss: 0.7665 - val_accuracy: 0.5970 - val_loss: 1.6632\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7659 - val_accuracy: 0.5972 - val_loss: 1.6591\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7653 - val_accuracy: 0.5973 - val_loss: 1.6603\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7647 - val_accuracy: 0.5974 - val_loss: 1.6581\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7641 - val_accuracy: 0.5986 - val_loss: 1.6550\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7770 - loss: 0.7635 - val_accuracy: 0.5986 - val_loss: 1.6603\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7770 - loss: 0.7630 - val_accuracy: 0.5986 - val_loss: 1.6588\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7774 - loss: 0.7625 - val_accuracy: 0.5985 - val_loss: 1.6601\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7774 - loss: 0.7619 - val_accuracy: 0.5986 - val_loss: 1.6557\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7614 - val_accuracy: 0.5985 - val_loss: 1.6617\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7609 - val_accuracy: 0.5985 - val_loss: 1.6564\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7760 - loss: 0.7604 - val_accuracy: 0.5986 - val_loss: 1.6564\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7599 - val_accuracy: 0.5985 - val_loss: 1.6578\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7758 - loss: 0.7595 - val_accuracy: 0.5998 - val_loss: 1.6539\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7590 - val_accuracy: 0.5997 - val_loss: 1.6568\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7586 - val_accuracy: 0.5997 - val_loss: 1.6544\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7581 - val_accuracy: 0.6002 - val_loss: 1.6529\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7756 - loss: 0.7577 - val_accuracy: 0.5999 - val_loss: 1.6573\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7573 - val_accuracy: 0.6001 - val_loss: 1.6549\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7569 - val_accuracy: 0.6006 - val_loss: 1.6536\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7565 - val_accuracy: 0.6007 - val_loss: 1.6544\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7561 - val_accuracy: 0.6007 - val_loss: 1.6549\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7557 - val_accuracy: 0.6006 - val_loss: 1.6568\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7757 - loss: 0.7553 - val_accuracy: 0.6007 - val_loss: 1.6535\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7549 - val_accuracy: 0.6007 - val_loss: 1.6534\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7545 - val_accuracy: 0.6005 - val_loss: 1.6574\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7756 - loss: 0.7542 - val_accuracy: 0.6007 - val_loss: 1.6526\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7538 - val_accuracy: 0.6005 - val_loss: 1.6555\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7535 - val_accuracy: 0.6004 - val_loss: 1.6589\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7757 - loss: 0.7531 - val_accuracy: 0.6005 - val_loss: 1.6587\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7528 - val_accuracy: 0.6003 - val_loss: 1.6525\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7525 - val_accuracy: 0.6004 - val_loss: 1.6612\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7521 - val_accuracy: 0.6004 - val_loss: 1.6553\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7754 - loss: 0.7518 - val_accuracy: 0.6002 - val_loss: 1.6579\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7754 - loss: 0.7515 - val_accuracy: 0.6007 - val_loss: 1.6551\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7755 - loss: 0.7512 - val_accuracy: 0.6006 - val_loss: 1.6551\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7509 - val_accuracy: 0.6008 - val_loss: 1.6578\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7755 - loss: 0.7506 - val_accuracy: 0.6008 - val_loss: 1.6560\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7503 - val_accuracy: 0.6006 - val_loss: 1.6596\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7500 - val_accuracy: 0.6007 - val_loss: 1.6584\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7757 - loss: 0.7497 - val_accuracy: 0.6007 - val_loss: 1.6566\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7494 - val_accuracy: 0.6004 - val_loss: 1.6621\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7758 - loss: 0.7491 - val_accuracy: 0.6006 - val_loss: 1.6578\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7759 - loss: 0.7489 - val_accuracy: 0.6006 - val_loss: 1.6569\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7486 - val_accuracy: 0.6006 - val_loss: 1.6578\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7483 - val_accuracy: 0.6005 - val_loss: 1.6633\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7480 - val_accuracy: 0.6006 - val_loss: 1.6561\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7478 - val_accuracy: 0.6005 - val_loss: 1.6614\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7475 - val_accuracy: 0.6006 - val_loss: 1.6578\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7472 - val_accuracy: 0.6005 - val_loss: 1.6590\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7470 - val_accuracy: 0.6005 - val_loss: 1.6599\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7467 - val_accuracy: 0.6004 - val_loss: 1.6623\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7763 - loss: 0.7465 - val_accuracy: 0.6007 - val_loss: 1.6590\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7761 - loss: 0.7462 - val_accuracy: 0.6006 - val_loss: 1.6605\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7760 - loss: 0.7460 - val_accuracy: 0.6006 - val_loss: 1.6610\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7760 - loss: 0.7458 - val_accuracy: 0.6004 - val_loss: 1.6628\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7762 - loss: 0.7455 - val_accuracy: 0.6006 - val_loss: 1.6607\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7764 - loss: 0.7453 - val_accuracy: 0.6004 - val_loss: 1.6613\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7767 - loss: 0.7451 - val_accuracy: 0.6000 - val_loss: 1.6659\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7772 - loss: 0.7448 - val_accuracy: 0.6002 - val_loss: 1.6650\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7772 - loss: 0.7446 - val_accuracy: 0.6002 - val_loss: 1.6647\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7772 - loss: 0.7444 - val_accuracy: 0.5991 - val_loss: 1.6667\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7442 - val_accuracy: 0.5991 - val_loss: 1.6629\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7439 - val_accuracy: 0.5991 - val_loss: 1.6663\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7776 - loss: 0.7437 - val_accuracy: 0.6002 - val_loss: 1.6694\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7774 - loss: 0.7435 - val_accuracy: 0.6002 - val_loss: 1.6642\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7773 - loss: 0.7433 - val_accuracy: 0.5992 - val_loss: 1.6629\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7776 - loss: 0.7431 - val_accuracy: 0.5992 - val_loss: 1.6646\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7775 - loss: 0.7429 - val_accuracy: 0.5991 - val_loss: 1.6697\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7775 - loss: 0.7426 - val_accuracy: 0.5991 - val_loss: 1.6667\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7776 - loss: 0.7424 - val_accuracy: 0.5991 - val_loss: 1.6643\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7778 - loss: 0.7422 - val_accuracy: 0.5992 - val_loss: 1.6679\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7776 - loss: 0.7420 - val_accuracy: 0.5993 - val_loss: 1.6640\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7418 - val_accuracy: 0.5991 - val_loss: 1.6699\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7777 - loss: 0.7416 - val_accuracy: 0.5993 - val_loss: 1.6641\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7781 - loss: 0.7414 - val_accuracy: 0.5993 - val_loss: 1.6643\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7786 - loss: 0.7412 - val_accuracy: 0.5993 - val_loss: 1.6667\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7783 - loss: 0.7410 - val_accuracy: 0.5993 - val_loss: 1.6671\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7805 - loss: 0.7409 - val_accuracy: 0.5993 - val_loss: 1.6680\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7783 - loss: 0.7407 - val_accuracy: 0.5993 - val_loss: 1.6666\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7405 - val_accuracy: 0.5993 - val_loss: 1.6693\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7403 - val_accuracy: 0.5993 - val_loss: 1.6704\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7785 - loss: 0.7401 - val_accuracy: 0.5992 - val_loss: 1.6714\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7399 - val_accuracy: 0.5992 - val_loss: 1.6724\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7784 - loss: 0.7397 - val_accuracy: 0.5992 - val_loss: 1.6727\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7396 - val_accuracy: 0.5991 - val_loss: 1.6733\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7786 - loss: 0.7394 - val_accuracy: 0.5992 - val_loss: 1.6704\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7796 - loss: 0.7392 - val_accuracy: 0.5991 - val_loss: 1.6748\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7783 - loss: 0.7390 - val_accuracy: 0.5992 - val_loss: 1.6699\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7389 - val_accuracy: 0.5992 - val_loss: 1.6699\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7783 - loss: 0.7387 - val_accuracy: 0.5991 - val_loss: 1.6699\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7385 - val_accuracy: 0.5992 - val_loss: 1.6691\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7383 - val_accuracy: 0.5990 - val_loss: 1.6727\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7789 - loss: 0.7382 - val_accuracy: 0.5990 - val_loss: 1.6727\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7380 - val_accuracy: 0.5990 - val_loss: 1.6756\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7378 - val_accuracy: 0.5991 - val_loss: 1.6707\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7784 - loss: 0.7377 - val_accuracy: 0.5991 - val_loss: 1.6691\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7375 - val_accuracy: 0.5990 - val_loss: 1.6736\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7373 - val_accuracy: 0.5990 - val_loss: 1.6751\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7795 - loss: 0.7372 - val_accuracy: 0.5990 - val_loss: 1.6745\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7370 - val_accuracy: 0.5990 - val_loss: 1.6726\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7782 - loss: 0.7369 - val_accuracy: 0.5990 - val_loss: 1.6759\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7784 - loss: 0.7367 - val_accuracy: 0.5990 - val_loss: 1.6782\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7794 - loss: 0.7365 - val_accuracy: 0.5990 - val_loss: 1.6737\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7792 - loss: 0.7364 - val_accuracy: 0.5994 - val_loss: 1.6794\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7791 - loss: 0.7362 - val_accuracy: 0.5994 - val_loss: 1.6792\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7793 - loss: 0.7361 - val_accuracy: 0.5994 - val_loss: 1.6778\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7803 - loss: 0.7359 - val_accuracy: 0.5994 - val_loss: 1.6807\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7791 - loss: 0.7358 - val_accuracy: 0.5994 - val_loss: 1.6744\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7791 - loss: 0.7356 - val_accuracy: 0.5994 - val_loss: 1.6811\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7799 - loss: 0.7355 - val_accuracy: 0.5994 - val_loss: 1.6804\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7797 - loss: 0.7353 - val_accuracy: 0.5994 - val_loss: 1.6759\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7824 - loss: 0.7352 - val_accuracy: 0.5984 - val_loss: 1.6791\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7810 - loss: 0.7350 - val_accuracy: 0.5994 - val_loss: 1.6804\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7823 - loss: 0.7349 - val_accuracy: 0.5984 - val_loss: 1.6821\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7348 - val_accuracy: 0.5994 - val_loss: 1.6806\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7346 - val_accuracy: 0.5984 - val_loss: 1.6811\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7345 - val_accuracy: 0.5984 - val_loss: 1.6807\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7343 - val_accuracy: 0.5980 - val_loss: 1.6820\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7342 - val_accuracy: 0.5981 - val_loss: 1.6821\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7341 - val_accuracy: 0.5980 - val_loss: 1.6849\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7830 - loss: 0.7339 - val_accuracy: 0.5981 - val_loss: 1.6818\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7338 - val_accuracy: 0.5981 - val_loss: 1.6849\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7336 - val_accuracy: 0.5981 - val_loss: 1.6850\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7335 - val_accuracy: 0.5981 - val_loss: 1.6873\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7334 - val_accuracy: 0.5981 - val_loss: 1.6841\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7332 - val_accuracy: 0.5981 - val_loss: 1.6813\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7830 - loss: 0.7331 - val_accuracy: 0.5981 - val_loss: 1.6879\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7330 - val_accuracy: 0.5981 - val_loss: 1.6866\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7328 - val_accuracy: 0.5981 - val_loss: 1.6836\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7327 - val_accuracy: 0.5979 - val_loss: 1.6873\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7326 - val_accuracy: 0.5980 - val_loss: 1.6853\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7325 - val_accuracy: 0.5980 - val_loss: 1.6879\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7830 - loss: 0.7323 - val_accuracy: 0.5980 - val_loss: 1.6810\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7322 - val_accuracy: 0.5978 - val_loss: 1.6858\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7321 - val_accuracy: 0.5978 - val_loss: 1.6888\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7837 - loss: 0.7319 - val_accuracy: 0.5977 - val_loss: 1.6897\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7318 - val_accuracy: 0.5977 - val_loss: 1.6860\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7317 - val_accuracy: 0.5977 - val_loss: 1.6871\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7831 - loss: 0.7316 - val_accuracy: 0.5977 - val_loss: 1.6856\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7315 - val_accuracy: 0.5977 - val_loss: 1.6918\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7313 - val_accuracy: 0.5977 - val_loss: 1.6912\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7312 - val_accuracy: 0.5977 - val_loss: 1.6906\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7311 - val_accuracy: 0.5977 - val_loss: 1.6946\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7829 - loss: 0.7310 - val_accuracy: 0.5977 - val_loss: 1.6883\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7830 - loss: 0.7309 - val_accuracy: 0.5977 - val_loss: 1.6883\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7307 - val_accuracy: 0.5977 - val_loss: 1.6934\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7306 - val_accuracy: 0.5973 - val_loss: 1.6909\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7305 - val_accuracy: 0.5973 - val_loss: 1.6940\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7304 - val_accuracy: 0.5973 - val_loss: 1.6895\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7836 - loss: 0.7303 - val_accuracy: 0.5972 - val_loss: 1.6963\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7830 - loss: 0.7302 - val_accuracy: 0.5973 - val_loss: 1.6896\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7830 - loss: 0.7301 - val_accuracy: 0.5972 - val_loss: 1.6933\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7299 - val_accuracy: 0.5969 - val_loss: 1.7002\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7835 - loss: 0.7298 - val_accuracy: 0.6015 - val_loss: 1.6945\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7297 - val_accuracy: 0.5969 - val_loss: 1.6976\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7836 - loss: 0.7296 - val_accuracy: 0.5970 - val_loss: 1.6940\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7295 - val_accuracy: 0.5970 - val_loss: 1.6951\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7294 - val_accuracy: 0.5970 - val_loss: 1.6963\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7293 - val_accuracy: 0.5959 - val_loss: 1.6975\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7292 - val_accuracy: 0.5959 - val_loss: 1.6993\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7291 - val_accuracy: 0.5970 - val_loss: 1.6993\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7841 - loss: 0.7290 - val_accuracy: 0.5958 - val_loss: 1.7003\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7838 - loss: 0.7288 - val_accuracy: 0.5970 - val_loss: 1.6975\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7287 - val_accuracy: 0.5958 - val_loss: 1.6982\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7286 - val_accuracy: 0.5969 - val_loss: 1.6964\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7834 - loss: 0.7285 - val_accuracy: 0.5958 - val_loss: 1.7018\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7284 - val_accuracy: 0.5958 - val_loss: 1.7036\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7283 - val_accuracy: 0.5969 - val_loss: 1.6965\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.7832 - loss: 0.7282 - val_accuracy: 0.5958 - val_loss: 1.7003\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7281 - val_accuracy: 0.5958 - val_loss: 1.7012\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7835 - loss: 0.7280 - val_accuracy: 0.5958 - val_loss: 1.7009\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7279 - val_accuracy: 0.5958 - val_loss: 1.7019\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7278 - val_accuracy: 0.5958 - val_loss: 1.7028\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7277 - val_accuracy: 0.5958 - val_loss: 1.6995\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7276 - val_accuracy: 0.5958 - val_loss: 1.7025\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7836 - loss: 0.7275 - val_accuracy: 0.5958 - val_loss: 1.7045\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7274 - val_accuracy: 0.5958 - val_loss: 1.7013\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7273 - val_accuracy: 0.5958 - val_loss: 1.7046\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7272 - val_accuracy: 0.5958 - val_loss: 1.7022\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7271 - val_accuracy: 0.5958 - val_loss: 1.7078\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7270 - val_accuracy: 0.5958 - val_loss: 1.7027\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7269 - val_accuracy: 0.5958 - val_loss: 1.7026\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7835 - loss: 0.7268 - val_accuracy: 0.5958 - val_loss: 1.7041\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7267 - val_accuracy: 0.5958 - val_loss: 1.7063\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7267 - val_accuracy: 0.5958 - val_loss: 1.7065\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7834 - loss: 0.7266 - val_accuracy: 0.5958 - val_loss: 1.7054\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7265 - val_accuracy: 0.5958 - val_loss: 1.7071\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7264 - val_accuracy: 0.5958 - val_loss: 1.7100\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7263 - val_accuracy: 0.5958 - val_loss: 1.7080\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7262 - val_accuracy: 0.5958 - val_loss: 1.7076\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7261 - val_accuracy: 0.5958 - val_loss: 1.7102\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7260 - val_accuracy: 0.5958 - val_loss: 1.7056\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7259 - val_accuracy: 0.5958 - val_loss: 1.7108\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7258 - val_accuracy: 0.5958 - val_loss: 1.7081\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7257 - val_accuracy: 0.5958 - val_loss: 1.7098\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7256 - val_accuracy: 0.5958 - val_loss: 1.7106\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7256 - val_accuracy: 0.5958 - val_loss: 1.7103\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7255 - val_accuracy: 0.5958 - val_loss: 1.7142\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7831 - loss: 0.7254 - val_accuracy: 0.5958 - val_loss: 1.7134\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7253 - val_accuracy: 0.5958 - val_loss: 1.7118\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7832 - loss: 0.7252 - val_accuracy: 0.5958 - val_loss: 1.7120\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7832 - loss: 0.7251 - val_accuracy: 0.5958 - val_loss: 1.7142\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7250 - val_accuracy: 0.5958 - val_loss: 1.7148\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7250 - val_accuracy: 0.5958 - val_loss: 1.7133\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7249 - val_accuracy: 0.5959 - val_loss: 1.7123\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7248 - val_accuracy: 0.5959 - val_loss: 1.7168\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7247 - val_accuracy: 0.5959 - val_loss: 1.7147\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7246 - val_accuracy: 0.5962 - val_loss: 1.7184\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7245 - val_accuracy: 0.5962 - val_loss: 1.7178\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7244 - val_accuracy: 0.5962 - val_loss: 1.7163\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7838 - loss: 0.7244 - val_accuracy: 0.5962 - val_loss: 1.7184\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7243 - val_accuracy: 0.5962 - val_loss: 1.7160\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7832 - loss: 0.7242 - val_accuracy: 0.5962 - val_loss: 1.7156\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7832 - loss: 0.7241 - val_accuracy: 0.5962 - val_loss: 1.7161\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7240 - val_accuracy: 0.5962 - val_loss: 1.7190\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7240 - val_accuracy: 0.5962 - val_loss: 1.7232\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7239 - val_accuracy: 0.5962 - val_loss: 1.7176\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7238 - val_accuracy: 0.5962 - val_loss: 1.7175\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7237 - val_accuracy: 0.5962 - val_loss: 1.7215\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7236 - val_accuracy: 0.5962 - val_loss: 1.7173\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7236 - val_accuracy: 0.5962 - val_loss: 1.7190\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7235 - val_accuracy: 0.5962 - val_loss: 1.7196\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7832 - loss: 0.7234 - val_accuracy: 0.5962 - val_loss: 1.7216\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7233 - val_accuracy: 0.5962 - val_loss: 1.7248\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7232 - val_accuracy: 0.5962 - val_loss: 1.7236\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7832 - loss: 0.7232 - val_accuracy: 0.5962 - val_loss: 1.7235\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7231 - val_accuracy: 0.5962 - val_loss: 1.7239\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7832 - loss: 0.7230 - val_accuracy: 0.5962 - val_loss: 1.7248\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7229 - val_accuracy: 0.5961 - val_loss: 1.7213\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7835 - loss: 0.7229 - val_accuracy: 0.5961 - val_loss: 1.7257\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7228 - val_accuracy: 0.5961 - val_loss: 1.7253\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7227 - val_accuracy: 0.5961 - val_loss: 1.7250\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7226 - val_accuracy: 0.5961 - val_loss: 1.7229\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7837 - loss: 0.7226 - val_accuracy: 0.5961 - val_loss: 1.7252\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7225 - val_accuracy: 0.5961 - val_loss: 1.7241\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7224 - val_accuracy: 0.5963 - val_loss: 1.7255\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7223 - val_accuracy: 0.5963 - val_loss: 1.7265\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7223 - val_accuracy: 0.5963 - val_loss: 1.7284\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7222 - val_accuracy: 0.5963 - val_loss: 1.7293\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7221 - val_accuracy: 0.5963 - val_loss: 1.7308\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7833 - loss: 0.7221 - val_accuracy: 0.5963 - val_loss: 1.7299\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7220 - val_accuracy: 0.5963 - val_loss: 1.7287\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7219 - val_accuracy: 0.5963 - val_loss: 1.7285\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7840 - loss: 0.7218 - val_accuracy: 0.5963 - val_loss: 1.7315\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7218 - val_accuracy: 0.5963 - val_loss: 1.7297\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7217 - val_accuracy: 0.5963 - val_loss: 1.7325\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7216 - val_accuracy: 0.5963 - val_loss: 1.7312\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7216 - val_accuracy: 0.5963 - val_loss: 1.7347\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7215 - val_accuracy: 0.5966 - val_loss: 1.7305\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7214 - val_accuracy: 0.5964 - val_loss: 1.7348\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.7214 - val_accuracy: 0.5963 - val_loss: 1.7376\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7833 - loss: 0.7213 - val_accuracy: 0.5963 - val_loss: 1.7353\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7834 - loss: 0.7212 - val_accuracy: 0.5963 - val_loss: 1.7372\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7837 - loss: 0.7211 - val_accuracy: 0.5963 - val_loss: 1.7370\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7836 - loss: 0.7211 - val_accuracy: 0.5963 - val_loss: 1.7373\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7838 - loss: 0.7210 - val_accuracy: 0.5963 - val_loss: 1.7398\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7840 - loss: 0.7209 - val_accuracy: 0.5964 - val_loss: 1.7367\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7847 - loss: 0.7209 - val_accuracy: 0.5963 - val_loss: 1.7383\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7844 - loss: 0.7208 - val_accuracy: 0.5966 - val_loss: 1.7374\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7208 - val_accuracy: 0.5966 - val_loss: 1.7359\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7207 - val_accuracy: 0.5939 - val_loss: 1.7384\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7849 - loss: 0.7206 - val_accuracy: 0.5938 - val_loss: 1.7348\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7206 - val_accuracy: 0.5938 - val_loss: 1.7364\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7846 - loss: 0.7205 - val_accuracy: 0.5938 - val_loss: 1.7386\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7204 - val_accuracy: 0.5938 - val_loss: 1.7408\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7204 - val_accuracy: 0.5938 - val_loss: 1.7390\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7846 - loss: 0.7203 - val_accuracy: 0.5938 - val_loss: 1.7417\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7202 - val_accuracy: 0.5938 - val_loss: 1.7398\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7845 - loss: 0.7202 - val_accuracy: 0.5938 - val_loss: 1.7430\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7844 - loss: 0.7201 - val_accuracy: 0.5938 - val_loss: 1.7391\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7200 - val_accuracy: 0.5938 - val_loss: 1.7392\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7200 - val_accuracy: 0.5938 - val_loss: 1.7411\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7199 - val_accuracy: 0.5938 - val_loss: 1.7446\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7199 - val_accuracy: 0.5938 - val_loss: 1.7402\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7198 - val_accuracy: 0.5938 - val_loss: 1.7408\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7843 - loss: 0.7197 - val_accuracy: 0.5938 - val_loss: 1.7409\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7197 - val_accuracy: 0.5938 - val_loss: 1.7473\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7843 - loss: 0.7196 - val_accuracy: 0.5938 - val_loss: 1.7437\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7195 - val_accuracy: 0.5938 - val_loss: 1.7453\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7849 - loss: 0.7195 - val_accuracy: 0.5939 - val_loss: 1.7458\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7846 - loss: 0.7194 - val_accuracy: 0.5939 - val_loss: 1.7455\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7843 - loss: 0.7194 - val_accuracy: 0.5939 - val_loss: 1.7456\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7845 - loss: 0.7193 - val_accuracy: 0.5939 - val_loss: 1.7463\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7849 - loss: 0.7192 - val_accuracy: 0.5939 - val_loss: 1.7450\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7844 - loss: 0.7192 - val_accuracy: 0.5979 - val_loss: 1.7489\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7845 - loss: 0.7191 - val_accuracy: 0.5939 - val_loss: 1.7461\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7852 - loss: 0.7191 - val_accuracy: 0.5937 - val_loss: 1.7491\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7190 - val_accuracy: 0.5939 - val_loss: 1.7452\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7845 - loss: 0.7189 - val_accuracy: 0.5937 - val_loss: 1.7489\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7847 - loss: 0.7189 - val_accuracy: 0.5939 - val_loss: 1.7466\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7188 - val_accuracy: 0.5936 - val_loss: 1.7480\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7851 - loss: 0.7188 - val_accuracy: 0.5936 - val_loss: 1.7479\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7187 - val_accuracy: 0.5936 - val_loss: 1.7530\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7843 - loss: 0.7187 - val_accuracy: 0.5936 - val_loss: 1.7495\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7844 - loss: 0.7186 - val_accuracy: 0.5980 - val_loss: 1.7495\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7845 - loss: 0.7185 - val_accuracy: 0.5937 - val_loss: 1.7503\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7851 - loss: 0.7185 - val_accuracy: 0.5937 - val_loss: 1.7517\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7847 - loss: 0.7184 - val_accuracy: 0.5936 - val_loss: 1.7524\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7843 - loss: 0.7184 - val_accuracy: 0.5937 - val_loss: 1.7504\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7183 - val_accuracy: 0.5937 - val_loss: 1.7524\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7854 - loss: 0.7183 - val_accuracy: 0.5932 - val_loss: 1.7527\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7182 - val_accuracy: 0.5933 - val_loss: 1.7496\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7872 - loss: 0.7182 - val_accuracy: 0.5974 - val_loss: 1.7554\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7897 - loss: 0.7181 - val_accuracy: 0.5933 - val_loss: 1.7502\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7875 - loss: 0.7180 - val_accuracy: 0.5932 - val_loss: 1.7533\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7180 - val_accuracy: 0.5932 - val_loss: 1.7565\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7179 - val_accuracy: 0.5932 - val_loss: 1.7540\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7179 - val_accuracy: 0.5932 - val_loss: 1.7574\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7884 - loss: 0.7178 - val_accuracy: 0.5933 - val_loss: 1.7539\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7877 - loss: 0.7178 - val_accuracy: 0.5932 - val_loss: 1.7574\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7177 - val_accuracy: 0.5932 - val_loss: 1.7550\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7177 - val_accuracy: 0.5933 - val_loss: 1.7547\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7176 - val_accuracy: 0.5932 - val_loss: 1.7528\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7176 - val_accuracy: 0.5932 - val_loss: 1.7579\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7175 - val_accuracy: 0.5933 - val_loss: 1.7564\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7876 - loss: 0.7175 - val_accuracy: 0.5933 - val_loss: 1.7565\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7876 - loss: 0.7174 - val_accuracy: 0.5932 - val_loss: 1.7600\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7879 - loss: 0.7173 - val_accuracy: 0.5932 - val_loss: 1.7644\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7173 - val_accuracy: 0.5933 - val_loss: 1.7578\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7172 - val_accuracy: 0.5932 - val_loss: 1.7609\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7172 - val_accuracy: 0.5932 - val_loss: 1.7613\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60427\n726/726 - 10s - 14ms/step - accuracy: 0.7873 - loss: 0.7171 - val_accuracy: 0.5932 - val_loss: 1.7612\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7171 - val_accuracy: 0.5934 - val_loss: 1.7594\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7170 - val_accuracy: 0.5935 - val_loss: 1.7600\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7884 - loss: 0.7170 - val_accuracy: 0.5935 - val_loss: 1.7610\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7169 - val_accuracy: 0.5934 - val_loss: 1.7649\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7885 - loss: 0.7169 - val_accuracy: 0.5934 - val_loss: 1.7687\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7882 - loss: 0.7168 - val_accuracy: 0.5934 - val_loss: 1.7614\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7168 - val_accuracy: 0.5934 - val_loss: 1.7642\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7874 - loss: 0.7167 - val_accuracy: 0.5935 - val_loss: 1.7633\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7167 - val_accuracy: 0.5935 - val_loss: 1.7609\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7166 - val_accuracy: 0.5978 - val_loss: 1.7633\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7898 - loss: 0.7166 - val_accuracy: 0.5935 - val_loss: 1.7620\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7874 - loss: 0.7165 - val_accuracy: 0.5935 - val_loss: 1.7635\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7876 - loss: 0.7165 - val_accuracy: 0.5934 - val_loss: 1.7668\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7877 - loss: 0.7164 - val_accuracy: 0.5940 - val_loss: 1.7624\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7877 - loss: 0.7164 - val_accuracy: 0.5983 - val_loss: 1.7617\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7894 - loss: 0.7163 - val_accuracy: 0.5935 - val_loss: 1.7657\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7876 - loss: 0.7163 - val_accuracy: 0.5935 - val_loss: 1.7663\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7875 - loss: 0.7162 - val_accuracy: 0.5935 - val_loss: 1.7638\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7876 - loss: 0.7162 - val_accuracy: 0.5940 - val_loss: 1.7649\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7161 - val_accuracy: 0.5940 - val_loss: 1.7652\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7879 - loss: 0.7161 - val_accuracy: 0.5935 - val_loss: 1.7679\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7878 - loss: 0.7160 - val_accuracy: 0.5941 - val_loss: 1.7644\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7890 - loss: 0.7160 - val_accuracy: 0.5935 - val_loss: 1.7708\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7159 - val_accuracy: 0.5940 - val_loss: 1.7659\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7898 - loss: 0.7159 - val_accuracy: 0.5937 - val_loss: 1.7680\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7158 - val_accuracy: 0.5940 - val_loss: 1.7686\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7878 - loss: 0.7158 - val_accuracy: 0.5940 - val_loss: 1.7689\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7891 - loss: 0.7157 - val_accuracy: 0.5933 - val_loss: 1.7710\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7157 - val_accuracy: 0.5933 - val_loss: 1.7697\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7157 - val_accuracy: 0.5933 - val_loss: 1.7709\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7876 - loss: 0.7156 - val_accuracy: 0.5975 - val_loss: 1.7707\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7156 - val_accuracy: 0.5933 - val_loss: 1.7748\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7155 - val_accuracy: 0.5938 - val_loss: 1.7688\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7877 - loss: 0.7155 - val_accuracy: 0.5980 - val_loss: 1.7763\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7154 - val_accuracy: 0.5938 - val_loss: 1.7701\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7154 - val_accuracy: 0.5937 - val_loss: 1.7724\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7153 - val_accuracy: 0.5974 - val_loss: 1.7725\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7897 - loss: 0.7153 - val_accuracy: 0.5937 - val_loss: 1.7700\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7152 - val_accuracy: 0.5932 - val_loss: 1.7739\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7152 - val_accuracy: 0.5932 - val_loss: 1.7735\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.7151 - val_accuracy: 0.5937 - val_loss: 1.7744\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7151 - val_accuracy: 0.5932 - val_loss: 1.7749\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7151 - val_accuracy: 0.5937 - val_loss: 1.7718\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7904 - loss: 0.7150 - val_accuracy: 0.5937 - val_loss: 1.7727\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7150 - val_accuracy: 0.5932 - val_loss: 1.7770\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7888 - loss: 0.7149 - val_accuracy: 0.5937 - val_loss: 1.7743\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7893 - loss: 0.7149 - val_accuracy: 0.5932 - val_loss: 1.7791\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7148 - val_accuracy: 0.5937 - val_loss: 1.7762\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7148 - val_accuracy: 0.5980 - val_loss: 1.7759\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7147 - val_accuracy: 0.5937 - val_loss: 1.7776\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7147 - val_accuracy: 0.5974 - val_loss: 1.7787\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.7147 - val_accuracy: 0.5980 - val_loss: 1.7779\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7896 - loss: 0.7146 - val_accuracy: 0.5937 - val_loss: 1.7758\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7146 - val_accuracy: 0.5932 - val_loss: 1.7788\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7145 - val_accuracy: 0.5936 - val_loss: 1.7797\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7882 - loss: 0.7145 - val_accuracy: 0.5937 - val_loss: 1.7782\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7144 - val_accuracy: 0.5937 - val_loss: 1.7775\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7144 - val_accuracy: 0.5937 - val_loss: 1.7783\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7881 - loss: 0.7144 - val_accuracy: 0.5975 - val_loss: 1.7814\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7896 - loss: 0.7143 - val_accuracy: 0.5937 - val_loss: 1.7823\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7895 - loss: 0.7143 - val_accuracy: 0.5937 - val_loss: 1.7807\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7875 - loss: 0.7142 - val_accuracy: 0.5937 - val_loss: 1.7806\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.7142 - val_accuracy: 0.5980 - val_loss: 1.7794\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.7141 - val_accuracy: 0.5937 - val_loss: 1.7802\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7141 - val_accuracy: 0.5937 - val_loss: 1.7813\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7902 - loss: 0.7141 - val_accuracy: 0.5937 - val_loss: 1.7823\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7878 - loss: 0.7140 - val_accuracy: 0.5917 - val_loss: 1.7855\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7887 - loss: 0.7140 - val_accuracy: 0.5923 - val_loss: 1.7863\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7893 - loss: 0.7139 - val_accuracy: 0.5923 - val_loss: 1.7849\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7888 - loss: 0.7139 - val_accuracy: 0.5937 - val_loss: 1.7817\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.7138 - val_accuracy: 0.5922 - val_loss: 1.7837\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7884 - loss: 0.7138 - val_accuracy: 0.5937 - val_loss: 1.7829\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7890 - loss: 0.7138 - val_accuracy: 0.5922 - val_loss: 1.7855\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7875 - loss: 0.7137 - val_accuracy: 0.5965 - val_loss: 1.7866\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7894 - loss: 0.7137 - val_accuracy: 0.5964 - val_loss: 1.7866\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7136 - val_accuracy: 0.5965 - val_loss: 1.7865\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7889 - loss: 0.7136 - val_accuracy: 0.5922 - val_loss: 1.7853\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7893 - loss: 0.7136 - val_accuracy: 0.5923 - val_loss: 1.7862\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7879 - loss: 0.7135 - val_accuracy: 0.5965 - val_loss: 1.7832\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7902 - loss: 0.7135 - val_accuracy: 0.5922 - val_loss: 1.7867\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7881 - loss: 0.7134 - val_accuracy: 0.5966 - val_loss: 1.7839\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7897 - loss: 0.7134 - val_accuracy: 0.5917 - val_loss: 1.7920\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7873 - loss: 0.7134 - val_accuracy: 0.5922 - val_loss: 1.7895\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7893 - loss: 0.7133 - val_accuracy: 0.5922 - val_loss: 1.7870\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7133 - val_accuracy: 0.5923 - val_loss: 1.7863\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7892 - loss: 0.7132 - val_accuracy: 0.5965 - val_loss: 1.7875\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7132 - val_accuracy: 0.5965 - val_loss: 1.7882\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7132 - val_accuracy: 0.5961 - val_loss: 1.7896\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7903 - loss: 0.7131 - val_accuracy: 0.5918 - val_loss: 1.7917\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7899 - loss: 0.7131 - val_accuracy: 0.5919 - val_loss: 1.7921\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7881 - loss: 0.7130 - val_accuracy: 0.5919 - val_loss: 1.7928\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7900 - loss: 0.7130 - val_accuracy: 0.5919 - val_loss: 1.7901\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7130 - val_accuracy: 0.5962 - val_loss: 1.7922\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7129 - val_accuracy: 0.5962 - val_loss: 1.7945\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7129 - val_accuracy: 0.5919 - val_loss: 1.7916\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7892 - loss: 0.7128 - val_accuracy: 0.5962 - val_loss: 1.7918\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7892 - loss: 0.7128 - val_accuracy: 0.5962 - val_loss: 1.7919\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7906 - loss: 0.7128 - val_accuracy: 0.5919 - val_loss: 1.7905\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7877 - loss: 0.7127 - val_accuracy: 0.5962 - val_loss: 1.7988\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7904 - loss: 0.7127 - val_accuracy: 0.5962 - val_loss: 1.7943\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7126 - val_accuracy: 0.5962 - val_loss: 1.7943\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7896 - loss: 0.7126 - val_accuracy: 0.5962 - val_loss: 1.7971\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7902 - loss: 0.7126 - val_accuracy: 0.5919 - val_loss: 1.7937\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7125 - val_accuracy: 0.5962 - val_loss: 1.7954\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7898 - loss: 0.7125 - val_accuracy: 0.5962 - val_loss: 1.7955\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7884 - loss: 0.7125 - val_accuracy: 0.5962 - val_loss: 1.7966\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7903 - loss: 0.7124 - val_accuracy: 0.5919 - val_loss: 1.7985\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7899 - loss: 0.7124 - val_accuracy: 0.5919 - val_loss: 1.7965\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7877 - loss: 0.7123 - val_accuracy: 0.5961 - val_loss: 1.7966\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7901 - loss: 0.7123 - val_accuracy: 0.5919 - val_loss: 1.7969\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7899 - loss: 0.7123 - val_accuracy: 0.5962 - val_loss: 1.7994\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7896 - loss: 0.7122 - val_accuracy: 0.5962 - val_loss: 1.7953\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7906 - loss: 0.7122 - val_accuracy: 0.5918 - val_loss: 1.7994\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7885 - loss: 0.7122 - val_accuracy: 0.5919 - val_loss: 1.7974\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7121 - val_accuracy: 0.5960 - val_loss: 1.7961\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7897 - loss: 0.7121 - val_accuracy: 0.5958 - val_loss: 1.8001\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7908 - loss: 0.7120 - val_accuracy: 0.5916 - val_loss: 1.7991\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7888 - loss: 0.7120 - val_accuracy: 0.5917 - val_loss: 1.7990\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7894 - loss: 0.7120 - val_accuracy: 0.5960 - val_loss: 1.7975\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7901 - loss: 0.7119 - val_accuracy: 0.5960 - val_loss: 1.7983\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7119 - val_accuracy: 0.5960 - val_loss: 1.8013\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7910 - loss: 0.7119 - val_accuracy: 0.5960 - val_loss: 1.8007\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7909 - loss: 0.7118 - val_accuracy: 0.5917 - val_loss: 1.8008\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7897 - loss: 0.7118 - val_accuracy: 0.5958 - val_loss: 1.8014\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7898 - loss: 0.7118 - val_accuracy: 0.5916 - val_loss: 1.8034\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7117 - val_accuracy: 0.5959 - val_loss: 1.8005\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7117 - val_accuracy: 0.5960 - val_loss: 1.8012\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7891 - loss: 0.7116 - val_accuracy: 0.5958 - val_loss: 1.8054\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7898 - loss: 0.7116 - val_accuracy: 0.5958 - val_loss: 1.8097\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7905 - loss: 0.7116 - val_accuracy: 0.5917 - val_loss: 1.8029\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7896 - loss: 0.7115 - val_accuracy: 0.5960 - val_loss: 1.8014\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7893 - loss: 0.7115 - val_accuracy: 0.5958 - val_loss: 1.8044\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7909 - loss: 0.7115 - val_accuracy: 0.5917 - val_loss: 1.8036\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7904 - loss: 0.7114 - val_accuracy: 0.5916 - val_loss: 1.8043\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7900 - loss: 0.7114 - val_accuracy: 0.5960 - val_loss: 1.8037\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7888 - loss: 0.7114 - val_accuracy: 0.5959 - val_loss: 1.8060\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7909 - loss: 0.7113 - val_accuracy: 0.5958 - val_loss: 1.8090\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_17, X_test_17, y_train_17, y_test_17 = train_test_split(\n    X, y, test_size=0.3, random_state=59, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_17, X_val_17, y_train_17, y_val_17 = train_test_split(\n    X_train_17, y_train_17, test_size=0.2, random_state=59, stratify=y_train_17\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_17:\", np.max(X_train_17))\nprint(\"Min value in X_train_17:\", np.min(X_train_17))\n\nX_train_17_scaled = scaler.fit_transform(X_train_17)\n\n# Get the original class distribution\nclass_counts_17 = Counter(y_train_17)\nprint(\"Original class distribution:\", class_counts_17)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_17 = class_counts_17[min(class_counts_17, key=class_counts_17.get)]\ndesired_majority_size_17 = minority_class_size_17 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_17 = {0: desired_majority_size_17, 1: minority_class_size_17}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_17 = RandomUnderSampler(sampling_strategy=sampling_strategy_17, random_state=42)\nX_resampled_17, y_resampled_17 = undersampler_17.fit_resample(X_train_17, y_train_17)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_17))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_17, y_train_resampled_17 = smote.fit_resample(X_resampled_17, y_resampled_17)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_17))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_17))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T10:28:22.883638Z","iopub.execute_input":"2025-03-07T10:28:22.884069Z","iopub.status.idle":"2025-03-07T10:29:02.189634Z","shell.execute_reply.started":"2025-03-07T10:28:22.884035Z","shell.execute_reply":"2025-03-07T10:29:02.188456Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_17: 2071000000.0\nMin value in X_train_17: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_17 = X_train_resampled_17.reshape(X_train_resampled_17.shape[0], 1, 56)\nX_val_17 = X_val_17.reshape(X_val_17.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_17,  # Features from CICIDS2017\n    y_train_resampled_17,  # Labels from CICIDS2017\n    validation_data=(X_val_17, y_val_17),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T10:29:02.192077Z","iopub.execute_input":"2025-03-07T10:29:02.192360Z","iopub.status.idle":"2025-03-07T11:15:11.330441Z","shell.execute_reply.started":"2025-03-07T10:29:02.192337Z","shell.execute_reply":"2025-03-07T11:15:11.328810Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7766 - val_accuracy: 0.6031 - val_loss: 1.7655\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7894 - loss: 0.7727 - val_accuracy: 0.6031 - val_loss: 1.7659\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7897 - loss: 0.7705 - val_accuracy: 0.6014 - val_loss: 1.7679\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7912 - loss: 0.7688 - val_accuracy: 0.6016 - val_loss: 1.7655\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7923 - loss: 0.7674 - val_accuracy: 0.6009 - val_loss: 1.7682\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7661 - val_accuracy: 0.6000 - val_loss: 1.7703\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7975 - loss: 0.7649 - val_accuracy: 0.5971 - val_loss: 1.7697\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7638 - val_accuracy: 0.5970 - val_loss: 1.7685\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7949 - loss: 0.7628 - val_accuracy: 0.5970 - val_loss: 1.7660\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7619 - val_accuracy: 0.5969 - val_loss: 1.7647\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7968 - loss: 0.7611 - val_accuracy: 0.5969 - val_loss: 1.7658\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7603 - val_accuracy: 0.5969 - val_loss: 1.7680\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7966 - loss: 0.7595 - val_accuracy: 0.5999 - val_loss: 1.7666\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7588 - val_accuracy: 0.5998 - val_loss: 1.7654\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7581 - val_accuracy: 0.5998 - val_loss: 1.7640\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7575 - val_accuracy: 0.5998 - val_loss: 1.7620\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7569 - val_accuracy: 0.5997 - val_loss: 1.7610\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7563 - val_accuracy: 0.5997 - val_loss: 1.7642\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7558 - val_accuracy: 0.5997 - val_loss: 1.7645\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7553 - val_accuracy: 0.5998 - val_loss: 1.7647\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7548 - val_accuracy: 0.5998 - val_loss: 1.7601\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7544 - val_accuracy: 0.5998 - val_loss: 1.7626\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7539 - val_accuracy: 0.5997 - val_loss: 1.7624\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7947 - loss: 0.7535 - val_accuracy: 0.5995 - val_loss: 1.7611\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7947 - loss: 0.7531 - val_accuracy: 0.5992 - val_loss: 1.7594\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7947 - loss: 0.7527 - val_accuracy: 0.5991 - val_loss: 1.7594\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7947 - loss: 0.7523 - val_accuracy: 0.5990 - val_loss: 1.7562\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7520 - val_accuracy: 0.5990 - val_loss: 1.7583\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7516 - val_accuracy: 0.5987 - val_loss: 1.7551\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7956 - loss: 0.7513 - val_accuracy: 0.5985 - val_loss: 1.7576\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7510 - val_accuracy: 0.5985 - val_loss: 1.7543\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7965 - loss: 0.7507 - val_accuracy: 0.5985 - val_loss: 1.7571\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7983 - loss: 0.7504 - val_accuracy: 0.5986 - val_loss: 1.7542\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7501 - val_accuracy: 0.5984 - val_loss: 1.7526\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7499 - val_accuracy: 0.5981 - val_loss: 1.7520\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7496 - val_accuracy: 0.5981 - val_loss: 1.7521\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7493 - val_accuracy: 0.5984 - val_loss: 1.7534\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7988 - loss: 0.7491 - val_accuracy: 0.5981 - val_loss: 1.7512\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7489 - val_accuracy: 0.5981 - val_loss: 1.7543\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7486 - val_accuracy: 0.5981 - val_loss: 1.7498\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7484 - val_accuracy: 0.5981 - val_loss: 1.7461\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7482 - val_accuracy: 0.5981 - val_loss: 1.7523\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7480 - val_accuracy: 0.5979 - val_loss: 1.7531\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7478 - val_accuracy: 0.5979 - val_loss: 1.7482\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7476 - val_accuracy: 0.5981 - val_loss: 1.7465\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7474 - val_accuracy: 0.5981 - val_loss: 1.7442\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7472 - val_accuracy: 0.5979 - val_loss: 1.7505\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7470 - val_accuracy: 0.5980 - val_loss: 1.7457\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7468 - val_accuracy: 0.5982 - val_loss: 1.7438\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.7985 - loss: 0.7466 - val_accuracy: 0.5981 - val_loss: 1.7460\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.7985 - loss: 0.7465 - val_accuracy: 0.5980 - val_loss: 1.7444\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.7463 - val_accuracy: 0.5978 - val_loss: 1.7444\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7461 - val_accuracy: 0.5977 - val_loss: 1.7478\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.7460 - val_accuracy: 0.5976 - val_loss: 1.7455\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.7458 - val_accuracy: 0.5977 - val_loss: 1.7426\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7983 - loss: 0.7457 - val_accuracy: 0.5977 - val_loss: 1.7440\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7978 - loss: 0.7455 - val_accuracy: 0.5977 - val_loss: 1.7402\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7978 - loss: 0.7454 - val_accuracy: 0.5977 - val_loss: 1.7414\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7976 - loss: 0.7452 - val_accuracy: 0.5976 - val_loss: 1.7414\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7977 - loss: 0.7451 - val_accuracy: 0.5976 - val_loss: 1.7456\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7976 - loss: 0.7449 - val_accuracy: 0.5976 - val_loss: 1.7424\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7968 - loss: 0.7448 - val_accuracy: 0.5976 - val_loss: 1.7394\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7447 - val_accuracy: 0.5977 - val_loss: 1.7408\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7445 - val_accuracy: 0.5976 - val_loss: 1.7411\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7444 - val_accuracy: 0.5976 - val_loss: 1.7381\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7443 - val_accuracy: 0.5976 - val_loss: 1.7432\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7441 - val_accuracy: 0.5976 - val_loss: 1.7383\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7440 - val_accuracy: 0.5976 - val_loss: 1.7379\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7439 - val_accuracy: 0.5977 - val_loss: 1.7370\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7438 - val_accuracy: 0.5976 - val_loss: 1.7400\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7436 - val_accuracy: 0.5977 - val_loss: 1.7360\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7435 - val_accuracy: 0.5976 - val_loss: 1.7365\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7434 - val_accuracy: 0.5976 - val_loss: 1.7349\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7433 - val_accuracy: 0.5976 - val_loss: 1.7342\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7432 - val_accuracy: 0.5974 - val_loss: 1.7396\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7431 - val_accuracy: 0.5974 - val_loss: 1.7355\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7430 - val_accuracy: 0.5974 - val_loss: 1.7355\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7429 - val_accuracy: 0.5974 - val_loss: 1.7361\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7428 - val_accuracy: 0.5976 - val_loss: 1.7396\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7427 - val_accuracy: 0.5976 - val_loss: 1.7349\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7967 - loss: 0.7425 - val_accuracy: 0.5976 - val_loss: 1.7366\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7967 - loss: 0.7424 - val_accuracy: 0.5976 - val_loss: 1.7346\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7423 - val_accuracy: 0.5977 - val_loss: 1.7300\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7967 - loss: 0.7422 - val_accuracy: 0.5976 - val_loss: 1.7357\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7421 - val_accuracy: 0.5977 - val_loss: 1.7318\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7420 - val_accuracy: 0.5976 - val_loss: 1.7302\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7968 - loss: 0.7419 - val_accuracy: 0.5975 - val_loss: 1.7323\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7968 - loss: 0.7418 - val_accuracy: 0.5975 - val_loss: 1.7309\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7418 - val_accuracy: 0.5975 - val_loss: 1.7297\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7417 - val_accuracy: 0.5975 - val_loss: 1.7284\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7969 - loss: 0.7416 - val_accuracy: 0.5975 - val_loss: 1.7298\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7969 - loss: 0.7415 - val_accuracy: 0.5975 - val_loss: 1.7243\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7963 - loss: 0.7414 - val_accuracy: 0.5974 - val_loss: 1.7333\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7413 - val_accuracy: 0.5975 - val_loss: 1.7248\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7958 - loss: 0.7412 - val_accuracy: 0.5975 - val_loss: 1.7276\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7411 - val_accuracy: 0.5975 - val_loss: 1.7282\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7410 - val_accuracy: 0.5975 - val_loss: 1.7246\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7409 - val_accuracy: 0.5975 - val_loss: 1.7302\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7409 - val_accuracy: 0.5975 - val_loss: 1.7309\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7408 - val_accuracy: 0.5975 - val_loss: 1.7274\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7407 - val_accuracy: 0.5975 - val_loss: 1.7296\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7406 - val_accuracy: 0.5975 - val_loss: 1.7234\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7405 - val_accuracy: 0.5975 - val_loss: 1.7260\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7404 - val_accuracy: 0.5975 - val_loss: 1.7262\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7403 - val_accuracy: 0.5975 - val_loss: 1.7216\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7403 - val_accuracy: 0.5974 - val_loss: 1.7302\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7402 - val_accuracy: 0.5975 - val_loss: 1.7273\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7401 - val_accuracy: 0.5978 - val_loss: 1.7227\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7400 - val_accuracy: 0.5969 - val_loss: 1.7270\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7399 - val_accuracy: 0.5972 - val_loss: 1.7237\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7399 - val_accuracy: 0.5972 - val_loss: 1.7218\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7398 - val_accuracy: 0.5972 - val_loss: 1.7216\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7397 - val_accuracy: 0.5972 - val_loss: 1.7236\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7396 - val_accuracy: 0.5972 - val_loss: 1.7227\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7396 - val_accuracy: 0.5972 - val_loss: 1.7238\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7395 - val_accuracy: 0.5972 - val_loss: 1.7253\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7394 - val_accuracy: 0.5972 - val_loss: 1.7223\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7393 - val_accuracy: 0.5972 - val_loss: 1.7213\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7393 - val_accuracy: 0.5972 - val_loss: 1.7223\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7392 - val_accuracy: 0.5972 - val_loss: 1.7251\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7391 - val_accuracy: 0.5972 - val_loss: 1.7207\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7390 - val_accuracy: 0.5972 - val_loss: 1.7219\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7390 - val_accuracy: 0.5972 - val_loss: 1.7171\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7389 - val_accuracy: 0.5972 - val_loss: 1.7200\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7388 - val_accuracy: 0.5972 - val_loss: 1.7209\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7387 - val_accuracy: 0.5972 - val_loss: 1.7199\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7387 - val_accuracy: 0.5972 - val_loss: 1.7207\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7386 - val_accuracy: 0.5972 - val_loss: 1.7205\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7385 - val_accuracy: 0.5972 - val_loss: 1.7159\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7385 - val_accuracy: 0.5967 - val_loss: 1.7227\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7384 - val_accuracy: 0.5968 - val_loss: 1.7171\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7383 - val_accuracy: 0.5968 - val_loss: 1.7186\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7383 - val_accuracy: 0.5964 - val_loss: 1.7215\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7382 - val_accuracy: 0.5964 - val_loss: 1.7171\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7381 - val_accuracy: 0.5964 - val_loss: 1.7174\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7381 - val_accuracy: 0.5964 - val_loss: 1.7205\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7380 - val_accuracy: 0.5964 - val_loss: 1.7184\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.7957 - loss: 0.7379 - val_accuracy: 0.5964 - val_loss: 1.7196\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7379 - val_accuracy: 0.5964 - val_loss: 1.7181\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7378 - val_accuracy: 0.5964 - val_loss: 1.7202\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7377 - val_accuracy: 0.5964 - val_loss: 1.7160\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7377 - val_accuracy: 0.5964 - val_loss: 1.7199\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7957 - loss: 0.7376 - val_accuracy: 0.5964 - val_loss: 1.7151\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7957 - loss: 0.7375 - val_accuracy: 0.5964 - val_loss: 1.7168\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7375 - val_accuracy: 0.5964 - val_loss: 1.7168\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.7374 - val_accuracy: 0.5964 - val_loss: 1.7130\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7373 - val_accuracy: 0.5964 - val_loss: 1.7172\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7373 - val_accuracy: 0.5964 - val_loss: 1.7125\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7956 - loss: 0.7372 - val_accuracy: 0.5964 - val_loss: 1.7141\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7371 - val_accuracy: 0.5964 - val_loss: 1.7121\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7371 - val_accuracy: 0.5964 - val_loss: 1.7177\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7370 - val_accuracy: 0.5964 - val_loss: 1.7107\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7370 - val_accuracy: 0.5964 - val_loss: 1.7127\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7369 - val_accuracy: 0.5961 - val_loss: 1.7165\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7954 - loss: 0.7368 - val_accuracy: 0.5962 - val_loss: 1.7140\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7954 - loss: 0.7368 - val_accuracy: 0.5962 - val_loss: 1.7137\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7367 - val_accuracy: 0.5962 - val_loss: 1.7110\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7366 - val_accuracy: 0.5962 - val_loss: 1.7101\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7366 - val_accuracy: 0.5962 - val_loss: 1.7138\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7365 - val_accuracy: 0.5960 - val_loss: 1.7087\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7365 - val_accuracy: 0.5959 - val_loss: 1.7127\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7364 - val_accuracy: 0.5960 - val_loss: 1.7083\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7363 - val_accuracy: 0.5960 - val_loss: 1.7138\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7363 - val_accuracy: 0.5959 - val_loss: 1.7150\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7362 - val_accuracy: 0.5960 - val_loss: 1.7118\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7362 - val_accuracy: 0.5959 - val_loss: 1.7143\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7361 - val_accuracy: 0.5960 - val_loss: 1.7108\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7360 - val_accuracy: 0.5959 - val_loss: 1.7105\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7360 - val_accuracy: 0.5960 - val_loss: 1.7111\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7359 - val_accuracy: 0.5946 - val_loss: 1.7151\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7359 - val_accuracy: 0.5960 - val_loss: 1.7085\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7358 - val_accuracy: 0.5960 - val_loss: 1.7094\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7358 - val_accuracy: 0.5946 - val_loss: 1.7112\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7357 - val_accuracy: 0.5959 - val_loss: 1.7089\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7356 - val_accuracy: 0.5946 - val_loss: 1.7117\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7356 - val_accuracy: 0.5946 - val_loss: 1.7166\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7355 - val_accuracy: 0.5960 - val_loss: 1.7099\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7355 - val_accuracy: 0.5960 - val_loss: 1.7087\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7354 - val_accuracy: 0.5959 - val_loss: 1.7114\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7354 - val_accuracy: 0.5960 - val_loss: 1.7053\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7353 - val_accuracy: 0.5959 - val_loss: 1.7092\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7352 - val_accuracy: 0.5959 - val_loss: 1.7086\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7352 - val_accuracy: 0.5946 - val_loss: 1.7088\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7351 - val_accuracy: 0.5946 - val_loss: 1.7098\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7351 - val_accuracy: 0.5946 - val_loss: 1.7127\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7350 - val_accuracy: 0.5946 - val_loss: 1.7083\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7350 - val_accuracy: 0.5946 - val_loss: 1.7094\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7349 - val_accuracy: 0.5946 - val_loss: 1.7087\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7349 - val_accuracy: 0.5959 - val_loss: 1.7085\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7348 - val_accuracy: 0.5946 - val_loss: 1.7099\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7348 - val_accuracy: 0.5946 - val_loss: 1.7093\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7347 - val_accuracy: 0.5959 - val_loss: 1.7072\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7346 - val_accuracy: 0.5946 - val_loss: 1.7051\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7346 - val_accuracy: 0.5946 - val_loss: 1.7056\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7345 - val_accuracy: 0.5946 - val_loss: 1.7053\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7345 - val_accuracy: 0.5946 - val_loss: 1.7072\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7344 - val_accuracy: 0.5946 - val_loss: 1.7057\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7344 - val_accuracy: 0.5946 - val_loss: 1.7057\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7343 - val_accuracy: 0.5946 - val_loss: 1.7084\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7343 - val_accuracy: 0.5946 - val_loss: 1.7100\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7342 - val_accuracy: 0.5946 - val_loss: 1.7070\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7342 - val_accuracy: 0.5946 - val_loss: 1.7038\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7341 - val_accuracy: 0.5946 - val_loss: 1.7092\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7341 - val_accuracy: 0.5946 - val_loss: 1.7078\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7340 - val_accuracy: 0.5946 - val_loss: 1.7086\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7340 - val_accuracy: 0.5946 - val_loss: 1.7029\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7339 - val_accuracy: 0.5946 - val_loss: 1.7029\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7339 - val_accuracy: 0.5946 - val_loss: 1.7061\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7338 - val_accuracy: 0.5945 - val_loss: 1.7066\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7338 - val_accuracy: 0.5945 - val_loss: 1.7078\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7337 - val_accuracy: 0.5945 - val_loss: 1.7037\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7337 - val_accuracy: 0.5945 - val_loss: 1.7052\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7336 - val_accuracy: 0.5945 - val_loss: 1.7033\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7336 - val_accuracy: 0.5945 - val_loss: 1.7056\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7335 - val_accuracy: 0.5946 - val_loss: 1.7026\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7335 - val_accuracy: 0.5945 - val_loss: 1.7044\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7334 - val_accuracy: 0.5945 - val_loss: 1.7030\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7334 - val_accuracy: 0.5945 - val_loss: 1.7043\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7333 - val_accuracy: 0.5945 - val_loss: 1.7031\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7333 - val_accuracy: 0.5945 - val_loss: 1.7069\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7332 - val_accuracy: 0.5945 - val_loss: 1.7049\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7332 - val_accuracy: 0.5945 - val_loss: 1.7030\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7331 - val_accuracy: 0.5945 - val_loss: 1.7051\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7331 - val_accuracy: 0.5945 - val_loss: 1.7027\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7330 - val_accuracy: 0.5945 - val_loss: 1.7028\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7330 - val_accuracy: 0.5945 - val_loss: 1.7051\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7329 - val_accuracy: 0.5945 - val_loss: 1.7030\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7329 - val_accuracy: 0.5945 - val_loss: 1.7013\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7328 - val_accuracy: 0.5945 - val_loss: 1.7026\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7328 - val_accuracy: 0.5945 - val_loss: 1.7040\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7327 - val_accuracy: 0.5945 - val_loss: 1.7081\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7327 - val_accuracy: 0.5945 - val_loss: 1.6975\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7326 - val_accuracy: 0.5945 - val_loss: 1.7041\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7326 - val_accuracy: 0.5945 - val_loss: 1.6995\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7326 - val_accuracy: 0.5945 - val_loss: 1.7038\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7325 - val_accuracy: 0.5945 - val_loss: 1.7040\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7325 - val_accuracy: 0.5945 - val_loss: 1.7043\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7324 - val_accuracy: 0.5945 - val_loss: 1.7037\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7324 - val_accuracy: 0.5945 - val_loss: 1.7008\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7323 - val_accuracy: 0.5945 - val_loss: 1.7031\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7323 - val_accuracy: 0.5945 - val_loss: 1.7041\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7950 - loss: 0.7322 - val_accuracy: 0.5945 - val_loss: 1.7014\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7322 - val_accuracy: 0.5945 - val_loss: 1.7016\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7321 - val_accuracy: 0.5945 - val_loss: 1.7000\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7321 - val_accuracy: 0.5946 - val_loss: 1.6982\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7320 - val_accuracy: 0.5945 - val_loss: 1.7005\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7320 - val_accuracy: 0.5945 - val_loss: 1.7042\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7320 - val_accuracy: 0.5945 - val_loss: 1.6983\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7950 - loss: 0.7319 - val_accuracy: 0.5945 - val_loss: 1.6961\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7319 - val_accuracy: 0.5945 - val_loss: 1.7028\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7318 - val_accuracy: 0.5945 - val_loss: 1.7011\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7318 - val_accuracy: 0.5945 - val_loss: 1.7018\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7317 - val_accuracy: 0.5945 - val_loss: 1.7013\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7317 - val_accuracy: 0.5946 - val_loss: 1.6978\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7316 - val_accuracy: 0.5946 - val_loss: 1.6955\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7316 - val_accuracy: 0.5946 - val_loss: 1.6976\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7316 - val_accuracy: 0.5945 - val_loss: 1.6977\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7315 - val_accuracy: 0.5946 - val_loss: 1.6987\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7315 - val_accuracy: 0.5945 - val_loss: 1.6995\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7314 - val_accuracy: 0.5946 - val_loss: 1.6972\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7314 - val_accuracy: 0.5945 - val_loss: 1.7020\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7313 - val_accuracy: 0.5946 - val_loss: 1.6969\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7313 - val_accuracy: 0.5945 - val_loss: 1.7005\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7313 - val_accuracy: 0.5946 - val_loss: 1.7011\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7312 - val_accuracy: 0.5945 - val_loss: 1.7018\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7312 - val_accuracy: 0.5946 - val_loss: 1.6973\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7311 - val_accuracy: 0.5945 - val_loss: 1.6986\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7311 - val_accuracy: 0.5946 - val_loss: 1.6999\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7310 - val_accuracy: 0.5946 - val_loss: 1.6957\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7310 - val_accuracy: 0.5946 - val_loss: 1.6961\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7310 - val_accuracy: 0.5945 - val_loss: 1.6986\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7309 - val_accuracy: 0.5946 - val_loss: 1.6992\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7309 - val_accuracy: 0.5945 - val_loss: 1.6962\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7308 - val_accuracy: 0.5946 - val_loss: 1.6947\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7308 - val_accuracy: 0.5946 - val_loss: 1.6981\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7307 - val_accuracy: 0.5945 - val_loss: 1.6973\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7307 - val_accuracy: 0.5946 - val_loss: 1.6963\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7307 - val_accuracy: 0.5945 - val_loss: 1.6973\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7306 - val_accuracy: 0.5946 - val_loss: 1.6941\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7306 - val_accuracy: 0.5945 - val_loss: 1.6977\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7954 - loss: 0.7305 - val_accuracy: 0.5945 - val_loss: 1.6982\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7305 - val_accuracy: 0.5946 - val_loss: 1.6951\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7305 - val_accuracy: 0.5945 - val_loss: 1.6985\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7304 - val_accuracy: 0.5946 - val_loss: 1.6946\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7304 - val_accuracy: 0.5946 - val_loss: 1.6935\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7303 - val_accuracy: 0.5946 - val_loss: 1.6947\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7303 - val_accuracy: 0.5945 - val_loss: 1.6949\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7954 - loss: 0.7303 - val_accuracy: 0.5945 - val_loss: 1.7005\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7954 - loss: 0.7302 - val_accuracy: 0.5946 - val_loss: 1.6961\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7302 - val_accuracy: 0.5942 - val_loss: 1.6973\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7301 - val_accuracy: 0.5946 - val_loss: 1.6977\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7301 - val_accuracy: 0.5946 - val_loss: 1.6937\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7301 - val_accuracy: 0.5946 - val_loss: 1.6939\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7955 - loss: 0.7300 - val_accuracy: 0.5946 - val_loss: 1.6946\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7300 - val_accuracy: 0.5946 - val_loss: 1.6957\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7299 - val_accuracy: 0.5946 - val_loss: 1.6963\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7299 - val_accuracy: 0.5946 - val_loss: 1.6916\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7955 - loss: 0.7299 - val_accuracy: 0.5946 - val_loss: 1.6920\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7956 - loss: 0.7298 - val_accuracy: 0.5946 - val_loss: 1.6938\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7956 - loss: 0.7298 - val_accuracy: 0.5943 - val_loss: 1.6955\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7297 - val_accuracy: 0.5943 - val_loss: 1.6947\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7956 - loss: 0.7297 - val_accuracy: 0.5944 - val_loss: 1.6932\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7297 - val_accuracy: 0.5943 - val_loss: 1.6957\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7956 - loss: 0.7296 - val_accuracy: 0.5944 - val_loss: 1.6926\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7956 - loss: 0.7296 - val_accuracy: 0.5946 - val_loss: 1.6904\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7955 - loss: 0.7295 - val_accuracy: 0.5943 - val_loss: 1.6965\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7956 - loss: 0.7295 - val_accuracy: 0.5943 - val_loss: 1.6941\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7295 - val_accuracy: 0.5933 - val_loss: 1.6967\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7956 - loss: 0.7294 - val_accuracy: 0.5933 - val_loss: 1.6958\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7294 - val_accuracy: 0.5936 - val_loss: 1.6942\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7956 - loss: 0.7294 - val_accuracy: 0.5936 - val_loss: 1.6888\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7293 - val_accuracy: 0.5936 - val_loss: 1.6911\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7293 - val_accuracy: 0.5933 - val_loss: 1.6966\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7292 - val_accuracy: 0.5933 - val_loss: 1.6938\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7292 - val_accuracy: 0.5933 - val_loss: 1.6899\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7955 - loss: 0.7292 - val_accuracy: 0.5933 - val_loss: 1.6948\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7956 - loss: 0.7291 - val_accuracy: 0.5933 - val_loss: 1.6914\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7291 - val_accuracy: 0.5933 - val_loss: 1.6946\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7291 - val_accuracy: 0.5933 - val_loss: 1.6895\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7290 - val_accuracy: 0.5932 - val_loss: 1.6949\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7290 - val_accuracy: 0.5933 - val_loss: 1.6954\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7956 - loss: 0.7289 - val_accuracy: 0.5933 - val_loss: 1.6913\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7289 - val_accuracy: 0.5933 - val_loss: 1.6900\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7289 - val_accuracy: 0.5933 - val_loss: 1.6938\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7954 - loss: 0.7288 - val_accuracy: 0.5933 - val_loss: 1.6912\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7288 - val_accuracy: 0.5932 - val_loss: 1.6913\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7949 - loss: 0.7288 - val_accuracy: 0.5933 - val_loss: 1.6930\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7287 - val_accuracy: 0.5933 - val_loss: 1.6882\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7287 - val_accuracy: 0.5933 - val_loss: 1.6877\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7286 - val_accuracy: 0.5932 - val_loss: 1.6931\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7286 - val_accuracy: 0.5933 - val_loss: 1.6883\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7286 - val_accuracy: 0.5933 - val_loss: 1.6943\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7949 - loss: 0.7285 - val_accuracy: 0.5933 - val_loss: 1.6903\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7285 - val_accuracy: 0.5933 - val_loss: 1.6897\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7285 - val_accuracy: 0.5936 - val_loss: 1.6889\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7284 - val_accuracy: 0.5933 - val_loss: 1.6915\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7284 - val_accuracy: 0.5933 - val_loss: 1.6903\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7284 - val_accuracy: 0.5933 - val_loss: 1.6865\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7283 - val_accuracy: 0.5933 - val_loss: 1.6885\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7283 - val_accuracy: 0.5933 - val_loss: 1.6894\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7282 - val_accuracy: 0.5936 - val_loss: 1.6880\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7282 - val_accuracy: 0.5935 - val_loss: 1.6889\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7282 - val_accuracy: 0.5935 - val_loss: 1.6913\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7281 - val_accuracy: 0.5932 - val_loss: 1.6885\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7950 - loss: 0.7281 - val_accuracy: 0.5932 - val_loss: 1.6863\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7281 - val_accuracy: 0.5936 - val_loss: 1.6887\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7280 - val_accuracy: 0.5934 - val_loss: 1.6919\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7280 - val_accuracy: 0.5934 - val_loss: 1.6909\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7280 - val_accuracy: 0.5931 - val_loss: 1.6883\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7950 - loss: 0.7279 - val_accuracy: 0.5936 - val_loss: 1.6859\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7951 - loss: 0.7279 - val_accuracy: 0.5935 - val_loss: 1.6895\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7279 - val_accuracy: 0.5936 - val_loss: 1.6858\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7278 - val_accuracy: 0.5932 - val_loss: 1.6891\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7278 - val_accuracy: 0.5933 - val_loss: 1.6887\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7278 - val_accuracy: 0.5932 - val_loss: 1.6890\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7277 - val_accuracy: 0.5935 - val_loss: 1.6883\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7277 - val_accuracy: 0.5934 - val_loss: 1.6887\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7277 - val_accuracy: 0.5936 - val_loss: 1.6861\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7276 - val_accuracy: 0.5930 - val_loss: 1.6901\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7276 - val_accuracy: 0.5934 - val_loss: 1.6892\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7276 - val_accuracy: 0.5934 - val_loss: 1.6856\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7275 - val_accuracy: 0.5935 - val_loss: 1.6846\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7275 - val_accuracy: 0.5934 - val_loss: 1.6887\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7274 - val_accuracy: 0.5934 - val_loss: 1.6903\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7274 - val_accuracy: 0.5930 - val_loss: 1.6892\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7274 - val_accuracy: 0.5931 - val_loss: 1.6880\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7273 - val_accuracy: 0.5934 - val_loss: 1.6876\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7273 - val_accuracy: 0.5931 - val_loss: 1.6889\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7273 - val_accuracy: 0.5932 - val_loss: 1.6866\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7272 - val_accuracy: 0.5932 - val_loss: 1.6883\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7272 - val_accuracy: 0.5931 - val_loss: 1.6878\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7272 - val_accuracy: 0.5935 - val_loss: 1.6839\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7271 - val_accuracy: 0.5934 - val_loss: 1.6860\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7271 - val_accuracy: 0.5934 - val_loss: 1.6892\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7952 - loss: 0.7271 - val_accuracy: 0.5934 - val_loss: 1.6881\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7271 - val_accuracy: 0.5934 - val_loss: 1.6885\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7270 - val_accuracy: 0.5935 - val_loss: 1.6859\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7270 - val_accuracy: 0.5934 - val_loss: 1.6882\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7270 - val_accuracy: 0.5936 - val_loss: 1.6846\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7269 - val_accuracy: 0.5939 - val_loss: 1.6848\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7269 - val_accuracy: 0.5936 - val_loss: 1.6856\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7269 - val_accuracy: 0.5935 - val_loss: 1.6913\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7268 - val_accuracy: 0.5939 - val_loss: 1.6862\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7954 - loss: 0.7268 - val_accuracy: 0.5937 - val_loss: 1.6904\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7268 - val_accuracy: 0.5937 - val_loss: 1.6893\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7267 - val_accuracy: 0.5939 - val_loss: 1.6866\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7267 - val_accuracy: 0.5937 - val_loss: 1.6919\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7267 - val_accuracy: 0.5938 - val_loss: 1.6830\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7266 - val_accuracy: 0.5938 - val_loss: 1.6878\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7266 - val_accuracy: 0.5938 - val_loss: 1.6855\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7266 - val_accuracy: 0.5939 - val_loss: 1.6836\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7265 - val_accuracy: 0.5938 - val_loss: 1.6842\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7265 - val_accuracy: 0.5939 - val_loss: 1.6828\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7265 - val_accuracy: 0.5938 - val_loss: 1.6889\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7264 - val_accuracy: 0.5938 - val_loss: 1.6866\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7264 - val_accuracy: 0.5938 - val_loss: 1.6833\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7264 - val_accuracy: 0.5939 - val_loss: 1.6836\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7263 - val_accuracy: 0.5938 - val_loss: 1.6858\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7263 - val_accuracy: 0.5938 - val_loss: 1.6841\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7263 - val_accuracy: 0.5938 - val_loss: 1.6821\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7262 - val_accuracy: 0.5939 - val_loss: 1.6807\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7262 - val_accuracy: 0.5938 - val_loss: 1.6837\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7953 - loss: 0.7262 - val_accuracy: 0.5938 - val_loss: 1.6860\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7262 - val_accuracy: 0.5937 - val_loss: 1.6833\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7261 - val_accuracy: 0.5937 - val_loss: 1.6881\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7261 - val_accuracy: 0.5937 - val_loss: 1.6883\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7954 - loss: 0.7261 - val_accuracy: 0.5938 - val_loss: 1.6852\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7260 - val_accuracy: 0.5938 - val_loss: 1.6848\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7260 - val_accuracy: 0.5938 - val_loss: 1.6830\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7953 - loss: 0.7260 - val_accuracy: 0.5938 - val_loss: 1.6842\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7259 - val_accuracy: 0.5938 - val_loss: 1.6823\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7259 - val_accuracy: 0.5938 - val_loss: 1.6856\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7259 - val_accuracy: 0.5938 - val_loss: 1.6824\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7258 - val_accuracy: 0.5938 - val_loss: 1.6887\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7258 - val_accuracy: 0.5938 - val_loss: 1.6834\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7258 - val_accuracy: 0.5938 - val_loss: 1.6809\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7258 - val_accuracy: 0.5938 - val_loss: 1.6846\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7257 - val_accuracy: 0.5938 - val_loss: 1.6833\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7257 - val_accuracy: 0.5938 - val_loss: 1.6858\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7257 - val_accuracy: 0.5952 - val_loss: 1.6837\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7256 - val_accuracy: 0.5952 - val_loss: 1.6811\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7256 - val_accuracy: 0.5952 - val_loss: 1.6786\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7256 - val_accuracy: 0.5950 - val_loss: 1.6834\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7255 - val_accuracy: 0.5938 - val_loss: 1.6851\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7255 - val_accuracy: 0.5938 - val_loss: 1.6835\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7255 - val_accuracy: 0.5935 - val_loss: 1.6844\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7952 - loss: 0.7255 - val_accuracy: 0.5938 - val_loss: 1.6809\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7254 - val_accuracy: 0.5882 - val_loss: 1.6856\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7254 - val_accuracy: 0.5938 - val_loss: 1.6823\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7254 - val_accuracy: 0.5951 - val_loss: 1.6799\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.7253 - val_accuracy: 0.5950 - val_loss: 1.6835\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7253 - val_accuracy: 0.5938 - val_loss: 1.6860\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7253 - val_accuracy: 0.5938 - val_loss: 1.6844\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7252 - val_accuracy: 0.5951 - val_loss: 1.6837\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7252 - val_accuracy: 0.5950 - val_loss: 1.6808\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7252 - val_accuracy: 0.5951 - val_loss: 1.6816\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7252 - val_accuracy: 0.5882 - val_loss: 1.6829\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7251 - val_accuracy: 0.5938 - val_loss: 1.6825\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7251 - val_accuracy: 0.5880 - val_loss: 1.6892\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7251 - val_accuracy: 0.5951 - val_loss: 1.6820\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7250 - val_accuracy: 0.5952 - val_loss: 1.6789\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7952 - loss: 0.7250 - val_accuracy: 0.5952 - val_loss: 1.6786\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7250 - val_accuracy: 0.5950 - val_loss: 1.6826\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7951 - loss: 0.7249 - val_accuracy: 0.5938 - val_loss: 1.6833\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7249 - val_accuracy: 0.5950 - val_loss: 1.6821\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7950 - loss: 0.7249 - val_accuracy: 0.5936 - val_loss: 1.6858\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7249 - val_accuracy: 0.5951 - val_loss: 1.6820\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7248 - val_accuracy: 0.5950 - val_loss: 1.6797\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7248 - val_accuracy: 0.5950 - val_loss: 1.6832\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7948 - loss: 0.7248 - val_accuracy: 0.5950 - val_loss: 1.6848\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7247 - val_accuracy: 0.5950 - val_loss: 1.6779\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7247 - val_accuracy: 0.5950 - val_loss: 1.6786\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7247 - val_accuracy: 0.5952 - val_loss: 1.6824\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7247 - val_accuracy: 0.5950 - val_loss: 1.6837\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7246 - val_accuracy: 0.5950 - val_loss: 1.6832\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7246 - val_accuracy: 0.5894 - val_loss: 1.6816\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7246 - val_accuracy: 0.5950 - val_loss: 1.6820\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7245 - val_accuracy: 0.5950 - val_loss: 1.6815\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7245 - val_accuracy: 0.5950 - val_loss: 1.6821\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7245 - val_accuracy: 0.5950 - val_loss: 1.6809\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7245 - val_accuracy: 0.5950 - val_loss: 1.6818\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7244 - val_accuracy: 0.5950 - val_loss: 1.6798\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7244 - val_accuracy: 0.5950 - val_loss: 1.6821\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7244 - val_accuracy: 0.5895 - val_loss: 1.6850\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7244 - val_accuracy: 0.5895 - val_loss: 1.6812\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7243 - val_accuracy: 0.5895 - val_loss: 1.6840\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7243 - val_accuracy: 0.5950 - val_loss: 1.6780\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7243 - val_accuracy: 0.5950 - val_loss: 1.6802\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7242 - val_accuracy: 0.5950 - val_loss: 1.6810\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7242 - val_accuracy: 0.5950 - val_loss: 1.6811\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7242 - val_accuracy: 0.5950 - val_loss: 1.6814\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7242 - val_accuracy: 0.5895 - val_loss: 1.6809\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7241 - val_accuracy: 0.5895 - val_loss: 1.6801\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7241 - val_accuracy: 0.5950 - val_loss: 1.6802\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7241 - val_accuracy: 0.5950 - val_loss: 1.6780\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7240 - val_accuracy: 0.5950 - val_loss: 1.6769\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7240 - val_accuracy: 0.5950 - val_loss: 1.6771\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7240 - val_accuracy: 0.5951 - val_loss: 1.6753\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7240 - val_accuracy: 0.5950 - val_loss: 1.6759\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7239 - val_accuracy: 0.5950 - val_loss: 1.6803\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7239 - val_accuracy: 0.5894 - val_loss: 1.6798\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7946 - loss: 0.7239 - val_accuracy: 0.5894 - val_loss: 1.6812\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7239 - val_accuracy: 0.5895 - val_loss: 1.6783\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7238 - val_accuracy: 0.5950 - val_loss: 1.6790\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7238 - val_accuracy: 0.5950 - val_loss: 1.6779\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7238 - val_accuracy: 0.5949 - val_loss: 1.6777\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7238 - val_accuracy: 0.5894 - val_loss: 1.6808\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7237 - val_accuracy: 0.5949 - val_loss: 1.6788\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7237 - val_accuracy: 0.5949 - val_loss: 1.6760\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7237 - val_accuracy: 0.5949 - val_loss: 1.6783\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7236 - val_accuracy: 0.5949 - val_loss: 1.6774\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7236 - val_accuracy: 0.5894 - val_loss: 1.6801\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7236 - val_accuracy: 0.5894 - val_loss: 1.6784\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7236 - val_accuracy: 0.5949 - val_loss: 1.6760\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7945 - loss: 0.7235 - val_accuracy: 0.5949 - val_loss: 1.6793\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7235 - val_accuracy: 0.5895 - val_loss: 1.6778\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7235 - val_accuracy: 0.5949 - val_loss: 1.6802\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7945 - loss: 0.7235 - val_accuracy: 0.5950 - val_loss: 1.6777\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7234 - val_accuracy: 0.5895 - val_loss: 1.6788\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7945 - loss: 0.7234 - val_accuracy: 0.5949 - val_loss: 1.6772\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_18, X_test_18, y_train_18, y_test_18 = train_test_split(\n    X, y, test_size=0.3, random_state=60, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_18, X_val_18, y_train_18, y_val_18 = train_test_split(\n    X_train_18, y_train_18, test_size=0.2, random_state=60, stratify=y_train_18\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_18:\", np.max(X_train_18))\nprint(\"Min value in X_train_18:\", np.min(X_train_18))\n\nX_train_18_scaled = scaler.fit_transform(X_train_18)\n\n# Get the original class distribution\nclass_counts_18 = Counter(y_train_18)\nprint(\"Original class distribution:\", class_counts_18)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_18 = class_counts_18[min(class_counts_18, key=class_counts_18.get)]\ndesired_majority_size_18 = minority_class_size_18 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_18 = {0: desired_majority_size_18, 1: minority_class_size_18}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_18 = RandomUnderSampler(sampling_strategy=sampling_strategy_18, random_state=42)\nX_resampled_18, y_resampled_18 = undersampler_18.fit_resample(X_train_18, y_train_18)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_18))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_18, y_train_resampled_18 = smote.fit_resample(X_resampled_18, y_resampled_18)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_18))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_18))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:15:11.334727Z","iopub.execute_input":"2025-03-07T11:15:11.335216Z","iopub.status.idle":"2025-03-07T11:15:50.717108Z","shell.execute_reply.started":"2025-03-07T11:15:11.335161Z","shell.execute_reply":"2025-03-07T11:15:50.715921Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_18: 2071000000.0\nMin value in X_train_18: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_18 = X_train_resampled_18.reshape(X_train_resampled_18.shape[0], 1, 56)\nX_val_18 = X_val_18.reshape(X_val_18.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_18,  # Features from CICIDS2017\n    y_train_resampled_18,  # Labels from CICIDS2017\n    validation_data=(X_val_18, y_val_18),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T11:15:50.718399Z","iopub.execute_input":"2025-03-07T11:15:50.718831Z","iopub.status.idle":"2025-03-07T12:01:25.015789Z","shell.execute_reply.started":"2025-03-07T11:15:50.718791Z","shell.execute_reply":"2025-03-07T12:01:25.014396Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7911 - loss: 0.7334 - val_accuracy: 0.5838 - val_loss: 1.7063\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7921 - loss: 0.7306 - val_accuracy: 0.5834 - val_loss: 1.7248\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7923 - loss: 0.7292 - val_accuracy: 0.5832 - val_loss: 1.7367\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7985 - loss: 0.7281 - val_accuracy: 0.5833 - val_loss: 1.7430\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7272 - val_accuracy: 0.5820 - val_loss: 1.7551\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7264 - val_accuracy: 0.5819 - val_loss: 1.7577\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7257 - val_accuracy: 0.5875 - val_loss: 1.7655\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7251 - val_accuracy: 0.5818 - val_loss: 1.7778\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7245 - val_accuracy: 0.5864 - val_loss: 1.7818\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.7240 - val_accuracy: 0.5864 - val_loss: 1.7863\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.7236 - val_accuracy: 0.5864 - val_loss: 1.7896\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.7231 - val_accuracy: 0.5865 - val_loss: 1.7934\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.7991 - loss: 0.7228 - val_accuracy: 0.5860 - val_loss: 1.8025\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7224 - val_accuracy: 0.5857 - val_loss: 1.8008\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7220 - val_accuracy: 0.5857 - val_loss: 1.8094\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7217 - val_accuracy: 0.5857 - val_loss: 1.8090\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7214 - val_accuracy: 0.5857 - val_loss: 1.8126\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7211 - val_accuracy: 0.5857 - val_loss: 1.8142\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7209 - val_accuracy: 0.5855 - val_loss: 1.8205\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7206 - val_accuracy: 0.5856 - val_loss: 1.8231\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7203 - val_accuracy: 0.5855 - val_loss: 1.8255\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7201 - val_accuracy: 0.5855 - val_loss: 1.8256\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.7985 - loss: 0.7198 - val_accuracy: 0.5855 - val_loss: 1.8255\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7196 - val_accuracy: 0.5855 - val_loss: 1.8287\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7194 - val_accuracy: 0.5848 - val_loss: 1.8226\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7192 - val_accuracy: 0.5845 - val_loss: 1.8295\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7189 - val_accuracy: 0.5846 - val_loss: 1.8303\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.7187 - val_accuracy: 0.5846 - val_loss: 1.8288\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7185 - val_accuracy: 0.5842 - val_loss: 1.8330\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.7984 - loss: 0.7183 - val_accuracy: 0.5841 - val_loss: 1.8356\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.7181 - val_accuracy: 0.5841 - val_loss: 1.8378\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.7180 - val_accuracy: 0.5843 - val_loss: 1.8326\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7178 - val_accuracy: 0.5843 - val_loss: 1.8317\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.7176 - val_accuracy: 0.5841 - val_loss: 1.8387\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7990 - loss: 0.7174 - val_accuracy: 0.5842 - val_loss: 1.8359\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7172 - val_accuracy: 0.5842 - val_loss: 1.8347\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7990 - loss: 0.7171 - val_accuracy: 0.5842 - val_loss: 1.8373\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7169 - val_accuracy: 0.5841 - val_loss: 1.8386\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7168 - val_accuracy: 0.5842 - val_loss: 1.8391\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7991 - loss: 0.7166 - val_accuracy: 0.5842 - val_loss: 1.8393\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7164 - val_accuracy: 0.5841 - val_loss: 1.8416\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7163 - val_accuracy: 0.5842 - val_loss: 1.8365\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7161 - val_accuracy: 0.5841 - val_loss: 1.8466\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7160 - val_accuracy: 0.5841 - val_loss: 1.8418\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7158 - val_accuracy: 0.5841 - val_loss: 1.8455\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.7157 - val_accuracy: 0.5841 - val_loss: 1.8437\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7156 - val_accuracy: 0.5842 - val_loss: 1.8433\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7154 - val_accuracy: 0.5842 - val_loss: 1.8438\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7153 - val_accuracy: 0.5841 - val_loss: 1.8462\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7152 - val_accuracy: 0.5841 - val_loss: 1.8478\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.7150 - val_accuracy: 0.5863 - val_loss: 1.8467\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7149 - val_accuracy: 0.5863 - val_loss: 1.8480\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.7148 - val_accuracy: 0.5863 - val_loss: 1.8440\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7146 - val_accuracy: 0.5862 - val_loss: 1.8474\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7986 - loss: 0.7145 - val_accuracy: 0.5861 - val_loss: 1.8516\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.7144 - val_accuracy: 0.5863 - val_loss: 1.8469\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.7143 - val_accuracy: 0.5861 - val_loss: 1.8491\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.7141 - val_accuracy: 0.5862 - val_loss: 1.8468\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.7140 - val_accuracy: 0.5862 - val_loss: 1.8481\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.7139 - val_accuracy: 0.5861 - val_loss: 1.8530\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.7138 - val_accuracy: 0.5862 - val_loss: 1.8527\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7137 - val_accuracy: 0.5862 - val_loss: 1.8538\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7989 - loss: 0.7136 - val_accuracy: 0.5860 - val_loss: 1.8570\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7990 - loss: 0.7135 - val_accuracy: 0.5861 - val_loss: 1.8532\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.7134 - val_accuracy: 0.5863 - val_loss: 1.8512\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.7990 - loss: 0.7132 - val_accuracy: 0.5863 - val_loss: 1.8531\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.7131 - val_accuracy: 0.5861 - val_loss: 1.8539\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7130 - val_accuracy: 0.5862 - val_loss: 1.8557\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7129 - val_accuracy: 0.5863 - val_loss: 1.8516\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.7128 - val_accuracy: 0.5861 - val_loss: 1.8559\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7127 - val_accuracy: 0.5861 - val_loss: 1.8584\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7126 - val_accuracy: 0.5862 - val_loss: 1.8555\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7125 - val_accuracy: 0.5862 - val_loss: 1.8549\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7124 - val_accuracy: 0.5863 - val_loss: 1.8550\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7123 - val_accuracy: 0.5863 - val_loss: 1.8537\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7122 - val_accuracy: 0.5862 - val_loss: 1.8595\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7121 - val_accuracy: 0.5862 - val_loss: 1.8576\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7120 - val_accuracy: 0.5862 - val_loss: 1.8577\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7991 - loss: 0.7119 - val_accuracy: 0.5863 - val_loss: 1.8558\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7118 - val_accuracy: 0.5861 - val_loss: 1.8634\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7117 - val_accuracy: 0.5862 - val_loss: 1.8610\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.7116 - val_accuracy: 0.5861 - val_loss: 1.8586\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7116 - val_accuracy: 0.5860 - val_loss: 1.8607\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7115 - val_accuracy: 0.5860 - val_loss: 1.8629\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7114 - val_accuracy: 0.5859 - val_loss: 1.8658\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7113 - val_accuracy: 0.5860 - val_loss: 1.8604\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7112 - val_accuracy: 0.5860 - val_loss: 1.8610\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.7111 - val_accuracy: 0.5861 - val_loss: 1.8630\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7110 - val_accuracy: 0.5859 - val_loss: 1.8683\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7109 - val_accuracy: 0.5861 - val_loss: 1.8616\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7108 - val_accuracy: 0.5860 - val_loss: 1.8641\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7108 - val_accuracy: 0.5860 - val_loss: 1.8632\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7107 - val_accuracy: 0.5861 - val_loss: 1.8640\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7106 - val_accuracy: 0.5860 - val_loss: 1.8643\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7105 - val_accuracy: 0.5860 - val_loss: 1.8654\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7104 - val_accuracy: 0.5861 - val_loss: 1.8631\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.7103 - val_accuracy: 0.5860 - val_loss: 1.8646\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7103 - val_accuracy: 0.5860 - val_loss: 1.8663\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7102 - val_accuracy: 0.5860 - val_loss: 1.8648\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7101 - val_accuracy: 0.5861 - val_loss: 1.8636\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7100 - val_accuracy: 0.5860 - val_loss: 1.8661\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7099 - val_accuracy: 0.5859 - val_loss: 1.8689\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7099 - val_accuracy: 0.5804 - val_loss: 1.8680\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7098 - val_accuracy: 0.5867 - val_loss: 1.8674\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7097 - val_accuracy: 0.5861 - val_loss: 1.8656\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7096 - val_accuracy: 0.5861 - val_loss: 1.8663\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7096 - val_accuracy: 0.5860 - val_loss: 1.8671\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7095 - val_accuracy: 0.5857 - val_loss: 1.8704\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7094 - val_accuracy: 0.5867 - val_loss: 1.8661\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7093 - val_accuracy: 0.5866 - val_loss: 1.8675\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7093 - val_accuracy: 0.5858 - val_loss: 1.8667\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7092 - val_accuracy: 0.5858 - val_loss: 1.8689\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7091 - val_accuracy: 0.5866 - val_loss: 1.8681\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7090 - val_accuracy: 0.5864 - val_loss: 1.8694\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7090 - val_accuracy: 0.5858 - val_loss: 1.8699\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7089 - val_accuracy: 0.5866 - val_loss: 1.8662\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7088 - val_accuracy: 0.5865 - val_loss: 1.8706\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7087 - val_accuracy: 0.5858 - val_loss: 1.8681\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.7087 - val_accuracy: 0.5857 - val_loss: 1.8690\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7086 - val_accuracy: 0.5866 - val_loss: 1.8672\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7085 - val_accuracy: 0.5858 - val_loss: 1.8696\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7085 - val_accuracy: 0.5858 - val_loss: 1.8722\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7084 - val_accuracy: 0.5865 - val_loss: 1.8702\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7083 - val_accuracy: 0.5857 - val_loss: 1.8725\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7083 - val_accuracy: 0.5866 - val_loss: 1.8681\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7082 - val_accuracy: 0.5857 - val_loss: 1.8711\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7081 - val_accuracy: 0.5865 - val_loss: 1.8724\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7081 - val_accuracy: 0.5858 - val_loss: 1.8728\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7080 - val_accuracy: 0.5865 - val_loss: 1.8727\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7079 - val_accuracy: 0.5857 - val_loss: 1.8764\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7079 - val_accuracy: 0.5865 - val_loss: 1.8730\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7078 - val_accuracy: 0.5865 - val_loss: 1.8718\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.7077 - val_accuracy: 0.5865 - val_loss: 1.8723\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7996 - loss: 0.7077 - val_accuracy: 0.5809 - val_loss: 1.8725\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.7076 - val_accuracy: 0.5857 - val_loss: 1.8724\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.7075 - val_accuracy: 0.5866 - val_loss: 1.8717\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.7075 - val_accuracy: 0.5866 - val_loss: 1.8720\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.7074 - val_accuracy: 0.5858 - val_loss: 1.8743\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7994 - loss: 0.7073 - val_accuracy: 0.5866 - val_loss: 1.8708\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7997 - loss: 0.7073 - val_accuracy: 0.5866 - val_loss: 1.8744\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7072 - val_accuracy: 0.5809 - val_loss: 1.8767\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.7072 - val_accuracy: 0.5858 - val_loss: 1.8741\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7999 - loss: 0.7071 - val_accuracy: 0.5866 - val_loss: 1.8717\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7070 - val_accuracy: 0.5858 - val_loss: 1.8776\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7070 - val_accuracy: 0.5858 - val_loss: 1.8772\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7069 - val_accuracy: 0.5865 - val_loss: 1.8749\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7068 - val_accuracy: 0.5858 - val_loss: 1.8768\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7068 - val_accuracy: 0.5866 - val_loss: 1.8746\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.7067 - val_accuracy: 0.5866 - val_loss: 1.8723\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7067 - val_accuracy: 0.5865 - val_loss: 1.8780\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7066 - val_accuracy: 0.5857 - val_loss: 1.8790\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7065 - val_accuracy: 0.5865 - val_loss: 1.8762\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7065 - val_accuracy: 0.5857 - val_loss: 1.8770\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7064 - val_accuracy: 0.5864 - val_loss: 1.8771\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.7064 - val_accuracy: 0.5865 - val_loss: 1.8741\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7063 - val_accuracy: 0.5857 - val_loss: 1.8778\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7062 - val_accuracy: 0.5865 - val_loss: 1.8750\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7062 - val_accuracy: 0.5857 - val_loss: 1.8782\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7061 - val_accuracy: 0.5865 - val_loss: 1.8757\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7061 - val_accuracy: 0.5864 - val_loss: 1.8756\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.7060 - val_accuracy: 0.5865 - val_loss: 1.8765\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7060 - val_accuracy: 0.5858 - val_loss: 1.8812\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.7059 - val_accuracy: 0.5865 - val_loss: 1.8788\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7058 - val_accuracy: 0.5866 - val_loss: 1.8762\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7058 - val_accuracy: 0.5865 - val_loss: 1.8779\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7057 - val_accuracy: 0.5888 - val_loss: 1.8813\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.7057 - val_accuracy: 0.5897 - val_loss: 1.8748\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7056 - val_accuracy: 0.5888 - val_loss: 1.8790\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7056 - val_accuracy: 0.5888 - val_loss: 1.8794\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8008 - loss: 0.7055 - val_accuracy: 0.5889 - val_loss: 1.8807\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7055 - val_accuracy: 0.5896 - val_loss: 1.8772\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7054 - val_accuracy: 0.5897 - val_loss: 1.8744\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.7054 - val_accuracy: 0.5895 - val_loss: 1.8761\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7053 - val_accuracy: 0.5896 - val_loss: 1.8789\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7052 - val_accuracy: 0.5896 - val_loss: 1.8784\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7052 - val_accuracy: 0.5895 - val_loss: 1.8786\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7051 - val_accuracy: 0.5895 - val_loss: 1.8806\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7051 - val_accuracy: 0.5896 - val_loss: 1.8781\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.7050 - val_accuracy: 0.5895 - val_loss: 1.8796\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7050 - val_accuracy: 0.5888 - val_loss: 1.8803\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7049 - val_accuracy: 0.5888 - val_loss: 1.8850\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7049 - val_accuracy: 0.5897 - val_loss: 1.8776\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8007 - loss: 0.7048 - val_accuracy: 0.5896 - val_loss: 1.8794\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.7048 - val_accuracy: 0.5896 - val_loss: 1.8771\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.7047 - val_accuracy: 0.5888 - val_loss: 1.8832\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8016 - loss: 0.7047 - val_accuracy: 0.5896 - val_loss: 1.8799\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.7046 - val_accuracy: 0.5898 - val_loss: 1.8790\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.7046 - val_accuracy: 0.5898 - val_loss: 1.8781\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7045 - val_accuracy: 0.5896 - val_loss: 1.8837\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7045 - val_accuracy: 0.5906 - val_loss: 1.8773\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7044 - val_accuracy: 0.5897 - val_loss: 1.8805\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.7044 - val_accuracy: 0.5897 - val_loss: 1.8807\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7043 - val_accuracy: 0.5906 - val_loss: 1.8770\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7043 - val_accuracy: 0.5905 - val_loss: 1.8803\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7042 - val_accuracy: 0.5906 - val_loss: 1.8772\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7042 - val_accuracy: 0.5897 - val_loss: 1.8824\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7041 - val_accuracy: 0.5897 - val_loss: 1.8827\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7041 - val_accuracy: 0.5906 - val_loss: 1.8804\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7040 - val_accuracy: 0.5897 - val_loss: 1.8806\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7040 - val_accuracy: 0.5898 - val_loss: 1.8791\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7039 - val_accuracy: 0.5905 - val_loss: 1.8829\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7039 - val_accuracy: 0.5889 - val_loss: 1.8839\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7038 - val_accuracy: 0.5906 - val_loss: 1.8794\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7038 - val_accuracy: 0.5905 - val_loss: 1.8793\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7037 - val_accuracy: 0.5905 - val_loss: 1.8815\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7037 - val_accuracy: 0.5906 - val_loss: 1.8793\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7036 - val_accuracy: 0.5905 - val_loss: 1.8807\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7036 - val_accuracy: 0.5905 - val_loss: 1.8820\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7035 - val_accuracy: 0.5916 - val_loss: 1.8825\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7035 - val_accuracy: 0.5923 - val_loss: 1.8814\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7034 - val_accuracy: 0.5924 - val_loss: 1.8789\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7034 - val_accuracy: 0.5925 - val_loss: 1.8786\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7033 - val_accuracy: 0.5917 - val_loss: 1.8816\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7033 - val_accuracy: 0.5923 - val_loss: 1.8810\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7033 - val_accuracy: 0.5923 - val_loss: 1.8819\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7032 - val_accuracy: 0.5924 - val_loss: 1.8808\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7032 - val_accuracy: 0.5924 - val_loss: 1.8802\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7031 - val_accuracy: 0.5923 - val_loss: 1.8846\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7031 - val_accuracy: 0.5923 - val_loss: 1.8823\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7030 - val_accuracy: 0.5924 - val_loss: 1.8807\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7030 - val_accuracy: 0.5923 - val_loss: 1.8842\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7029 - val_accuracy: 0.5916 - val_loss: 1.8854\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7029 - val_accuracy: 0.5923 - val_loss: 1.8869\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7028 - val_accuracy: 0.5928 - val_loss: 1.8798\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7028 - val_accuracy: 0.5920 - val_loss: 1.8850\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7028 - val_accuracy: 0.5927 - val_loss: 1.8848\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.7027 - val_accuracy: 0.5927 - val_loss: 1.8826\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7027 - val_accuracy: 0.5928 - val_loss: 1.8787\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7026 - val_accuracy: 0.5928 - val_loss: 1.8815\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7026 - val_accuracy: 0.5927 - val_loss: 1.8818\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7025 - val_accuracy: 0.5927 - val_loss: 1.8840\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8023 - loss: 0.7025 - val_accuracy: 0.5927 - val_loss: 1.8860\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7025 - val_accuracy: 0.5928 - val_loss: 1.8834\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7024 - val_accuracy: 0.5927 - val_loss: 1.8853\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7024 - val_accuracy: 0.5927 - val_loss: 1.8860\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8021 - loss: 0.7023 - val_accuracy: 0.5927 - val_loss: 1.8843\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7023 - val_accuracy: 0.5928 - val_loss: 1.8835\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7022 - val_accuracy: 0.5928 - val_loss: 1.8824\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8024 - loss: 0.7022 - val_accuracy: 0.5927 - val_loss: 1.8837\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7022 - val_accuracy: 0.5928 - val_loss: 1.8820\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7021 - val_accuracy: 0.5927 - val_loss: 1.8847\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7021 - val_accuracy: 0.5928 - val_loss: 1.8837\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7020 - val_accuracy: 0.5929 - val_loss: 1.8811\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7020 - val_accuracy: 0.5928 - val_loss: 1.8847\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7019 - val_accuracy: 0.5928 - val_loss: 1.8834\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7019 - val_accuracy: 0.5928 - val_loss: 1.8818\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7019 - val_accuracy: 0.5927 - val_loss: 1.8857\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7018 - val_accuracy: 0.5928 - val_loss: 1.8840\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7018 - val_accuracy: 0.5929 - val_loss: 1.8813\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7017 - val_accuracy: 0.5928 - val_loss: 1.8845\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8021 - loss: 0.7017 - val_accuracy: 0.5929 - val_loss: 1.8840\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7017 - val_accuracy: 0.5928 - val_loss: 1.8860\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7016 - val_accuracy: 0.5928 - val_loss: 1.8831\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.7016 - val_accuracy: 0.5929 - val_loss: 1.8850\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7015 - val_accuracy: 0.5929 - val_loss: 1.8848\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7015 - val_accuracy: 0.5928 - val_loss: 1.8855\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60427\n726/726 - 10s - 14ms/step - accuracy: 0.8022 - loss: 0.7014 - val_accuracy: 0.5928 - val_loss: 1.8859\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7014 - val_accuracy: 0.5928 - val_loss: 1.8852\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7014 - val_accuracy: 0.5929 - val_loss: 1.8824\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7013 - val_accuracy: 0.5928 - val_loss: 1.8852\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7013 - val_accuracy: 0.5929 - val_loss: 1.8848\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7012 - val_accuracy: 0.5929 - val_loss: 1.8818\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7012 - val_accuracy: 0.5929 - val_loss: 1.8828\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7012 - val_accuracy: 0.5928 - val_loss: 1.8850\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8022 - loss: 0.7011 - val_accuracy: 0.5928 - val_loss: 1.8837\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7011 - val_accuracy: 0.5928 - val_loss: 1.8860\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7011 - val_accuracy: 0.5929 - val_loss: 1.8837\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7010 - val_accuracy: 0.5930 - val_loss: 1.8801\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7010 - val_accuracy: 0.5928 - val_loss: 1.8880\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7009 - val_accuracy: 0.5929 - val_loss: 1.8839\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7009 - val_accuracy: 0.5928 - val_loss: 1.8870\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7009 - val_accuracy: 0.5929 - val_loss: 1.8850\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7008 - val_accuracy: 0.5929 - val_loss: 1.8835\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7008 - val_accuracy: 0.5929 - val_loss: 1.8843\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7007 - val_accuracy: 0.5928 - val_loss: 1.8855\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7007 - val_accuracy: 0.5929 - val_loss: 1.8847\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7007 - val_accuracy: 0.5929 - val_loss: 1.8863\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7006 - val_accuracy: 0.5929 - val_loss: 1.8849\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7006 - val_accuracy: 0.5930 - val_loss: 1.8814\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7005 - val_accuracy: 0.5928 - val_loss: 1.8873\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7005 - val_accuracy: 0.5928 - val_loss: 1.8874\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7005 - val_accuracy: 0.5929 - val_loss: 1.8872\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7004 - val_accuracy: 0.5928 - val_loss: 1.8873\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7004 - val_accuracy: 0.5928 - val_loss: 1.8848\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7004 - val_accuracy: 0.5928 - val_loss: 1.8878\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7003 - val_accuracy: 0.5928 - val_loss: 1.8853\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7003 - val_accuracy: 0.5930 - val_loss: 1.8830\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7002 - val_accuracy: 0.5928 - val_loss: 1.8859\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7002 - val_accuracy: 0.5928 - val_loss: 1.8874\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7002 - val_accuracy: 0.5928 - val_loss: 1.8865\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7001 - val_accuracy: 0.5928 - val_loss: 1.8840\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7001 - val_accuracy: 0.5929 - val_loss: 1.8832\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7001 - val_accuracy: 0.5930 - val_loss: 1.8840\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.7000 - val_accuracy: 0.5929 - val_loss: 1.8835\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8020 - loss: 0.7000 - val_accuracy: 0.5929 - val_loss: 1.8849\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.7000 - val_accuracy: 0.5928 - val_loss: 1.8865\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6999 - val_accuracy: 0.5928 - val_loss: 1.8902\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6999 - val_accuracy: 0.5929 - val_loss: 1.8864\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6998 - val_accuracy: 0.5928 - val_loss: 1.8878\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6998 - val_accuracy: 0.5930 - val_loss: 1.8847\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6998 - val_accuracy: 0.5928 - val_loss: 1.8863\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6997 - val_accuracy: 0.5928 - val_loss: 1.8871\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6997 - val_accuracy: 0.5928 - val_loss: 1.8849\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6997 - val_accuracy: 0.5929 - val_loss: 1.8861\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6996 - val_accuracy: 0.5928 - val_loss: 1.8833\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6996 - val_accuracy: 0.5930 - val_loss: 1.8864\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6996 - val_accuracy: 0.5928 - val_loss: 1.8892\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6995 - val_accuracy: 0.5928 - val_loss: 1.8877\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6995 - val_accuracy: 0.5928 - val_loss: 1.8857\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6995 - val_accuracy: 0.5929 - val_loss: 1.8860\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6994 - val_accuracy: 0.5929 - val_loss: 1.8868\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6994 - val_accuracy: 0.5928 - val_loss: 1.8872\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6993 - val_accuracy: 0.5929 - val_loss: 1.8849\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6993 - val_accuracy: 0.5928 - val_loss: 1.8874\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6993 - val_accuracy: 0.5928 - val_loss: 1.8854\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6992 - val_accuracy: 0.5928 - val_loss: 1.8884\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6992 - val_accuracy: 0.5929 - val_loss: 1.8858\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6992 - val_accuracy: 0.5929 - val_loss: 1.8875\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6991 - val_accuracy: 0.5929 - val_loss: 1.8867\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6991 - val_accuracy: 0.5929 - val_loss: 1.8867\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6991 - val_accuracy: 0.5930 - val_loss: 1.8829\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6990 - val_accuracy: 0.5928 - val_loss: 1.8908\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6990 - val_accuracy: 0.5928 - val_loss: 1.8897\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6990 - val_accuracy: 0.5929 - val_loss: 1.8874\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6989 - val_accuracy: 0.5929 - val_loss: 1.8879\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6989 - val_accuracy: 0.5929 - val_loss: 1.8880\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6989 - val_accuracy: 0.5929 - val_loss: 1.8865\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6988 - val_accuracy: 0.5929 - val_loss: 1.8861\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6988 - val_accuracy: 0.5929 - val_loss: 1.8846\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6988 - val_accuracy: 0.5929 - val_loss: 1.8859\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6987 - val_accuracy: 0.5929 - val_loss: 1.8858\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6987 - val_accuracy: 0.5929 - val_loss: 1.8855\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6987 - val_accuracy: 0.5929 - val_loss: 1.8887\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6986 - val_accuracy: 0.5929 - val_loss: 1.8872\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6986 - val_accuracy: 0.5930 - val_loss: 1.8863\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6986 - val_accuracy: 0.5929 - val_loss: 1.8852\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6985 - val_accuracy: 0.5929 - val_loss: 1.8853\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6985 - val_accuracy: 0.5929 - val_loss: 1.8844\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6985 - val_accuracy: 0.5929 - val_loss: 1.8865\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6984 - val_accuracy: 0.5929 - val_loss: 1.8898\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6984 - val_accuracy: 0.5929 - val_loss: 1.8884\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6984 - val_accuracy: 0.5929 - val_loss: 1.8888\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6983 - val_accuracy: 0.5929 - val_loss: 1.8916\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6983 - val_accuracy: 0.5929 - val_loss: 1.8867\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6983 - val_accuracy: 0.5929 - val_loss: 1.8857\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6982 - val_accuracy: 0.5929 - val_loss: 1.8880\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6982 - val_accuracy: 0.5929 - val_loss: 1.8897\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6982 - val_accuracy: 0.5929 - val_loss: 1.8873\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8019 - loss: 0.6981 - val_accuracy: 0.5929 - val_loss: 1.8869\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6981 - val_accuracy: 0.5930 - val_loss: 1.8842\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6981 - val_accuracy: 0.5931 - val_loss: 1.8842\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6980 - val_accuracy: 0.5929 - val_loss: 1.8874\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6980 - val_accuracy: 0.5929 - val_loss: 1.8892\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6980 - val_accuracy: 0.5930 - val_loss: 1.8852\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6980 - val_accuracy: 0.5931 - val_loss: 1.8824\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6979 - val_accuracy: 0.5929 - val_loss: 1.8906\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6979 - val_accuracy: 0.5929 - val_loss: 1.8891\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6979 - val_accuracy: 0.5929 - val_loss: 1.8917\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6978 - val_accuracy: 0.5930 - val_loss: 1.8902\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6978 - val_accuracy: 0.5931 - val_loss: 1.8816\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6978 - val_accuracy: 0.5930 - val_loss: 1.8852\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6977 - val_accuracy: 0.5930 - val_loss: 1.8873\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6977 - val_accuracy: 0.5930 - val_loss: 1.8853\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6977 - val_accuracy: 0.5929 - val_loss: 1.8907\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6976 - val_accuracy: 0.5929 - val_loss: 1.8907\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6976 - val_accuracy: 0.5930 - val_loss: 1.8883\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6976 - val_accuracy: 0.5930 - val_loss: 1.8894\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6975 - val_accuracy: 0.5929 - val_loss: 1.8900\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6975 - val_accuracy: 0.5929 - val_loss: 1.8882\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6975 - val_accuracy: 0.5929 - val_loss: 1.8859\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6975 - val_accuracy: 0.5929 - val_loss: 1.8868\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6974 - val_accuracy: 0.5929 - val_loss: 1.8867\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6974 - val_accuracy: 0.5929 - val_loss: 1.8891\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6974 - val_accuracy: 0.5929 - val_loss: 1.8920\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6973 - val_accuracy: 0.5929 - val_loss: 1.8883\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6973 - val_accuracy: 0.5929 - val_loss: 1.8888\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6973 - val_accuracy: 0.5929 - val_loss: 1.8893\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6972 - val_accuracy: 0.5929 - val_loss: 1.8897\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6972 - val_accuracy: 0.5929 - val_loss: 1.8902\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6972 - val_accuracy: 0.5929 - val_loss: 1.8870\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6972 - val_accuracy: 0.5929 - val_loss: 1.8874\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6971 - val_accuracy: 0.5929 - val_loss: 1.8908\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6971 - val_accuracy: 0.5929 - val_loss: 1.8894\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6971 - val_accuracy: 0.5930 - val_loss: 1.8899\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6970 - val_accuracy: 0.5925 - val_loss: 1.8897\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6970 - val_accuracy: 0.5924 - val_loss: 1.8863\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6970 - val_accuracy: 0.5924 - val_loss: 1.8875\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6970 - val_accuracy: 0.5925 - val_loss: 1.8870\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8017 - loss: 0.6969 - val_accuracy: 0.5924 - val_loss: 1.8920\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6969 - val_accuracy: 0.5924 - val_loss: 1.8909\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6969 - val_accuracy: 0.5924 - val_loss: 1.8915\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6968 - val_accuracy: 0.5925 - val_loss: 1.8906\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6968 - val_accuracy: 0.5925 - val_loss: 1.8879\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6968 - val_accuracy: 0.5925 - val_loss: 1.8880\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6967 - val_accuracy: 0.5924 - val_loss: 1.8855\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8017 - loss: 0.6967 - val_accuracy: 0.5925 - val_loss: 1.8887\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6967 - val_accuracy: 0.5925 - val_loss: 1.8909\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6967 - val_accuracy: 0.5925 - val_loss: 1.8880\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8017 - loss: 0.6966 - val_accuracy: 0.5925 - val_loss: 1.8883\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6966 - val_accuracy: 0.5925 - val_loss: 1.8918\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6966 - val_accuracy: 0.5925 - val_loss: 1.8910\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6965 - val_accuracy: 0.5925 - val_loss: 1.8884\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6965 - val_accuracy: 0.5925 - val_loss: 1.8865\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6965 - val_accuracy: 0.5925 - val_loss: 1.8870\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6965 - val_accuracy: 0.5923 - val_loss: 1.8936\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6964 - val_accuracy: 0.5925 - val_loss: 1.8894\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6964 - val_accuracy: 0.5925 - val_loss: 1.8878\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6964 - val_accuracy: 0.5925 - val_loss: 1.8896\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6963 - val_accuracy: 0.5925 - val_loss: 1.8882\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6963 - val_accuracy: 0.5924 - val_loss: 1.8889\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6963 - val_accuracy: 0.5923 - val_loss: 1.8893\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6963 - val_accuracy: 0.5923 - val_loss: 1.8894\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6962 - val_accuracy: 0.5924 - val_loss: 1.8872\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6962 - val_accuracy: 0.5924 - val_loss: 1.8878\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6962 - val_accuracy: 0.5904 - val_loss: 1.8894\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6962 - val_accuracy: 0.5923 - val_loss: 1.8893\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6961 - val_accuracy: 0.5905 - val_loss: 1.8911\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6961 - val_accuracy: 0.5904 - val_loss: 1.8891\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6961 - val_accuracy: 0.5904 - val_loss: 1.8878\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6960 - val_accuracy: 0.5904 - val_loss: 1.8894\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6960 - val_accuracy: 0.5902 - val_loss: 1.8920\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6960 - val_accuracy: 0.5902 - val_loss: 1.8868\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6960 - val_accuracy: 0.5904 - val_loss: 1.8913\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6959 - val_accuracy: 0.5902 - val_loss: 1.8901\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6959 - val_accuracy: 0.5902 - val_loss: 1.8898\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6959 - val_accuracy: 0.5902 - val_loss: 1.8882\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6958 - val_accuracy: 0.5896 - val_loss: 1.8911\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6958 - val_accuracy: 0.5904 - val_loss: 1.8891\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6958 - val_accuracy: 0.5904 - val_loss: 1.8905\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6958 - val_accuracy: 0.5903 - val_loss: 1.8881\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6957 - val_accuracy: 0.5904 - val_loss: 1.8907\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6957 - val_accuracy: 0.5900 - val_loss: 1.8942\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6957 - val_accuracy: 0.5904 - val_loss: 1.8923\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6957 - val_accuracy: 0.5903 - val_loss: 1.8876\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6956 - val_accuracy: 0.5901 - val_loss: 1.8874\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6956 - val_accuracy: 0.5900 - val_loss: 1.8909\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6956 - val_accuracy: 0.5900 - val_loss: 1.8949\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6956 - val_accuracy: 0.5900 - val_loss: 1.8893\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6955 - val_accuracy: 0.5901 - val_loss: 1.8912\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6955 - val_accuracy: 0.5900 - val_loss: 1.8920\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6955 - val_accuracy: 0.5901 - val_loss: 1.8886\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6954 - val_accuracy: 0.5900 - val_loss: 1.8932\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6954 - val_accuracy: 0.5901 - val_loss: 1.8866\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6954 - val_accuracy: 0.5901 - val_loss: 1.8884\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6954 - val_accuracy: 0.5900 - val_loss: 1.8908\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6953 - val_accuracy: 0.5901 - val_loss: 1.8906\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6953 - val_accuracy: 0.5900 - val_loss: 1.8901\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6953 - val_accuracy: 0.5900 - val_loss: 1.8885\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6953 - val_accuracy: 0.5899 - val_loss: 1.8900\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6952 - val_accuracy: 0.5900 - val_loss: 1.8922\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6952 - val_accuracy: 0.5899 - val_loss: 1.8889\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6952 - val_accuracy: 0.5901 - val_loss: 1.8892\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6952 - val_accuracy: 0.5900 - val_loss: 1.8886\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6951 - val_accuracy: 0.5899 - val_loss: 1.8888\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6951 - val_accuracy: 0.5900 - val_loss: 1.8904\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6951 - val_accuracy: 0.5899 - val_loss: 1.8884\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6951 - val_accuracy: 0.5900 - val_loss: 1.8912\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6950 - val_accuracy: 0.5899 - val_loss: 1.8898\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6950 - val_accuracy: 0.5899 - val_loss: 1.8892\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6950 - val_accuracy: 0.5899 - val_loss: 1.8916\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6950 - val_accuracy: 0.5900 - val_loss: 1.8893\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6949 - val_accuracy: 0.5900 - val_loss: 1.8926\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6949 - val_accuracy: 0.5900 - val_loss: 1.8907\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6949 - val_accuracy: 0.5899 - val_loss: 1.8889\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6948 - val_accuracy: 0.5900 - val_loss: 1.8923\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6948 - val_accuracy: 0.5900 - val_loss: 1.8896\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6948 - val_accuracy: 0.5900 - val_loss: 1.8893\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6948 - val_accuracy: 0.5900 - val_loss: 1.8916\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6947 - val_accuracy: 0.5899 - val_loss: 1.8877\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6947 - val_accuracy: 0.5900 - val_loss: 1.8919\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6947 - val_accuracy: 0.5900 - val_loss: 1.8909\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6947 - val_accuracy: 0.5899 - val_loss: 1.8895\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6946 - val_accuracy: 0.5902 - val_loss: 1.8864\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6946 - val_accuracy: 0.5899 - val_loss: 1.8899\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6946 - val_accuracy: 0.5899 - val_loss: 1.8904\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6946 - val_accuracy: 0.5899 - val_loss: 1.8908\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6946 - val_accuracy: 0.5900 - val_loss: 1.8919\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6945 - val_accuracy: 0.5899 - val_loss: 1.8924\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6945 - val_accuracy: 0.5900 - val_loss: 1.8912\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6945 - val_accuracy: 0.5900 - val_loss: 1.8935\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6945 - val_accuracy: 0.5900 - val_loss: 1.8929\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6944 - val_accuracy: 0.5900 - val_loss: 1.8933\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6944 - val_accuracy: 0.5900 - val_loss: 1.8896\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6944 - val_accuracy: 0.5900 - val_loss: 1.8889\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6944 - val_accuracy: 0.5900 - val_loss: 1.8896\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6943 - val_accuracy: 0.5900 - val_loss: 1.8917\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6943 - val_accuracy: 0.5900 - val_loss: 1.8878\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6943 - val_accuracy: 0.5900 - val_loss: 1.8893\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6943 - val_accuracy: 0.5900 - val_loss: 1.8913\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6942 - val_accuracy: 0.5900 - val_loss: 1.8929\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8018 - loss: 0.6942 - val_accuracy: 0.5900 - val_loss: 1.8866\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6942 - val_accuracy: 0.5900 - val_loss: 1.8916\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6942 - val_accuracy: 0.5900 - val_loss: 1.8898\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6941 - val_accuracy: 0.5900 - val_loss: 1.8947\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6941 - val_accuracy: 0.5900 - val_loss: 1.8916\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6941 - val_accuracy: 0.5900 - val_loss: 1.8906\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6941 - val_accuracy: 0.5900 - val_loss: 1.8902\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6940 - val_accuracy: 0.5900 - val_loss: 1.8869\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8018 - loss: 0.6940 - val_accuracy: 0.5900 - val_loss: 1.8915\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8018 - loss: 0.6940 - val_accuracy: 0.5900 - val_loss: 1.8921\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_19, X_test_19, y_train_19, y_test_19 = train_test_split(\n    X, y, test_size=0.3, random_state=61, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_19, X_val_19, y_train_19, y_val_19 = train_test_split(\n    X_train_19, y_train_19, test_size=0.2, random_state=61, stratify=y_train_19\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_19:\", np.max(X_train_19))\nprint(\"Min value in X_train_19:\", np.min(X_train_19))\n\nX_train_19_scaled = scaler.fit_transform(X_train_19)\n\n# Get the original class distribution\nclass_counts_19 = Counter(y_train_19)\nprint(\"Original class distribution:\", class_counts_19)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_19 = class_counts_19[min(class_counts_19, key=class_counts_19.get)]\ndesired_majority_size_19 = minority_class_size_19 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_19 = {0: desired_majority_size_19, 1: minority_class_size_19}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_19 = RandomUnderSampler(sampling_strategy=sampling_strategy_19, random_state=42)\nX_resampled_19, y_resampled_19 = undersampler_19.fit_resample(X_train_19, y_train_19)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_19))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_19, y_train_resampled_19 = smote.fit_resample(X_resampled_19, y_resampled_19)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_19))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_19))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T12:01:25.017740Z","iopub.execute_input":"2025-03-07T12:01:25.018138Z","iopub.status.idle":"2025-03-07T12:02:06.455081Z","shell.execute_reply.started":"2025-03-07T12:01:25.018104Z","shell.execute_reply":"2025-03-07T12:02:06.453962Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_19: 2071000000.0\nMin value in X_train_19: -6442447920.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_19 = X_train_resampled_19.reshape(X_train_resampled_19.shape[0], 1, 56)\nX_val_19 = X_val_19.reshape(X_val_19.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_19,  # Features from CICIDS2017\n    y_train_resampled_19,  # Labels from CICIDS2017\n    validation_data=(X_val_19, y_val_19),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T12:02:06.456463Z","iopub.execute_input":"2025-03-07T12:02:06.456922Z","iopub.status.idle":"2025-03-07T12:48:05.207144Z","shell.execute_reply.started":"2025-03-07T12:02:06.456867Z","shell.execute_reply":"2025-03-07T12:48:05.205924Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7432 - loss: 0.8338 - val_accuracy: 0.5792 - val_loss: 1.9233\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7391 - loss: 0.8210 - val_accuracy: 0.5750 - val_loss: 1.9029\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 8s - 12ms/step - accuracy: 0.7391 - loss: 0.8149 - val_accuracy: 0.5755 - val_loss: 1.8855\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7456 - loss: 0.8107 - val_accuracy: 0.5754 - val_loss: 1.8703\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7513 - loss: 0.8075 - val_accuracy: 0.5755 - val_loss: 1.8496\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7514 - loss: 0.8049 - val_accuracy: 0.5758 - val_loss: 1.8371\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7513 - loss: 0.8026 - val_accuracy: 0.5819 - val_loss: 1.8207\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7495 - loss: 0.8006 - val_accuracy: 0.5740 - val_loss: 1.8124\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7482 - loss: 0.7989 - val_accuracy: 0.5777 - val_loss: 1.8014\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7477 - loss: 0.7974 - val_accuracy: 0.5783 - val_loss: 1.7932\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7477 - loss: 0.7960 - val_accuracy: 0.5786 - val_loss: 1.7808\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7477 - loss: 0.7948 - val_accuracy: 0.5787 - val_loss: 1.7724\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7479 - loss: 0.7938 - val_accuracy: 0.5788 - val_loss: 1.7628\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7483 - loss: 0.7928 - val_accuracy: 0.5788 - val_loss: 1.7593\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7487 - loss: 0.7920 - val_accuracy: 0.5790 - val_loss: 1.7494\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7487 - loss: 0.7912 - val_accuracy: 0.5796 - val_loss: 1.7429\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7487 - loss: 0.7904 - val_accuracy: 0.5817 - val_loss: 1.7402\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7486 - loss: 0.7897 - val_accuracy: 0.5826 - val_loss: 1.7345\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7486 - loss: 0.7891 - val_accuracy: 0.5826 - val_loss: 1.7291\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7484 - loss: 0.7885 - val_accuracy: 0.5828 - val_loss: 1.7258\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7484 - loss: 0.7880 - val_accuracy: 0.5828 - val_loss: 1.7254\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7483 - loss: 0.7874 - val_accuracy: 0.5830 - val_loss: 1.7181\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7488 - loss: 0.7869 - val_accuracy: 0.5830 - val_loss: 1.7173\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7483 - loss: 0.7865 - val_accuracy: 0.5830 - val_loss: 1.7155\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7480 - loss: 0.7860 - val_accuracy: 0.5873 - val_loss: 1.7111\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7478 - loss: 0.7856 - val_accuracy: 0.5834 - val_loss: 1.7119\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7466 - loss: 0.7852 - val_accuracy: 0.5878 - val_loss: 1.7075\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7483 - loss: 0.7848 - val_accuracy: 0.5886 - val_loss: 1.7058\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7487 - loss: 0.7844 - val_accuracy: 0.5922 - val_loss: 1.7047\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7502 - loss: 0.7841 - val_accuracy: 0.5923 - val_loss: 1.7024\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7513 - loss: 0.7837 - val_accuracy: 0.5889 - val_loss: 1.7014\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7505 - loss: 0.7834 - val_accuracy: 0.5925 - val_loss: 1.6988\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.7831 - val_accuracy: 0.5925 - val_loss: 1.6965\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7515 - loss: 0.7828 - val_accuracy: 0.5923 - val_loss: 1.6934\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7529 - loss: 0.7825 - val_accuracy: 0.5921 - val_loss: 1.6975\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7524 - loss: 0.7822 - val_accuracy: 0.5922 - val_loss: 1.6990\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7527 - loss: 0.7819 - val_accuracy: 0.5918 - val_loss: 1.6913\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7517 - loss: 0.7817 - val_accuracy: 0.5921 - val_loss: 1.6873\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7536 - loss: 0.7814 - val_accuracy: 0.5920 - val_loss: 1.6920\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7534 - loss: 0.7812 - val_accuracy: 0.5920 - val_loss: 1.6908\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7529 - loss: 0.7809 - val_accuracy: 0.5921 - val_loss: 1.6816\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7537 - loss: 0.7807 - val_accuracy: 0.5922 - val_loss: 1.6875\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7541 - loss: 0.7804 - val_accuracy: 0.5922 - val_loss: 1.6877\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7542 - loss: 0.7802 - val_accuracy: 0.5924 - val_loss: 1.6840\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7548 - loss: 0.7800 - val_accuracy: 0.5923 - val_loss: 1.6827\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7543 - loss: 0.7798 - val_accuracy: 0.5923 - val_loss: 1.6854\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7541 - loss: 0.7796 - val_accuracy: 0.5915 - val_loss: 1.6854\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7547 - loss: 0.7794 - val_accuracy: 0.5923 - val_loss: 1.6802\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7549 - loss: 0.7792 - val_accuracy: 0.5914 - val_loss: 1.6828\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7549 - loss: 0.7790 - val_accuracy: 0.5924 - val_loss: 1.6766\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7554 - loss: 0.7788 - val_accuracy: 0.5924 - val_loss: 1.6811\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7556 - loss: 0.7786 - val_accuracy: 0.5924 - val_loss: 1.6755\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7784 - val_accuracy: 0.5921 - val_loss: 1.6759\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7782 - val_accuracy: 0.5912 - val_loss: 1.6800\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7780 - val_accuracy: 0.5919 - val_loss: 1.6760\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7779 - val_accuracy: 0.5921 - val_loss: 1.6749\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7556 - loss: 0.7777 - val_accuracy: 0.5910 - val_loss: 1.6760\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7775 - val_accuracy: 0.5910 - val_loss: 1.6757\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7774 - val_accuracy: 0.5910 - val_loss: 1.6765\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7772 - val_accuracy: 0.5910 - val_loss: 1.6782\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7770 - val_accuracy: 0.5909 - val_loss: 1.6761\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7555 - loss: 0.7769 - val_accuracy: 0.5910 - val_loss: 1.6733\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7555 - loss: 0.7767 - val_accuracy: 0.5909 - val_loss: 1.6766\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7766 - val_accuracy: 0.5909 - val_loss: 1.6761\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7764 - val_accuracy: 0.5909 - val_loss: 1.6733\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7763 - val_accuracy: 0.5920 - val_loss: 1.6710\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7554 - loss: 0.7761 - val_accuracy: 0.5910 - val_loss: 1.6755\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7554 - loss: 0.7760 - val_accuracy: 0.5911 - val_loss: 1.6731\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7554 - loss: 0.7759 - val_accuracy: 0.5911 - val_loss: 1.6732\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7554 - loss: 0.7757 - val_accuracy: 0.5911 - val_loss: 1.6707\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7554 - loss: 0.7756 - val_accuracy: 0.5911 - val_loss: 1.6725\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7555 - loss: 0.7755 - val_accuracy: 0.5912 - val_loss: 1.6693\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7753 - val_accuracy: 0.5912 - val_loss: 1.6709\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7752 - val_accuracy: 0.5912 - val_loss: 1.6724\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7751 - val_accuracy: 0.5911 - val_loss: 1.6720\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7749 - val_accuracy: 0.5912 - val_loss: 1.6700\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7748 - val_accuracy: 0.5912 - val_loss: 1.6680\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7556 - loss: 0.7747 - val_accuracy: 0.5912 - val_loss: 1.6681\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7556 - loss: 0.7746 - val_accuracy: 0.5912 - val_loss: 1.6685\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7744 - val_accuracy: 0.5912 - val_loss: 1.6705\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7743 - val_accuracy: 0.5911 - val_loss: 1.6678\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7742 - val_accuracy: 0.5912 - val_loss: 1.6680\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7556 - loss: 0.7741 - val_accuracy: 0.5913 - val_loss: 1.6637\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7556 - loss: 0.7740 - val_accuracy: 0.5911 - val_loss: 1.6688\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7739 - val_accuracy: 0.5913 - val_loss: 1.6680\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7737 - val_accuracy: 0.5911 - val_loss: 1.6693\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7558 - loss: 0.7736 - val_accuracy: 0.5913 - val_loss: 1.6672\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7735 - val_accuracy: 0.5913 - val_loss: 1.6692\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7734 - val_accuracy: 0.5913 - val_loss: 1.6691\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7733 - val_accuracy: 0.5913 - val_loss: 1.6701\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7732 - val_accuracy: 0.5913 - val_loss: 1.6705\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7557 - loss: 0.7731 - val_accuracy: 0.5913 - val_loss: 1.6687\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7730 - val_accuracy: 0.5913 - val_loss: 1.6721\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7729 - val_accuracy: 0.5913 - val_loss: 1.6677\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7728 - val_accuracy: 0.5913 - val_loss: 1.6663\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7727 - val_accuracy: 0.5913 - val_loss: 1.6664\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7726 - val_accuracy: 0.5913 - val_loss: 1.6684\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7557 - loss: 0.7725 - val_accuracy: 0.5913 - val_loss: 1.6649\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7724 - val_accuracy: 0.5913 - val_loss: 1.6676\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7723 - val_accuracy: 0.5912 - val_loss: 1.6696\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7722 - val_accuracy: 0.5912 - val_loss: 1.6685\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7556 - loss: 0.7721 - val_accuracy: 0.5912 - val_loss: 1.6711\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7557 - loss: 0.7720 - val_accuracy: 0.5912 - val_loss: 1.6683\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7558 - loss: 0.7719 - val_accuracy: 0.5913 - val_loss: 1.6670\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7560 - loss: 0.7718 - val_accuracy: 0.5912 - val_loss: 1.6712\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7557 - loss: 0.7717 - val_accuracy: 0.5912 - val_loss: 1.6693\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7558 - loss: 0.7716 - val_accuracy: 0.5913 - val_loss: 1.6676\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7562 - loss: 0.7715 - val_accuracy: 0.5913 - val_loss: 1.6650\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7564 - loss: 0.7714 - val_accuracy: 0.5912 - val_loss: 1.6696\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7559 - loss: 0.7714 - val_accuracy: 0.5912 - val_loss: 1.6657\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7566 - loss: 0.7713 - val_accuracy: 0.5912 - val_loss: 1.6648\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7569 - loss: 0.7712 - val_accuracy: 0.5914 - val_loss: 1.6667\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7569 - loss: 0.7711 - val_accuracy: 0.5912 - val_loss: 1.6670\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7576 - loss: 0.7710 - val_accuracy: 0.5912 - val_loss: 1.6725\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7580 - loss: 0.7709 - val_accuracy: 0.5912 - val_loss: 1.6671\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7575 - loss: 0.7708 - val_accuracy: 0.5914 - val_loss: 1.6663\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7582 - loss: 0.7707 - val_accuracy: 0.5914 - val_loss: 1.6669\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7585 - loss: 0.7707 - val_accuracy: 0.5914 - val_loss: 1.6631\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.7706 - val_accuracy: 0.5913 - val_loss: 1.6681\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7705 - val_accuracy: 0.5913 - val_loss: 1.6685\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7704 - val_accuracy: 0.5912 - val_loss: 1.6711\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7589 - loss: 0.7703 - val_accuracy: 0.5912 - val_loss: 1.6671\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7702 - val_accuracy: 0.5912 - val_loss: 1.6663\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7702 - val_accuracy: 0.5912 - val_loss: 1.6660\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7701 - val_accuracy: 0.5912 - val_loss: 1.6698\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7700 - val_accuracy: 0.5912 - val_loss: 1.6680\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7589 - loss: 0.7699 - val_accuracy: 0.5910 - val_loss: 1.6665\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7698 - val_accuracy: 0.5914 - val_loss: 1.6656\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7698 - val_accuracy: 0.5910 - val_loss: 1.6703\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7697 - val_accuracy: 0.5913 - val_loss: 1.6663\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7590 - loss: 0.7696 - val_accuracy: 0.5910 - val_loss: 1.6692\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7695 - val_accuracy: 0.5909 - val_loss: 1.6708\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7695 - val_accuracy: 0.5862 - val_loss: 1.6690\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7694 - val_accuracy: 0.5860 - val_loss: 1.6698\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7693 - val_accuracy: 0.5861 - val_loss: 1.6720\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7692 - val_accuracy: 0.5861 - val_loss: 1.6696\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7692 - val_accuracy: 0.5860 - val_loss: 1.6712\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7691 - val_accuracy: 0.5861 - val_loss: 1.6694\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7690 - val_accuracy: 0.5860 - val_loss: 1.6710\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7689 - val_accuracy: 0.5863 - val_loss: 1.6674\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7689 - val_accuracy: 0.5863 - val_loss: 1.6701\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7688 - val_accuracy: 0.5860 - val_loss: 1.6705\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7687 - val_accuracy: 0.5863 - val_loss: 1.6672\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7687 - val_accuracy: 0.5860 - val_loss: 1.6717\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7686 - val_accuracy: 0.5863 - val_loss: 1.6676\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7685 - val_accuracy: 0.5861 - val_loss: 1.6738\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7684 - val_accuracy: 0.5863 - val_loss: 1.6675\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7684 - val_accuracy: 0.5861 - val_loss: 1.6730\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7683 - val_accuracy: 0.5861 - val_loss: 1.6707\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7682 - val_accuracy: 0.5863 - val_loss: 1.6692\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7682 - val_accuracy: 0.5863 - val_loss: 1.6687\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7681 - val_accuracy: 0.5864 - val_loss: 1.6694\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7680 - val_accuracy: 0.5864 - val_loss: 1.6710\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7680 - val_accuracy: 0.5863 - val_loss: 1.6688\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7679 - val_accuracy: 0.5861 - val_loss: 1.6702\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7678 - val_accuracy: 0.5861 - val_loss: 1.6724\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7678 - val_accuracy: 0.5863 - val_loss: 1.6698\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7677 - val_accuracy: 0.5861 - val_loss: 1.6751\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7676 - val_accuracy: 0.5863 - val_loss: 1.6677\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7676 - val_accuracy: 0.5863 - val_loss: 1.6730\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7675 - val_accuracy: 0.5863 - val_loss: 1.6700\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7674 - val_accuracy: 0.5863 - val_loss: 1.6720\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7674 - val_accuracy: 0.5861 - val_loss: 1.6749\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7588 - loss: 0.7673 - val_accuracy: 0.5862 - val_loss: 1.6695\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7672 - val_accuracy: 0.5863 - val_loss: 1.6680\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7672 - val_accuracy: 0.5862 - val_loss: 1.6746\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7671 - val_accuracy: 0.5863 - val_loss: 1.6681\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7671 - val_accuracy: 0.5862 - val_loss: 1.6721\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7670 - val_accuracy: 0.5863 - val_loss: 1.6728\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7669 - val_accuracy: 0.5862 - val_loss: 1.6734\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7669 - val_accuracy: 0.5864 - val_loss: 1.6716\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7668 - val_accuracy: 0.5863 - val_loss: 1.6691\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7668 - val_accuracy: 0.5862 - val_loss: 1.6733\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7667 - val_accuracy: 0.5863 - val_loss: 1.6733\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7588 - loss: 0.7666 - val_accuracy: 0.5864 - val_loss: 1.6730\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7666 - val_accuracy: 0.5862 - val_loss: 1.6751\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7665 - val_accuracy: 0.5864 - val_loss: 1.6711\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7664 - val_accuracy: 0.5870 - val_loss: 1.6706\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7664 - val_accuracy: 0.5865 - val_loss: 1.6712\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7588 - loss: 0.7663 - val_accuracy: 0.5863 - val_loss: 1.6738\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7663 - val_accuracy: 0.5863 - val_loss: 1.6768\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7662 - val_accuracy: 0.5864 - val_loss: 1.6751\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7662 - val_accuracy: 0.5863 - val_loss: 1.6744\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7661 - val_accuracy: 0.5864 - val_loss: 1.6748\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7660 - val_accuracy: 0.5864 - val_loss: 1.6750\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7660 - val_accuracy: 0.5870 - val_loss: 1.6712\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7659 - val_accuracy: 0.5863 - val_loss: 1.6745\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7659 - val_accuracy: 0.5873 - val_loss: 1.6728\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7658 - val_accuracy: 0.5864 - val_loss: 1.6742\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7658 - val_accuracy: 0.5873 - val_loss: 1.6726\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7657 - val_accuracy: 0.5879 - val_loss: 1.6713\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7656 - val_accuracy: 0.5864 - val_loss: 1.6764\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7590 - loss: 0.7656 - val_accuracy: 0.5864 - val_loss: 1.6748\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7590 - loss: 0.7655 - val_accuracy: 0.5864 - val_loss: 1.6752\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7589 - loss: 0.7655 - val_accuracy: 0.5856 - val_loss: 1.6761\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7590 - loss: 0.7654 - val_accuracy: 0.5854 - val_loss: 1.6771\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7654 - val_accuracy: 0.5856 - val_loss: 1.6778\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7590 - loss: 0.7653 - val_accuracy: 0.5862 - val_loss: 1.6732\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7653 - val_accuracy: 0.5856 - val_loss: 1.6747\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7652 - val_accuracy: 0.5856 - val_loss: 1.6772\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7652 - val_accuracy: 0.5856 - val_loss: 1.6770\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7590 - loss: 0.7651 - val_accuracy: 0.5856 - val_loss: 1.6761\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7651 - val_accuracy: 0.5862 - val_loss: 1.6759\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7650 - val_accuracy: 0.5856 - val_loss: 1.6773\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7650 - val_accuracy: 0.5856 - val_loss: 1.6829\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7649 - val_accuracy: 0.5856 - val_loss: 1.6764\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7649 - val_accuracy: 0.5871 - val_loss: 1.6733\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7591 - loss: 0.7648 - val_accuracy: 0.5871 - val_loss: 1.6744\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7647 - val_accuracy: 0.5871 - val_loss: 1.6754\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7647 - val_accuracy: 0.5862 - val_loss: 1.6771\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7646 - val_accuracy: 0.5857 - val_loss: 1.6769\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7646 - val_accuracy: 0.5856 - val_loss: 1.6800\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7645 - val_accuracy: 0.5871 - val_loss: 1.6759\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7591 - loss: 0.7645 - val_accuracy: 0.5871 - val_loss: 1.6762\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7644 - val_accuracy: 0.5862 - val_loss: 1.6794\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.7644 - val_accuracy: 0.5871 - val_loss: 1.6771\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.7643 - val_accuracy: 0.5862 - val_loss: 1.6795\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.7643 - val_accuracy: 0.5862 - val_loss: 1.6768\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7592 - loss: 0.7642 - val_accuracy: 0.5862 - val_loss: 1.6776\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7592 - loss: 0.7642 - val_accuracy: 0.5871 - val_loss: 1.6757\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7642 - val_accuracy: 0.5856 - val_loss: 1.6823\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7641 - val_accuracy: 0.5871 - val_loss: 1.6806\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7641 - val_accuracy: 0.5871 - val_loss: 1.6770\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7640 - val_accuracy: 0.5871 - val_loss: 1.6812\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7640 - val_accuracy: 0.5871 - val_loss: 1.6771\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7639 - val_accuracy: 0.5862 - val_loss: 1.6790\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7639 - val_accuracy: 0.5862 - val_loss: 1.6797\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7638 - val_accuracy: 0.5871 - val_loss: 1.6770\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7638 - val_accuracy: 0.5871 - val_loss: 1.6784\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7637 - val_accuracy: 0.5871 - val_loss: 1.6770\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7637 - val_accuracy: 0.5871 - val_loss: 1.6774\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7636 - val_accuracy: 0.5871 - val_loss: 1.6756\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7636 - val_accuracy: 0.5871 - val_loss: 1.6772\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7635 - val_accuracy: 0.5871 - val_loss: 1.6732\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7593 - loss: 0.7635 - val_accuracy: 0.5869 - val_loss: 1.6800\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7634 - val_accuracy: 0.5869 - val_loss: 1.6787\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7634 - val_accuracy: 0.5870 - val_loss: 1.6806\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7634 - val_accuracy: 0.5870 - val_loss: 1.6778\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7633 - val_accuracy: 0.5869 - val_loss: 1.6813\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7633 - val_accuracy: 0.5870 - val_loss: 1.6812\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7632 - val_accuracy: 0.5864 - val_loss: 1.6849\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7632 - val_accuracy: 0.5869 - val_loss: 1.6792\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7631 - val_accuracy: 0.5869 - val_loss: 1.6817\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7631 - val_accuracy: 0.5869 - val_loss: 1.6817\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7630 - val_accuracy: 0.5869 - val_loss: 1.6839\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7630 - val_accuracy: 0.5869 - val_loss: 1.6838\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7630 - val_accuracy: 0.5870 - val_loss: 1.6822\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7629 - val_accuracy: 0.5869 - val_loss: 1.6843\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7629 - val_accuracy: 0.5869 - val_loss: 1.6793\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7628 - val_accuracy: 0.5869 - val_loss: 1.6833\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7628 - val_accuracy: 0.5869 - val_loss: 1.6789\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7627 - val_accuracy: 0.5869 - val_loss: 1.6796\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7627 - val_accuracy: 0.5869 - val_loss: 1.6828\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7593 - loss: 0.7627 - val_accuracy: 0.5869 - val_loss: 1.6836\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7593 - loss: 0.7626 - val_accuracy: 0.5869 - val_loss: 1.6804\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7626 - val_accuracy: 0.5869 - val_loss: 1.6838\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7625 - val_accuracy: 0.5869 - val_loss: 1.6847\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7625 - val_accuracy: 0.5870 - val_loss: 1.6834\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7624 - val_accuracy: 0.5870 - val_loss: 1.6820\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7624 - val_accuracy: 0.5870 - val_loss: 1.6819\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7624 - val_accuracy: 0.5870 - val_loss: 1.6807\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7623 - val_accuracy: 0.5869 - val_loss: 1.6846\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7623 - val_accuracy: 0.5870 - val_loss: 1.6821\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7622 - val_accuracy: 0.5867 - val_loss: 1.6872\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7593 - loss: 0.7622 - val_accuracy: 0.5868 - val_loss: 1.6847\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7622 - val_accuracy: 0.5868 - val_loss: 1.6851\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7594 - loss: 0.7621 - val_accuracy: 0.5868 - val_loss: 1.6887\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7621 - val_accuracy: 0.5867 - val_loss: 1.6867\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7594 - loss: 0.7620 - val_accuracy: 0.5866 - val_loss: 1.6856\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7620 - val_accuracy: 0.5866 - val_loss: 1.6829\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7594 - loss: 0.7620 - val_accuracy: 0.5866 - val_loss: 1.6860\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7594 - loss: 0.7619 - val_accuracy: 0.5866 - val_loss: 1.6839\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7619 - val_accuracy: 0.5866 - val_loss: 1.6830\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7618 - val_accuracy: 0.5866 - val_loss: 1.6843\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7618 - val_accuracy: 0.5866 - val_loss: 1.6873\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7593 - loss: 0.7618 - val_accuracy: 0.5866 - val_loss: 1.6815\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7594 - loss: 0.7617 - val_accuracy: 0.5866 - val_loss: 1.6832\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7617 - val_accuracy: 0.5866 - val_loss: 1.6823\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7616 - val_accuracy: 0.5866 - val_loss: 1.6845\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7616 - val_accuracy: 0.5866 - val_loss: 1.6893\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7616 - val_accuracy: 0.5866 - val_loss: 1.6827\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7594 - loss: 0.7615 - val_accuracy: 0.5865 - val_loss: 1.6903\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7595 - loss: 0.7615 - val_accuracy: 0.5865 - val_loss: 1.6926\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7595 - loss: 0.7614 - val_accuracy: 0.5865 - val_loss: 1.6921\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7595 - loss: 0.7614 - val_accuracy: 0.5865 - val_loss: 1.6880\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7596 - loss: 0.7614 - val_accuracy: 0.5865 - val_loss: 1.6874\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7596 - loss: 0.7613 - val_accuracy: 0.5867 - val_loss: 1.6875\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7613 - val_accuracy: 0.5868 - val_loss: 1.6807\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7613 - val_accuracy: 0.5865 - val_loss: 1.6874\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7612 - val_accuracy: 0.5865 - val_loss: 1.6897\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7596 - loss: 0.7612 - val_accuracy: 0.5867 - val_loss: 1.6842\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7611 - val_accuracy: 0.5867 - val_loss: 1.6877\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7611 - val_accuracy: 0.5867 - val_loss: 1.6881\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7611 - val_accuracy: 0.5867 - val_loss: 1.6881\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7610 - val_accuracy: 0.5867 - val_loss: 1.6892\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7597 - loss: 0.7610 - val_accuracy: 0.5867 - val_loss: 1.6873\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7599 - loss: 0.7610 - val_accuracy: 0.5867 - val_loss: 1.6895\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.7609 - val_accuracy: 0.5867 - val_loss: 1.6906\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7607 - loss: 0.7609 - val_accuracy: 0.5867 - val_loss: 1.6869\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7621 - loss: 0.7608 - val_accuracy: 0.5867 - val_loss: 1.6857\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7608 - val_accuracy: 0.5867 - val_loss: 1.6857\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7608 - val_accuracy: 0.5867 - val_loss: 1.6884\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7607 - val_accuracy: 0.5867 - val_loss: 1.6883\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7607 - val_accuracy: 0.5867 - val_loss: 1.6904\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7607 - val_accuracy: 0.5867 - val_loss: 1.6863\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7625 - loss: 0.7606 - val_accuracy: 0.5867 - val_loss: 1.6893\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7606 - val_accuracy: 0.5867 - val_loss: 1.6888\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7625 - loss: 0.7606 - val_accuracy: 0.5867 - val_loss: 1.6884\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7605 - val_accuracy: 0.5867 - val_loss: 1.6870\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7605 - val_accuracy: 0.5867 - val_loss: 1.6904\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7605 - val_accuracy: 0.5867 - val_loss: 1.6881\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7604 - val_accuracy: 0.5867 - val_loss: 1.6859\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7604 - val_accuracy: 0.5867 - val_loss: 1.6884\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7603 - val_accuracy: 0.5867 - val_loss: 1.6834\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7603 - val_accuracy: 0.5867 - val_loss: 1.6908\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7603 - val_accuracy: 0.5867 - val_loss: 1.6895\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7625 - loss: 0.7602 - val_accuracy: 0.5867 - val_loss: 1.6879\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7622 - loss: 0.7602 - val_accuracy: 0.5867 - val_loss: 1.6869\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7602 - val_accuracy: 0.5867 - val_loss: 1.6899\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7601 - val_accuracy: 0.5867 - val_loss: 1.6893\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7601 - val_accuracy: 0.5867 - val_loss: 1.6927\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7623 - loss: 0.7601 - val_accuracy: 0.5867 - val_loss: 1.6914\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7600 - val_accuracy: 0.5867 - val_loss: 1.6909\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7625 - loss: 0.7600 - val_accuracy: 0.5867 - val_loss: 1.6911\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7600 - val_accuracy: 0.5867 - val_loss: 1.6931\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7599 - val_accuracy: 0.5867 - val_loss: 1.6865\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7622 - loss: 0.7599 - val_accuracy: 0.5867 - val_loss: 1.6910\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7599 - val_accuracy: 0.5867 - val_loss: 1.6920\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7619 - loss: 0.7598 - val_accuracy: 0.5867 - val_loss: 1.6928\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7625 - loss: 0.7598 - val_accuracy: 0.5867 - val_loss: 1.6974\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7598 - val_accuracy: 0.5867 - val_loss: 1.6929\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7597 - val_accuracy: 0.5867 - val_loss: 1.6929\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7604 - loss: 0.7597 - val_accuracy: 0.5867 - val_loss: 1.6941\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7625 - loss: 0.7597 - val_accuracy: 0.5867 - val_loss: 1.6892\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7624 - loss: 0.7596 - val_accuracy: 0.5867 - val_loss: 1.6928\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.7596 - val_accuracy: 0.5867 - val_loss: 1.6905\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7596 - val_accuracy: 0.5867 - val_loss: 1.6962\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7623 - loss: 0.7595 - val_accuracy: 0.5867 - val_loss: 1.6930\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7624 - loss: 0.7595 - val_accuracy: 0.5867 - val_loss: 1.6926\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7618 - loss: 0.7595 - val_accuracy: 0.5867 - val_loss: 1.6866\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7614 - loss: 0.7594 - val_accuracy: 0.5867 - val_loss: 1.6938\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7611 - loss: 0.7594 - val_accuracy: 0.5867 - val_loss: 1.6917\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7623 - loss: 0.7594 - val_accuracy: 0.5867 - val_loss: 1.6942\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7617 - loss: 0.7593 - val_accuracy: 0.5823 - val_loss: 1.6977\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7610 - loss: 0.7593 - val_accuracy: 0.5867 - val_loss: 1.6976\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.7593 - val_accuracy: 0.5867 - val_loss: 1.6928\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7617 - loss: 0.7593 - val_accuracy: 0.5823 - val_loss: 1.6939\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7619 - loss: 0.7592 - val_accuracy: 0.5823 - val_loss: 1.6951\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7603 - loss: 0.7592 - val_accuracy: 0.5867 - val_loss: 1.6899\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7619 - loss: 0.7592 - val_accuracy: 0.5867 - val_loss: 1.6925\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7614 - loss: 0.7591 - val_accuracy: 0.5824 - val_loss: 1.6916\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.7591 - val_accuracy: 0.5823 - val_loss: 1.6961\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7613 - loss: 0.7591 - val_accuracy: 0.5867 - val_loss: 1.6948\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7602 - loss: 0.7590 - val_accuracy: 0.5867 - val_loss: 1.6958\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7605 - loss: 0.7590 - val_accuracy: 0.5867 - val_loss: 1.6970\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7604 - loss: 0.7590 - val_accuracy: 0.5867 - val_loss: 1.6959\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7608 - loss: 0.7589 - val_accuracy: 0.5867 - val_loss: 1.6947\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7617 - loss: 0.7589 - val_accuracy: 0.5868 - val_loss: 1.6924\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7610 - loss: 0.7589 - val_accuracy: 0.5824 - val_loss: 1.6942\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7608 - loss: 0.7588 - val_accuracy: 0.5824 - val_loss: 1.6971\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7592 - loss: 0.7588 - val_accuracy: 0.5824 - val_loss: 1.6974\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7604 - loss: 0.7588 - val_accuracy: 0.5867 - val_loss: 1.6976\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7592 - loss: 0.7588 - val_accuracy: 0.5823 - val_loss: 1.6963\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7592 - loss: 0.7587 - val_accuracy: 0.5823 - val_loss: 1.6957\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7606 - loss: 0.7587 - val_accuracy: 0.5823 - val_loss: 1.6952\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7607 - loss: 0.7587 - val_accuracy: 0.5823 - val_loss: 1.6982\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7593 - loss: 0.7586 - val_accuracy: 0.5823 - val_loss: 1.7005\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7598 - loss: 0.7586 - val_accuracy: 0.5866 - val_loss: 1.6968\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7586 - val_accuracy: 0.5872 - val_loss: 1.6959\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7608 - loss: 0.7585 - val_accuracy: 0.5823 - val_loss: 1.7029\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7596 - loss: 0.7585 - val_accuracy: 0.5823 - val_loss: 1.6962\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7585 - val_accuracy: 0.5823 - val_loss: 1.6965\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7585 - val_accuracy: 0.5821 - val_loss: 1.6992\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7601 - loss: 0.7584 - val_accuracy: 0.5821 - val_loss: 1.6974\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7595 - loss: 0.7584 - val_accuracy: 0.5821 - val_loss: 1.6994\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7591 - loss: 0.7584 - val_accuracy: 0.5829 - val_loss: 1.6948\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7594 - loss: 0.7583 - val_accuracy: 0.5828 - val_loss: 1.6955\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7591 - loss: 0.7583 - val_accuracy: 0.5822 - val_loss: 1.6988\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7593 - loss: 0.7583 - val_accuracy: 0.5865 - val_loss: 1.7006\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7614 - loss: 0.7583 - val_accuracy: 0.5827 - val_loss: 1.7013\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7582 - val_accuracy: 0.5829 - val_loss: 1.6954\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7582 - val_accuracy: 0.5827 - val_loss: 1.6975\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7588 - loss: 0.7582 - val_accuracy: 0.5827 - val_loss: 1.6990\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7597 - loss: 0.7581 - val_accuracy: 0.5828 - val_loss: 1.6945\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7581 - val_accuracy: 0.5827 - val_loss: 1.7003\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7581 - val_accuracy: 0.5827 - val_loss: 1.6972\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7590 - loss: 0.7581 - val_accuracy: 0.5828 - val_loss: 1.6985\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7589 - loss: 0.7580 - val_accuracy: 0.5827 - val_loss: 1.6983\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7580 - val_accuracy: 0.5827 - val_loss: 1.7010\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7600 - loss: 0.7580 - val_accuracy: 0.5827 - val_loss: 1.7013\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7579 - val_accuracy: 0.5826 - val_loss: 1.7006\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7579 - val_accuracy: 0.5826 - val_loss: 1.7023\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7579 - val_accuracy: 0.5826 - val_loss: 1.7007\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7579 - val_accuracy: 0.5869 - val_loss: 1.7015\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7578 - val_accuracy: 0.5826 - val_loss: 1.7028\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7578 - val_accuracy: 0.5826 - val_loss: 1.6992\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7578 - val_accuracy: 0.5826 - val_loss: 1.6988\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7577 - val_accuracy: 0.5826 - val_loss: 1.7039\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7577 - val_accuracy: 0.5826 - val_loss: 1.7032\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7577 - val_accuracy: 0.5869 - val_loss: 1.7032\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7590 - loss: 0.7577 - val_accuracy: 0.5826 - val_loss: 1.7033\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7591 - loss: 0.7576 - val_accuracy: 0.5826 - val_loss: 1.7008\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7576 - val_accuracy: 0.5826 - val_loss: 1.7046\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7576 - val_accuracy: 0.5826 - val_loss: 1.7051\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7587 - loss: 0.7576 - val_accuracy: 0.5826 - val_loss: 1.6996\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7575 - val_accuracy: 0.5826 - val_loss: 1.7004\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7587 - loss: 0.7575 - val_accuracy: 0.5826 - val_loss: 1.7033\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7587 - loss: 0.7575 - val_accuracy: 0.5826 - val_loss: 1.6995\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7586 - loss: 0.7574 - val_accuracy: 0.5826 - val_loss: 1.7018\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7583 - loss: 0.7574 - val_accuracy: 0.5826 - val_loss: 1.7027\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7588 - loss: 0.7574 - val_accuracy: 0.5826 - val_loss: 1.7014\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7586 - loss: 0.7574 - val_accuracy: 0.5826 - val_loss: 1.7029\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7582 - loss: 0.7573 - val_accuracy: 0.5826 - val_loss: 1.7051\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7573 - val_accuracy: 0.5826 - val_loss: 1.7027\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7582 - loss: 0.7573 - val_accuracy: 0.5826 - val_loss: 1.7103\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7573 - loss: 0.7573 - val_accuracy: 0.5826 - val_loss: 1.7020\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7573 - loss: 0.7572 - val_accuracy: 0.5826 - val_loss: 1.7019\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7572 - val_accuracy: 0.5826 - val_loss: 1.7041\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7574 - loss: 0.7572 - val_accuracy: 0.5826 - val_loss: 1.7005\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7572 - val_accuracy: 0.5826 - val_loss: 1.7039\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7570 - loss: 0.7571 - val_accuracy: 0.5826 - val_loss: 1.7055\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7571 - val_accuracy: 0.5826 - val_loss: 1.7043\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7571 - val_accuracy: 0.5826 - val_loss: 1.7054\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7570 - loss: 0.7570 - val_accuracy: 0.5826 - val_loss: 1.7051\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7570 - val_accuracy: 0.5826 - val_loss: 1.7089\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7570 - val_accuracy: 0.5826 - val_loss: 1.7064\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7570 - loss: 0.7570 - val_accuracy: 0.5826 - val_loss: 1.7044\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7570 - loss: 0.7569 - val_accuracy: 0.5826 - val_loss: 1.7066\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7569 - val_accuracy: 0.5826 - val_loss: 1.7053\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7569 - val_accuracy: 0.5826 - val_loss: 1.7015\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7569 - val_accuracy: 0.5826 - val_loss: 1.7079\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7570 - loss: 0.7568 - val_accuracy: 0.5825 - val_loss: 1.7114\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7570 - loss: 0.7568 - val_accuracy: 0.5826 - val_loss: 1.7074\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7570 - loss: 0.7568 - val_accuracy: 0.5826 - val_loss: 1.7076\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7568 - val_accuracy: 0.5826 - val_loss: 1.7084\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7567 - val_accuracy: 0.5825 - val_loss: 1.7074\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7567 - val_accuracy: 0.5825 - val_loss: 1.7054\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7571 - loss: 0.7567 - val_accuracy: 0.5826 - val_loss: 1.7076\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7571 - loss: 0.7567 - val_accuracy: 0.5825 - val_loss: 1.7113\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7570 - loss: 0.7566 - val_accuracy: 0.5825 - val_loss: 1.7083\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7566 - val_accuracy: 0.5826 - val_loss: 1.7048\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7566 - val_accuracy: 0.5825 - val_loss: 1.7067\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7566 - val_accuracy: 0.5825 - val_loss: 1.7091\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7565 - val_accuracy: 0.5826 - val_loss: 1.7041\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7565 - val_accuracy: 0.5826 - val_loss: 1.7071\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7565 - val_accuracy: 0.5825 - val_loss: 1.7093\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7565 - val_accuracy: 0.5825 - val_loss: 1.7084\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7564 - val_accuracy: 0.5826 - val_loss: 1.7064\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7571 - loss: 0.7564 - val_accuracy: 0.5825 - val_loss: 1.7042\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7564 - val_accuracy: 0.5826 - val_loss: 1.7061\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7564 - val_accuracy: 0.5826 - val_loss: 1.7075\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7563 - val_accuracy: 0.5825 - val_loss: 1.7100\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7563 - val_accuracy: 0.5825 - val_loss: 1.7075\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7563 - val_accuracy: 0.5825 - val_loss: 1.7086\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7563 - val_accuracy: 0.5825 - val_loss: 1.7068\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7562 - val_accuracy: 0.5825 - val_loss: 1.7117\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7562 - val_accuracy: 0.5825 - val_loss: 1.7128\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7562 - val_accuracy: 0.5825 - val_loss: 1.7119\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7562 - val_accuracy: 0.5825 - val_loss: 1.7059\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7561 - val_accuracy: 0.5825 - val_loss: 1.7094\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7561 - val_accuracy: 0.5825 - val_loss: 1.7101\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7561 - val_accuracy: 0.5825 - val_loss: 1.7104\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7561 - val_accuracy: 0.5826 - val_loss: 1.7057\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7560 - val_accuracy: 0.5825 - val_loss: 1.7080\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7560 - val_accuracy: 0.5825 - val_loss: 1.7127\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7560 - val_accuracy: 0.5825 - val_loss: 1.7115\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7560 - val_accuracy: 0.5826 - val_loss: 1.7053\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7560 - val_accuracy: 0.5825 - val_loss: 1.7115\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7559 - val_accuracy: 0.5825 - val_loss: 1.7097\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7559 - val_accuracy: 0.5825 - val_loss: 1.7103\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7559 - val_accuracy: 0.5825 - val_loss: 1.7083\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7559 - val_accuracy: 0.5826 - val_loss: 1.7080\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7558 - val_accuracy: 0.5826 - val_loss: 1.7115\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7558 - val_accuracy: 0.5826 - val_loss: 1.7083\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7558 - val_accuracy: 0.5826 - val_loss: 1.7061\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7558 - val_accuracy: 0.5825 - val_loss: 1.7119\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7557 - val_accuracy: 0.5825 - val_loss: 1.7116\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7557 - val_accuracy: 0.5826 - val_loss: 1.7118\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7557 - val_accuracy: 0.5826 - val_loss: 1.7095\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7557 - val_accuracy: 0.5825 - val_loss: 1.7109\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7556 - val_accuracy: 0.5825 - val_loss: 1.7167\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7556 - val_accuracy: 0.5825 - val_loss: 1.7126\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7556 - val_accuracy: 0.5825 - val_loss: 1.7133\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7556 - val_accuracy: 0.5826 - val_loss: 1.7099\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7556 - val_accuracy: 0.5825 - val_loss: 1.7163\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7555 - val_accuracy: 0.5825 - val_loss: 1.7147\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7555 - val_accuracy: 0.5825 - val_loss: 1.7139\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7555 - val_accuracy: 0.5825 - val_loss: 1.7151\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7555 - val_accuracy: 0.5825 - val_loss: 1.7130\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7554 - val_accuracy: 0.5825 - val_loss: 1.7158\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7554 - val_accuracy: 0.5825 - val_loss: 1.7134\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7554 - val_accuracy: 0.5825 - val_loss: 1.7131\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7554 - val_accuracy: 0.5826 - val_loss: 1.7093\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7554 - val_accuracy: 0.5825 - val_loss: 1.7138\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7553 - val_accuracy: 0.5825 - val_loss: 1.7151\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7572 - loss: 0.7553 - val_accuracy: 0.5825 - val_loss: 1.7122\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7553 - val_accuracy: 0.5825 - val_loss: 1.7115\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7572 - loss: 0.7553 - val_accuracy: 0.5825 - val_loss: 1.7119\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7552 - val_accuracy: 0.5825 - val_loss: 1.7129\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7572 - loss: 0.7552 - val_accuracy: 0.5825 - val_loss: 1.7129\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_20, X_test_20, y_train_20, y_test_20 = train_test_split(\n    X, y, test_size=0.3, random_state=62, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_20, X_val_20, y_train_20, y_val_20 = train_test_split(\n    X_train_20, y_train_20, test_size=0.2, random_state=62, stratify=y_train_20\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_20:\", np.max(X_train_20))\nprint(\"Min value in X_train_20:\", np.min(X_train_20))\n\nX_train_20_scaled = scaler.fit_transform(X_train_20)\n\n# Get the original class distribution\nclass_counts_20 = Counter(y_train_20)\nprint(\"Original class distribution:\", class_counts_20)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_20 = class_counts_20[min(class_counts_20, key=class_counts_20.get)]\ndesired_majority_size_20 = minority_class_size_20 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_20 = {0: desired_majority_size_20, 1: minority_class_size_20}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_20 = RandomUnderSampler(sampling_strategy=sampling_strategy_20, random_state=42)\nX_resampled_20, y_resampled_20 = undersampler_20.fit_resample(X_train_20, y_train_20)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_20))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_20, y_train_resampled_20 = smote.fit_resample(X_resampled_20, y_resampled_20)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_20))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_20))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T12:48:05.209276Z","iopub.execute_input":"2025-03-07T12:48:05.209781Z","iopub.status.idle":"2025-03-07T12:48:42.162871Z","shell.execute_reply.started":"2025-03-07T12:48:05.209730Z","shell.execute_reply":"2025-03-07T12:48:42.161575Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_20: 2071000000.0\nMin value in X_train_20: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_20 = X_train_resampled_20.reshape(X_train_resampled_20.shape[0], 1, 56)\nX_val_20 = X_val_20.reshape(X_val_20.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_20,  # Features from CICIDS2017\n    y_train_resampled_20,  # Labels from CICIDS2017\n    validation_data=(X_val_20, y_val_20),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T12:48:42.168242Z","iopub.execute_input":"2025-03-07T12:48:42.168592Z","iopub.status.idle":"2025-03-07T13:36:22.919229Z","shell.execute_reply.started":"2025-03-07T12:48:42.168545Z","shell.execute_reply":"2025-03-07T13:36:22.917244Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7763 - loss: 0.9605 - val_accuracy: 0.5944 - val_loss: 1.5923\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7803 - loss: 0.9453 - val_accuracy: 0.5940 - val_loss: 1.5917\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7847 - loss: 0.9360 - val_accuracy: 0.5941 - val_loss: 1.6026\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7888 - loss: 0.9280 - val_accuracy: 0.5939 - val_loss: 1.6108\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7890 - loss: 0.9207 - val_accuracy: 0.5939 - val_loss: 1.6229\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7891 - loss: 0.9139 - val_accuracy: 0.5951 - val_loss: 1.6278\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7890 - loss: 0.9074 - val_accuracy: 0.5928 - val_loss: 1.6427\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7879 - loss: 0.9010 - val_accuracy: 0.5927 - val_loss: 1.6485\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7883 - loss: 0.8949 - val_accuracy: 0.5924 - val_loss: 1.6588\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.8889 - val_accuracy: 0.5903 - val_loss: 1.6634\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7884 - loss: 0.8830 - val_accuracy: 0.5901 - val_loss: 1.6723\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7884 - loss: 0.8772 - val_accuracy: 0.5900 - val_loss: 1.6784\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7854 - loss: 0.8716 - val_accuracy: 0.5907 - val_loss: 1.6875\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7849 - loss: 0.8660 - val_accuracy: 0.5855 - val_loss: 1.6945\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7846 - loss: 0.8606 - val_accuracy: 0.5853 - val_loss: 1.7005\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7835 - loss: 0.8553 - val_accuracy: 0.5900 - val_loss: 1.7074\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7837 - loss: 0.8501 - val_accuracy: 0.5882 - val_loss: 1.7174\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7841 - loss: 0.8451 - val_accuracy: 0.5882 - val_loss: 1.7199\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7834 - loss: 0.8402 - val_accuracy: 0.5855 - val_loss: 1.7277\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7825 - loss: 0.8354 - val_accuracy: 0.5854 - val_loss: 1.7333\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7827 - loss: 0.8307 - val_accuracy: 0.5851 - val_loss: 1.7401\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.8262 - val_accuracy: 0.5838 - val_loss: 1.7439\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7833 - loss: 0.8218 - val_accuracy: 0.5836 - val_loss: 1.7497\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7838 - loss: 0.8176 - val_accuracy: 0.5835 - val_loss: 1.7573\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7856 - loss: 0.8136 - val_accuracy: 0.5834 - val_loss: 1.7592\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7856 - loss: 0.8097 - val_accuracy: 0.5734 - val_loss: 1.7655\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.8059 - val_accuracy: 0.5733 - val_loss: 1.7713\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7865 - loss: 0.8023 - val_accuracy: 0.5733 - val_loss: 1.7763\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7869 - loss: 0.7988 - val_accuracy: 0.5733 - val_loss: 1.7829\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7869 - loss: 0.7954 - val_accuracy: 0.5733 - val_loss: 1.7885\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7869 - loss: 0.7920 - val_accuracy: 0.5732 - val_loss: 1.7899\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7868 - loss: 0.7888 - val_accuracy: 0.5732 - val_loss: 1.7960\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7868 - loss: 0.7856 - val_accuracy: 0.5728 - val_loss: 1.8008\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7866 - loss: 0.7825 - val_accuracy: 0.5726 - val_loss: 1.8043\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7871 - loss: 0.7795 - val_accuracy: 0.5727 - val_loss: 1.8067\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7879 - loss: 0.7765 - val_accuracy: 0.5726 - val_loss: 1.8094\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7736 - val_accuracy: 0.5726 - val_loss: 1.8136\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7707 - val_accuracy: 0.5724 - val_loss: 1.8177\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7888 - loss: 0.7679 - val_accuracy: 0.5747 - val_loss: 1.8167\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7891 - loss: 0.7651 - val_accuracy: 0.5736 - val_loss: 1.8191\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7891 - loss: 0.7624 - val_accuracy: 0.5735 - val_loss: 1.8246\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7597 - val_accuracy: 0.5731 - val_loss: 1.8274\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7571 - val_accuracy: 0.5702 - val_loss: 1.8331\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7889 - loss: 0.7545 - val_accuracy: 0.5724 - val_loss: 1.8330\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7890 - loss: 0.7520 - val_accuracy: 0.5702 - val_loss: 1.8355\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7889 - loss: 0.7496 - val_accuracy: 0.5700 - val_loss: 1.8391\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7905 - loss: 0.7472 - val_accuracy: 0.5711 - val_loss: 1.8435\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7901 - loss: 0.7449 - val_accuracy: 0.5754 - val_loss: 1.8450\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7913 - loss: 0.7426 - val_accuracy: 0.5731 - val_loss: 1.8506\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7917 - loss: 0.7405 - val_accuracy: 0.5731 - val_loss: 1.8477\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7918 - loss: 0.7384 - val_accuracy: 0.5754 - val_loss: 1.8494\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7928 - loss: 0.7364 - val_accuracy: 0.5753 - val_loss: 1.8516\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7951 - loss: 0.7344 - val_accuracy: 0.5731 - val_loss: 1.8566\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.7326 - val_accuracy: 0.5752 - val_loss: 1.8550\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7308 - val_accuracy: 0.5728 - val_loss: 1.8623\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8019 - loss: 0.7292 - val_accuracy: 0.5751 - val_loss: 1.8601\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8023 - loss: 0.7276 - val_accuracy: 0.5750 - val_loss: 1.8606\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8022 - loss: 0.7261 - val_accuracy: 0.5749 - val_loss: 1.8609\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.7247 - val_accuracy: 0.5727 - val_loss: 1.8635\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.7234 - val_accuracy: 0.5749 - val_loss: 1.8652\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.7222 - val_accuracy: 0.5749 - val_loss: 1.8654\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7210 - val_accuracy: 0.5749 - val_loss: 1.8694\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8027 - loss: 0.7199 - val_accuracy: 0.5749 - val_loss: 1.8671\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.7189 - val_accuracy: 0.5741 - val_loss: 1.8707\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8056 - loss: 0.7179 - val_accuracy: 0.5741 - val_loss: 1.8724\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8058 - loss: 0.7170 - val_accuracy: 0.5742 - val_loss: 1.8717\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8055 - loss: 0.7162 - val_accuracy: 0.5741 - val_loss: 1.8752\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8061 - loss: 0.7154 - val_accuracy: 0.5740 - val_loss: 1.8729\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8048 - loss: 0.7147 - val_accuracy: 0.5740 - val_loss: 1.8733\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8051 - loss: 0.7140 - val_accuracy: 0.5717 - val_loss: 1.8788\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8057 - loss: 0.7134 - val_accuracy: 0.5740 - val_loss: 1.8740\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8045 - loss: 0.7128 - val_accuracy: 0.5738 - val_loss: 1.8790\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8050 - loss: 0.7122 - val_accuracy: 0.5739 - val_loss: 1.8738\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8049 - loss: 0.7117 - val_accuracy: 0.5707 - val_loss: 1.8819\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8048 - loss: 0.7112 - val_accuracy: 0.5729 - val_loss: 1.8803\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8042 - loss: 0.7107 - val_accuracy: 0.5729 - val_loss: 1.8836\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8049 - loss: 0.7103 - val_accuracy: 0.5729 - val_loss: 1.8807\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8042 - loss: 0.7099 - val_accuracy: 0.5729 - val_loss: 1.8786\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8049 - loss: 0.7095 - val_accuracy: 0.5706 - val_loss: 1.8830\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8050 - loss: 0.7091 - val_accuracy: 0.5706 - val_loss: 1.8863\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8049 - loss: 0.7088 - val_accuracy: 0.5706 - val_loss: 1.8844\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8050 - loss: 0.7085 - val_accuracy: 0.5595 - val_loss: 1.8843\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8048 - loss: 0.7081 - val_accuracy: 0.5616 - val_loss: 1.8848\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8050 - loss: 0.7079 - val_accuracy: 0.5594 - val_loss: 1.8882\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.7076 - val_accuracy: 0.5594 - val_loss: 1.8915\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8045 - loss: 0.7073 - val_accuracy: 0.5594 - val_loss: 1.8887\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8044 - loss: 0.7071 - val_accuracy: 0.5616 - val_loss: 1.8903\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8048 - loss: 0.7068 - val_accuracy: 0.5616 - val_loss: 1.8874\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8048 - loss: 0.7066 - val_accuracy: 0.5594 - val_loss: 1.8895\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8050 - loss: 0.7064 - val_accuracy: 0.5594 - val_loss: 1.8918\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.7062 - val_accuracy: 0.5596 - val_loss: 1.8928\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8050 - loss: 0.7060 - val_accuracy: 0.5618 - val_loss: 1.8880\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8047 - loss: 0.7058 - val_accuracy: 0.5596 - val_loss: 1.8943\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8050 - loss: 0.7056 - val_accuracy: 0.5596 - val_loss: 1.8932\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8052 - loss: 0.7055 - val_accuracy: 0.5598 - val_loss: 1.8871\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8057 - loss: 0.7053 - val_accuracy: 0.5605 - val_loss: 1.8945\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8059 - loss: 0.7051 - val_accuracy: 0.5605 - val_loss: 1.8929\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8067 - loss: 0.7050 - val_accuracy: 0.5604 - val_loss: 1.8951\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8059 - loss: 0.7048 - val_accuracy: 0.5604 - val_loss: 1.8934\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8068 - loss: 0.7047 - val_accuracy: 0.5617 - val_loss: 1.8923\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8066 - loss: 0.7045 - val_accuracy: 0.5605 - val_loss: 1.8940\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8068 - loss: 0.7044 - val_accuracy: 0.5617 - val_loss: 1.8939\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8067 - loss: 0.7043 - val_accuracy: 0.5617 - val_loss: 1.8962\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8065 - loss: 0.7041 - val_accuracy: 0.5617 - val_loss: 1.8950\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8060 - loss: 0.7040 - val_accuracy: 0.5617 - val_loss: 1.8950\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8066 - loss: 0.7039 - val_accuracy: 0.5617 - val_loss: 1.8928\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8062 - loss: 0.7038 - val_accuracy: 0.5617 - val_loss: 1.8966\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8069 - loss: 0.7036 - val_accuracy: 0.5617 - val_loss: 1.8960\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8066 - loss: 0.7035 - val_accuracy: 0.5617 - val_loss: 1.8947\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8062 - loss: 0.7034 - val_accuracy: 0.5617 - val_loss: 1.8983\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8061 - loss: 0.7033 - val_accuracy: 0.5617 - val_loss: 1.8916\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8062 - loss: 0.7032 - val_accuracy: 0.5616 - val_loss: 1.8958\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8057 - loss: 0.7031 - val_accuracy: 0.5617 - val_loss: 1.8943\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8061 - loss: 0.7030 - val_accuracy: 0.5616 - val_loss: 1.8989\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8060 - loss: 0.7029 - val_accuracy: 0.5617 - val_loss: 1.8993\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8069 - loss: 0.7028 - val_accuracy: 0.5617 - val_loss: 1.8978\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8061 - loss: 0.7027 - val_accuracy: 0.5618 - val_loss: 1.8978\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8060 - loss: 0.7026 - val_accuracy: 0.5618 - val_loss: 1.8958\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8061 - loss: 0.7025 - val_accuracy: 0.5618 - val_loss: 1.8977\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8066 - loss: 0.7024 - val_accuracy: 0.5618 - val_loss: 1.8953\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8060 - loss: 0.7023 - val_accuracy: 0.5617 - val_loss: 1.8964\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8056 - loss: 0.7022 - val_accuracy: 0.5618 - val_loss: 1.8951\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8055 - loss: 0.7021 - val_accuracy: 0.5618 - val_loss: 1.8983\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8064 - loss: 0.7020 - val_accuracy: 0.5616 - val_loss: 1.8969\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8055 - loss: 0.7019 - val_accuracy: 0.5618 - val_loss: 1.8957\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8053 - loss: 0.7018 - val_accuracy: 0.5618 - val_loss: 1.8953\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8064 - loss: 0.7017 - val_accuracy: 0.5616 - val_loss: 1.8963\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8046 - loss: 0.7016 - val_accuracy: 0.5616 - val_loss: 1.9013\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8049 - loss: 0.7015 - val_accuracy: 0.5616 - val_loss: 1.9003\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8066 - loss: 0.7014 - val_accuracy: 0.5615 - val_loss: 1.8978\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8059 - loss: 0.7013 - val_accuracy: 0.5615 - val_loss: 1.8959\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8060 - loss: 0.7012 - val_accuracy: 0.5608 - val_loss: 1.8986\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8059 - loss: 0.7012 - val_accuracy: 0.5609 - val_loss: 1.8958\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8053 - loss: 0.7011 - val_accuracy: 0.5609 - val_loss: 1.8963\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8051 - loss: 0.7010 - val_accuracy: 0.5609 - val_loss: 1.8967\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8056 - loss: 0.7009 - val_accuracy: 0.5609 - val_loss: 1.8951\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8060 - loss: 0.7008 - val_accuracy: 0.5608 - val_loss: 1.8978\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8052 - loss: 0.7007 - val_accuracy: 0.5608 - val_loss: 1.8948\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8056 - loss: 0.7007 - val_accuracy: 0.5609 - val_loss: 1.8950\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8061 - loss: 0.7006 - val_accuracy: 0.5608 - val_loss: 1.8981\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8055 - loss: 0.7005 - val_accuracy: 0.5609 - val_loss: 1.8961\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8048 - loss: 0.7004 - val_accuracy: 0.5609 - val_loss: 1.8988\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8056 - loss: 0.7003 - val_accuracy: 0.5609 - val_loss: 1.8937\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8055 - loss: 0.7003 - val_accuracy: 0.5608 - val_loss: 1.8966\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.8057 - loss: 0.7002 - val_accuracy: 0.5608 - val_loss: 1.8977\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8053 - loss: 0.7001 - val_accuracy: 0.5608 - val_loss: 1.8984\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8045 - loss: 0.7000 - val_accuracy: 0.5608 - val_loss: 1.8990\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8050 - loss: 0.6999 - val_accuracy: 0.5608 - val_loss: 1.9000\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8044 - loss: 0.6999 - val_accuracy: 0.5608 - val_loss: 1.9002\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8045 - loss: 0.6998 - val_accuracy: 0.5608 - val_loss: 1.8958\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.8049 - loss: 0.6997 - val_accuracy: 0.5608 - val_loss: 1.9006\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8049 - loss: 0.6996 - val_accuracy: 0.5608 - val_loss: 1.8994\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8043 - loss: 0.6996 - val_accuracy: 0.5609 - val_loss: 1.8992\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8054 - loss: 0.6995 - val_accuracy: 0.5609 - val_loss: 1.8977\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8050 - loss: 0.6994 - val_accuracy: 0.5608 - val_loss: 1.8998\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.8042 - loss: 0.6994 - val_accuracy: 0.5608 - val_loss: 1.9002\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8034 - loss: 0.6993 - val_accuracy: 0.5608 - val_loss: 1.8959\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8049 - loss: 0.6992 - val_accuracy: 0.5608 - val_loss: 1.9005\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8036 - loss: 0.6991 - val_accuracy: 0.5608 - val_loss: 1.8968\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8047 - loss: 0.6991 - val_accuracy: 0.5609 - val_loss: 1.8968\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8049 - loss: 0.6990 - val_accuracy: 0.5608 - val_loss: 1.8996\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8044 - loss: 0.6989 - val_accuracy: 0.5608 - val_loss: 1.8926\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8035 - loss: 0.6989 - val_accuracy: 0.5609 - val_loss: 1.8996\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8046 - loss: 0.6988 - val_accuracy: 0.5609 - val_loss: 1.8945\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8042 - loss: 0.6987 - val_accuracy: 0.5609 - val_loss: 1.8941\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8038 - loss: 0.6986 - val_accuracy: 0.5608 - val_loss: 1.9011\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8042 - loss: 0.6986 - val_accuracy: 0.5608 - val_loss: 1.8954\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8042 - loss: 0.6985 - val_accuracy: 0.5608 - val_loss: 1.8994\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6984 - val_accuracy: 0.5608 - val_loss: 1.8990\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8043 - loss: 0.6984 - val_accuracy: 0.5608 - val_loss: 1.8978\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8041 - loss: 0.6983 - val_accuracy: 0.5608 - val_loss: 1.8999\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6982 - val_accuracy: 0.5609 - val_loss: 1.8996\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8037 - loss: 0.6982 - val_accuracy: 0.5608 - val_loss: 1.9002\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8042 - loss: 0.6981 - val_accuracy: 0.5608 - val_loss: 1.8987\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8031 - loss: 0.6980 - val_accuracy: 0.5608 - val_loss: 1.9010\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6980 - val_accuracy: 0.5608 - val_loss: 1.8997\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6979 - val_accuracy: 0.5608 - val_loss: 1.8972\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6979 - val_accuracy: 0.5608 - val_loss: 1.8974\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6978 - val_accuracy: 0.5608 - val_loss: 1.8984\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6977 - val_accuracy: 0.5609 - val_loss: 1.8962\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8038 - loss: 0.6977 - val_accuracy: 0.5609 - val_loss: 1.8978\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6976 - val_accuracy: 0.5609 - val_loss: 1.9011\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8032 - loss: 0.6975 - val_accuracy: 0.5608 - val_loss: 1.9008\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8041 - loss: 0.6975 - val_accuracy: 0.5608 - val_loss: 1.9012\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8030 - loss: 0.6974 - val_accuracy: 0.5608 - val_loss: 1.8995\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8030 - loss: 0.6973 - val_accuracy: 0.5608 - val_loss: 1.8997\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6973 - val_accuracy: 0.5608 - val_loss: 1.9002\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8044 - loss: 0.6972 - val_accuracy: 0.5608 - val_loss: 1.9010\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6972 - val_accuracy: 0.5608 - val_loss: 1.9008\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8032 - loss: 0.6971 - val_accuracy: 0.5609 - val_loss: 1.8970\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6970 - val_accuracy: 0.5608 - val_loss: 1.8990\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6970 - val_accuracy: 0.5610 - val_loss: 1.9014\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8041 - loss: 0.6969 - val_accuracy: 0.5608 - val_loss: 1.9035\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6969 - val_accuracy: 0.5610 - val_loss: 1.9029\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6968 - val_accuracy: 0.5608 - val_loss: 1.9025\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6967 - val_accuracy: 0.5608 - val_loss: 1.8997\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6967 - val_accuracy: 0.5608 - val_loss: 1.9038\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6966 - val_accuracy: 0.5608 - val_loss: 1.9018\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8041 - loss: 0.6966 - val_accuracy: 0.5608 - val_loss: 1.9029\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6965 - val_accuracy: 0.5608 - val_loss: 1.9027\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6965 - val_accuracy: 0.5608 - val_loss: 1.9064\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8038 - loss: 0.6964 - val_accuracy: 0.5609 - val_loss: 1.9015\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6963 - val_accuracy: 0.5607 - val_loss: 1.9051\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6963 - val_accuracy: 0.5608 - val_loss: 1.9007\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6962 - val_accuracy: 0.5607 - val_loss: 1.9015\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6962 - val_accuracy: 0.5607 - val_loss: 1.9045\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6961 - val_accuracy: 0.5608 - val_loss: 1.9032\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8046 - loss: 0.6961 - val_accuracy: 0.5608 - val_loss: 1.9003\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6960 - val_accuracy: 0.5608 - val_loss: 1.9043\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6959 - val_accuracy: 0.5609 - val_loss: 1.9003\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6959 - val_accuracy: 0.5608 - val_loss: 1.9014\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6958 - val_accuracy: 0.5609 - val_loss: 1.9015\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6958 - val_accuracy: 0.5607 - val_loss: 1.9044\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6957 - val_accuracy: 0.5610 - val_loss: 1.9004\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6957 - val_accuracy: 0.5608 - val_loss: 1.9047\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6956 - val_accuracy: 0.5610 - val_loss: 1.8995\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6956 - val_accuracy: 0.5608 - val_loss: 1.9058\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8038 - loss: 0.6955 - val_accuracy: 0.5608 - val_loss: 1.9035\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6955 - val_accuracy: 0.5610 - val_loss: 1.9003\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6954 - val_accuracy: 0.5610 - val_loss: 1.9007\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6953 - val_accuracy: 0.5610 - val_loss: 1.9029\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6953 - val_accuracy: 0.5610 - val_loss: 1.9023\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6952 - val_accuracy: 0.5609 - val_loss: 1.9053\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6952 - val_accuracy: 0.5610 - val_loss: 1.9011\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6951 - val_accuracy: 0.5610 - val_loss: 1.8981\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6951 - val_accuracy: 0.5610 - val_loss: 1.9007\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6950 - val_accuracy: 0.5608 - val_loss: 1.9061\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6950 - val_accuracy: 0.5610 - val_loss: 1.9046\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6949 - val_accuracy: 0.5608 - val_loss: 1.9051\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6949 - val_accuracy: 0.5610 - val_loss: 1.9038\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6948 - val_accuracy: 0.5610 - val_loss: 1.8992\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6948 - val_accuracy: 0.5610 - val_loss: 1.9050\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8036 - loss: 0.6947 - val_accuracy: 0.5610 - val_loss: 1.9049\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8038 - loss: 0.6947 - val_accuracy: 0.5610 - val_loss: 1.9019\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8042 - loss: 0.6946 - val_accuracy: 0.5610 - val_loss: 1.9017\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6946 - val_accuracy: 0.5609 - val_loss: 1.9073\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6945 - val_accuracy: 0.5610 - val_loss: 1.9052\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6945 - val_accuracy: 0.5610 - val_loss: 1.9026\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6944 - val_accuracy: 0.5610 - val_loss: 1.9045\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6944 - val_accuracy: 0.5610 - val_loss: 1.9048\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6943 - val_accuracy: 0.5610 - val_loss: 1.9028\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8038 - loss: 0.6943 - val_accuracy: 0.5610 - val_loss: 1.9049\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6942 - val_accuracy: 0.5610 - val_loss: 1.9029\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6942 - val_accuracy: 0.5610 - val_loss: 1.9029\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6941 - val_accuracy: 0.5609 - val_loss: 1.9059\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6941 - val_accuracy: 0.5610 - val_loss: 1.9042\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6940 - val_accuracy: 0.5610 - val_loss: 1.9052\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6940 - val_accuracy: 0.5610 - val_loss: 1.9061\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6939 - val_accuracy: 0.5610 - val_loss: 1.9054\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6939 - val_accuracy: 0.5610 - val_loss: 1.9044\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6938 - val_accuracy: 0.5610 - val_loss: 1.9071\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6938 - val_accuracy: 0.5609 - val_loss: 1.9069\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6937 - val_accuracy: 0.5610 - val_loss: 1.9053\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6937 - val_accuracy: 0.5609 - val_loss: 1.9087\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6936 - val_accuracy: 0.5610 - val_loss: 1.9070\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6936 - val_accuracy: 0.5609 - val_loss: 1.9067\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6936 - val_accuracy: 0.5610 - val_loss: 1.9084\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6935 - val_accuracy: 0.5609 - val_loss: 1.9086\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6935 - val_accuracy: 0.5609 - val_loss: 1.9095\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6934 - val_accuracy: 0.5610 - val_loss: 1.9076\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6934 - val_accuracy: 0.5609 - val_loss: 1.9115\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6933 - val_accuracy: 0.5609 - val_loss: 1.9086\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6933 - val_accuracy: 0.5609 - val_loss: 1.9098\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8037 - loss: 0.6932 - val_accuracy: 0.5610 - val_loss: 1.9086\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8037 - loss: 0.6932 - val_accuracy: 0.5610 - val_loss: 1.9077\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8037 - loss: 0.6931 - val_accuracy: 0.5610 - val_loss: 1.9070\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6931 - val_accuracy: 0.5610 - val_loss: 1.9066\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6930 - val_accuracy: 0.5610 - val_loss: 1.9033\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6930 - val_accuracy: 0.5609 - val_loss: 1.9092\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6930 - val_accuracy: 0.5609 - val_loss: 1.9065\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6929 - val_accuracy: 0.5609 - val_loss: 1.9060\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6929 - val_accuracy: 0.5609 - val_loss: 1.9122\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8037 - loss: 0.6928 - val_accuracy: 0.5609 - val_loss: 1.9084\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8037 - loss: 0.6928 - val_accuracy: 0.5610 - val_loss: 1.9080\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6927 - val_accuracy: 0.5609 - val_loss: 1.9083\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6927 - val_accuracy: 0.5609 - val_loss: 1.9090\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6927 - val_accuracy: 0.5609 - val_loss: 1.9072\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6926 - val_accuracy: 0.5609 - val_loss: 1.9065\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60427\n726/726 - 7s - 9ms/step - accuracy: 0.8037 - loss: 0.6926 - val_accuracy: 0.5609 - val_loss: 1.9085\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6925 - val_accuracy: 0.5609 - val_loss: 1.9116\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6925 - val_accuracy: 0.5609 - val_loss: 1.9094\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6924 - val_accuracy: 0.5609 - val_loss: 1.9131\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6924 - val_accuracy: 0.5609 - val_loss: 1.9110\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8037 - loss: 0.6924 - val_accuracy: 0.5609 - val_loss: 1.9114\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6923 - val_accuracy: 0.5609 - val_loss: 1.9093\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6923 - val_accuracy: 0.5609 - val_loss: 1.9142\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6922 - val_accuracy: 0.5610 - val_loss: 1.9057\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6922 - val_accuracy: 0.5609 - val_loss: 1.9101\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6921 - val_accuracy: 0.5609 - val_loss: 1.9121\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6921 - val_accuracy: 0.5609 - val_loss: 1.9110\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6921 - val_accuracy: 0.5609 - val_loss: 1.9081\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6920 - val_accuracy: 0.5609 - val_loss: 1.9093\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6920 - val_accuracy: 0.5609 - val_loss: 1.9120\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6919 - val_accuracy: 0.5609 - val_loss: 1.9102\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6919 - val_accuracy: 0.5609 - val_loss: 1.9098\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6918 - val_accuracy: 0.5609 - val_loss: 1.9105\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6918 - val_accuracy: 0.5610 - val_loss: 1.9081\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6918 - val_accuracy: 0.5610 - val_loss: 1.9069\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6917 - val_accuracy: 0.5609 - val_loss: 1.9121\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6917 - val_accuracy: 0.5609 - val_loss: 1.9113\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6916 - val_accuracy: 0.5609 - val_loss: 1.9104\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8037 - loss: 0.6916 - val_accuracy: 0.5610 - val_loss: 1.9097\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6916 - val_accuracy: 0.5611 - val_loss: 1.9089\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8037 - loss: 0.6915 - val_accuracy: 0.5609 - val_loss: 1.9148\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6915 - val_accuracy: 0.5610 - val_loss: 1.9102\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8036 - loss: 0.6914 - val_accuracy: 0.5610 - val_loss: 1.9102\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6914 - val_accuracy: 0.5610 - val_loss: 1.9126\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8037 - loss: 0.6914 - val_accuracy: 0.5610 - val_loss: 1.9130\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6913 - val_accuracy: 0.5611 - val_loss: 1.9123\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6913 - val_accuracy: 0.5610 - val_loss: 1.9102\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6912 - val_accuracy: 0.5608 - val_loss: 1.9131\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6912 - val_accuracy: 0.5611 - val_loss: 1.9073\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6912 - val_accuracy: 0.5608 - val_loss: 1.9154\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6911 - val_accuracy: 0.5608 - val_loss: 1.9121\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6911 - val_accuracy: 0.5608 - val_loss: 1.9128\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6910 - val_accuracy: 0.5608 - val_loss: 1.9124\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6910 - val_accuracy: 0.5608 - val_loss: 1.9134\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6910 - val_accuracy: 0.5608 - val_loss: 1.9122\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6909 - val_accuracy: 0.5608 - val_loss: 1.9115\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6909 - val_accuracy: 0.5608 - val_loss: 1.9123\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6909 - val_accuracy: 0.5608 - val_loss: 1.9153\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6908 - val_accuracy: 0.5608 - val_loss: 1.9116\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6908 - val_accuracy: 0.5608 - val_loss: 1.9133\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6907 - val_accuracy: 0.5608 - val_loss: 1.9137\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6907 - val_accuracy: 0.5608 - val_loss: 1.9118\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6907 - val_accuracy: 0.5608 - val_loss: 1.9157\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6906 - val_accuracy: 0.5608 - val_loss: 1.9122\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6906 - val_accuracy: 0.5608 - val_loss: 1.9156\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6905 - val_accuracy: 0.5608 - val_loss: 1.9162\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6905 - val_accuracy: 0.5608 - val_loss: 1.9144\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6905 - val_accuracy: 0.5608 - val_loss: 1.9140\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6904 - val_accuracy: 0.5608 - val_loss: 1.9132\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6904 - val_accuracy: 0.5608 - val_loss: 1.9141\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6904 - val_accuracy: 0.5608 - val_loss: 1.9115\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6903 - val_accuracy: 0.5608 - val_loss: 1.9096\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6903 - val_accuracy: 0.5608 - val_loss: 1.9117\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6902 - val_accuracy: 0.5608 - val_loss: 1.9128\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6902 - val_accuracy: 0.5608 - val_loss: 1.9141\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6902 - val_accuracy: 0.5608 - val_loss: 1.9165\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6901 - val_accuracy: 0.5608 - val_loss: 1.9141\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6901 - val_accuracy: 0.5608 - val_loss: 1.9157\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6901 - val_accuracy: 0.5608 - val_loss: 1.9132\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6900 - val_accuracy: 0.5608 - val_loss: 1.9177\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6900 - val_accuracy: 0.5608 - val_loss: 1.9153\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6900 - val_accuracy: 0.5608 - val_loss: 1.9143\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6899 - val_accuracy: 0.5608 - val_loss: 1.9174\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6899 - val_accuracy: 0.5608 - val_loss: 1.9136\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6898 - val_accuracy: 0.5608 - val_loss: 1.9114\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6898 - val_accuracy: 0.5608 - val_loss: 1.9161\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6898 - val_accuracy: 0.5608 - val_loss: 1.9155\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6897 - val_accuracy: 0.5608 - val_loss: 1.9126\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6897 - val_accuracy: 0.5608 - val_loss: 1.9134\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6897 - val_accuracy: 0.5608 - val_loss: 1.9158\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6896 - val_accuracy: 0.5608 - val_loss: 1.9146\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6896 - val_accuracy: 0.5608 - val_loss: 1.9170\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6896 - val_accuracy: 0.5608 - val_loss: 1.9185\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6895 - val_accuracy: 0.5607 - val_loss: 1.9159\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6895 - val_accuracy: 0.5607 - val_loss: 1.9219\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6895 - val_accuracy: 0.5607 - val_loss: 1.9167\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6894 - val_accuracy: 0.5608 - val_loss: 1.9156\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6894 - val_accuracy: 0.5607 - val_loss: 1.9172\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6894 - val_accuracy: 0.5607 - val_loss: 1.9183\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6893 - val_accuracy: 0.5607 - val_loss: 1.9175\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6893 - val_accuracy: 0.5608 - val_loss: 1.9149\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6893 - val_accuracy: 0.5607 - val_loss: 1.9204\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6892 - val_accuracy: 0.5607 - val_loss: 1.9204\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6892 - val_accuracy: 0.5607 - val_loss: 1.9174\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6891 - val_accuracy: 0.5607 - val_loss: 1.9191\nEpoch 369/500\n\nEpoch 371: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6890 - val_accuracy: 0.5607 - val_loss: 1.9202\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6890 - val_accuracy: 0.5607 - val_loss: 1.9197\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6890 - val_accuracy: 0.5607 - val_loss: 1.9200\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6889 - val_accuracy: 0.5607 - val_loss: 1.9214\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6889 - val_accuracy: 0.5607 - val_loss: 1.9184\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6889 - val_accuracy: 0.5607 - val_loss: 1.9209\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6888 - val_accuracy: 0.5607 - val_loss: 1.9210\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6888 - val_accuracy: 0.5607 - val_loss: 1.9175\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6888 - val_accuracy: 0.5607 - val_loss: 1.9207\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6887 - val_accuracy: 0.5607 - val_loss: 1.9237\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6887 - val_accuracy: 0.5607 - val_loss: 1.9194\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6887 - val_accuracy: 0.5607 - val_loss: 1.9189\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6886 - val_accuracy: 0.5607 - val_loss: 1.9213\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6886 - val_accuracy: 0.5607 - val_loss: 1.9205\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8035 - loss: 0.6886 - val_accuracy: 0.5607 - val_loss: 1.9178\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6885 - val_accuracy: 0.5607 - val_loss: 1.9212\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6885 - val_accuracy: 0.5607 - val_loss: 1.9208\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6885 - val_accuracy: 0.5607 - val_loss: 1.9193\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6885 - val_accuracy: 0.5606 - val_loss: 1.9206\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6884 - val_accuracy: 0.5607 - val_loss: 1.9206\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6884 - val_accuracy: 0.5607 - val_loss: 1.9197\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6884 - val_accuracy: 0.5606 - val_loss: 1.9222\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6883 - val_accuracy: 0.5606 - val_loss: 1.9223\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6883 - val_accuracy: 0.5607 - val_loss: 1.9176\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6883 - val_accuracy: 0.5606 - val_loss: 1.9225\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6882 - val_accuracy: 0.5607 - val_loss: 1.9200\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6882 - val_accuracy: 0.5607 - val_loss: 1.9203\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6882 - val_accuracy: 0.5606 - val_loss: 1.9229\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6881 - val_accuracy: 0.5606 - val_loss: 1.9207\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6881 - val_accuracy: 0.5606 - val_loss: 1.9227\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6881 - val_accuracy: 0.5607 - val_loss: 1.9199\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6880 - val_accuracy: 0.5606 - val_loss: 1.9246\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6880 - val_accuracy: 0.5606 - val_loss: 1.9205\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6880 - val_accuracy: 0.5607 - val_loss: 1.9196\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6879 - val_accuracy: 0.5606 - val_loss: 1.9246\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6879 - val_accuracy: 0.5606 - val_loss: 1.9254\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6879 - val_accuracy: 0.5607 - val_loss: 1.9189\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6879 - val_accuracy: 0.5606 - val_loss: 1.9247\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6878 - val_accuracy: 0.5606 - val_loss: 1.9219\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6878 - val_accuracy: 0.5606 - val_loss: 1.9218\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6878 - val_accuracy: 0.5606 - val_loss: 1.9243\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6877 - val_accuracy: 0.5606 - val_loss: 1.9250\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6877 - val_accuracy: 0.5607 - val_loss: 1.9225\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6877 - val_accuracy: 0.5607 - val_loss: 1.9236\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6876 - val_accuracy: 0.5607 - val_loss: 1.9209\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6876 - val_accuracy: 0.5607 - val_loss: 1.9227\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6876 - val_accuracy: 0.5607 - val_loss: 1.9212\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6875 - val_accuracy: 0.5606 - val_loss: 1.9263\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6875 - val_accuracy: 0.5606 - val_loss: 1.9249\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6875 - val_accuracy: 0.5606 - val_loss: 1.9239\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6875 - val_accuracy: 0.5606 - val_loss: 1.9282\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6874 - val_accuracy: 0.5606 - val_loss: 1.9239\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8034 - loss: 0.6874 - val_accuracy: 0.5606 - val_loss: 1.9261\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6874 - val_accuracy: 0.5607 - val_loss: 1.9217\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6873 - val_accuracy: 0.5607 - val_loss: 1.9217\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6873 - val_accuracy: 0.5606 - val_loss: 1.9269\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6873 - val_accuracy: 0.5606 - val_loss: 1.9246\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6872 - val_accuracy: 0.5607 - val_loss: 1.9224\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6872 - val_accuracy: 0.5607 - val_loss: 1.9200\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6872 - val_accuracy: 0.5606 - val_loss: 1.9256\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6872 - val_accuracy: 0.5607 - val_loss: 1.9218\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6871 - val_accuracy: 0.5607 - val_loss: 1.9222\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6871 - val_accuracy: 0.5607 - val_loss: 1.9241\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6871 - val_accuracy: 0.5607 - val_loss: 1.9228\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6870 - val_accuracy: 0.5607 - val_loss: 1.9240\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6870 - val_accuracy: 0.5607 - val_loss: 1.9243\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6870 - val_accuracy: 0.5607 - val_loss: 1.9259\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6870 - val_accuracy: 0.5608 - val_loss: 1.9247\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6869 - val_accuracy: 0.5607 - val_loss: 1.9252\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6869 - val_accuracy: 0.5608 - val_loss: 1.9257\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6869 - val_accuracy: 0.5608 - val_loss: 1.9221\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6868 - val_accuracy: 0.5608 - val_loss: 1.9265\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6868 - val_accuracy: 0.5608 - val_loss: 1.9246\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6868 - val_accuracy: 0.5608 - val_loss: 1.9284\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6868 - val_accuracy: 0.5608 - val_loss: 1.9213\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6867 - val_accuracy: 0.5608 - val_loss: 1.9283\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6867 - val_accuracy: 0.5608 - val_loss: 1.9251\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6867 - val_accuracy: 0.5608 - val_loss: 1.9264\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6866 - val_accuracy: 0.5608 - val_loss: 1.9277\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6866 - val_accuracy: 0.5608 - val_loss: 1.9297\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6866 - val_accuracy: 0.5608 - val_loss: 1.9277\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6866 - val_accuracy: 0.5608 - val_loss: 1.9249\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8034 - loss: 0.6865 - val_accuracy: 0.5608 - val_loss: 1.9247\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6865 - val_accuracy: 0.5608 - val_loss: 1.9281\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6865 - val_accuracy: 0.5608 - val_loss: 1.9247\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8034 - loss: 0.6864 - val_accuracy: 0.5608 - val_loss: 1.9284\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6864 - val_accuracy: 0.5608 - val_loss: 1.9263\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6864 - val_accuracy: 0.5608 - val_loss: 1.9244\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6864 - val_accuracy: 0.5608 - val_loss: 1.9297\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6863 - val_accuracy: 0.5608 - val_loss: 1.9280\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6863 - val_accuracy: 0.5608 - val_loss: 1.9308\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6863 - val_accuracy: 0.5608 - val_loss: 1.9296\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6863 - val_accuracy: 0.5608 - val_loss: 1.9280\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.6862 - val_accuracy: 0.5608 - val_loss: 1.9290\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6862 - val_accuracy: 0.5608 - val_loss: 1.9226\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6862 - val_accuracy: 0.5608 - val_loss: 1.9270\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6861 - val_accuracy: 0.5608 - val_loss: 1.9232\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6861 - val_accuracy: 0.5608 - val_loss: 1.9284\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6861 - val_accuracy: 0.5608 - val_loss: 1.9269\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6861 - val_accuracy: 0.5608 - val_loss: 1.9284\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6860 - val_accuracy: 0.5607 - val_loss: 1.9326\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6860 - val_accuracy: 0.5607 - val_loss: 1.9302\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6860 - val_accuracy: 0.5609 - val_loss: 1.9281\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6860 - val_accuracy: 0.5608 - val_loss: 1.9284\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6859 - val_accuracy: 0.5607 - val_loss: 1.9302\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6859 - val_accuracy: 0.5608 - val_loss: 1.9287\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6859 - val_accuracy: 0.5608 - val_loss: 1.9311\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6858 - val_accuracy: 0.5609 - val_loss: 1.9268\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6858 - val_accuracy: 0.5608 - val_loss: 1.9307\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6858 - val_accuracy: 0.5609 - val_loss: 1.9279\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6858 - val_accuracy: 0.5609 - val_loss: 1.9280\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8034 - loss: 0.6857 - val_accuracy: 0.5608 - val_loss: 1.9281\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6857 - val_accuracy: 0.5608 - val_loss: 1.9298\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8035 - loss: 0.6857 - val_accuracy: 0.5609 - val_loss: 1.9295\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6857 - val_accuracy: 0.5609 - val_loss: 1.9272\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6856 - val_accuracy: 0.5607 - val_loss: 1.9293\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6856 - val_accuracy: 0.5608 - val_loss: 1.9328\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8038 - loss: 0.6856 - val_accuracy: 0.5607 - val_loss: 1.9297\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6856 - val_accuracy: 0.5609 - val_loss: 1.9299\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8036 - loss: 0.6855 - val_accuracy: 0.5608 - val_loss: 1.9303\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8044 - loss: 0.6855 - val_accuracy: 0.5607 - val_loss: 1.9330\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6855 - val_accuracy: 0.5607 - val_loss: 1.9307\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6855 - val_accuracy: 0.5607 - val_loss: 1.9317\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6854 - val_accuracy: 0.5609 - val_loss: 1.9276\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8037 - loss: 0.6854 - val_accuracy: 0.5608 - val_loss: 1.9293\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60427\n726/726 - 6s - 9ms/step - accuracy: 0.8036 - loss: 0.6854 - val_accuracy: 0.5609 - val_loss: 1.9304\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6853 - val_accuracy: 0.5607 - val_loss: 1.9333\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6853 - val_accuracy: 0.5607 - val_loss: 1.9293\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6853 - val_accuracy: 0.5607 - val_loss: 1.9316\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.8036 - loss: 0.6853 - val_accuracy: 0.5608 - val_loss: 1.9305\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(\"X_test original shape:\", X_test.shape)\n\nX_test = X_test.reshape(X_test.shape[0], 1, 56)  # Ensure 3D\n\nprint(\"X_test reshaped shape:\", X_test.shape)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T13:36:22.924161Z","iopub.execute_input":"2025-03-07T13:36:22.924639Z","iopub.status.idle":"2025-03-07T13:36:22.932824Z","shell.execute_reply.started":"2025-03-07T13:36:22.924602Z","shell.execute_reply":"2025-03-07T13:36:22.931634Z"}},"outputs":[{"name":"stdout","text":"X_test original shape: (756240, 56)\nX_test reshaped shape: (756240, 1, 56)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"\n# Evaluate the model\ntest_loss, test_accuracy = fine_tuned_model.evaluate(X_test, y_test, verbose=2)\n\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T13:36:22.934497Z","iopub.execute_input":"2025-03-07T13:36:22.935059Z","iopub.status.idle":"2025-03-07T13:37:01.159986Z","shell.execute_reply.started":"2025-03-07T13:36:22.934999Z","shell.execute_reply":"2025-03-07T13:37:01.158754Z"}},"outputs":[{"name":"stdout","text":"23633/23633 - 37s - 2ms/step - accuracy: 0.5607 - loss: 1.9231\nTest Loss: 1.9231085777282715\nTest Accuracy: 0.5606818199157715\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_21, X_test_21, y_train_21, y_test_21 = train_test_split(\n    X, y, test_size=0.3, random_state=63, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_21, X_val_21, y_train_21, y_val_21 = train_test_split(\n    X_train_21, y_train_21, test_size=0.2, random_state=63, stratify=y_train_21\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_21:\", np.max(X_train_21))\nprint(\"Min value in X_train_21:\", np.min(X_train_21))\n\nX_train_21_scaled = scaler.fit_transform(X_train_21)\n\n# Get the original class distribution\nclass_counts_21 = Counter(y_train_21)\nprint(\"Original class distribution:\", class_counts_21)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_21 = class_counts_21[min(class_counts_21, key=class_counts_21.get)]\ndesired_majority_size_21 = minority_class_size_21 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_21 = {0: desired_majority_size_21, 1: minority_class_size_21}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_21 = RandomUnderSampler(sampling_strategy=sampling_strategy_21, random_state=42)\nX_resampled_21, y_resampled_21 = undersampler_21.fit_resample(X_train_21, y_train_21)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_21))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_21, y_train_resampled_21 = smote.fit_resample(X_resampled_21, y_resampled_21)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_21))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_21))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T13:37:01.161293Z","iopub.execute_input":"2025-03-07T13:37:01.161836Z","iopub.status.idle":"2025-03-07T13:37:38.929022Z","shell.execute_reply.started":"2025-03-07T13:37:01.161791Z","shell.execute_reply":"2025-03-07T13:37:38.927934Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_21: 2071000000.0\nMin value in X_train_21: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_21 = X_train_resampled_21.reshape(X_train_resampled_21.shape[0], 1, 56)\nX_val_21 = X_val_21.reshape(X_val_21.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_21,  # Features from CICIDS2017\n    y_train_resampled_21,  # Labels from CICIDS2017\n    validation_data=(X_val_21, y_val_21),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T13:37:38.930495Z","iopub.execute_input":"2025-03-07T13:37:38.930846Z","iopub.status.idle":"2025-03-07T14:24:36.527006Z","shell.execute_reply.started":"2025-03-07T13:37:38.930814Z","shell.execute_reply":"2025-03-07T14:24:36.525711Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7882 - loss: 0.7650 - val_accuracy: 0.5506 - val_loss: 2.0599\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7880 - loss: 0.7560 - val_accuracy: 0.5398 - val_loss: 2.0542\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7877 - loss: 0.7520 - val_accuracy: 0.5401 - val_loss: 2.0389\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7868 - loss: 0.7490 - val_accuracy: 0.5413 - val_loss: 2.0275\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7874 - loss: 0.7465 - val_accuracy: 0.5413 - val_loss: 2.0112\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7877 - loss: 0.7444 - val_accuracy: 0.5414 - val_loss: 1.9921\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7895 - loss: 0.7425 - val_accuracy: 0.5427 - val_loss: 1.9773\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7897 - loss: 0.7408 - val_accuracy: 0.5431 - val_loss: 1.9642\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7897 - loss: 0.7392 - val_accuracy: 0.5541 - val_loss: 1.9443\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7900 - loss: 0.7378 - val_accuracy: 0.5543 - val_loss: 1.9357\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7904 - loss: 0.7365 - val_accuracy: 0.5543 - val_loss: 1.9207\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7906 - loss: 0.7352 - val_accuracy: 0.5565 - val_loss: 1.9118\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7915 - loss: 0.7341 - val_accuracy: 0.5565 - val_loss: 1.8982\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7929 - loss: 0.7330 - val_accuracy: 0.5564 - val_loss: 1.8890\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7946 - loss: 0.7321 - val_accuracy: 0.5564 - val_loss: 1.8807\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.7947 - loss: 0.7311 - val_accuracy: 0.5566 - val_loss: 1.8702\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60427\n726/726 - 7s - 10ms/step - accuracy: 0.7947 - loss: 0.7303 - val_accuracy: 0.5568 - val_loss: 1.8581\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7949 - loss: 0.7294 - val_accuracy: 0.5568 - val_loss: 1.8550\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7962 - loss: 0.7287 - val_accuracy: 0.5567 - val_loss: 1.8505\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7960 - loss: 0.7279 - val_accuracy: 0.5568 - val_loss: 1.8413\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7272 - val_accuracy: 0.5569 - val_loss: 1.8356\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7266 - val_accuracy: 0.5568 - val_loss: 1.8336\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7259 - val_accuracy: 0.5570 - val_loss: 1.8305\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7253 - val_accuracy: 0.5570 - val_loss: 1.8283\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7248 - val_accuracy: 0.5570 - val_loss: 1.8235\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7242 - val_accuracy: 0.5570 - val_loss: 1.8184\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7237 - val_accuracy: 0.5571 - val_loss: 1.8160\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7231 - val_accuracy: 0.5572 - val_loss: 1.8111\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7227 - val_accuracy: 0.5573 - val_loss: 1.8078\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7891 - loss: 0.7222 - val_accuracy: 0.5573 - val_loss: 1.8036\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7890 - loss: 0.7217 - val_accuracy: 0.5584 - val_loss: 1.8004\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7886 - loss: 0.7213 - val_accuracy: 0.5584 - val_loss: 1.8002\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7208 - val_accuracy: 0.5584 - val_loss: 1.7980\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7204 - val_accuracy: 0.5584 - val_loss: 1.7936\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7886 - loss: 0.7200 - val_accuracy: 0.5584 - val_loss: 1.7871\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7885 - loss: 0.7196 - val_accuracy: 0.5584 - val_loss: 1.7891\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7886 - loss: 0.7192 - val_accuracy: 0.5583 - val_loss: 1.7889\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7189 - val_accuracy: 0.5584 - val_loss: 1.7858\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7185 - val_accuracy: 0.5584 - val_loss: 1.7809\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7181 - val_accuracy: 0.5585 - val_loss: 1.7790\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7178 - val_accuracy: 0.5584 - val_loss: 1.7792\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7175 - val_accuracy: 0.5584 - val_loss: 1.7801\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7886 - loss: 0.7171 - val_accuracy: 0.5584 - val_loss: 1.7750\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7168 - val_accuracy: 0.5584 - val_loss: 1.7745\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7165 - val_accuracy: 0.5584 - val_loss: 1.7729\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7162 - val_accuracy: 0.5586 - val_loss: 1.7709\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7886 - loss: 0.7159 - val_accuracy: 0.5587 - val_loss: 1.7668\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7156 - val_accuracy: 0.5700 - val_loss: 1.7629\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7887 - loss: 0.7153 - val_accuracy: 0.5697 - val_loss: 1.7674\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7886 - loss: 0.7151 - val_accuracy: 0.5699 - val_loss: 1.7686\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7148 - val_accuracy: 0.5700 - val_loss: 1.7662\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7145 - val_accuracy: 0.5701 - val_loss: 1.7646\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7143 - val_accuracy: 0.5703 - val_loss: 1.7653\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7140 - val_accuracy: 0.5706 - val_loss: 1.7659\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7138 - val_accuracy: 0.5704 - val_loss: 1.7616\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7136 - val_accuracy: 0.5704 - val_loss: 1.7585\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7888 - loss: 0.7133 - val_accuracy: 0.5754 - val_loss: 1.7547\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7888 - loss: 0.7131 - val_accuracy: 0.5787 - val_loss: 1.7530\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7888 - loss: 0.7129 - val_accuracy: 0.5787 - val_loss: 1.7546\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7888 - loss: 0.7126 - val_accuracy: 0.5787 - val_loss: 1.7547\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7124 - val_accuracy: 0.5787 - val_loss: 1.7521\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7122 - val_accuracy: 0.5787 - val_loss: 1.7558\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7120 - val_accuracy: 0.5786 - val_loss: 1.7548\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7118 - val_accuracy: 0.5787 - val_loss: 1.7507\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7116 - val_accuracy: 0.5790 - val_loss: 1.7518\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7114 - val_accuracy: 0.5790 - val_loss: 1.7465\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7112 - val_accuracy: 0.5789 - val_loss: 1.7468\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7110 - val_accuracy: 0.5790 - val_loss: 1.7485\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7108 - val_accuracy: 0.5790 - val_loss: 1.7489\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7886 - loss: 0.7107 - val_accuracy: 0.5790 - val_loss: 1.7500\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7105 - val_accuracy: 0.5790 - val_loss: 1.7499\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7103 - val_accuracy: 0.5789 - val_loss: 1.7462\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7101 - val_accuracy: 0.5790 - val_loss: 1.7434\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7100 - val_accuracy: 0.5790 - val_loss: 1.7421\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7098 - val_accuracy: 0.5792 - val_loss: 1.7421\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7096 - val_accuracy: 0.5790 - val_loss: 1.7427\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7095 - val_accuracy: 0.5789 - val_loss: 1.7441\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7093 - val_accuracy: 0.5790 - val_loss: 1.7410\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7091 - val_accuracy: 0.5788 - val_loss: 1.7427\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7090 - val_accuracy: 0.5790 - val_loss: 1.7363\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7088 - val_accuracy: 0.5790 - val_loss: 1.7363\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7087 - val_accuracy: 0.5790 - val_loss: 1.7395\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7085 - val_accuracy: 0.5789 - val_loss: 1.7359\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7084 - val_accuracy: 0.5789 - val_loss: 1.7354\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7082 - val_accuracy: 0.5789 - val_loss: 1.7378\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7081 - val_accuracy: 0.5789 - val_loss: 1.7379\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7887 - loss: 0.7079 - val_accuracy: 0.5790 - val_loss: 1.7384\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7078 - val_accuracy: 0.5790 - val_loss: 1.7368\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7887 - loss: 0.7076 - val_accuracy: 0.5788 - val_loss: 1.7382\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7075 - val_accuracy: 0.5793 - val_loss: 1.7355\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7887 - loss: 0.7074 - val_accuracy: 0.5792 - val_loss: 1.7332\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.7072 - val_accuracy: 0.5792 - val_loss: 1.7358\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7887 - loss: 0.7071 - val_accuracy: 0.5792 - val_loss: 1.7361\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7878 - loss: 0.7070 - val_accuracy: 0.5791 - val_loss: 1.7312\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7874 - loss: 0.7068 - val_accuracy: 0.5791 - val_loss: 1.7289\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7873 - loss: 0.7067 - val_accuracy: 0.5789 - val_loss: 1.7313\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7870 - loss: 0.7066 - val_accuracy: 0.5791 - val_loss: 1.7358\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7874 - loss: 0.7065 - val_accuracy: 0.5791 - val_loss: 1.7338\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7869 - loss: 0.7063 - val_accuracy: 0.5791 - val_loss: 1.7315\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7869 - loss: 0.7062 - val_accuracy: 0.5789 - val_loss: 1.7287\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7868 - loss: 0.7061 - val_accuracy: 0.5788 - val_loss: 1.7283\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7060 - val_accuracy: 0.5788 - val_loss: 1.7344\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7058 - val_accuracy: 0.5788 - val_loss: 1.7269\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7867 - loss: 0.7057 - val_accuracy: 0.5788 - val_loss: 1.7290\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7056 - val_accuracy: 0.5788 - val_loss: 1.7263\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7055 - val_accuracy: 0.5788 - val_loss: 1.7297\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7054 - val_accuracy: 0.5788 - val_loss: 1.7282\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7053 - val_accuracy: 0.5785 - val_loss: 1.7290\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7052 - val_accuracy: 0.5788 - val_loss: 1.7271\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7865 - loss: 0.7050 - val_accuracy: 0.5786 - val_loss: 1.7290\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7049 - val_accuracy: 0.5784 - val_loss: 1.7317\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7865 - loss: 0.7048 - val_accuracy: 0.5783 - val_loss: 1.7315\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7866 - loss: 0.7047 - val_accuracy: 0.5785 - val_loss: 1.7264\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7865 - loss: 0.7046 - val_accuracy: 0.5785 - val_loss: 1.7271\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7864 - loss: 0.7045 - val_accuracy: 0.5786 - val_loss: 1.7220\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7865 - loss: 0.7044 - val_accuracy: 0.5789 - val_loss: 1.7274\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7866 - loss: 0.7043 - val_accuracy: 0.5785 - val_loss: 1.7220\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7864 - loss: 0.7042 - val_accuracy: 0.5786 - val_loss: 1.7267\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7866 - loss: 0.7041 - val_accuracy: 0.5791 - val_loss: 1.7266\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60427\n726/726 - 5s - 8ms/step - accuracy: 0.7866 - loss: 0.7040 - val_accuracy: 0.5785 - val_loss: 1.7253\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7865 - loss: 0.7039 - val_accuracy: 0.5789 - val_loss: 1.7246\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7867 - loss: 0.7038 - val_accuracy: 0.5786 - val_loss: 1.7239\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7037 - val_accuracy: 0.5792 - val_loss: 1.7240\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7880 - loss: 0.7036 - val_accuracy: 0.5790 - val_loss: 1.7242\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60427\n726/726 - 5s - 7ms/step - accuracy: 0.7866 - loss: 0.7035 - val_accuracy: 0.5791 - val_loss: 1.7238\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7900 - loss: 0.7034 - val_accuracy: 0.5786 - val_loss: 1.7206\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60427\n726/726 - 6s - 8ms/step - accuracy: 0.7917 - loss: 0.7033 - val_accuracy: 0.5791 - val_loss: 1.7276\nEpoch 128/500\n\nEpoch 128: val_accuracy improved from 0.60427 to 0.61841, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7903 - loss: 0.7032 - val_accuracy: 0.6184 - val_loss: 1.7235\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.61841\n726/726 - 5s - 7ms/step - accuracy: 0.7972 - loss: 0.7031 - val_accuracy: 0.6180 - val_loss: 1.7202\nEpoch 130/500\n\nEpoch 130: val_accuracy improved from 0.61841 to 0.61857, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7966 - loss: 0.7030 - val_accuracy: 0.6186 - val_loss: 1.7210\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.61857\n726/726 - 5s - 7ms/step - accuracy: 0.7979 - loss: 0.7029 - val_accuracy: 0.6184 - val_loss: 1.7240\nEpoch 132/500\n\nEpoch 132: val_accuracy improved from 0.61857 to 0.62145, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7939 - loss: 0.7028 - val_accuracy: 0.6214 - val_loss: 1.7238\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.62145\n726/726 - 6s - 8ms/step - accuracy: 0.7980 - loss: 0.7027 - val_accuracy: 0.6184 - val_loss: 1.7261\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.62145\n726/726 - 5s - 7ms/step - accuracy: 0.7980 - loss: 0.7026 - val_accuracy: 0.6213 - val_loss: 1.7232\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.62145\n726/726 - 6s - 8ms/step - accuracy: 0.7980 - loss: 0.7025 - val_accuracy: 0.6214 - val_loss: 1.7231\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.62145\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7024 - val_accuracy: 0.6184 - val_loss: 1.7220\nEpoch 137/500\n\nEpoch 137: val_accuracy improved from 0.62145 to 0.62146, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7023 - val_accuracy: 0.6215 - val_loss: 1.7183\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.62146\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7022 - val_accuracy: 0.6184 - val_loss: 1.7199\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.62146\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.7022 - val_accuracy: 0.6214 - val_loss: 1.7271\nEpoch 140/500\n\nEpoch 140: val_accuracy improved from 0.62146 to 0.62162, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.7021 - val_accuracy: 0.6216 - val_loss: 1.7218\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7020 - val_accuracy: 0.6215 - val_loss: 1.7239\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.62162\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.7019 - val_accuracy: 0.6185 - val_loss: 1.7246\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.62162\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.7018 - val_accuracy: 0.6214 - val_loss: 1.7223\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7017 - val_accuracy: 0.6216 - val_loss: 1.7192\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.62162\n726/726 - 5s - 7ms/step - accuracy: 0.7982 - loss: 0.7016 - val_accuracy: 0.6214 - val_loss: 1.7255\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7015 - val_accuracy: 0.6214 - val_loss: 1.7208\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7015 - val_accuracy: 0.6214 - val_loss: 1.7256\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7014 - val_accuracy: 0.6214 - val_loss: 1.7205\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7013 - val_accuracy: 0.6215 - val_loss: 1.7202\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.7012 - val_accuracy: 0.6214 - val_loss: 1.7209\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7011 - val_accuracy: 0.6215 - val_loss: 1.7218\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.62162\n726/726 - 5s - 8ms/step - accuracy: 0.7982 - loss: 0.7010 - val_accuracy: 0.6214 - val_loss: 1.7197\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7010 - val_accuracy: 0.6214 - val_loss: 1.7185\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.62162\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.7009 - val_accuracy: 0.6215 - val_loss: 1.7203\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.7008 - val_accuracy: 0.6215 - val_loss: 1.7191\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7007 - val_accuracy: 0.6216 - val_loss: 1.7187\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7006 - val_accuracy: 0.6216 - val_loss: 1.7214\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.62162\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7006 - val_accuracy: 0.6216 - val_loss: 1.7232\nEpoch 159/500\n\nEpoch 159: val_accuracy improved from 0.62162 to 0.62163, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7005 - val_accuracy: 0.6216 - val_loss: 1.7188\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.62163\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.7004 - val_accuracy: 0.6216 - val_loss: 1.7178\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.62163\n726/726 - 5s - 8ms/step - accuracy: 0.7982 - loss: 0.7003 - val_accuracy: 0.6216 - val_loss: 1.7184\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7002 - val_accuracy: 0.6216 - val_loss: 1.7192\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.62163\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.7002 - val_accuracy: 0.6216 - val_loss: 1.7233\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7001 - val_accuracy: 0.6216 - val_loss: 1.7193\nEpoch 165/500\n\nEpoch 165: val_accuracy improved from 0.62163 to 0.62163, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.7000 - val_accuracy: 0.6216 - val_loss: 1.7196\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.62163\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6999 - val_accuracy: 0.6216 - val_loss: 1.7207\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6999 - val_accuracy: 0.6216 - val_loss: 1.7209\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6998 - val_accuracy: 0.6216 - val_loss: 1.7214\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6997 - val_accuracy: 0.6216 - val_loss: 1.7197\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6996 - val_accuracy: 0.6216 - val_loss: 1.7193\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6996 - val_accuracy: 0.6216 - val_loss: 1.7192\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.62163\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6995 - val_accuracy: 0.6216 - val_loss: 1.7164\nEpoch 173/500\n\nEpoch 173: val_accuracy improved from 0.62163 to 0.62164, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6994 - val_accuracy: 0.6216 - val_loss: 1.7177\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.62164\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6993 - val_accuracy: 0.6216 - val_loss: 1.7215\nEpoch 175/500\n\nEpoch 175: val_accuracy improved from 0.62164 to 0.62164, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6993 - val_accuracy: 0.6216 - val_loss: 1.7207\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.62164\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6992 - val_accuracy: 0.6216 - val_loss: 1.7188\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.62164\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6991 - val_accuracy: 0.6216 - val_loss: 1.7157\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.62164\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6991 - val_accuracy: 0.6216 - val_loss: 1.7210\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.62164\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6990 - val_accuracy: 0.6216 - val_loss: 1.7186\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.62164\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6989 - val_accuracy: 0.6216 - val_loss: 1.7201\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.62164\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6988 - val_accuracy: 0.6216 - val_loss: 1.7159\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.62164\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6988 - val_accuracy: 0.6216 - val_loss: 1.7218\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.62164\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6987 - val_accuracy: 0.6216 - val_loss: 1.7229\nEpoch 184/500\n\nEpoch 184: val_accuracy improved from 0.62164 to 0.62167, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6986 - val_accuracy: 0.6217 - val_loss: 1.7174\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.62167\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6986 - val_accuracy: 0.6217 - val_loss: 1.7197\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.62167\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6985 - val_accuracy: 0.6217 - val_loss: 1.7206\nEpoch 187/500\n\nEpoch 187: val_accuracy improved from 0.62167 to 0.62169, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6984 - val_accuracy: 0.6217 - val_loss: 1.7169\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.62169\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.6984 - val_accuracy: 0.6217 - val_loss: 1.7203\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6983 - val_accuracy: 0.6217 - val_loss: 1.7174\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6982 - val_accuracy: 0.6217 - val_loss: 1.7121\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6982 - val_accuracy: 0.6217 - val_loss: 1.7177\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6981 - val_accuracy: 0.6217 - val_loss: 1.7163\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6980 - val_accuracy: 0.6217 - val_loss: 1.7165\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6980 - val_accuracy: 0.6217 - val_loss: 1.7179\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.62169\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.6979 - val_accuracy: 0.6217 - val_loss: 1.7169\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6978 - val_accuracy: 0.6217 - val_loss: 1.7190\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6978 - val_accuracy: 0.6215 - val_loss: 1.7210\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.62169\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.6977 - val_accuracy: 0.6215 - val_loss: 1.7201\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.62169\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.6976 - val_accuracy: 0.6212 - val_loss: 1.7155\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6976 - val_accuracy: 0.6215 - val_loss: 1.7182\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.62169\n726/726 - 5s - 8ms/step - accuracy: 0.7981 - loss: 0.6975 - val_accuracy: 0.6215 - val_loss: 1.7205\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6974 - val_accuracy: 0.6215 - val_loss: 1.7171\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6974 - val_accuracy: 0.6216 - val_loss: 1.7154\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.62169\n726/726 - 5s - 7ms/step - accuracy: 0.7981 - loss: 0.6973 - val_accuracy: 0.6216 - val_loss: 1.7178\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.62169\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6972 - val_accuracy: 0.6213 - val_loss: 1.7193\nEpoch 206/500\n\nEpoch 206: val_accuracy improved from 0.62169 to 0.62194, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.6972 - val_accuracy: 0.6219 - val_loss: 1.7180\nEpoch 207/500\n\nEpoch 207: val_accuracy improved from 0.62194 to 0.62195, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7981 - loss: 0.6971 - val_accuracy: 0.6220 - val_loss: 1.7171\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.62195\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.6970 - val_accuracy: 0.6217 - val_loss: 1.7228\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.62195\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.6970 - val_accuracy: 0.6218 - val_loss: 1.7176\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.62195\n726/726 - 5s - 8ms/step - accuracy: 0.7982 - loss: 0.6969 - val_accuracy: 0.6215 - val_loss: 1.7148\nEpoch 211/500\n\nEpoch 211: val_accuracy improved from 0.62195 to 0.62203, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7983 - loss: 0.6969 - val_accuracy: 0.6220 - val_loss: 1.7160\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.62203\n726/726 - 6s - 8ms/step - accuracy: 0.7983 - loss: 0.6968 - val_accuracy: 0.6215 - val_loss: 1.7169\nEpoch 213/500\n\nEpoch 213: val_accuracy improved from 0.62203 to 0.62203, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7984 - loss: 0.6967 - val_accuracy: 0.6220 - val_loss: 1.7165\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.62203\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.6967 - val_accuracy: 0.6220 - val_loss: 1.7198\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.62203\n726/726 - 6s - 8ms/step - accuracy: 0.7982 - loss: 0.6966 - val_accuracy: 0.6220 - val_loss: 1.7194\nEpoch 216/500\n\nEpoch 216: val_accuracy improved from 0.62203 to 0.62204, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6966 - val_accuracy: 0.6220 - val_loss: 1.7162\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.62204\n726/726 - 5s - 8ms/step - accuracy: 0.7986 - loss: 0.6965 - val_accuracy: 0.6220 - val_loss: 1.7150\nEpoch 218/500\n\nEpoch 218: val_accuracy improved from 0.62204 to 0.62205, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7985 - loss: 0.6964 - val_accuracy: 0.6221 - val_loss: 1.7143\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.62205\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6964 - val_accuracy: 0.6220 - val_loss: 1.7171\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.62205\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.6963 - val_accuracy: 0.6220 - val_loss: 1.7190\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.62205\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6963 - val_accuracy: 0.6220 - val_loss: 1.7218\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.62205\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.6962 - val_accuracy: 0.6220 - val_loss: 1.7192\nEpoch 223/500\n\nEpoch 223: val_accuracy improved from 0.62205 to 0.62230, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6961 - val_accuracy: 0.6223 - val_loss: 1.7168\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.62230\n726/726 - 5s - 7ms/step - accuracy: 0.7987 - loss: 0.6961 - val_accuracy: 0.6223 - val_loss: 1.7158\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.62230\n726/726 - 6s - 8ms/step - accuracy: 0.7986 - loss: 0.6960 - val_accuracy: 0.6223 - val_loss: 1.7204\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.62230\n726/726 - 5s - 8ms/step - accuracy: 0.7987 - loss: 0.6960 - val_accuracy: 0.6223 - val_loss: 1.7183\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.62230\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6959 - val_accuracy: 0.6223 - val_loss: 1.7255\nEpoch 228/500\n\nEpoch 228: val_accuracy improved from 0.62230 to 0.62234, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6958 - val_accuracy: 0.6223 - val_loss: 1.7195\nEpoch 229/500\n\nEpoch 229: val_accuracy improved from 0.62234 to 0.62234, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6958 - val_accuracy: 0.6223 - val_loss: 1.7186\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6957 - val_accuracy: 0.6223 - val_loss: 1.7185\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6957 - val_accuracy: 0.6223 - val_loss: 1.7205\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6956 - val_accuracy: 0.6223 - val_loss: 1.7165\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6956 - val_accuracy: 0.6223 - val_loss: 1.7176\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6955 - val_accuracy: 0.6223 - val_loss: 1.7183\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6955 - val_accuracy: 0.6223 - val_loss: 1.7174\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7987 - loss: 0.6954 - val_accuracy: 0.6223 - val_loss: 1.7167\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6953 - val_accuracy: 0.6223 - val_loss: 1.7170\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.62234\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6953 - val_accuracy: 0.6223 - val_loss: 1.7226\nEpoch 239/500\n\nEpoch 239: val_accuracy improved from 0.62234 to 0.62257, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6952 - val_accuracy: 0.6226 - val_loss: 1.7175\nEpoch 240/500\n\nEpoch 240: val_accuracy improved from 0.62257 to 0.62257, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6952 - val_accuracy: 0.6226 - val_loss: 1.7194\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.62257\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6951 - val_accuracy: 0.6226 - val_loss: 1.7150\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.62257\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6951 - val_accuracy: 0.6226 - val_loss: 1.7139\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.62257\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6950 - val_accuracy: 0.6226 - val_loss: 1.7188\nEpoch 244/500\n\nEpoch 244: val_accuracy improved from 0.62257 to 0.62258, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6950 - val_accuracy: 0.6226 - val_loss: 1.7146\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7989 - loss: 0.6949 - val_accuracy: 0.6226 - val_loss: 1.7201\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6948 - val_accuracy: 0.6226 - val_loss: 1.7133\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.62258\n726/726 - 5s - 8ms/step - accuracy: 0.7988 - loss: 0.6948 - val_accuracy: 0.6226 - val_loss: 1.7170\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6947 - val_accuracy: 0.6226 - val_loss: 1.7139\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6947 - val_accuracy: 0.6226 - val_loss: 1.7211\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6946 - val_accuracy: 0.6226 - val_loss: 1.7163\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6946 - val_accuracy: 0.6226 - val_loss: 1.7177\nEpoch 252/500\n\nEpoch 252: val_accuracy improved from 0.62258 to 0.62258, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6945 - val_accuracy: 0.6226 - val_loss: 1.7151\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.62258\n726/726 - 5s - 8ms/step - accuracy: 0.7988 - loss: 0.6945 - val_accuracy: 0.6226 - val_loss: 1.7145\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6944 - val_accuracy: 0.6197 - val_loss: 1.7220\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6944 - val_accuracy: 0.6226 - val_loss: 1.7210\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.62258\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6943 - val_accuracy: 0.6226 - val_loss: 1.7214\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.62258\n726/726 - 5s - 8ms/step - accuracy: 0.7988 - loss: 0.6943 - val_accuracy: 0.6226 - val_loss: 1.7186\nEpoch 258/500\n\nEpoch 258: val_accuracy improved from 0.62258 to 0.62286, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6942 - val_accuracy: 0.6229 - val_loss: 1.7188\nEpoch 259/500\n\nEpoch 259: val_accuracy improved from 0.62286 to 0.62287, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6942 - val_accuracy: 0.6229 - val_loss: 1.7139\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6941 - val_accuracy: 0.6229 - val_loss: 1.7244\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6941 - val_accuracy: 0.6229 - val_loss: 1.7212\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6940 - val_accuracy: 0.6229 - val_loss: 1.7212\nEpoch 263/500\n\nEpoch 263: val_accuracy improved from 0.62287 to 0.62287, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6940 - val_accuracy: 0.6229 - val_loss: 1.7190\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6939 - val_accuracy: 0.6229 - val_loss: 1.7200\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6939 - val_accuracy: 0.6199 - val_loss: 1.7211\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6938 - val_accuracy: 0.6229 - val_loss: 1.7195\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.62287\n726/726 - 5s - 8ms/step - accuracy: 0.7989 - loss: 0.6938 - val_accuracy: 0.6198 - val_loss: 1.7254\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.62287\n726/726 - 5s - 7ms/step - accuracy: 0.7988 - loss: 0.6937 - val_accuracy: 0.6200 - val_loss: 1.7182\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6937 - val_accuracy: 0.6199 - val_loss: 1.7242\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6936 - val_accuracy: 0.6199 - val_loss: 1.7196\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6936 - val_accuracy: 0.6199 - val_loss: 1.7238\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6935 - val_accuracy: 0.6199 - val_loss: 1.7230\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6935 - val_accuracy: 0.6200 - val_loss: 1.7216\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6934 - val_accuracy: 0.6199 - val_loss: 1.7223\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7988 - loss: 0.6934 - val_accuracy: 0.6199 - val_loss: 1.7226\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.6933 - val_accuracy: 0.6199 - val_loss: 1.7226\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7990 - loss: 0.6933 - val_accuracy: 0.6199 - val_loss: 1.7172\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.6932 - val_accuracy: 0.6199 - val_loss: 1.7180\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7991 - loss: 0.6932 - val_accuracy: 0.6199 - val_loss: 1.7221\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6931 - val_accuracy: 0.6199 - val_loss: 1.7227\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.62287\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.6931 - val_accuracy: 0.6197 - val_loss: 1.7245\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6930 - val_accuracy: 0.6197 - val_loss: 1.7213\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6930 - val_accuracy: 0.6199 - val_loss: 1.7203\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.62287\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.6929 - val_accuracy: 0.6199 - val_loss: 1.7224\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6929 - val_accuracy: 0.6199 - val_loss: 1.7206\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6928 - val_accuracy: 0.6199 - val_loss: 1.7203\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6928 - val_accuracy: 0.6197 - val_loss: 1.7220\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6927 - val_accuracy: 0.6197 - val_loss: 1.7215\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.62287\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6927 - val_accuracy: 0.6197 - val_loss: 1.7223\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6926 - val_accuracy: 0.6197 - val_loss: 1.7229\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6926 - val_accuracy: 0.6197 - val_loss: 1.7190\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6926 - val_accuracy: 0.6197 - val_loss: 1.7219\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6925 - val_accuracy: 0.6197 - val_loss: 1.7229\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6925 - val_accuracy: 0.6197 - val_loss: 1.7195\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6924 - val_accuracy: 0.6197 - val_loss: 1.7198\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6924 - val_accuracy: 0.6197 - val_loss: 1.7218\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6923 - val_accuracy: 0.6196 - val_loss: 1.7238\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6923 - val_accuracy: 0.6196 - val_loss: 1.7273\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6922 - val_accuracy: 0.6196 - val_loss: 1.7232\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6922 - val_accuracy: 0.6196 - val_loss: 1.7248\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6921 - val_accuracy: 0.6196 - val_loss: 1.7228\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6921 - val_accuracy: 0.6197 - val_loss: 1.7201\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6921 - val_accuracy: 0.6196 - val_loss: 1.7236\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6920 - val_accuracy: 0.6196 - val_loss: 1.7195\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6920 - val_accuracy: 0.6196 - val_loss: 1.7247\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6919 - val_accuracy: 0.6197 - val_loss: 1.7196\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6919 - val_accuracy: 0.6197 - val_loss: 1.7241\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6918 - val_accuracy: 0.6197 - val_loss: 1.7182\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6918 - val_accuracy: 0.6197 - val_loss: 1.7181\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.62287\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.6917 - val_accuracy: 0.6197 - val_loss: 1.7215\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6917 - val_accuracy: 0.6197 - val_loss: 1.7269\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6917 - val_accuracy: 0.6197 - val_loss: 1.7262\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6916 - val_accuracy: 0.6197 - val_loss: 1.7269\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6916 - val_accuracy: 0.6203 - val_loss: 1.7230\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6915 - val_accuracy: 0.6203 - val_loss: 1.7204\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6915 - val_accuracy: 0.6203 - val_loss: 1.7236\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6914 - val_accuracy: 0.6203 - val_loss: 1.7261\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6914 - val_accuracy: 0.6203 - val_loss: 1.7282\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6914 - val_accuracy: 0.6203 - val_loss: 1.7263\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6913 - val_accuracy: 0.6203 - val_loss: 1.7307\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6913 - val_accuracy: 0.6203 - val_loss: 1.7268\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6912 - val_accuracy: 0.6203 - val_loss: 1.7243\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6912 - val_accuracy: 0.6203 - val_loss: 1.7228\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6911 - val_accuracy: 0.6203 - val_loss: 1.7231\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6911 - val_accuracy: 0.6207 - val_loss: 1.7210\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6911 - val_accuracy: 0.6203 - val_loss: 1.7291\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6910 - val_accuracy: 0.6203 - val_loss: 1.7238\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6910 - val_accuracy: 0.6203 - val_loss: 1.7255\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6909 - val_accuracy: 0.6207 - val_loss: 1.7254\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6909 - val_accuracy: 0.6207 - val_loss: 1.7242\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6909 - val_accuracy: 0.6207 - val_loss: 1.7232\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.62287\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6908 - val_accuracy: 0.6203 - val_loss: 1.7272\nEpoch 333/500\n\nEpoch 333: val_accuracy improved from 0.62287 to 0.62489, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6908 - val_accuracy: 0.6249 - val_loss: 1.7227\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6907 - val_accuracy: 0.6207 - val_loss: 1.7263\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6907 - val_accuracy: 0.6207 - val_loss: 1.7287\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6906 - val_accuracy: 0.6249 - val_loss: 1.7300\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6906 - val_accuracy: 0.6249 - val_loss: 1.7264\nEpoch 338/500\n\nEpoch 338: val_accuracy improved from 0.62489 to 0.62489, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6906 - val_accuracy: 0.6249 - val_loss: 1.7241\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6905 - val_accuracy: 0.6249 - val_loss: 1.7231\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6905 - val_accuracy: 0.6249 - val_loss: 1.7294\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6904 - val_accuracy: 0.6245 - val_loss: 1.7303\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.62489\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6904 - val_accuracy: 0.6207 - val_loss: 1.7282\nEpoch 343/500\n\nEpoch 343: val_accuracy improved from 0.62489 to 0.62508, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6904 - val_accuracy: 0.6251 - val_loss: 1.7239\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6903 - val_accuracy: 0.6249 - val_loss: 1.7291\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6903 - val_accuracy: 0.6249 - val_loss: 1.7281\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6902 - val_accuracy: 0.6249 - val_loss: 1.7334\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6902 - val_accuracy: 0.6249 - val_loss: 1.7254\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6902 - val_accuracy: 0.6249 - val_loss: 1.7305\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6901 - val_accuracy: 0.6249 - val_loss: 1.7286\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6901 - val_accuracy: 0.6249 - val_loss: 1.7306\nEpoch 351/500\n\nEpoch 351: val_accuracy improved from 0.62508 to 0.62508, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6901 - val_accuracy: 0.6251 - val_loss: 1.7292\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.62508\n726/726 - 5s - 8ms/step - accuracy: 0.7993 - loss: 0.6900 - val_accuracy: 0.6249 - val_loss: 1.7313\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.62508\n726/726 - 5s - 8ms/step - accuracy: 0.7993 - loss: 0.6900 - val_accuracy: 0.6249 - val_loss: 1.7293\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6899 - val_accuracy: 0.6250 - val_loss: 1.7329\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.62508\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6899 - val_accuracy: 0.6249 - val_loss: 1.7302\nEpoch 356/500\n\nEpoch 356: val_accuracy improved from 0.62508 to 0.62509, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6899 - val_accuracy: 0.6251 - val_loss: 1.7231\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6898 - val_accuracy: 0.6248 - val_loss: 1.7347\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6898 - val_accuracy: 0.6250 - val_loss: 1.7315\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6897 - val_accuracy: 0.6250 - val_loss: 1.7328\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6897 - val_accuracy: 0.6250 - val_loss: 1.7312\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6897 - val_accuracy: 0.6250 - val_loss: 1.7279\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6896 - val_accuracy: 0.6250 - val_loss: 1.7266\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6896 - val_accuracy: 0.6250 - val_loss: 1.7312\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6896 - val_accuracy: 0.6250 - val_loss: 1.7339\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6895 - val_accuracy: 0.6250 - val_loss: 1.7304\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6895 - val_accuracy: 0.6250 - val_loss: 1.7299\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.62509\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6894 - val_accuracy: 0.6250 - val_loss: 1.7340\nEpoch 368/500\n\nEpoch 368: val_accuracy improved from 0.62509 to 0.62525, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6894 - val_accuracy: 0.6253 - val_loss: 1.7303\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.62525\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6894 - val_accuracy: 0.6250 - val_loss: 1.7348\nEpoch 370/500\n\nEpoch 370: val_accuracy improved from 0.62525 to 0.62526, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6893 - val_accuracy: 0.6253 - val_loss: 1.7290\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.62526\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6893 - val_accuracy: 0.6252 - val_loss: 1.7333\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.62526\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6893 - val_accuracy: 0.6253 - val_loss: 1.7286\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.62526\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6892 - val_accuracy: 0.6253 - val_loss: 1.7278\nEpoch 374/500\n\nEpoch 374: val_accuracy improved from 0.62526 to 0.62533, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6892 - val_accuracy: 0.6253 - val_loss: 1.7313\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.62533\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6891 - val_accuracy: 0.6253 - val_loss: 1.7276\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.62533\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6891 - val_accuracy: 0.6253 - val_loss: 1.7271\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.62533\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.6891 - val_accuracy: 0.6253 - val_loss: 1.7287\nEpoch 378/500\n\nEpoch 378: val_accuracy improved from 0.62533 to 0.62534, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6890 - val_accuracy: 0.6253 - val_loss: 1.7290\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.62534\n726/726 - 6s - 8ms/step - accuracy: 0.7993 - loss: 0.6890 - val_accuracy: 0.6253 - val_loss: 1.7341\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.62534\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6890 - val_accuracy: 0.6253 - val_loss: 1.7325\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.62534\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6889 - val_accuracy: 0.6253 - val_loss: 1.7329\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.62534\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6889 - val_accuracy: 0.6253 - val_loss: 1.7317\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.62534\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6889 - val_accuracy: 0.6253 - val_loss: 1.7321\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.62534\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6888 - val_accuracy: 0.6253 - val_loss: 1.7302\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.62534\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6888 - val_accuracy: 0.6253 - val_loss: 1.7327\nEpoch 386/500\n\nEpoch 386: val_accuracy improved from 0.62534 to 0.62535, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 7ms/step - accuracy: 0.7992 - loss: 0.6887 - val_accuracy: 0.6253 - val_loss: 1.7308\nEpoch 387/500\n\nEpoch 387: val_accuracy improved from 0.62535 to 0.62537, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 8ms/step - accuracy: 0.7992 - loss: 0.6887 - val_accuracy: 0.6254 - val_loss: 1.7266\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.62537\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6887 - val_accuracy: 0.6253 - val_loss: 1.7329\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.62537\n726/726 - 5s - 7ms/step - accuracy: 0.7993 - loss: 0.6886 - val_accuracy: 0.6253 - val_loss: 1.7334\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.62537\n726/726 - 5s - 8ms/step - accuracy: 0.7994 - loss: 0.6886 - val_accuracy: 0.6253 - val_loss: 1.7331\nEpoch 391/500\n\nEpoch 391: val_accuracy improved from 0.62537 to 0.62745, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.7992 - loss: 0.6886 - val_accuracy: 0.6274 - val_loss: 1.7320\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.62745\n726/726 - 6s - 8ms/step - accuracy: 0.7997 - loss: 0.6885 - val_accuracy: 0.6253 - val_loss: 1.7363\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.62745\n726/726 - 5s - 8ms/step - accuracy: 0.7999 - loss: 0.6885 - val_accuracy: 0.6253 - val_loss: 1.7313\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.62745\n726/726 - 6s - 8ms/step - accuracy: 0.7997 - loss: 0.6885 - val_accuracy: 0.6274 - val_loss: 1.7317\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.62745\n726/726 - 5s - 8ms/step - accuracy: 0.8004 - loss: 0.6884 - val_accuracy: 0.6253 - val_loss: 1.7336\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.62745\n726/726 - 6s - 8ms/step - accuracy: 0.8004 - loss: 0.6884 - val_accuracy: 0.6274 - val_loss: 1.7352\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.62745\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6884 - val_accuracy: 0.6274 - val_loss: 1.7351\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.62745\n726/726 - 6s - 8ms/step - accuracy: 0.8005 - loss: 0.6883 - val_accuracy: 0.6274 - val_loss: 1.7306\nEpoch 399/500\n\nEpoch 399: val_accuracy improved from 0.62745 to 0.62746, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6883 - val_accuracy: 0.6275 - val_loss: 1.7320\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6882 - val_accuracy: 0.6274 - val_loss: 1.7372\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6882 - val_accuracy: 0.6274 - val_loss: 1.7287\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8006 - loss: 0.6882 - val_accuracy: 0.6274 - val_loss: 1.7377\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6881 - val_accuracy: 0.6273 - val_loss: 1.7393\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6881 - val_accuracy: 0.6273 - val_loss: 1.7321\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6881 - val_accuracy: 0.6273 - val_loss: 1.7414\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6880 - val_accuracy: 0.6273 - val_loss: 1.7341\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6880 - val_accuracy: 0.6273 - val_loss: 1.7368\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8006 - loss: 0.6880 - val_accuracy: 0.6273 - val_loss: 1.7368\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6879 - val_accuracy: 0.6273 - val_loss: 1.7392\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8006 - loss: 0.6879 - val_accuracy: 0.6273 - val_loss: 1.7354\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6879 - val_accuracy: 0.6273 - val_loss: 1.7352\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6878 - val_accuracy: 0.6273 - val_loss: 1.7358\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.6878 - val_accuracy: 0.6273 - val_loss: 1.7362\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8006 - loss: 0.6878 - val_accuracy: 0.6273 - val_loss: 1.7374\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6877 - val_accuracy: 0.6273 - val_loss: 1.7330\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8008 - loss: 0.6877 - val_accuracy: 0.6273 - val_loss: 1.7342\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8008 - loss: 0.6877 - val_accuracy: 0.6272 - val_loss: 1.7345\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8007 - loss: 0.6876 - val_accuracy: 0.6274 - val_loss: 1.7393\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8009 - loss: 0.6876 - val_accuracy: 0.6272 - val_loss: 1.7375\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6876 - val_accuracy: 0.6274 - val_loss: 1.7393\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8010 - loss: 0.6875 - val_accuracy: 0.6273 - val_loss: 1.7392\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6875 - val_accuracy: 0.6273 - val_loss: 1.7402\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6875 - val_accuracy: 0.6273 - val_loss: 1.7392\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6874 - val_accuracy: 0.6273 - val_loss: 1.7366\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6874 - val_accuracy: 0.6273 - val_loss: 1.7369\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.6874 - val_accuracy: 0.6273 - val_loss: 1.7368\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6873 - val_accuracy: 0.6273 - val_loss: 1.7362\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6873 - val_accuracy: 0.6273 - val_loss: 1.7402\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6873 - val_accuracy: 0.6219 - val_loss: 1.7400\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6872 - val_accuracy: 0.6273 - val_loss: 1.7419\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6872 - val_accuracy: 0.6273 - val_loss: 1.7379\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6872 - val_accuracy: 0.6271 - val_loss: 1.7393\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8012 - loss: 0.6872 - val_accuracy: 0.6273 - val_loss: 1.7408\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6871 - val_accuracy: 0.6269 - val_loss: 1.7421\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6871 - val_accuracy: 0.6269 - val_loss: 1.7398\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6871 - val_accuracy: 0.6213 - val_loss: 1.7450\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6870 - val_accuracy: 0.6271 - val_loss: 1.7414\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8011 - loss: 0.6870 - val_accuracy: 0.6271 - val_loss: 1.7348\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8011 - loss: 0.6870 - val_accuracy: 0.6271 - val_loss: 1.7385\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.6869 - val_accuracy: 0.6271 - val_loss: 1.7386\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6869 - val_accuracy: 0.6271 - val_loss: 1.7412\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6869 - val_accuracy: 0.6271 - val_loss: 1.7384\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8011 - loss: 0.6868 - val_accuracy: 0.6269 - val_loss: 1.7395\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6868 - val_accuracy: 0.6268 - val_loss: 1.7425\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6868 - val_accuracy: 0.6271 - val_loss: 1.7398\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8012 - loss: 0.6867 - val_accuracy: 0.6267 - val_loss: 1.7431\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6867 - val_accuracy: 0.6269 - val_loss: 1.7388\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8014 - loss: 0.6867 - val_accuracy: 0.6268 - val_loss: 1.7406\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6866 - val_accuracy: 0.6267 - val_loss: 1.7395\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8014 - loss: 0.6866 - val_accuracy: 0.6269 - val_loss: 1.7381\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8014 - loss: 0.6866 - val_accuracy: 0.6267 - val_loss: 1.7412\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8014 - loss: 0.6866 - val_accuracy: 0.6265 - val_loss: 1.7422\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8013 - loss: 0.6865 - val_accuracy: 0.6265 - val_loss: 1.7438\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6865 - val_accuracy: 0.6265 - val_loss: 1.7474\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8013 - loss: 0.6865 - val_accuracy: 0.6266 - val_loss: 1.7399\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8014 - loss: 0.6864 - val_accuracy: 0.6265 - val_loss: 1.7443\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8014 - loss: 0.6864 - val_accuracy: 0.6265 - val_loss: 1.7402\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.6864 - val_accuracy: 0.6266 - val_loss: 1.7451\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8016 - loss: 0.6863 - val_accuracy: 0.6211 - val_loss: 1.7435\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8020 - loss: 0.6863 - val_accuracy: 0.6265 - val_loss: 1.7432\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8020 - loss: 0.6863 - val_accuracy: 0.6211 - val_loss: 1.7437\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.6863 - val_accuracy: 0.6266 - val_loss: 1.7475\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8024 - loss: 0.6862 - val_accuracy: 0.6211 - val_loss: 1.7483\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8022 - loss: 0.6862 - val_accuracy: 0.6265 - val_loss: 1.7453\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6862 - val_accuracy: 0.6265 - val_loss: 1.7424\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6861 - val_accuracy: 0.6265 - val_loss: 1.7439\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6861 - val_accuracy: 0.6266 - val_loss: 1.7417\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6861 - val_accuracy: 0.6266 - val_loss: 1.7429\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6860 - val_accuracy: 0.6266 - val_loss: 1.7420\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6860 - val_accuracy: 0.6266 - val_loss: 1.7452\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6860 - val_accuracy: 0.6265 - val_loss: 1.7408\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6860 - val_accuracy: 0.6265 - val_loss: 1.7434\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8025 - loss: 0.6859 - val_accuracy: 0.6266 - val_loss: 1.7404\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6859 - val_accuracy: 0.6265 - val_loss: 1.7403\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6859 - val_accuracy: 0.6265 - val_loss: 1.7432\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6858 - val_accuracy: 0.6265 - val_loss: 1.7415\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6858 - val_accuracy: 0.6210 - val_loss: 1.7476\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6858 - val_accuracy: 0.6266 - val_loss: 1.7411\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6857 - val_accuracy: 0.6266 - val_loss: 1.7467\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6857 - val_accuracy: 0.6211 - val_loss: 1.7441\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6857 - val_accuracy: 0.6266 - val_loss: 1.7421\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8026 - loss: 0.6857 - val_accuracy: 0.6212 - val_loss: 1.7440\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6856 - val_accuracy: 0.6266 - val_loss: 1.7418\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6856 - val_accuracy: 0.6211 - val_loss: 1.7473\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8026 - loss: 0.6856 - val_accuracy: 0.6211 - val_loss: 1.7479\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6855 - val_accuracy: 0.6211 - val_loss: 1.7459\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6855 - val_accuracy: 0.6266 - val_loss: 1.7470\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6855 - val_accuracy: 0.6211 - val_loss: 1.7453\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6855 - val_accuracy: 0.6266 - val_loss: 1.7459\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6854 - val_accuracy: 0.6266 - val_loss: 1.7465\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6854 - val_accuracy: 0.6266 - val_loss: 1.7474\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6854 - val_accuracy: 0.6266 - val_loss: 1.7470\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8027 - loss: 0.6853 - val_accuracy: 0.6266 - val_loss: 1.7509\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6853 - val_accuracy: 0.6265 - val_loss: 1.7492\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6853 - val_accuracy: 0.6266 - val_loss: 1.7462\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6853 - val_accuracy: 0.6211 - val_loss: 1.7524\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6852 - val_accuracy: 0.6211 - val_loss: 1.7532\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8025 - loss: 0.6852 - val_accuracy: 0.6211 - val_loss: 1.7496\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6852 - val_accuracy: 0.6211 - val_loss: 1.7496\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8025 - loss: 0.6851 - val_accuracy: 0.6266 - val_loss: 1.7458\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_22, X_test_22, y_train_22, y_test_22 = train_test_split(\n    X, y, test_size=0.3, random_state=64, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_22, X_val_22, y_train_22, y_val_22 = train_test_split(\n    X_train_22, y_train_22, test_size=0.2, random_state=64, stratify=y_train_22\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_22:\", np.max(X_train_22))\nprint(\"Min value in X_train_22:\", np.min(X_train_22))\n\nX_train_22_scaled = scaler.fit_transform(X_train_22)\n\n# Get the original class distribution\nclass_counts_22 = Counter(y_train_22)\nprint(\"Original class distribution:\", class_counts_22)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_22 = class_counts_22[min(class_counts_22, key=class_counts_22.get)]\ndesired_majority_size_22 = minority_class_size_22 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_22 = {0: desired_majority_size_22, 1: minority_class_size_22}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_22 = RandomUnderSampler(sampling_strategy=sampling_strategy_22, random_state=42)\nX_resampled_22, y_resampled_22 = undersampler_22.fit_resample(X_train_22, y_train_22)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_22))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_22, y_train_resampled_22 = smote.fit_resample(X_resampled_22, y_resampled_22)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_22))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_22))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T14:24:36.529188Z","iopub.execute_input":"2025-03-07T14:24:36.529520Z","iopub.status.idle":"2025-03-07T14:25:18.045867Z","shell.execute_reply.started":"2025-03-07T14:24:36.529490Z","shell.execute_reply":"2025-03-07T14:25:18.044708Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_22: 2071000000.0\nMin value in X_train_22: -6442447920.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_22 = X_train_resampled_22.reshape(X_train_resampled_22.shape[0], 1, 56)\nX_val_22 = X_val_22.reshape(X_val_22.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_22,  # Features from CICIDS2017\n    y_train_resampled_22,  # Labels from CICIDS2017\n    validation_data=(X_val_22, y_val_22),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T14:25:18.047313Z","iopub.execute_input":"2025-03-07T14:25:18.047839Z","iopub.status.idle":"2025-03-07T15:12:40.264179Z","shell.execute_reply.started":"2025-03-07T14:25:18.047792Z","shell.execute_reply":"2025-03-07T15:12:40.261877Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.7957 - loss: 0.6776 - val_accuracy: 0.5759 - val_loss: 1.7128\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.7953 - loss: 0.6712 - val_accuracy: 0.5748 - val_loss: 1.7350\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.7971 - loss: 0.6684 - val_accuracy: 0.5748 - val_loss: 1.7452\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.7983 - loss: 0.6666 - val_accuracy: 0.5761 - val_loss: 1.7547\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8012 - loss: 0.6651 - val_accuracy: 0.5762 - val_loss: 1.7655\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8013 - loss: 0.6639 - val_accuracy: 0.5749 - val_loss: 1.7737\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8013 - loss: 0.6629 - val_accuracy: 0.5733 - val_loss: 1.7817\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8034 - loss: 0.6620 - val_accuracy: 0.5728 - val_loss: 1.7908\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6612 - val_accuracy: 0.5722 - val_loss: 1.7969\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6605 - val_accuracy: 0.5717 - val_loss: 1.8006\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.6598 - val_accuracy: 0.5717 - val_loss: 1.8042\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8024 - loss: 0.6592 - val_accuracy: 0.5717 - val_loss: 1.8075\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8023 - loss: 0.6586 - val_accuracy: 0.5716 - val_loss: 1.8159\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8028 - loss: 0.6581 - val_accuracy: 0.5718 - val_loss: 1.8149\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8027 - loss: 0.6576 - val_accuracy: 0.5718 - val_loss: 1.8189\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8033 - loss: 0.6571 - val_accuracy: 0.5713 - val_loss: 1.8270\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8044 - loss: 0.6567 - val_accuracy: 0.5709 - val_loss: 1.8318\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8092 - loss: 0.6562 - val_accuracy: 0.5716 - val_loss: 1.8249\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8092 - loss: 0.6558 - val_accuracy: 0.5715 - val_loss: 1.8281\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8091 - loss: 0.6555 - val_accuracy: 0.5712 - val_loss: 1.8325\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8102 - loss: 0.6551 - val_accuracy: 0.5713 - val_loss: 1.8366\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8091 - loss: 0.6547 - val_accuracy: 0.5715 - val_loss: 1.8339\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8094 - loss: 0.6544 - val_accuracy: 0.5712 - val_loss: 1.8379\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8096 - loss: 0.6541 - val_accuracy: 0.5713 - val_loss: 1.8371\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8094 - loss: 0.6537 - val_accuracy: 0.5715 - val_loss: 1.8375\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8100 - loss: 0.6534 - val_accuracy: 0.5715 - val_loss: 1.8364\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8097 - loss: 0.6531 - val_accuracy: 0.5715 - val_loss: 1.8400\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8098 - loss: 0.6528 - val_accuracy: 0.5722 - val_loss: 1.8422\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8092 - loss: 0.6526 - val_accuracy: 0.5721 - val_loss: 1.8395\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8098 - loss: 0.6523 - val_accuracy: 0.5724 - val_loss: 1.8409\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8095 - loss: 0.6520 - val_accuracy: 0.5724 - val_loss: 1.8391\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8094 - loss: 0.6518 - val_accuracy: 0.5724 - val_loss: 1.8415\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8091 - loss: 0.6515 - val_accuracy: 0.5725 - val_loss: 1.8417\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.6513 - val_accuracy: 0.5725 - val_loss: 1.8404\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8093 - loss: 0.6510 - val_accuracy: 0.5724 - val_loss: 1.8416\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8100 - loss: 0.6508 - val_accuracy: 0.5724 - val_loss: 1.8437\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8096 - loss: 0.6505 - val_accuracy: 0.5724 - val_loss: 1.8418\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8103 - loss: 0.6503 - val_accuracy: 0.5724 - val_loss: 1.8455\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8096 - loss: 0.6501 - val_accuracy: 0.5724 - val_loss: 1.8459\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.6499 - val_accuracy: 0.5725 - val_loss: 1.8442\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8103 - loss: 0.6497 - val_accuracy: 0.5725 - val_loss: 1.8431\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8103 - loss: 0.6495 - val_accuracy: 0.5725 - val_loss: 1.8448\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8107 - loss: 0.6493 - val_accuracy: 0.5725 - val_loss: 1.8413\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8097 - loss: 0.6491 - val_accuracy: 0.5726 - val_loss: 1.8385\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.6489 - val_accuracy: 0.5726 - val_loss: 1.8395\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8098 - loss: 0.6487 - val_accuracy: 0.5726 - val_loss: 1.8400\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6485 - val_accuracy: 0.5725 - val_loss: 1.8435\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8103 - loss: 0.6484 - val_accuracy: 0.5725 - val_loss: 1.8437\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.6482 - val_accuracy: 0.5725 - val_loss: 1.8441\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8106 - loss: 0.6480 - val_accuracy: 0.5725 - val_loss: 1.8429\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8100 - loss: 0.6478 - val_accuracy: 0.5725 - val_loss: 1.8431\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8105 - loss: 0.6477 - val_accuracy: 0.5727 - val_loss: 1.8443\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8103 - loss: 0.6475 - val_accuracy: 0.5727 - val_loss: 1.8419\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6473 - val_accuracy: 0.5727 - val_loss: 1.8433\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8105 - loss: 0.6472 - val_accuracy: 0.5736 - val_loss: 1.8433\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8116 - loss: 0.6470 - val_accuracy: 0.5735 - val_loss: 1.8434\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.6469 - val_accuracy: 0.5736 - val_loss: 1.8455\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8110 - loss: 0.6467 - val_accuracy: 0.5735 - val_loss: 1.8446\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8114 - loss: 0.6466 - val_accuracy: 0.5735 - val_loss: 1.8441\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8106 - loss: 0.6464 - val_accuracy: 0.5735 - val_loss: 1.8408\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8113 - loss: 0.6463 - val_accuracy: 0.5704 - val_loss: 1.8434\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8121 - loss: 0.6461 - val_accuracy: 0.5705 - val_loss: 1.8411\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8124 - loss: 0.6460 - val_accuracy: 0.5705 - val_loss: 1.8440\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8121 - loss: 0.6459 - val_accuracy: 0.5705 - val_loss: 1.8420\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6457 - val_accuracy: 0.5706 - val_loss: 1.8431\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8128 - loss: 0.6456 - val_accuracy: 0.5705 - val_loss: 1.8436\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8126 - loss: 0.6455 - val_accuracy: 0.5706 - val_loss: 1.8452\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.62746\n726/726 - 8s - 11ms/step - accuracy: 0.8136 - loss: 0.6453 - val_accuracy: 0.5705 - val_loss: 1.8428\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8128 - loss: 0.6452 - val_accuracy: 0.5706 - val_loss: 1.8452\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6451 - val_accuracy: 0.5705 - val_loss: 1.8447\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8125 - loss: 0.6449 - val_accuracy: 0.5705 - val_loss: 1.8453\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8129 - loss: 0.6448 - val_accuracy: 0.5706 - val_loss: 1.8437\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8131 - loss: 0.6447 - val_accuracy: 0.5706 - val_loss: 1.8426\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8131 - loss: 0.6446 - val_accuracy: 0.5705 - val_loss: 1.8437\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8134 - loss: 0.6444 - val_accuracy: 0.5706 - val_loss: 1.8440\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8125 - loss: 0.6443 - val_accuracy: 0.5706 - val_loss: 1.8474\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8134 - loss: 0.6442 - val_accuracy: 0.5706 - val_loss: 1.8461\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8132 - loss: 0.6441 - val_accuracy: 0.5705 - val_loss: 1.8437\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8136 - loss: 0.6440 - val_accuracy: 0.5705 - val_loss: 1.8442\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8130 - loss: 0.6438 - val_accuracy: 0.5707 - val_loss: 1.8398\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8134 - loss: 0.6437 - val_accuracy: 0.5705 - val_loss: 1.8464\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8132 - loss: 0.6436 - val_accuracy: 0.5707 - val_loss: 1.8424\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6435 - val_accuracy: 0.5706 - val_loss: 1.8431\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6434 - val_accuracy: 0.5706 - val_loss: 1.8407\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8123 - loss: 0.6433 - val_accuracy: 0.5707 - val_loss: 1.8455\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6432 - val_accuracy: 0.5706 - val_loss: 1.8447\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8124 - loss: 0.6431 - val_accuracy: 0.5706 - val_loss: 1.8446\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8135 - loss: 0.6430 - val_accuracy: 0.5707 - val_loss: 1.8444\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8135 - loss: 0.6429 - val_accuracy: 0.5709 - val_loss: 1.8442\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8136 - loss: 0.6428 - val_accuracy: 0.5696 - val_loss: 1.8435\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6426 - val_accuracy: 0.5706 - val_loss: 1.8450\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8135 - loss: 0.6425 - val_accuracy: 0.5708 - val_loss: 1.8427\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8135 - loss: 0.6424 - val_accuracy: 0.5708 - val_loss: 1.8441\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8131 - loss: 0.6423 - val_accuracy: 0.5697 - val_loss: 1.8415\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6422 - val_accuracy: 0.5696 - val_loss: 1.8456\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8133 - loss: 0.6421 - val_accuracy: 0.5696 - val_loss: 1.8440\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6420 - val_accuracy: 0.5708 - val_loss: 1.8426\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8134 - loss: 0.6419 - val_accuracy: 0.5699 - val_loss: 1.8439\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6418 - val_accuracy: 0.5697 - val_loss: 1.8443\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8132 - loss: 0.6417 - val_accuracy: 0.5711 - val_loss: 1.8417\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6416 - val_accuracy: 0.5710 - val_loss: 1.8417\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6415 - val_accuracy: 0.5697 - val_loss: 1.8479\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8133 - loss: 0.6414 - val_accuracy: 0.5698 - val_loss: 1.8427\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8132 - loss: 0.6413 - val_accuracy: 0.5699 - val_loss: 1.8438\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8139 - loss: 0.6412 - val_accuracy: 0.5699 - val_loss: 1.8398\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6412 - val_accuracy: 0.5698 - val_loss: 1.8456\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8136 - loss: 0.6411 - val_accuracy: 0.5698 - val_loss: 1.8396\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8134 - loss: 0.6410 - val_accuracy: 0.5698 - val_loss: 1.8470\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6409 - val_accuracy: 0.5699 - val_loss: 1.8467\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6408 - val_accuracy: 0.5698 - val_loss: 1.8427\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8131 - loss: 0.6407 - val_accuracy: 0.5697 - val_loss: 1.8432\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8132 - loss: 0.6406 - val_accuracy: 0.5699 - val_loss: 1.8438\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8145 - loss: 0.6405 - val_accuracy: 0.5698 - val_loss: 1.8420\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8132 - loss: 0.6404 - val_accuracy: 0.5699 - val_loss: 1.8432\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6403 - val_accuracy: 0.5699 - val_loss: 1.8411\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6402 - val_accuracy: 0.5698 - val_loss: 1.8443\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6401 - val_accuracy: 0.5699 - val_loss: 1.8470\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6401 - val_accuracy: 0.5700 - val_loss: 1.8435\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6400 - val_accuracy: 0.5699 - val_loss: 1.8460\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6399 - val_accuracy: 0.5699 - val_loss: 1.8458\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6398 - val_accuracy: 0.5699 - val_loss: 1.8398\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6397 - val_accuracy: 0.5700 - val_loss: 1.8421\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6396 - val_accuracy: 0.5699 - val_loss: 1.8422\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6395 - val_accuracy: 0.5699 - val_loss: 1.8458\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6395 - val_accuracy: 0.5698 - val_loss: 1.8513\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6394 - val_accuracy: 0.5700 - val_loss: 1.8461\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6393 - val_accuracy: 0.5700 - val_loss: 1.8421\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6392 - val_accuracy: 0.5700 - val_loss: 1.8482\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6391 - val_accuracy: 0.5701 - val_loss: 1.8457\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6390 - val_accuracy: 0.5702 - val_loss: 1.8411\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8159 - loss: 0.6390 - val_accuracy: 0.5700 - val_loss: 1.8469\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6389 - val_accuracy: 0.5700 - val_loss: 1.8475\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6388 - val_accuracy: 0.5700 - val_loss: 1.8454\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6387 - val_accuracy: 0.5701 - val_loss: 1.8445\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6386 - val_accuracy: 0.5701 - val_loss: 1.8469\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6386 - val_accuracy: 0.5699 - val_loss: 1.8460\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8158 - loss: 0.6385 - val_accuracy: 0.5699 - val_loss: 1.8463\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6384 - val_accuracy: 0.5700 - val_loss: 1.8451\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6383 - val_accuracy: 0.5699 - val_loss: 1.8465\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6382 - val_accuracy: 0.5698 - val_loss: 1.8450\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8156 - loss: 0.6382 - val_accuracy: 0.5700 - val_loss: 1.8442\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6381 - val_accuracy: 0.5699 - val_loss: 1.8482\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6380 - val_accuracy: 0.5698 - val_loss: 1.8483\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6379 - val_accuracy: 0.5698 - val_loss: 1.8447\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6379 - val_accuracy: 0.5698 - val_loss: 1.8480\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6378 - val_accuracy: 0.5699 - val_loss: 1.8453\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6377 - val_accuracy: 0.5698 - val_loss: 1.8479\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6376 - val_accuracy: 0.5698 - val_loss: 1.8490\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6376 - val_accuracy: 0.5700 - val_loss: 1.8455\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8160 - loss: 0.6375 - val_accuracy: 0.5700 - val_loss: 1.8476\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6374 - val_accuracy: 0.5699 - val_loss: 1.8477\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6373 - val_accuracy: 0.5711 - val_loss: 1.8450\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8160 - loss: 0.6373 - val_accuracy: 0.5698 - val_loss: 1.8472\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8154 - loss: 0.6372 - val_accuracy: 0.5711 - val_loss: 1.8467\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8165 - loss: 0.6371 - val_accuracy: 0.5698 - val_loss: 1.8461\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8155 - loss: 0.6371 - val_accuracy: 0.5711 - val_loss: 1.8452\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8159 - loss: 0.6370 - val_accuracy: 0.5711 - val_loss: 1.8467\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8155 - loss: 0.6369 - val_accuracy: 0.5712 - val_loss: 1.8499\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8168 - loss: 0.6368 - val_accuracy: 0.5711 - val_loss: 1.8476\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8150 - loss: 0.6368 - val_accuracy: 0.5712 - val_loss: 1.8486\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8169 - loss: 0.6367 - val_accuracy: 0.5713 - val_loss: 1.8455\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8157 - loss: 0.6366 - val_accuracy: 0.5713 - val_loss: 1.8466\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8154 - loss: 0.6366 - val_accuracy: 0.5714 - val_loss: 1.8446\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8163 - loss: 0.6365 - val_accuracy: 0.5713 - val_loss: 1.8469\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6364 - val_accuracy: 0.5714 - val_loss: 1.8491\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8167 - loss: 0.6364 - val_accuracy: 0.5711 - val_loss: 1.8492\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8156 - loss: 0.6363 - val_accuracy: 0.5713 - val_loss: 1.8481\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8155 - loss: 0.6362 - val_accuracy: 0.5713 - val_loss: 1.8469\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8153 - loss: 0.6362 - val_accuracy: 0.5714 - val_loss: 1.8504\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8162 - loss: 0.6361 - val_accuracy: 0.5714 - val_loss: 1.8497\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6360 - val_accuracy: 0.5713 - val_loss: 1.8499\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6360 - val_accuracy: 0.5715 - val_loss: 1.8492\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8155 - loss: 0.6359 - val_accuracy: 0.5714 - val_loss: 1.8467\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6358 - val_accuracy: 0.5714 - val_loss: 1.8491\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8158 - loss: 0.6358 - val_accuracy: 0.5714 - val_loss: 1.8486\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8151 - loss: 0.6357 - val_accuracy: 0.5716 - val_loss: 1.8479\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8157 - loss: 0.6356 - val_accuracy: 0.5715 - val_loss: 1.8508\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8151 - loss: 0.6356 - val_accuracy: 0.5714 - val_loss: 1.8514\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6355 - val_accuracy: 0.5716 - val_loss: 1.8450\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8148 - loss: 0.6354 - val_accuracy: 0.5716 - val_loss: 1.8474\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8156 - loss: 0.6354 - val_accuracy: 0.5715 - val_loss: 1.8546\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6353 - val_accuracy: 0.5716 - val_loss: 1.8506\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6352 - val_accuracy: 0.5716 - val_loss: 1.8480\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8156 - loss: 0.6352 - val_accuracy: 0.5715 - val_loss: 1.8483\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8151 - loss: 0.6351 - val_accuracy: 0.5715 - val_loss: 1.8514\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6351 - val_accuracy: 0.5715 - val_loss: 1.8502\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6350 - val_accuracy: 0.5716 - val_loss: 1.8493\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6349 - val_accuracy: 0.5715 - val_loss: 1.8514\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6349 - val_accuracy: 0.5716 - val_loss: 1.8499\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6348 - val_accuracy: 0.5716 - val_loss: 1.8527\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8156 - loss: 0.6347 - val_accuracy: 0.5715 - val_loss: 1.8496\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6347 - val_accuracy: 0.5715 - val_loss: 1.8511\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6346 - val_accuracy: 0.5716 - val_loss: 1.8513\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8158 - loss: 0.6346 - val_accuracy: 0.5715 - val_loss: 1.8510\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8143 - loss: 0.6345 - val_accuracy: 0.5715 - val_loss: 1.8467\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6344 - val_accuracy: 0.5716 - val_loss: 1.8528\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6344 - val_accuracy: 0.5716 - val_loss: 1.8496\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8149 - loss: 0.6343 - val_accuracy: 0.5715 - val_loss: 1.8498\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6343 - val_accuracy: 0.5716 - val_loss: 1.8479\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8160 - loss: 0.6342 - val_accuracy: 0.5729 - val_loss: 1.8477\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8149 - loss: 0.6341 - val_accuracy: 0.5717 - val_loss: 1.8526\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6341 - val_accuracy: 0.5730 - val_loss: 1.8463\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8158 - loss: 0.6340 - val_accuracy: 0.5715 - val_loss: 1.8531\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6340 - val_accuracy: 0.5730 - val_loss: 1.8494\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6339 - val_accuracy: 0.5716 - val_loss: 1.8529\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6339 - val_accuracy: 0.5716 - val_loss: 1.8541\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6338 - val_accuracy: 0.5733 - val_loss: 1.8493\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6337 - val_accuracy: 0.5732 - val_loss: 1.8505\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6337 - val_accuracy: 0.5716 - val_loss: 1.8539\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6336 - val_accuracy: 0.5732 - val_loss: 1.8518\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6336 - val_accuracy: 0.5733 - val_loss: 1.8521\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6335 - val_accuracy: 0.5734 - val_loss: 1.8485\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6335 - val_accuracy: 0.5732 - val_loss: 1.8522\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6334 - val_accuracy: 0.5732 - val_loss: 1.8518\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6333 - val_accuracy: 0.5732 - val_loss: 1.8520\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6333 - val_accuracy: 0.5732 - val_loss: 1.8555\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6332 - val_accuracy: 0.5733 - val_loss: 1.8517\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6332 - val_accuracy: 0.5733 - val_loss: 1.8517\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8150 - loss: 0.6331 - val_accuracy: 0.5732 - val_loss: 1.8559\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8150 - loss: 0.6331 - val_accuracy: 0.5732 - val_loss: 1.8521\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6330 - val_accuracy: 0.5727 - val_loss: 1.8545\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8154 - loss: 0.6330 - val_accuracy: 0.5734 - val_loss: 1.8522\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8157 - loss: 0.6329 - val_accuracy: 0.5732 - val_loss: 1.8554\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6329 - val_accuracy: 0.5726 - val_loss: 1.8591\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6328 - val_accuracy: 0.5732 - val_loss: 1.8531\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8140 - loss: 0.6328 - val_accuracy: 0.5727 - val_loss: 1.8540\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8154 - loss: 0.6327 - val_accuracy: 0.5726 - val_loss: 1.8558\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6327 - val_accuracy: 0.5728 - val_loss: 1.8562\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6326 - val_accuracy: 0.5727 - val_loss: 1.8568\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8149 - loss: 0.6325 - val_accuracy: 0.5726 - val_loss: 1.8562\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8148 - loss: 0.6325 - val_accuracy: 0.5727 - val_loss: 1.8563\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8153 - loss: 0.6324 - val_accuracy: 0.5726 - val_loss: 1.8529\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8144 - loss: 0.6324 - val_accuracy: 0.5727 - val_loss: 1.8568\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6323 - val_accuracy: 0.5726 - val_loss: 1.8569\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6323 - val_accuracy: 0.5726 - val_loss: 1.8553\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8156 - loss: 0.6322 - val_accuracy: 0.5726 - val_loss: 1.8546\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8144 - loss: 0.6322 - val_accuracy: 0.5727 - val_loss: 1.8558\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8145 - loss: 0.6321 - val_accuracy: 0.5726 - val_loss: 1.8541\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8145 - loss: 0.6321 - val_accuracy: 0.5726 - val_loss: 1.8583\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6320 - val_accuracy: 0.5726 - val_loss: 1.8524\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8150 - loss: 0.6320 - val_accuracy: 0.5723 - val_loss: 1.8554\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8148 - loss: 0.6319 - val_accuracy: 0.5723 - val_loss: 1.8547\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8145 - loss: 0.6319 - val_accuracy: 0.5723 - val_loss: 1.8575\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8149 - loss: 0.6318 - val_accuracy: 0.5725 - val_loss: 1.8549\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8152 - loss: 0.6318 - val_accuracy: 0.5723 - val_loss: 1.8570\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6317 - val_accuracy: 0.5723 - val_loss: 1.8552\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6317 - val_accuracy: 0.5723 - val_loss: 1.8576\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8135 - loss: 0.6316 - val_accuracy: 0.5724 - val_loss: 1.8564\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8145 - loss: 0.6316 - val_accuracy: 0.5725 - val_loss: 1.8533\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8157 - loss: 0.6315 - val_accuracy: 0.5723 - val_loss: 1.8544\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6315 - val_accuracy: 0.5723 - val_loss: 1.8593\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6314 - val_accuracy: 0.5721 - val_loss: 1.8588\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8154 - loss: 0.6314 - val_accuracy: 0.5721 - val_loss: 1.8574\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8140 - loss: 0.6313 - val_accuracy: 0.5723 - val_loss: 1.8572\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6313 - val_accuracy: 0.5722 - val_loss: 1.8587\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6313 - val_accuracy: 0.5723 - val_loss: 1.8547\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6312 - val_accuracy: 0.5721 - val_loss: 1.8566\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6312 - val_accuracy: 0.5721 - val_loss: 1.8585\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8140 - loss: 0.6311 - val_accuracy: 0.5722 - val_loss: 1.8587\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8148 - loss: 0.6311 - val_accuracy: 0.5721 - val_loss: 1.8535\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8145 - loss: 0.6310 - val_accuracy: 0.5721 - val_loss: 1.8568\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8142 - loss: 0.6310 - val_accuracy: 0.5721 - val_loss: 1.8568\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8138 - loss: 0.6309 - val_accuracy: 0.5722 - val_loss: 1.8623\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6309 - val_accuracy: 0.5721 - val_loss: 1.8591\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6308 - val_accuracy: 0.5721 - val_loss: 1.8581\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8137 - loss: 0.6308 - val_accuracy: 0.5721 - val_loss: 1.8541\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8135 - loss: 0.6307 - val_accuracy: 0.5722 - val_loss: 1.8604\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8152 - loss: 0.6307 - val_accuracy: 0.5721 - val_loss: 1.8561\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6306 - val_accuracy: 0.5721 - val_loss: 1.8564\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8134 - loss: 0.6306 - val_accuracy: 0.5721 - val_loss: 1.8541\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8148 - loss: 0.6306 - val_accuracy: 0.5721 - val_loss: 1.8563\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8145 - loss: 0.6305 - val_accuracy: 0.5721 - val_loss: 1.8587\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8144 - loss: 0.6305 - val_accuracy: 0.5721 - val_loss: 1.8577\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8145 - loss: 0.6304 - val_accuracy: 0.5721 - val_loss: 1.8584\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8138 - loss: 0.6304 - val_accuracy: 0.5721 - val_loss: 1.8596\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6303 - val_accuracy: 0.5721 - val_loss: 1.8578\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8137 - loss: 0.6303 - val_accuracy: 0.5721 - val_loss: 1.8597\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6302 - val_accuracy: 0.5721 - val_loss: 1.8597\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8137 - loss: 0.6302 - val_accuracy: 0.5721 - val_loss: 1.8595\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8140 - loss: 0.6302 - val_accuracy: 0.5721 - val_loss: 1.8561\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8137 - loss: 0.6301 - val_accuracy: 0.5721 - val_loss: 1.8591\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6301 - val_accuracy: 0.5721 - val_loss: 1.8598\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8146 - loss: 0.6300 - val_accuracy: 0.5721 - val_loss: 1.8604\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8142 - loss: 0.6300 - val_accuracy: 0.5721 - val_loss: 1.8582\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8141 - loss: 0.6299 - val_accuracy: 0.5722 - val_loss: 1.8625\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8141 - loss: 0.6299 - val_accuracy: 0.5721 - val_loss: 1.8605\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6299 - val_accuracy: 0.5721 - val_loss: 1.8606\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6298 - val_accuracy: 0.5721 - val_loss: 1.8629\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8139 - loss: 0.6298 - val_accuracy: 0.5720 - val_loss: 1.8606\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8150 - loss: 0.6297 - val_accuracy: 0.5721 - val_loss: 1.8611\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6297 - val_accuracy: 0.5722 - val_loss: 1.8620\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8150 - loss: 0.6297 - val_accuracy: 0.5734 - val_loss: 1.8594\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8145 - loss: 0.6296 - val_accuracy: 0.5734 - val_loss: 1.8601\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6296 - val_accuracy: 0.5732 - val_loss: 1.8605\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6295 - val_accuracy: 0.5734 - val_loss: 1.8598\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8150 - loss: 0.6295 - val_accuracy: 0.5732 - val_loss: 1.8616\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6294 - val_accuracy: 0.5732 - val_loss: 1.8622\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8146 - loss: 0.6294 - val_accuracy: 0.5732 - val_loss: 1.8627\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6294 - val_accuracy: 0.5734 - val_loss: 1.8596\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6293 - val_accuracy: 0.5734 - val_loss: 1.8622\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8142 - loss: 0.6293 - val_accuracy: 0.5734 - val_loss: 1.8607\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6292 - val_accuracy: 0.5732 - val_loss: 1.8609\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6292 - val_accuracy: 0.5732 - val_loss: 1.8648\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8150 - loss: 0.6292 - val_accuracy: 0.5733 - val_loss: 1.8606\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6291 - val_accuracy: 0.5732 - val_loss: 1.8622\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6291 - val_accuracy: 0.5732 - val_loss: 1.8632\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6290 - val_accuracy: 0.5732 - val_loss: 1.8626\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8148 - loss: 0.6290 - val_accuracy: 0.5732 - val_loss: 1.8639\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6290 - val_accuracy: 0.5733 - val_loss: 1.8588\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8146 - loss: 0.6289 - val_accuracy: 0.5734 - val_loss: 1.8641\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6289 - val_accuracy: 0.5733 - val_loss: 1.8644\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8145 - loss: 0.6288 - val_accuracy: 0.5733 - val_loss: 1.8631\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8149 - loss: 0.6288 - val_accuracy: 0.5732 - val_loss: 1.8646\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8144 - loss: 0.6288 - val_accuracy: 0.5733 - val_loss: 1.8631\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8143 - loss: 0.6287 - val_accuracy: 0.5733 - val_loss: 1.8648\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6287 - val_accuracy: 0.5734 - val_loss: 1.8663\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6286 - val_accuracy: 0.5733 - val_loss: 1.8650\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8155 - loss: 0.6286 - val_accuracy: 0.5733 - val_loss: 1.8684\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6286 - val_accuracy: 0.5733 - val_loss: 1.8613\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8146 - loss: 0.6285 - val_accuracy: 0.5732 - val_loss: 1.8666\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8150 - loss: 0.6285 - val_accuracy: 0.5733 - val_loss: 1.8652\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6285 - val_accuracy: 0.5733 - val_loss: 1.8653\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6284 - val_accuracy: 0.5733 - val_loss: 1.8636\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8148 - loss: 0.6284 - val_accuracy: 0.5734 - val_loss: 1.8653\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8147 - loss: 0.6283 - val_accuracy: 0.5734 - val_loss: 1.8665\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8148 - loss: 0.6283 - val_accuracy: 0.5734 - val_loss: 1.8654\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8159 - loss: 0.6283 - val_accuracy: 0.5733 - val_loss: 1.8654\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6282 - val_accuracy: 0.5733 - val_loss: 1.8654\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6282 - val_accuracy: 0.5733 - val_loss: 1.8639\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6282 - val_accuracy: 0.5733 - val_loss: 1.8673\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6281 - val_accuracy: 0.5733 - val_loss: 1.8666\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6281 - val_accuracy: 0.5732 - val_loss: 1.8692\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6280 - val_accuracy: 0.5734 - val_loss: 1.8672\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8156 - loss: 0.6280 - val_accuracy: 0.5733 - val_loss: 1.8664\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6280 - val_accuracy: 0.5734 - val_loss: 1.8665\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6279 - val_accuracy: 0.5733 - val_loss: 1.8669\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8155 - loss: 0.6279 - val_accuracy: 0.5733 - val_loss: 1.8666\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6279 - val_accuracy: 0.5733 - val_loss: 1.8688\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6278 - val_accuracy: 0.5733 - val_loss: 1.8685\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6278 - val_accuracy: 0.5733 - val_loss: 1.8669\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6278 - val_accuracy: 0.5733 - val_loss: 1.8675\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6277 - val_accuracy: 0.5733 - val_loss: 1.8676\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6277 - val_accuracy: 0.5734 - val_loss: 1.8691\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6277 - val_accuracy: 0.5733 - val_loss: 1.8655\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6276 - val_accuracy: 0.5733 - val_loss: 1.8670\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6276 - val_accuracy: 0.5733 - val_loss: 1.8686\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6275 - val_accuracy: 0.5733 - val_loss: 1.8691\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6275 - val_accuracy: 0.5734 - val_loss: 1.8683\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6275 - val_accuracy: 0.5733 - val_loss: 1.8691\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6274 - val_accuracy: 0.5732 - val_loss: 1.8713\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6274 - val_accuracy: 0.5733 - val_loss: 1.8690\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6274 - val_accuracy: 0.5734 - val_loss: 1.8688\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8156 - loss: 0.6273 - val_accuracy: 0.5732 - val_loss: 1.8717\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8142 - loss: 0.6273 - val_accuracy: 0.5734 - val_loss: 1.8665\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6273 - val_accuracy: 0.5733 - val_loss: 1.8650\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8140 - loss: 0.6272 - val_accuracy: 0.5733 - val_loss: 1.8693\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6272 - val_accuracy: 0.5732 - val_loss: 1.8701\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6272 - val_accuracy: 0.5733 - val_loss: 1.8682\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6271 - val_accuracy: 0.5733 - val_loss: 1.8686\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6271 - val_accuracy: 0.5732 - val_loss: 1.8691\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6271 - val_accuracy: 0.5732 - val_loss: 1.8705\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6270 - val_accuracy: 0.5731 - val_loss: 1.8733\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6270 - val_accuracy: 0.5732 - val_loss: 1.8657\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6270 - val_accuracy: 0.5732 - val_loss: 1.8720\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6269 - val_accuracy: 0.5732 - val_loss: 1.8694\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6269 - val_accuracy: 0.5732 - val_loss: 1.8690\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6269 - val_accuracy: 0.5734 - val_loss: 1.8691\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6268 - val_accuracy: 0.5732 - val_loss: 1.8693\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6268 - val_accuracy: 0.5732 - val_loss: 1.8688\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6268 - val_accuracy: 0.5731 - val_loss: 1.8749\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8148 - loss: 0.6267 - val_accuracy: 0.5731 - val_loss: 1.8706\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8141 - loss: 0.6267 - val_accuracy: 0.5731 - val_loss: 1.8738\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8146 - loss: 0.6267 - val_accuracy: 0.5734 - val_loss: 1.8727\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8147 - loss: 0.6266 - val_accuracy: 0.5732 - val_loss: 1.8731\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6266 - val_accuracy: 0.5734 - val_loss: 1.8687\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6266 - val_accuracy: 0.5732 - val_loss: 1.8721\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6265 - val_accuracy: 0.5732 - val_loss: 1.8687\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6265 - val_accuracy: 0.5733 - val_loss: 1.8725\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6265 - val_accuracy: 0.5731 - val_loss: 1.8730\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6264 - val_accuracy: 0.5734 - val_loss: 1.8691\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6264 - val_accuracy: 0.5733 - val_loss: 1.8702\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6264 - val_accuracy: 0.5731 - val_loss: 1.8724\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6263 - val_accuracy: 0.5731 - val_loss: 1.8726\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6263 - val_accuracy: 0.5733 - val_loss: 1.8692\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6263 - val_accuracy: 0.5731 - val_loss: 1.8765\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6262 - val_accuracy: 0.5731 - val_loss: 1.8761\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6262 - val_accuracy: 0.5734 - val_loss: 1.8727\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6262 - val_accuracy: 0.5731 - val_loss: 1.8768\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6261 - val_accuracy: 0.5733 - val_loss: 1.8692\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6261 - val_accuracy: 0.5733 - val_loss: 1.8733\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6261 - val_accuracy: 0.5734 - val_loss: 1.8751\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6261 - val_accuracy: 0.5731 - val_loss: 1.8760\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6260 - val_accuracy: 0.5735 - val_loss: 1.8707\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6260 - val_accuracy: 0.5733 - val_loss: 1.8721\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8137 - loss: 0.6260 - val_accuracy: 0.5733 - val_loss: 1.8732\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8135 - loss: 0.6259 - val_accuracy: 0.5731 - val_loss: 1.8801\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6259 - val_accuracy: 0.5735 - val_loss: 1.8723\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6259 - val_accuracy: 0.5733 - val_loss: 1.8747\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6258 - val_accuracy: 0.5735 - val_loss: 1.8703\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6258 - val_accuracy: 0.5735 - val_loss: 1.8727\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8143 - loss: 0.6258 - val_accuracy: 0.5735 - val_loss: 1.8722\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6257 - val_accuracy: 0.5735 - val_loss: 1.8748\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6257 - val_accuracy: 0.5733 - val_loss: 1.8757\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6257 - val_accuracy: 0.5732 - val_loss: 1.8766\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6257 - val_accuracy: 0.5734 - val_loss: 1.8759\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6256 - val_accuracy: 0.5736 - val_loss: 1.8750\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6256 - val_accuracy: 0.5736 - val_loss: 1.8719\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6256 - val_accuracy: 0.5735 - val_loss: 1.8733\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6255 - val_accuracy: 0.5735 - val_loss: 1.8747\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6255 - val_accuracy: 0.5734 - val_loss: 1.8773\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6255 - val_accuracy: 0.5734 - val_loss: 1.8750\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6254 - val_accuracy: 0.5735 - val_loss: 1.8709\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6254 - val_accuracy: 0.5734 - val_loss: 1.8765\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6254 - val_accuracy: 0.5735 - val_loss: 1.8729\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6254 - val_accuracy: 0.5736 - val_loss: 1.8740\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6253 - val_accuracy: 0.5734 - val_loss: 1.8794\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6253 - val_accuracy: 0.5736 - val_loss: 1.8765\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6253 - val_accuracy: 0.5735 - val_loss: 1.8744\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6252 - val_accuracy: 0.5735 - val_loss: 1.8743\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6252 - val_accuracy: 0.5734 - val_loss: 1.8770\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8142 - loss: 0.6252 - val_accuracy: 0.5735 - val_loss: 1.8787\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6252 - val_accuracy: 0.5734 - val_loss: 1.8788\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6251 - val_accuracy: 0.5734 - val_loss: 1.8769\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8136 - loss: 0.6251 - val_accuracy: 0.5735 - val_loss: 1.8760\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6251 - val_accuracy: 0.5734 - val_loss: 1.8761\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6250 - val_accuracy: 0.5735 - val_loss: 1.8725\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6250 - val_accuracy: 0.5734 - val_loss: 1.8797\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6250 - val_accuracy: 0.5735 - val_loss: 1.8763\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6250 - val_accuracy: 0.5735 - val_loss: 1.8757\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6249 - val_accuracy: 0.5734 - val_loss: 1.8789\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6249 - val_accuracy: 0.5734 - val_loss: 1.8752\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6249 - val_accuracy: 0.5734 - val_loss: 1.8772\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6248 - val_accuracy: 0.5734 - val_loss: 1.8786\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6248 - val_accuracy: 0.5735 - val_loss: 1.8768\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6248 - val_accuracy: 0.5735 - val_loss: 1.8753\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6248 - val_accuracy: 0.5734 - val_loss: 1.8784\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8142 - loss: 0.6247 - val_accuracy: 0.5737 - val_loss: 1.8745\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6247 - val_accuracy: 0.5735 - val_loss: 1.8774\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6247 - val_accuracy: 0.5735 - val_loss: 1.8763\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8144 - loss: 0.6246 - val_accuracy: 0.5734 - val_loss: 1.8817\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8150 - loss: 0.6246 - val_accuracy: 0.5735 - val_loss: 1.8751\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8140 - loss: 0.6246 - val_accuracy: 0.5736 - val_loss: 1.8775\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8141 - loss: 0.6246 - val_accuracy: 0.5736 - val_loss: 1.8774\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8146 - loss: 0.6245 - val_accuracy: 0.5735 - val_loss: 1.8800\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.62746\n726/726 - 7s - 10ms/step - accuracy: 0.8145 - loss: 0.6245 - val_accuracy: 0.5737 - val_loss: 1.8789\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8145 - loss: 0.6245 - val_accuracy: 0.5736 - val_loss: 1.8759\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6245 - val_accuracy: 0.5736 - val_loss: 1.8758\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6244 - val_accuracy: 0.5736 - val_loss: 1.8816\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6244 - val_accuracy: 0.5735 - val_loss: 1.8833\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.62746\n726/726 - 7s - 9ms/step - accuracy: 0.8148 - loss: 0.6244 - val_accuracy: 0.5735 - val_loss: 1.8791\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8141 - loss: 0.6243 - val_accuracy: 0.5737 - val_loss: 1.8798\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6243 - val_accuracy: 0.5735 - val_loss: 1.8805\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6243 - val_accuracy: 0.5735 - val_loss: 1.8819\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6243 - val_accuracy: 0.5735 - val_loss: 1.8805\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6242 - val_accuracy: 0.5736 - val_loss: 1.8789\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6242 - val_accuracy: 0.5736 - val_loss: 1.8793\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8142 - loss: 0.6242 - val_accuracy: 0.5735 - val_loss: 1.8826\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6242 - val_accuracy: 0.5735 - val_loss: 1.8831\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6241 - val_accuracy: 0.5735 - val_loss: 1.8817\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6241 - val_accuracy: 0.5736 - val_loss: 1.8816\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6241 - val_accuracy: 0.5735 - val_loss: 1.8837\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6240 - val_accuracy: 0.5735 - val_loss: 1.8839\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6240 - val_accuracy: 0.5736 - val_loss: 1.8807\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6240 - val_accuracy: 0.5735 - val_loss: 1.8822\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6240 - val_accuracy: 0.5735 - val_loss: 1.8812\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6239 - val_accuracy: 0.5736 - val_loss: 1.8796\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8140 - loss: 0.6239 - val_accuracy: 0.5736 - val_loss: 1.8846\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6239 - val_accuracy: 0.5735 - val_loss: 1.8820\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6239 - val_accuracy: 0.5735 - val_loss: 1.8809\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6238 - val_accuracy: 0.5736 - val_loss: 1.8804\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6238 - val_accuracy: 0.5736 - val_loss: 1.8857\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8146 - loss: 0.6238 - val_accuracy: 0.5737 - val_loss: 1.8816\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8149 - loss: 0.6238 - val_accuracy: 0.5737 - val_loss: 1.8814\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8155 - loss: 0.6237 - val_accuracy: 0.5736 - val_loss: 1.8812\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6237 - val_accuracy: 0.5735 - val_loss: 1.8847\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6237 - val_accuracy: 0.5735 - val_loss: 1.8856\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8144 - loss: 0.6237 - val_accuracy: 0.5736 - val_loss: 1.8860\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8154 - loss: 0.6236 - val_accuracy: 0.5736 - val_loss: 1.8856\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6236 - val_accuracy: 0.5736 - val_loss: 1.8803\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6236 - val_accuracy: 0.5736 - val_loss: 1.8831\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6236 - val_accuracy: 0.5735 - val_loss: 1.8850\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8139 - loss: 0.6235 - val_accuracy: 0.5736 - val_loss: 1.8844\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6235 - val_accuracy: 0.5736 - val_loss: 1.8836\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8146 - loss: 0.6235 - val_accuracy: 0.5735 - val_loss: 1.8844\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8153 - loss: 0.6235 - val_accuracy: 0.5736 - val_loss: 1.8818\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8138 - loss: 0.6234 - val_accuracy: 0.5735 - val_loss: 1.8855\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8151 - loss: 0.6234 - val_accuracy: 0.5735 - val_loss: 1.8886\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6234 - val_accuracy: 0.5736 - val_loss: 1.8815\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8152 - loss: 0.6234 - val_accuracy: 0.5736 - val_loss: 1.8824\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8140 - loss: 0.6233 - val_accuracy: 0.5736 - val_loss: 1.8826\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8145 - loss: 0.6233 - val_accuracy: 0.5735 - val_loss: 1.8851\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8147 - loss: 0.6233 - val_accuracy: 0.5733 - val_loss: 1.8900\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8143 - loss: 0.6233 - val_accuracy: 0.5734 - val_loss: 1.8886\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6232 - val_accuracy: 0.5736 - val_loss: 1.8834\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6232 - val_accuracy: 0.5736 - val_loss: 1.8850\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8140 - loss: 0.6232 - val_accuracy: 0.5733 - val_loss: 1.8856\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8141 - loss: 0.6232 - val_accuracy: 0.5737 - val_loss: 1.8836\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8148 - loss: 0.6231 - val_accuracy: 0.5734 - val_loss: 1.8880\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8160 - loss: 0.6231 - val_accuracy: 0.5733 - val_loss: 1.8905\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8150 - loss: 0.6231 - val_accuracy: 0.5734 - val_loss: 1.8871\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_23, X_test_23, y_train_23, y_test_23 = train_test_split(\n    X, y, test_size=0.3, random_state=65, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_23, X_val_23, y_train_23, y_val_23 = train_test_split(\n    X_train_23, y_train_23, test_size=0.2, random_state=65, stratify=y_train_23\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_23:\", np.max(X_train_23))\nprint(\"Min value in X_train_23:\", np.min(X_train_23))\n\nX_train_23_scaled = scaler.fit_transform(X_train_23)\n\n# Get the original class distribution\nclass_counts_23 = Counter(y_train_23)\nprint(\"Original class distribution:\", class_counts_23)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_23 = class_counts_23[min(class_counts_23, key=class_counts_23.get)]\ndesired_majority_size_23 = minority_class_size_23 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_23 = {0: desired_majority_size_23, 1: minority_class_size_23}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_23 = RandomUnderSampler(sampling_strategy=sampling_strategy_23, random_state=42)\nX_resampled_23, y_resampled_23 = undersampler_23.fit_resample(X_train_23, y_train_23)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_23))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_23, y_train_resampled_23 = smote.fit_resample(X_resampled_23, y_resampled_23)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_23))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_23))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:12:40.267803Z","iopub.execute_input":"2025-03-07T15:12:40.268480Z","iopub.status.idle":"2025-03-07T15:13:25.312841Z","shell.execute_reply.started":"2025-03-07T15:12:40.268402Z","shell.execute_reply":"2025-03-07T15:13:25.311652Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_23: 2071000000.0\nMin value in X_train_23: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_23 = X_train_resampled_23.reshape(X_train_resampled_23.shape[0], 1, 56)\nX_val_23 = X_val_23.reshape(X_val_23.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_23,  # Features from CICIDS2017\n    y_train_resampled_23,  # Labels from CICIDS2017\n    validation_data=(X_val_23, y_val_23),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:13:25.314096Z","iopub.execute_input":"2025-03-07T15:13:25.314570Z","iopub.status.idle":"2025-03-07T16:01:14.376878Z","shell.execute_reply.started":"2025-03-07T15:13:25.314504Z","shell.execute_reply":"2025-03-07T16:01:14.375519Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8003 - loss: 0.7566 - val_accuracy: 0.5840 - val_loss: 1.7942\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8026 - loss: 0.7494 - val_accuracy: 0.5823 - val_loss: 1.8039\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8029 - loss: 0.7459 - val_accuracy: 0.5822 - val_loss: 1.8036\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8046 - loss: 0.7434 - val_accuracy: 0.5819 - val_loss: 1.8037\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8048 - loss: 0.7412 - val_accuracy: 0.5817 - val_loss: 1.7973\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8049 - loss: 0.7393 - val_accuracy: 0.5814 - val_loss: 1.7945\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8049 - loss: 0.7375 - val_accuracy: 0.5806 - val_loss: 1.7900\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8049 - loss: 0.7358 - val_accuracy: 0.5806 - val_loss: 1.7860\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8055 - loss: 0.7342 - val_accuracy: 0.5809 - val_loss: 1.7841\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8051 - loss: 0.7328 - val_accuracy: 0.5805 - val_loss: 1.7837\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8051 - loss: 0.7313 - val_accuracy: 0.5803 - val_loss: 1.7824\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8059 - loss: 0.7300 - val_accuracy: 0.5802 - val_loss: 1.7809\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8058 - loss: 0.7287 - val_accuracy: 0.5791 - val_loss: 1.7771\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8075 - loss: 0.7275 - val_accuracy: 0.5785 - val_loss: 1.7771\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8071 - loss: 0.7263 - val_accuracy: 0.5785 - val_loss: 1.7738\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8067 - loss: 0.7251 - val_accuracy: 0.5792 - val_loss: 1.7715\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.7240 - val_accuracy: 0.5778 - val_loss: 1.7756\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8076 - loss: 0.7229 - val_accuracy: 0.5770 - val_loss: 1.7740\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.7219 - val_accuracy: 0.5769 - val_loss: 1.7749\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8080 - loss: 0.7209 - val_accuracy: 0.5771 - val_loss: 1.7709\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8084 - loss: 0.7199 - val_accuracy: 0.5769 - val_loss: 1.7713\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8090 - loss: 0.7190 - val_accuracy: 0.5770 - val_loss: 1.7749\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.7180 - val_accuracy: 0.5770 - val_loss: 1.7723\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.7172 - val_accuracy: 0.5770 - val_loss: 1.7746\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8104 - loss: 0.7163 - val_accuracy: 0.5769 - val_loss: 1.7726\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8107 - loss: 0.7155 - val_accuracy: 0.5767 - val_loss: 1.7760\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.7147 - val_accuracy: 0.5767 - val_loss: 1.7793\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8095 - loss: 0.7139 - val_accuracy: 0.5774 - val_loss: 1.7738\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.7131 - val_accuracy: 0.5767 - val_loss: 1.7762\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.7124 - val_accuracy: 0.5766 - val_loss: 1.7778\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8107 - loss: 0.7117 - val_accuracy: 0.5764 - val_loss: 1.7770\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8108 - loss: 0.7110 - val_accuracy: 0.5762 - val_loss: 1.7801\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8099 - loss: 0.7103 - val_accuracy: 0.5760 - val_loss: 1.7796\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8107 - loss: 0.7096 - val_accuracy: 0.5742 - val_loss: 1.7780\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.7090 - val_accuracy: 0.5743 - val_loss: 1.7775\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8098 - loss: 0.7083 - val_accuracy: 0.5740 - val_loss: 1.7768\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8107 - loss: 0.7077 - val_accuracy: 0.5737 - val_loss: 1.7824\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.7071 - val_accuracy: 0.5737 - val_loss: 1.7798\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8104 - loss: 0.7065 - val_accuracy: 0.5738 - val_loss: 1.7846\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.7060 - val_accuracy: 0.5736 - val_loss: 1.7831\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8097 - loss: 0.7054 - val_accuracy: 0.5738 - val_loss: 1.7854\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8104 - loss: 0.7049 - val_accuracy: 0.5738 - val_loss: 1.7856\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8105 - loss: 0.7044 - val_accuracy: 0.5738 - val_loss: 1.7847\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8100 - loss: 0.7039 - val_accuracy: 0.5737 - val_loss: 1.7866\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8099 - loss: 0.7034 - val_accuracy: 0.5734 - val_loss: 1.7894\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.7029 - val_accuracy: 0.5734 - val_loss: 1.7878\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8105 - loss: 0.7024 - val_accuracy: 0.5734 - val_loss: 1.7875\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.7020 - val_accuracy: 0.5735 - val_loss: 1.7860\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8106 - loss: 0.7015 - val_accuracy: 0.5734 - val_loss: 1.7886\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8097 - loss: 0.7011 - val_accuracy: 0.5733 - val_loss: 1.7924\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8099 - loss: 0.7007 - val_accuracy: 0.5734 - val_loss: 1.7929\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8100 - loss: 0.7002 - val_accuracy: 0.5734 - val_loss: 1.7917\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6998 - val_accuracy: 0.5732 - val_loss: 1.7968\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8099 - loss: 0.6994 - val_accuracy: 0.5732 - val_loss: 1.7951\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6990 - val_accuracy: 0.5733 - val_loss: 1.7954\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8090 - loss: 0.6987 - val_accuracy: 0.5735 - val_loss: 1.7984\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6983 - val_accuracy: 0.5734 - val_loss: 1.7977\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8091 - loss: 0.6979 - val_accuracy: 0.5734 - val_loss: 1.7994\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8093 - loss: 0.6976 - val_accuracy: 0.5735 - val_loss: 1.7974\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8105 - loss: 0.6972 - val_accuracy: 0.5734 - val_loss: 1.8005\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6969 - val_accuracy: 0.5736 - val_loss: 1.7966\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.6965 - val_accuracy: 0.5734 - val_loss: 1.8020\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6962 - val_accuracy: 0.5735 - val_loss: 1.8064\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.6959 - val_accuracy: 0.5734 - val_loss: 1.8044\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8098 - loss: 0.6956 - val_accuracy: 0.5736 - val_loss: 1.8050\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8098 - loss: 0.6953 - val_accuracy: 0.5735 - val_loss: 1.8046\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.6950 - val_accuracy: 0.5734 - val_loss: 1.8088\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8100 - loss: 0.6947 - val_accuracy: 0.5733 - val_loss: 1.8068\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8094 - loss: 0.6944 - val_accuracy: 0.5733 - val_loss: 1.8099\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8094 - loss: 0.6941 - val_accuracy: 0.5733 - val_loss: 1.8085\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6938 - val_accuracy: 0.5734 - val_loss: 1.8087\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8096 - loss: 0.6936 - val_accuracy: 0.5734 - val_loss: 1.8142\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6933 - val_accuracy: 0.5734 - val_loss: 1.8116\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8091 - loss: 0.6930 - val_accuracy: 0.5732 - val_loss: 1.8125\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8074 - loss: 0.6928 - val_accuracy: 0.5733 - val_loss: 1.8161\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6925 - val_accuracy: 0.5733 - val_loss: 1.8150\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6923 - val_accuracy: 0.5735 - val_loss: 1.8154\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6920 - val_accuracy: 0.5735 - val_loss: 1.8141\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6918 - val_accuracy: 0.5734 - val_loss: 1.8204\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6916 - val_accuracy: 0.5735 - val_loss: 1.8209\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8095 - loss: 0.6913 - val_accuracy: 0.5734 - val_loss: 1.8188\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6911 - val_accuracy: 0.5735 - val_loss: 1.8207\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6909 - val_accuracy: 0.5733 - val_loss: 1.8268\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8091 - loss: 0.6907 - val_accuracy: 0.5735 - val_loss: 1.8214\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6904 - val_accuracy: 0.5733 - val_loss: 1.8255\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6902 - val_accuracy: 0.5622 - val_loss: 1.8230\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6900 - val_accuracy: 0.5624 - val_loss: 1.8227\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8090 - loss: 0.6898 - val_accuracy: 0.5625 - val_loss: 1.8203\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8093 - loss: 0.6896 - val_accuracy: 0.5623 - val_loss: 1.8230\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6894 - val_accuracy: 0.5624 - val_loss: 1.8276\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8094 - loss: 0.6892 - val_accuracy: 0.5623 - val_loss: 1.8282\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6890 - val_accuracy: 0.5624 - val_loss: 1.8275\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6888 - val_accuracy: 0.5624 - val_loss: 1.8301\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6886 - val_accuracy: 0.5623 - val_loss: 1.8336\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8080 - loss: 0.6885 - val_accuracy: 0.5623 - val_loss: 1.8286\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8076 - loss: 0.6883 - val_accuracy: 0.5613 - val_loss: 1.8344\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6881 - val_accuracy: 0.5612 - val_loss: 1.8331\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8079 - loss: 0.6879 - val_accuracy: 0.5613 - val_loss: 1.8322\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8072 - loss: 0.6877 - val_accuracy: 0.5613 - val_loss: 1.8330\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8081 - loss: 0.6876 - val_accuracy: 0.5614 - val_loss: 1.8359\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8075 - loss: 0.6874 - val_accuracy: 0.5614 - val_loss: 1.8357\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8080 - loss: 0.6872 - val_accuracy: 0.5613 - val_loss: 1.8358\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8079 - loss: 0.6871 - val_accuracy: 0.5613 - val_loss: 1.8364\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8079 - loss: 0.6869 - val_accuracy: 0.5612 - val_loss: 1.8409\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8074 - loss: 0.6867 - val_accuracy: 0.5611 - val_loss: 1.8413\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8071 - loss: 0.6866 - val_accuracy: 0.5612 - val_loss: 1.8429\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8077 - loss: 0.6864 - val_accuracy: 0.5612 - val_loss: 1.8406\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8066 - loss: 0.6863 - val_accuracy: 0.5612 - val_loss: 1.8391\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6861 - val_accuracy: 0.5612 - val_loss: 1.8423\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8071 - loss: 0.6859 - val_accuracy: 0.5617 - val_loss: 1.8438\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8073 - loss: 0.6858 - val_accuracy: 0.5617 - val_loss: 1.8450\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8073 - loss: 0.6856 - val_accuracy: 0.5612 - val_loss: 1.8481\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8086 - loss: 0.6855 - val_accuracy: 0.5610 - val_loss: 1.8454\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8074 - loss: 0.6854 - val_accuracy: 0.5616 - val_loss: 1.8453\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6852 - val_accuracy: 0.5612 - val_loss: 1.8416\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6851 - val_accuracy: 0.5612 - val_loss: 1.8449\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8081 - loss: 0.6849 - val_accuracy: 0.5612 - val_loss: 1.8446\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8074 - loss: 0.6848 - val_accuracy: 0.5612 - val_loss: 1.8505\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8077 - loss: 0.6846 - val_accuracy: 0.5612 - val_loss: 1.8459\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8076 - loss: 0.6845 - val_accuracy: 0.5611 - val_loss: 1.8493\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8076 - loss: 0.6844 - val_accuracy: 0.5612 - val_loss: 1.8466\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6842 - val_accuracy: 0.5612 - val_loss: 1.8458\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6841 - val_accuracy: 0.5617 - val_loss: 1.8494\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6840 - val_accuracy: 0.5610 - val_loss: 1.8511\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8079 - loss: 0.6838 - val_accuracy: 0.5610 - val_loss: 1.8526\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8074 - loss: 0.6837 - val_accuracy: 0.5612 - val_loss: 1.8472\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6836 - val_accuracy: 0.5611 - val_loss: 1.8502\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8074 - loss: 0.6835 - val_accuracy: 0.5611 - val_loss: 1.8546\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8069 - loss: 0.6833 - val_accuracy: 0.5611 - val_loss: 1.8540\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6832 - val_accuracy: 0.5605 - val_loss: 1.8564\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8069 - loss: 0.6831 - val_accuracy: 0.5611 - val_loss: 1.8609\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6830 - val_accuracy: 0.5606 - val_loss: 1.8576\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6828 - val_accuracy: 0.5606 - val_loss: 1.8564\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6827 - val_accuracy: 0.5611 - val_loss: 1.8558\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6826 - val_accuracy: 0.5611 - val_loss: 1.8537\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8081 - loss: 0.6825 - val_accuracy: 0.5616 - val_loss: 1.8567\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8072 - loss: 0.6824 - val_accuracy: 0.5612 - val_loss: 1.8552\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8090 - loss: 0.6823 - val_accuracy: 0.5616 - val_loss: 1.8572\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8071 - loss: 0.6821 - val_accuracy: 0.5612 - val_loss: 1.8571\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6820 - val_accuracy: 0.5616 - val_loss: 1.8600\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8080 - loss: 0.6819 - val_accuracy: 0.5612 - val_loss: 1.8589\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8078 - loss: 0.6818 - val_accuracy: 0.5618 - val_loss: 1.8611\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8075 - loss: 0.6817 - val_accuracy: 0.5612 - val_loss: 1.8586\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6816 - val_accuracy: 0.5606 - val_loss: 1.8625\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6815 - val_accuracy: 0.5612 - val_loss: 1.8596\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6814 - val_accuracy: 0.5612 - val_loss: 1.8626\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6813 - val_accuracy: 0.5606 - val_loss: 1.8614\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6812 - val_accuracy: 0.5617 - val_loss: 1.8643\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6811 - val_accuracy: 0.5612 - val_loss: 1.8651\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6810 - val_accuracy: 0.5612 - val_loss: 1.8607\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6809 - val_accuracy: 0.5617 - val_loss: 1.8645\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8081 - loss: 0.6808 - val_accuracy: 0.5617 - val_loss: 1.8649\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8090 - loss: 0.6807 - val_accuracy: 0.5617 - val_loss: 1.8669\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6806 - val_accuracy: 0.5606 - val_loss: 1.8670\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6805 - val_accuracy: 0.5605 - val_loss: 1.8649\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8076 - loss: 0.6804 - val_accuracy: 0.5609 - val_loss: 1.8644\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6803 - val_accuracy: 0.5608 - val_loss: 1.8720\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6802 - val_accuracy: 0.5609 - val_loss: 1.8650\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6801 - val_accuracy: 0.5613 - val_loss: 1.8693\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6800 - val_accuracy: 0.5608 - val_loss: 1.8673\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6799 - val_accuracy: 0.5613 - val_loss: 1.8689\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6798 - val_accuracy: 0.5600 - val_loss: 1.8677\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8091 - loss: 0.6797 - val_accuracy: 0.5608 - val_loss: 1.8645\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6796 - val_accuracy: 0.5603 - val_loss: 1.8708\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6795 - val_accuracy: 0.5609 - val_loss: 1.8715\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8090 - loss: 0.6794 - val_accuracy: 0.5598 - val_loss: 1.8715\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6793 - val_accuracy: 0.5603 - val_loss: 1.8711\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8097 - loss: 0.6792 - val_accuracy: 0.5609 - val_loss: 1.8704\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8111 - loss: 0.6791 - val_accuracy: 0.5603 - val_loss: 1.8716\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8107 - loss: 0.6791 - val_accuracy: 0.5609 - val_loss: 1.8732\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6790 - val_accuracy: 0.5603 - val_loss: 1.8785\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8100 - loss: 0.6789 - val_accuracy: 0.5604 - val_loss: 1.8679\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6788 - val_accuracy: 0.5603 - val_loss: 1.8727\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8110 - loss: 0.6787 - val_accuracy: 0.5603 - val_loss: 1.8767\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8115 - loss: 0.6786 - val_accuracy: 0.5598 - val_loss: 1.8760\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8113 - loss: 0.6785 - val_accuracy: 0.5603 - val_loss: 1.8770\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8110 - loss: 0.6785 - val_accuracy: 0.5609 - val_loss: 1.8756\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8115 - loss: 0.6784 - val_accuracy: 0.5609 - val_loss: 1.8762\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6783 - val_accuracy: 0.5609 - val_loss: 1.8760\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6782 - val_accuracy: 0.5604 - val_loss: 1.8759\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8106 - loss: 0.6781 - val_accuracy: 0.5598 - val_loss: 1.8784\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6780 - val_accuracy: 0.5604 - val_loss: 1.8778\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6780 - val_accuracy: 0.5604 - val_loss: 1.8762\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6779 - val_accuracy: 0.5604 - val_loss: 1.8805\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8115 - loss: 0.6778 - val_accuracy: 0.5604 - val_loss: 1.8806\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6777 - val_accuracy: 0.5598 - val_loss: 1.8772\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6776 - val_accuracy: 0.5604 - val_loss: 1.8781\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6776 - val_accuracy: 0.5598 - val_loss: 1.8808\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6775 - val_accuracy: 0.5604 - val_loss: 1.8819\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6774 - val_accuracy: 0.5599 - val_loss: 1.8804\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6773 - val_accuracy: 0.5604 - val_loss: 1.8827\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6772 - val_accuracy: 0.5604 - val_loss: 1.8835\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6772 - val_accuracy: 0.5604 - val_loss: 1.8847\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8114 - loss: 0.6771 - val_accuracy: 0.5604 - val_loss: 1.8819\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8115 - loss: 0.6770 - val_accuracy: 0.5604 - val_loss: 1.8815\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8113 - loss: 0.6770 - val_accuracy: 0.5604 - val_loss: 1.8831\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8116 - loss: 0.6769 - val_accuracy: 0.5604 - val_loss: 1.8826\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8116 - loss: 0.6768 - val_accuracy: 0.5604 - val_loss: 1.8858\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6767 - val_accuracy: 0.5604 - val_loss: 1.8863\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6767 - val_accuracy: 0.5604 - val_loss: 1.8827\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8111 - loss: 0.6766 - val_accuracy: 0.5599 - val_loss: 1.8854\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8116 - loss: 0.6765 - val_accuracy: 0.5604 - val_loss: 1.8867\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6764 - val_accuracy: 0.5604 - val_loss: 1.8839\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8110 - loss: 0.6764 - val_accuracy: 0.5604 - val_loss: 1.8891\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6763 - val_accuracy: 0.5604 - val_loss: 1.8898\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8121 - loss: 0.6762 - val_accuracy: 0.5604 - val_loss: 1.8858\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8120 - loss: 0.6762 - val_accuracy: 0.5604 - val_loss: 1.8840\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6761 - val_accuracy: 0.5604 - val_loss: 1.8892\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6760 - val_accuracy: 0.5603 - val_loss: 1.8912\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6760 - val_accuracy: 0.5604 - val_loss: 1.8874\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8121 - loss: 0.6759 - val_accuracy: 0.5604 - val_loss: 1.8870\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6758 - val_accuracy: 0.5604 - val_loss: 1.8884\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8121 - loss: 0.6757 - val_accuracy: 0.5598 - val_loss: 1.8893\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6757 - val_accuracy: 0.5604 - val_loss: 1.8890\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6756 - val_accuracy: 0.5604 - val_loss: 1.8903\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8120 - loss: 0.6755 - val_accuracy: 0.5604 - val_loss: 1.8913\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6755 - val_accuracy: 0.5604 - val_loss: 1.8886\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8116 - loss: 0.6754 - val_accuracy: 0.5604 - val_loss: 1.8921\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8119 - loss: 0.6753 - val_accuracy: 0.5598 - val_loss: 1.8890\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6753 - val_accuracy: 0.5604 - val_loss: 1.8926\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6752 - val_accuracy: 0.5598 - val_loss: 1.8886\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6752 - val_accuracy: 0.5604 - val_loss: 1.8938\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8116 - loss: 0.6751 - val_accuracy: 0.5604 - val_loss: 1.8935\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6750 - val_accuracy: 0.5600 - val_loss: 1.8949\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6750 - val_accuracy: 0.5599 - val_loss: 1.8919\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6749 - val_accuracy: 0.5602 - val_loss: 1.8922\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6748 - val_accuracy: 0.5605 - val_loss: 1.8889\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6748 - val_accuracy: 0.5571 - val_loss: 1.8930\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8118 - loss: 0.6747 - val_accuracy: 0.5600 - val_loss: 1.8946\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6747 - val_accuracy: 0.5572 - val_loss: 1.8938\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6746 - val_accuracy: 0.5566 - val_loss: 1.8974\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6745 - val_accuracy: 0.5601 - val_loss: 1.8934\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6745 - val_accuracy: 0.5599 - val_loss: 1.8948\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6744 - val_accuracy: 0.5601 - val_loss: 1.8929\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6743 - val_accuracy: 0.5567 - val_loss: 1.8959\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6743 - val_accuracy: 0.5570 - val_loss: 1.8947\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6742 - val_accuracy: 0.5569 - val_loss: 1.8953\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6742 - val_accuracy: 0.5567 - val_loss: 1.8989\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8116 - loss: 0.6741 - val_accuracy: 0.5567 - val_loss: 1.8975\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6740 - val_accuracy: 0.5567 - val_loss: 1.8972\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6740 - val_accuracy: 0.5567 - val_loss: 1.9000\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6739 - val_accuracy: 0.5566 - val_loss: 1.8961\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6739 - val_accuracy: 0.5566 - val_loss: 1.8991\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6738 - val_accuracy: 0.5567 - val_loss: 1.8951\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6738 - val_accuracy: 0.5566 - val_loss: 1.8986\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6737 - val_accuracy: 0.5566 - val_loss: 1.8967\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6736 - val_accuracy: 0.5566 - val_loss: 1.9005\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6736 - val_accuracy: 0.5566 - val_loss: 1.9012\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8119 - loss: 0.6735 - val_accuracy: 0.5566 - val_loss: 1.9012\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6735 - val_accuracy: 0.5566 - val_loss: 1.8958\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6734 - val_accuracy: 0.5566 - val_loss: 1.9021\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6734 - val_accuracy: 0.5566 - val_loss: 1.9001\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8118 - loss: 0.6733 - val_accuracy: 0.5566 - val_loss: 1.9030\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6733 - val_accuracy: 0.5566 - val_loss: 1.8973\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6732 - val_accuracy: 0.5566 - val_loss: 1.9016\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6731 - val_accuracy: 0.5566 - val_loss: 1.9005\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6731 - val_accuracy: 0.5566 - val_loss: 1.9001\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6730 - val_accuracy: 0.5566 - val_loss: 1.9013\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6730 - val_accuracy: 0.5566 - val_loss: 1.8996\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6729 - val_accuracy: 0.5566 - val_loss: 1.9044\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6729 - val_accuracy: 0.5566 - val_loss: 1.9010\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6728 - val_accuracy: 0.5566 - val_loss: 1.9013\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6728 - val_accuracy: 0.5566 - val_loss: 1.9032\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6727 - val_accuracy: 0.5566 - val_loss: 1.9010\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6727 - val_accuracy: 0.5566 - val_loss: 1.9011\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6726 - val_accuracy: 0.5566 - val_loss: 1.9013\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6726 - val_accuracy: 0.5566 - val_loss: 1.9057\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6725 - val_accuracy: 0.5566 - val_loss: 1.9057\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6725 - val_accuracy: 0.5566 - val_loss: 1.9061\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6724 - val_accuracy: 0.5566 - val_loss: 1.9071\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6724 - val_accuracy: 0.5566 - val_loss: 1.9079\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6723 - val_accuracy: 0.5566 - val_loss: 1.9066\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6723 - val_accuracy: 0.5566 - val_loss: 1.9058\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6722 - val_accuracy: 0.5566 - val_loss: 1.9063\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6722 - val_accuracy: 0.5566 - val_loss: 1.9068\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6721 - val_accuracy: 0.5566 - val_loss: 1.9063\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6721 - val_accuracy: 0.5566 - val_loss: 1.9074\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6720 - val_accuracy: 0.5566 - val_loss: 1.9075\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8118 - loss: 0.6720 - val_accuracy: 0.5566 - val_loss: 1.9069\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6719 - val_accuracy: 0.5566 - val_loss: 1.9068\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8118 - loss: 0.6719 - val_accuracy: 0.5566 - val_loss: 1.9080\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6718 - val_accuracy: 0.5566 - val_loss: 1.9096\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6718 - val_accuracy: 0.5566 - val_loss: 1.9065\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6717 - val_accuracy: 0.5566 - val_loss: 1.9063\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6717 - val_accuracy: 0.5566 - val_loss: 1.9091\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6716 - val_accuracy: 0.5566 - val_loss: 1.9107\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6716 - val_accuracy: 0.5566 - val_loss: 1.9082\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6715 - val_accuracy: 0.5566 - val_loss: 1.9090\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6715 - val_accuracy: 0.5566 - val_loss: 1.9090\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6714 - val_accuracy: 0.5566 - val_loss: 1.9097\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6714 - val_accuracy: 0.5566 - val_loss: 1.9121\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6713 - val_accuracy: 0.5566 - val_loss: 1.9088\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6713 - val_accuracy: 0.5566 - val_loss: 1.9088\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6713 - val_accuracy: 0.5566 - val_loss: 1.9096\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6712 - val_accuracy: 0.5566 - val_loss: 1.9118\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6712 - val_accuracy: 0.5566 - val_loss: 1.9097\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6711 - val_accuracy: 0.5566 - val_loss: 1.9097\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.62746\n726/726 - 10s - 14ms/step - accuracy: 0.8118 - loss: 0.6711 - val_accuracy: 0.5566 - val_loss: 1.9109\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6710 - val_accuracy: 0.5566 - val_loss: 1.9107\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8118 - loss: 0.6710 - val_accuracy: 0.5566 - val_loss: 1.9143\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6709 - val_accuracy: 0.5566 - val_loss: 1.9135\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6709 - val_accuracy: 0.5566 - val_loss: 1.9102\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6708 - val_accuracy: 0.5566 - val_loss: 1.9142\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6708 - val_accuracy: 0.5566 - val_loss: 1.9111\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6708 - val_accuracy: 0.5566 - val_loss: 1.9134\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6707 - val_accuracy: 0.5566 - val_loss: 1.9156\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6707 - val_accuracy: 0.5566 - val_loss: 1.9109\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6706 - val_accuracy: 0.5566 - val_loss: 1.9103\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6706 - val_accuracy: 0.5566 - val_loss: 1.9151\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6705 - val_accuracy: 0.5566 - val_loss: 1.9129\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8113 - loss: 0.6705 - val_accuracy: 0.5566 - val_loss: 1.9094\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6705 - val_accuracy: 0.5566 - val_loss: 1.9147\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8115 - loss: 0.6704 - val_accuracy: 0.5566 - val_loss: 1.9125\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6704 - val_accuracy: 0.5566 - val_loss: 1.9130\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6703 - val_accuracy: 0.5566 - val_loss: 1.9138\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6703 - val_accuracy: 0.5566 - val_loss: 1.9147\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6703 - val_accuracy: 0.5566 - val_loss: 1.9196\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6702 - val_accuracy: 0.5566 - val_loss: 1.9138\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8112 - loss: 0.6702 - val_accuracy: 0.5566 - val_loss: 1.9175\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6701 - val_accuracy: 0.5566 - val_loss: 1.9137\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6701 - val_accuracy: 0.5566 - val_loss: 1.9165\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6700 - val_accuracy: 0.5566 - val_loss: 1.9183\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6700 - val_accuracy: 0.5566 - val_loss: 1.9174\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.6700 - val_accuracy: 0.5566 - val_loss: 1.9152\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8114 - loss: 0.6699 - val_accuracy: 0.5566 - val_loss: 1.9189\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6699 - val_accuracy: 0.5566 - val_loss: 1.9186\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6698 - val_accuracy: 0.5566 - val_loss: 1.9168\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8111 - loss: 0.6698 - val_accuracy: 0.5566 - val_loss: 1.9205\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8117 - loss: 0.6698 - val_accuracy: 0.5566 - val_loss: 1.9202\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6697 - val_accuracy: 0.5566 - val_loss: 1.9154\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8111 - loss: 0.6697 - val_accuracy: 0.5566 - val_loss: 1.9187\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8118 - loss: 0.6697 - val_accuracy: 0.5566 - val_loss: 1.9173\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8116 - loss: 0.6696 - val_accuracy: 0.5566 - val_loss: 1.9192\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.6696 - val_accuracy: 0.5566 - val_loss: 1.9206\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8110 - loss: 0.6695 - val_accuracy: 0.5565 - val_loss: 1.9180\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8108 - loss: 0.6695 - val_accuracy: 0.5565 - val_loss: 1.9165\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8104 - loss: 0.6695 - val_accuracy: 0.5565 - val_loss: 1.9195\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8107 - loss: 0.6694 - val_accuracy: 0.5565 - val_loss: 1.9201\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8113 - loss: 0.6694 - val_accuracy: 0.5565 - val_loss: 1.9197\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8101 - loss: 0.6693 - val_accuracy: 0.5565 - val_loss: 1.9177\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8113 - loss: 0.6693 - val_accuracy: 0.5565 - val_loss: 1.9174\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8106 - loss: 0.6693 - val_accuracy: 0.5565 - val_loss: 1.9181\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8097 - loss: 0.6692 - val_accuracy: 0.5522 - val_loss: 1.9206\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8092 - loss: 0.6692 - val_accuracy: 0.5565 - val_loss: 1.9211\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8109 - loss: 0.6692 - val_accuracy: 0.5565 - val_loss: 1.9181\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8107 - loss: 0.6691 - val_accuracy: 0.5565 - val_loss: 1.9234\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8096 - loss: 0.6691 - val_accuracy: 0.5565 - val_loss: 1.9183\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8095 - loss: 0.6690 - val_accuracy: 0.5565 - val_loss: 1.9217\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8095 - loss: 0.6690 - val_accuracy: 0.5522 - val_loss: 1.9226\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8094 - loss: 0.6690 - val_accuracy: 0.5565 - val_loss: 1.9228\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8096 - loss: 0.6689 - val_accuracy: 0.5565 - val_loss: 1.9193\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8110 - loss: 0.6689 - val_accuracy: 0.5568 - val_loss: 1.9222\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8103 - loss: 0.6689 - val_accuracy: 0.5565 - val_loss: 1.9208\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8092 - loss: 0.6688 - val_accuracy: 0.5568 - val_loss: 1.9189\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8091 - loss: 0.6688 - val_accuracy: 0.5525 - val_loss: 1.9173\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6688 - val_accuracy: 0.5568 - val_loss: 1.9215\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.6687 - val_accuracy: 0.5524 - val_loss: 1.9215\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8102 - loss: 0.6687 - val_accuracy: 0.5522 - val_loss: 1.9220\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8081 - loss: 0.6686 - val_accuracy: 0.5524 - val_loss: 1.9197\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6686 - val_accuracy: 0.5568 - val_loss: 1.9243\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8093 - loss: 0.6686 - val_accuracy: 0.5524 - val_loss: 1.9216\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6685 - val_accuracy: 0.5522 - val_loss: 1.9259\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6685 - val_accuracy: 0.5524 - val_loss: 1.9208\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8093 - loss: 0.6685 - val_accuracy: 0.5524 - val_loss: 1.9249\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8088 - loss: 0.6684 - val_accuracy: 0.5524 - val_loss: 1.9232\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8097 - loss: 0.6684 - val_accuracy: 0.5524 - val_loss: 1.9231\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6684 - val_accuracy: 0.5524 - val_loss: 1.9207\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6683 - val_accuracy: 0.5524 - val_loss: 1.9246\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6683 - val_accuracy: 0.5568 - val_loss: 1.9205\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8093 - loss: 0.6683 - val_accuracy: 0.5568 - val_loss: 1.9199\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6682 - val_accuracy: 0.5524 - val_loss: 1.9235\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6682 - val_accuracy: 0.5524 - val_loss: 1.9271\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6682 - val_accuracy: 0.5524 - val_loss: 1.9274\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6681 - val_accuracy: 0.5524 - val_loss: 1.9283\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6681 - val_accuracy: 0.5524 - val_loss: 1.9240\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6681 - val_accuracy: 0.5524 - val_loss: 1.9273\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8089 - loss: 0.6680 - val_accuracy: 0.5524 - val_loss: 1.9224\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8095 - loss: 0.6680 - val_accuracy: 0.5524 - val_loss: 1.9258\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8082 - loss: 0.6680 - val_accuracy: 0.5524 - val_loss: 1.9279\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6679 - val_accuracy: 0.5524 - val_loss: 1.9259\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6679 - val_accuracy: 0.5524 - val_loss: 1.9248\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6679 - val_accuracy: 0.5524 - val_loss: 1.9251\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6678 - val_accuracy: 0.5524 - val_loss: 1.9278\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6678 - val_accuracy: 0.5523 - val_loss: 1.9299\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6678 - val_accuracy: 0.5524 - val_loss: 1.9283\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6677 - val_accuracy: 0.5524 - val_loss: 1.9245\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6677 - val_accuracy: 0.5524 - val_loss: 1.9285\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6677 - val_accuracy: 0.5524 - val_loss: 1.9271\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6676 - val_accuracy: 0.5524 - val_loss: 1.9293\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8090 - loss: 0.6676 - val_accuracy: 0.5524 - val_loss: 1.9295\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8083 - loss: 0.6676 - val_accuracy: 0.5524 - val_loss: 1.9282\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6675 - val_accuracy: 0.5524 - val_loss: 1.9311\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6675 - val_accuracy: 0.5524 - val_loss: 1.9314\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6675 - val_accuracy: 0.5524 - val_loss: 1.9291\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8082 - loss: 0.6674 - val_accuracy: 0.5524 - val_loss: 1.9271\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6674 - val_accuracy: 0.5524 - val_loss: 1.9274\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6674 - val_accuracy: 0.5524 - val_loss: 1.9278\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6674 - val_accuracy: 0.5524 - val_loss: 1.9279\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6673 - val_accuracy: 0.5524 - val_loss: 1.9294\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6673 - val_accuracy: 0.5524 - val_loss: 1.9274\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6673 - val_accuracy: 0.5524 - val_loss: 1.9310\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6672 - val_accuracy: 0.5524 - val_loss: 1.9300\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6672 - val_accuracy: 0.5523 - val_loss: 1.9342\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6672 - val_accuracy: 0.5524 - val_loss: 1.9274\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6671 - val_accuracy: 0.5524 - val_loss: 1.9281\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6671 - val_accuracy: 0.5524 - val_loss: 1.9286\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6671 - val_accuracy: 0.5524 - val_loss: 1.9317\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6671 - val_accuracy: 0.5524 - val_loss: 1.9267\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6670 - val_accuracy: 0.5523 - val_loss: 1.9308\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6670 - val_accuracy: 0.5524 - val_loss: 1.9278\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6670 - val_accuracy: 0.5524 - val_loss: 1.9292\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6669 - val_accuracy: 0.5524 - val_loss: 1.9309\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8082 - loss: 0.6669 - val_accuracy: 0.5524 - val_loss: 1.9292\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6669 - val_accuracy: 0.5524 - val_loss: 1.9308\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6668 - val_accuracy: 0.5523 - val_loss: 1.9305\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6668 - val_accuracy: 0.5524 - val_loss: 1.9295\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6668 - val_accuracy: 0.5524 - val_loss: 1.9270\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6668 - val_accuracy: 0.5515 - val_loss: 1.9337\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6667 - val_accuracy: 0.5515 - val_loss: 1.9318\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6667 - val_accuracy: 0.5513 - val_loss: 1.9347\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6667 - val_accuracy: 0.5515 - val_loss: 1.9303\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6666 - val_accuracy: 0.5523 - val_loss: 1.9309\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6666 - val_accuracy: 0.5513 - val_loss: 1.9329\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6666 - val_accuracy: 0.5514 - val_loss: 1.9337\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6666 - val_accuracy: 0.5514 - val_loss: 1.9339\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6665 - val_accuracy: 0.5515 - val_loss: 1.9288\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6665 - val_accuracy: 0.5515 - val_loss: 1.9281\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6665 - val_accuracy: 0.5513 - val_loss: 1.9321\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6664 - val_accuracy: 0.5513 - val_loss: 1.9324\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6664 - val_accuracy: 0.5515 - val_loss: 1.9280\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6664 - val_accuracy: 0.5514 - val_loss: 1.9308\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8084 - loss: 0.6664 - val_accuracy: 0.5513 - val_loss: 1.9341\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8083 - loss: 0.6663 - val_accuracy: 0.5515 - val_loss: 1.9343\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8085 - loss: 0.6663 - val_accuracy: 0.5513 - val_loss: 1.9347\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6663 - val_accuracy: 0.5513 - val_loss: 1.9335\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6663 - val_accuracy: 0.5513 - val_loss: 1.9373\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8084 - loss: 0.6662 - val_accuracy: 0.5513 - val_loss: 1.9334\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6662 - val_accuracy: 0.5513 - val_loss: 1.9344\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6662 - val_accuracy: 0.5513 - val_loss: 1.9353\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6661 - val_accuracy: 0.5513 - val_loss: 1.9323\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6661 - val_accuracy: 0.5514 - val_loss: 1.9358\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6661 - val_accuracy: 0.5513 - val_loss: 1.9361\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6661 - val_accuracy: 0.5513 - val_loss: 1.9364\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6660 - val_accuracy: 0.5511 - val_loss: 1.9357\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6660 - val_accuracy: 0.5513 - val_loss: 1.9355\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6660 - val_accuracy: 0.5513 - val_loss: 1.9325\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6660 - val_accuracy: 0.5513 - val_loss: 1.9338\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.62746\n726/726 - 5s - 7ms/step - accuracy: 0.8084 - loss: 0.6659 - val_accuracy: 0.5513 - val_loss: 1.9336\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.62746\n726/726 - 5s - 8ms/step - accuracy: 0.8084 - loss: 0.6659 - val_accuracy: 0.5513 - val_loss: 1.9332\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6659 - val_accuracy: 0.5513 - val_loss: 1.9395\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6659 - val_accuracy: 0.5513 - val_loss: 1.9390\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6658 - val_accuracy: 0.5513 - val_loss: 1.9357\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6658 - val_accuracy: 0.5513 - val_loss: 1.9339\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6658 - val_accuracy: 0.5513 - val_loss: 1.9319\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8084 - loss: 0.6658 - val_accuracy: 0.5513 - val_loss: 1.9362\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6657 - val_accuracy: 0.5513 - val_loss: 1.9326\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6657 - val_accuracy: 0.5513 - val_loss: 1.9397\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6657 - val_accuracy: 0.5513 - val_loss: 1.9309\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6657 - val_accuracy: 0.5513 - val_loss: 1.9348\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6656 - val_accuracy: 0.5513 - val_loss: 1.9400\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6656 - val_accuracy: 0.5513 - val_loss: 1.9366\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6656 - val_accuracy: 0.5513 - val_loss: 1.9386\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6656 - val_accuracy: 0.5513 - val_loss: 1.9362\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6655 - val_accuracy: 0.5513 - val_loss: 1.9310\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6655 - val_accuracy: 0.5513 - val_loss: 1.9364\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6655 - val_accuracy: 0.5513 - val_loss: 1.9361\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6655 - val_accuracy: 0.5513 - val_loss: 1.9376\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.62746\n726/726 - 6s - 9ms/step - accuracy: 0.8085 - loss: 0.6654 - val_accuracy: 0.5513 - val_loss: 1.9352\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6654 - val_accuracy: 0.5513 - val_loss: 1.9343\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6654 - val_accuracy: 0.5513 - val_loss: 1.9357\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6654 - val_accuracy: 0.5513 - val_loss: 1.9375\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6653 - val_accuracy: 0.5511 - val_loss: 1.9420\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8085 - loss: 0.6653 - val_accuracy: 0.5511 - val_loss: 1.9387\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6653 - val_accuracy: 0.5513 - val_loss: 1.9352\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6653 - val_accuracy: 0.5511 - val_loss: 1.9396\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6652 - val_accuracy: 0.5513 - val_loss: 1.9379\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6652 - val_accuracy: 0.5513 - val_loss: 1.9393\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6652 - val_accuracy: 0.5513 - val_loss: 1.9394\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6652 - val_accuracy: 0.5511 - val_loss: 1.9409\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6651 - val_accuracy: 0.5513 - val_loss: 1.9332\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6651 - val_accuracy: 0.5513 - val_loss: 1.9400\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6651 - val_accuracy: 0.5513 - val_loss: 1.9350\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6651 - val_accuracy: 0.5511 - val_loss: 1.9392\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6650 - val_accuracy: 0.5511 - val_loss: 1.9411\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6650 - val_accuracy: 0.5513 - val_loss: 1.9363\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6650 - val_accuracy: 0.5513 - val_loss: 1.9366\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6650 - val_accuracy: 0.5513 - val_loss: 1.9368\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6650 - val_accuracy: 0.5513 - val_loss: 1.9384\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6649 - val_accuracy: 0.5511 - val_loss: 1.9393\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6649 - val_accuracy: 0.5511 - val_loss: 1.9406\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6649 - val_accuracy: 0.5513 - val_loss: 1.9405\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6649 - val_accuracy: 0.5513 - val_loss: 1.9372\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6648 - val_accuracy: 0.5513 - val_loss: 1.9402\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6648 - val_accuracy: 0.5513 - val_loss: 1.9391\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6648 - val_accuracy: 0.5511 - val_loss: 1.9418\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6648 - val_accuracy: 0.5511 - val_loss: 1.9422\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6647 - val_accuracy: 0.5511 - val_loss: 1.9402\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6647 - val_accuracy: 0.5511 - val_loss: 1.9417\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8086 - loss: 0.6647 - val_accuracy: 0.5513 - val_loss: 1.9405\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.62746\n726/726 - 6s - 8ms/step - accuracy: 0.8087 - loss: 0.6647 - val_accuracy: 0.5511 - val_loss: 1.9387\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_24, X_test_24, y_train_24, y_test_24 = train_test_split(\n    X, y, test_size=0.3, random_state=66, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_24, X_val_24, y_train_24, y_val_24 = train_test_split(\n    X_train_24, y_train_24, test_size=0.2, random_state=66, stratify=y_train_24\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_24:\", np.max(X_train_24))\nprint(\"Min value in X_train_24:\", np.min(X_train_24))\n\nX_train_24_scaled = scaler.fit_transform(X_train_24)\n\n# Get the original class distribution\nclass_counts_24 = Counter(y_train_24)\nprint(\"Original class distribution:\", class_counts_24)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_24 = class_counts_24[min(class_counts_24, key=class_counts_24.get)]\ndesired_majority_size_24 = minority_class_size_24 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_24 = {0: desired_majority_size_24, 1: minority_class_size_24}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_24 = RandomUnderSampler(sampling_strategy=sampling_strategy_24, random_state=42)\nX_resampled_24, y_resampled_24 = undersampler_24.fit_resample(X_train_24, y_train_24)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_24))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_24, y_train_resampled_24 = smote.fit_resample(X_resampled_24, y_resampled_24)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_24))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_24))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T22:55:06.018618Z","iopub.execute_input":"2025-03-07T22:55:06.019069Z","iopub.status.idle":"2025-03-07T22:55:27.268750Z","shell.execute_reply.started":"2025-03-07T22:55:06.019043Z","shell.execute_reply":"2025-03-07T22:55:27.267754Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_24: 2071000000.0\nMin value in X_train_24: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_24 = X_train_resampled_24.reshape(X_train_resampled_24.shape[0], 1, 56)\nX_val_24 = X_val_24.reshape(X_val_24.shape[0], 1, 56)\n\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_24,  # Features from CICIDS2017\n    y_train_resampled_24,  # Labels from CICIDS2017\n    validation_data=(X_val_24, y_val_24),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T22:55:27.270035Z","iopub.execute_input":"2025-03-07T22:55:27.270287Z","iopub.status.idle":"2025-03-07T23:26:39.277644Z","shell.execute_reply.started":"2025-03-07T22:55:27.270266Z","shell.execute_reply":"2025-03-07T23:26:39.276055Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy improved from -inf to 0.58672, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 6s - 9ms/step - accuracy: 0.7876 - loss: 0.7103 - val_accuracy: 0.5867 - val_loss: 1.6368\nEpoch 2/500\n\nEpoch 2: val_accuracy improved from 0.58672 to 0.58696, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.7865 - loss: 0.7003 - val_accuracy: 0.5870 - val_loss: 1.6420\nEpoch 3/500\n\nEpoch 3: val_accuracy improved from 0.58696 to 0.58805, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 3s - 5ms/step - accuracy: 0.7864 - loss: 0.6947 - val_accuracy: 0.5880 - val_loss: 1.6499\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.7913 - loss: 0.6908 - val_accuracy: 0.5875 - val_loss: 1.6567\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.7927 - loss: 0.6879 - val_accuracy: 0.5869 - val_loss: 1.6655\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.7989 - loss: 0.6856 - val_accuracy: 0.5866 - val_loss: 1.6714\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6838 - val_accuracy: 0.5866 - val_loss: 1.6777\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.6824 - val_accuracy: 0.5862 - val_loss: 1.6844\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6811 - val_accuracy: 0.5861 - val_loss: 1.6886\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8006 - loss: 0.6801 - val_accuracy: 0.5860 - val_loss: 1.6913\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8007 - loss: 0.6791 - val_accuracy: 0.5860 - val_loss: 1.6938\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8006 - loss: 0.6783 - val_accuracy: 0.5860 - val_loss: 1.6991\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.6775 - val_accuracy: 0.5861 - val_loss: 1.7026\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.6768 - val_accuracy: 0.5857 - val_loss: 1.7062\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8009 - loss: 0.6761 - val_accuracy: 0.5857 - val_loss: 1.7130\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8013 - loss: 0.6755 - val_accuracy: 0.5855 - val_loss: 1.7067\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8015 - loss: 0.6749 - val_accuracy: 0.5855 - val_loss: 1.7122\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8018 - loss: 0.6744 - val_accuracy: 0.5855 - val_loss: 1.7145\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.6739 - val_accuracy: 0.5855 - val_loss: 1.7167\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8004 - loss: 0.6734 - val_accuracy: 0.5855 - val_loss: 1.7194\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8003 - loss: 0.6730 - val_accuracy: 0.5855 - val_loss: 1.7203\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8000 - loss: 0.6726 - val_accuracy: 0.5855 - val_loss: 1.7244\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8000 - loss: 0.6722 - val_accuracy: 0.5855 - val_loss: 1.7266\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.7999 - loss: 0.6718 - val_accuracy: 0.5852 - val_loss: 1.7266\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.7998 - loss: 0.6714 - val_accuracy: 0.5851 - val_loss: 1.7289\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6710 - val_accuracy: 0.5853 - val_loss: 1.7247\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8013 - loss: 0.6707 - val_accuracy: 0.5852 - val_loss: 1.7265\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8013 - loss: 0.6704 - val_accuracy: 0.5853 - val_loss: 1.7249\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8013 - loss: 0.6700 - val_accuracy: 0.5853 - val_loss: 1.7267\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8013 - loss: 0.6697 - val_accuracy: 0.5848 - val_loss: 1.7343\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8013 - loss: 0.6694 - val_accuracy: 0.5849 - val_loss: 1.7305\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8013 - loss: 0.6691 - val_accuracy: 0.5849 - val_loss: 1.7293\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8014 - loss: 0.6688 - val_accuracy: 0.5849 - val_loss: 1.7325\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8016 - loss: 0.6685 - val_accuracy: 0.5849 - val_loss: 1.7315\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8016 - loss: 0.6683 - val_accuracy: 0.5849 - val_loss: 1.7337\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8018 - loss: 0.6680 - val_accuracy: 0.5849 - val_loss: 1.7328\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8018 - loss: 0.6677 - val_accuracy: 0.5849 - val_loss: 1.7323\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6675 - val_accuracy: 0.5849 - val_loss: 1.7329\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.7998 - loss: 0.6672 - val_accuracy: 0.5817 - val_loss: 1.7388\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.7989 - loss: 0.6670 - val_accuracy: 0.5818 - val_loss: 1.7314\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6667 - val_accuracy: 0.5817 - val_loss: 1.7370\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8014 - loss: 0.6665 - val_accuracy: 0.5817 - val_loss: 1.7363\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8019 - loss: 0.6663 - val_accuracy: 0.5817 - val_loss: 1.7355\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6660 - val_accuracy: 0.5815 - val_loss: 1.7386\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8025 - loss: 0.6658 - val_accuracy: 0.5803 - val_loss: 1.7442\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8023 - loss: 0.6656 - val_accuracy: 0.5816 - val_loss: 1.7358\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.58805\n726/726 - 3s - 4ms/step - accuracy: 0.8023 - loss: 0.6653 - val_accuracy: 0.5804 - val_loss: 1.7359\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8023 - loss: 0.6651 - val_accuracy: 0.5804 - val_loss: 1.7408\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8022 - loss: 0.6649 - val_accuracy: 0.5804 - val_loss: 1.7365\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8023 - loss: 0.6647 - val_accuracy: 0.5804 - val_loss: 1.7405\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8023 - loss: 0.6645 - val_accuracy: 0.5804 - val_loss: 1.7383\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8023 - loss: 0.6643 - val_accuracy: 0.5804 - val_loss: 1.7362\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8023 - loss: 0.6641 - val_accuracy: 0.5804 - val_loss: 1.7367\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8023 - loss: 0.6639 - val_accuracy: 0.5804 - val_loss: 1.7403\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8029 - loss: 0.6637 - val_accuracy: 0.5804 - val_loss: 1.7360\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6635 - val_accuracy: 0.5804 - val_loss: 1.7422\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6633 - val_accuracy: 0.5804 - val_loss: 1.7400\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8033 - loss: 0.6631 - val_accuracy: 0.5804 - val_loss: 1.7367\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8032 - loss: 0.6630 - val_accuracy: 0.5818 - val_loss: 1.7393\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8038 - loss: 0.6628 - val_accuracy: 0.5804 - val_loss: 1.7415\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8036 - loss: 0.6626 - val_accuracy: 0.5818 - val_loss: 1.7427\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8041 - loss: 0.6624 - val_accuracy: 0.5818 - val_loss: 1.7407\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8044 - loss: 0.6622 - val_accuracy: 0.5818 - val_loss: 1.7434\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8044 - loss: 0.6621 - val_accuracy: 0.5818 - val_loss: 1.7387\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8045 - loss: 0.6619 - val_accuracy: 0.5818 - val_loss: 1.7410\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8045 - loss: 0.6617 - val_accuracy: 0.5818 - val_loss: 1.7413\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8045 - loss: 0.6616 - val_accuracy: 0.5819 - val_loss: 1.7433\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8037 - loss: 0.6614 - val_accuracy: 0.5818 - val_loss: 1.7436\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8041 - loss: 0.6612 - val_accuracy: 0.5818 - val_loss: 1.7390\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8035 - loss: 0.6611 - val_accuracy: 0.5818 - val_loss: 1.7444\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6609 - val_accuracy: 0.5818 - val_loss: 1.7417\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6608 - val_accuracy: 0.5818 - val_loss: 1.7399\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6606 - val_accuracy: 0.5818 - val_loss: 1.7433\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6605 - val_accuracy: 0.5818 - val_loss: 1.7513\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6603 - val_accuracy: 0.5819 - val_loss: 1.7399\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6602 - val_accuracy: 0.5819 - val_loss: 1.7414\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6600 - val_accuracy: 0.5819 - val_loss: 1.7446\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6599 - val_accuracy: 0.5819 - val_loss: 1.7444\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6597 - val_accuracy: 0.5819 - val_loss: 1.7413\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6596 - val_accuracy: 0.5819 - val_loss: 1.7436\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6594 - val_accuracy: 0.5819 - val_loss: 1.7465\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6593 - val_accuracy: 0.5819 - val_loss: 1.7459\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6592 - val_accuracy: 0.5819 - val_loss: 1.7468\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6590 - val_accuracy: 0.5819 - val_loss: 1.7443\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6589 - val_accuracy: 0.5819 - val_loss: 1.7427\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8032 - loss: 0.6588 - val_accuracy: 0.5819 - val_loss: 1.7478\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6586 - val_accuracy: 0.5819 - val_loss: 1.7442\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6585 - val_accuracy: 0.5819 - val_loss: 1.7496\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6584 - val_accuracy: 0.5819 - val_loss: 1.7454\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6582 - val_accuracy: 0.5819 - val_loss: 1.7437\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6581 - val_accuracy: 0.5819 - val_loss: 1.7471\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6580 - val_accuracy: 0.5819 - val_loss: 1.7501\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6578 - val_accuracy: 0.5819 - val_loss: 1.7465\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8032 - loss: 0.6577 - val_accuracy: 0.5819 - val_loss: 1.7497\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6576 - val_accuracy: 0.5819 - val_loss: 1.7450\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6575 - val_accuracy: 0.5819 - val_loss: 1.7476\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8032 - loss: 0.6574 - val_accuracy: 0.5819 - val_loss: 1.7484\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8032 - loss: 0.6572 - val_accuracy: 0.5819 - val_loss: 1.7484\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8033 - loss: 0.6571 - val_accuracy: 0.5819 - val_loss: 1.7476\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8033 - loss: 0.6570 - val_accuracy: 0.5819 - val_loss: 1.7480\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8037 - loss: 0.6569 - val_accuracy: 0.5819 - val_loss: 1.7504\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8052 - loss: 0.6568 - val_accuracy: 0.5824 - val_loss: 1.7488\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8052 - loss: 0.6566 - val_accuracy: 0.5819 - val_loss: 1.7540\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8052 - loss: 0.6565 - val_accuracy: 0.5820 - val_loss: 1.7474\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8053 - loss: 0.6564 - val_accuracy: 0.5825 - val_loss: 1.7441\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8053 - loss: 0.6563 - val_accuracy: 0.5824 - val_loss: 1.7453\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8053 - loss: 0.6562 - val_accuracy: 0.5819 - val_loss: 1.7526\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8054 - loss: 0.6561 - val_accuracy: 0.5820 - val_loss: 1.7461\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8054 - loss: 0.6560 - val_accuracy: 0.5819 - val_loss: 1.7476\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8054 - loss: 0.6559 - val_accuracy: 0.5824 - val_loss: 1.7485\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6558 - val_accuracy: 0.5823 - val_loss: 1.7502\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6557 - val_accuracy: 0.5824 - val_loss: 1.7492\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8055 - loss: 0.6555 - val_accuracy: 0.5819 - val_loss: 1.7527\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6554 - val_accuracy: 0.5820 - val_loss: 1.7499\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6553 - val_accuracy: 0.5824 - val_loss: 1.7520\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8055 - loss: 0.6552 - val_accuracy: 0.5819 - val_loss: 1.7538\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6551 - val_accuracy: 0.5820 - val_loss: 1.7547\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6550 - val_accuracy: 0.5826 - val_loss: 1.7496\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8055 - loss: 0.6549 - val_accuracy: 0.5825 - val_loss: 1.7516\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6548 - val_accuracy: 0.5826 - val_loss: 1.7475\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8055 - loss: 0.6547 - val_accuracy: 0.5820 - val_loss: 1.7541\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6546 - val_accuracy: 0.5825 - val_loss: 1.7546\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8055 - loss: 0.6545 - val_accuracy: 0.5825 - val_loss: 1.7532\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8056 - loss: 0.6544 - val_accuracy: 0.5826 - val_loss: 1.7505\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8056 - loss: 0.6543 - val_accuracy: 0.5826 - val_loss: 1.7538\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8056 - loss: 0.6542 - val_accuracy: 0.5827 - val_loss: 1.7533\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.58805\n726/726 - 3s - 4ms/step - accuracy: 0.8056 - loss: 0.6542 - val_accuracy: 0.5827 - val_loss: 1.7540\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8056 - loss: 0.6541 - val_accuracy: 0.5828 - val_loss: 1.7509\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8056 - loss: 0.6540 - val_accuracy: 0.5828 - val_loss: 1.7535\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8056 - loss: 0.6539 - val_accuracy: 0.5828 - val_loss: 1.7514\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8056 - loss: 0.6538 - val_accuracy: 0.5829 - val_loss: 1.7512\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8057 - loss: 0.6537 - val_accuracy: 0.5822 - val_loss: 1.7603\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8056 - loss: 0.6536 - val_accuracy: 0.5829 - val_loss: 1.7505\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8057 - loss: 0.6535 - val_accuracy: 0.5828 - val_loss: 1.7540\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8057 - loss: 0.6534 - val_accuracy: 0.5828 - val_loss: 1.7584\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8057 - loss: 0.6533 - val_accuracy: 0.5828 - val_loss: 1.7558\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.6533 - val_accuracy: 0.5831 - val_loss: 1.7533\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.6532 - val_accuracy: 0.5832 - val_loss: 1.7516\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.58805\n726/726 - 5s - 6ms/step - accuracy: 0.8057 - loss: 0.6531 - val_accuracy: 0.5831 - val_loss: 1.7543\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.6530 - val_accuracy: 0.5831 - val_loss: 1.7555\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8057 - loss: 0.6529 - val_accuracy: 0.5831 - val_loss: 1.7537\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8057 - loss: 0.6528 - val_accuracy: 0.5831 - val_loss: 1.7536\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8057 - loss: 0.6527 - val_accuracy: 0.5831 - val_loss: 1.7554\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8059 - loss: 0.6527 - val_accuracy: 0.5831 - val_loss: 1.7551\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6526 - val_accuracy: 0.5831 - val_loss: 1.7569\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6525 - val_accuracy: 0.5831 - val_loss: 1.7564\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6524 - val_accuracy: 0.5830 - val_loss: 1.7560\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6523 - val_accuracy: 0.5843 - val_loss: 1.7533\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6523 - val_accuracy: 0.5843 - val_loss: 1.7543\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6522 - val_accuracy: 0.5843 - val_loss: 1.7567\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6521 - val_accuracy: 0.5844 - val_loss: 1.7564\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6520 - val_accuracy: 0.5844 - val_loss: 1.7569\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6519 - val_accuracy: 0.5845 - val_loss: 1.7538\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8061 - loss: 0.6519 - val_accuracy: 0.5845 - val_loss: 1.7555\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6518 - val_accuracy: 0.5843 - val_loss: 1.7604\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6517 - val_accuracy: 0.5843 - val_loss: 1.7595\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8062 - loss: 0.6516 - val_accuracy: 0.5842 - val_loss: 1.7576\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6516 - val_accuracy: 0.5842 - val_loss: 1.7590\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8061 - loss: 0.6515 - val_accuracy: 0.5842 - val_loss: 1.7579\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6514 - val_accuracy: 0.5842 - val_loss: 1.7612\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6513 - val_accuracy: 0.5842 - val_loss: 1.7600\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6513 - val_accuracy: 0.5732 - val_loss: 1.7603\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6512 - val_accuracy: 0.5841 - val_loss: 1.7613\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6511 - val_accuracy: 0.5732 - val_loss: 1.7593\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6510 - val_accuracy: 0.5842 - val_loss: 1.7591\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6510 - val_accuracy: 0.5842 - val_loss: 1.7603\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6509 - val_accuracy: 0.5842 - val_loss: 1.7607\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6508 - val_accuracy: 0.5732 - val_loss: 1.7643\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8060 - loss: 0.6508 - val_accuracy: 0.5844 - val_loss: 1.7593\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6507 - val_accuracy: 0.5734 - val_loss: 1.7636\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6506 - val_accuracy: 0.5735 - val_loss: 1.7649\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6505 - val_accuracy: 0.5847 - val_loss: 1.7596\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8064 - loss: 0.6505 - val_accuracy: 0.5737 - val_loss: 1.7617\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6504 - val_accuracy: 0.5847 - val_loss: 1.7599\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8065 - loss: 0.6503 - val_accuracy: 0.5737 - val_loss: 1.7653\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8063 - loss: 0.6503 - val_accuracy: 0.5737 - val_loss: 1.7628\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8063 - loss: 0.6502 - val_accuracy: 0.5737 - val_loss: 1.7656\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6501 - val_accuracy: 0.5737 - val_loss: 1.7616\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6501 - val_accuracy: 0.5847 - val_loss: 1.7621\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8063 - loss: 0.6500 - val_accuracy: 0.5737 - val_loss: 1.7650\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8062 - loss: 0.6499 - val_accuracy: 0.5737 - val_loss: 1.7622\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8063 - loss: 0.6499 - val_accuracy: 0.5737 - val_loss: 1.7633\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6498 - val_accuracy: 0.5732 - val_loss: 1.7629\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8063 - loss: 0.6498 - val_accuracy: 0.5843 - val_loss: 1.7574\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8063 - loss: 0.6497 - val_accuracy: 0.5733 - val_loss: 1.7634\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8065 - loss: 0.6496 - val_accuracy: 0.5733 - val_loss: 1.7636\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8068 - loss: 0.6496 - val_accuracy: 0.5733 - val_loss: 1.7637\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8069 - loss: 0.6495 - val_accuracy: 0.5733 - val_loss: 1.7663\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6494 - val_accuracy: 0.5733 - val_loss: 1.7679\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6494 - val_accuracy: 0.5734 - val_loss: 1.7622\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8076 - loss: 0.6493 - val_accuracy: 0.5734 - val_loss: 1.7619\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8072 - loss: 0.6493 - val_accuracy: 0.5734 - val_loss: 1.7674\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8072 - loss: 0.6492 - val_accuracy: 0.5734 - val_loss: 1.7642\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8072 - loss: 0.6491 - val_accuracy: 0.5734 - val_loss: 1.7647\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8075 - loss: 0.6491 - val_accuracy: 0.5734 - val_loss: 1.7674\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6490 - val_accuracy: 0.5732 - val_loss: 1.7709\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8072 - loss: 0.6490 - val_accuracy: 0.5734 - val_loss: 1.7650\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6489 - val_accuracy: 0.5734 - val_loss: 1.7683\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8075 - loss: 0.6488 - val_accuracy: 0.5734 - val_loss: 1.7674\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6488 - val_accuracy: 0.5732 - val_loss: 1.7712\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6487 - val_accuracy: 0.5733 - val_loss: 1.7694\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6487 - val_accuracy: 0.5735 - val_loss: 1.7656\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6486 - val_accuracy: 0.5732 - val_loss: 1.7695\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6486 - val_accuracy: 0.5732 - val_loss: 1.7727\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6485 - val_accuracy: 0.5735 - val_loss: 1.7670\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6484 - val_accuracy: 0.5732 - val_loss: 1.7727\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8077 - loss: 0.6484 - val_accuracy: 0.5732 - val_loss: 1.7737\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6483 - val_accuracy: 0.5736 - val_loss: 1.7675\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8078 - loss: 0.6483 - val_accuracy: 0.5733 - val_loss: 1.7713\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8075 - loss: 0.6482 - val_accuracy: 0.5735 - val_loss: 1.7732\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8075 - loss: 0.6482 - val_accuracy: 0.5734 - val_loss: 1.7708\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6481 - val_accuracy: 0.5733 - val_loss: 1.7706\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6481 - val_accuracy: 0.5733 - val_loss: 1.7734\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8073 - loss: 0.6480 - val_accuracy: 0.5735 - val_loss: 1.7742\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8076 - loss: 0.6479 - val_accuracy: 0.5740 - val_loss: 1.7705\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8078 - loss: 0.6479 - val_accuracy: 0.5738 - val_loss: 1.7704\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8078 - loss: 0.6478 - val_accuracy: 0.5738 - val_loss: 1.7710\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8074 - loss: 0.6478 - val_accuracy: 0.5738 - val_loss: 1.7736\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8078 - loss: 0.6477 - val_accuracy: 0.5740 - val_loss: 1.7712\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8075 - loss: 0.6477 - val_accuracy: 0.5740 - val_loss: 1.7730\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8079 - loss: 0.6476 - val_accuracy: 0.5738 - val_loss: 1.7732\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8084 - loss: 0.6476 - val_accuracy: 0.5738 - val_loss: 1.7716\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8079 - loss: 0.6475 - val_accuracy: 0.5739 - val_loss: 1.7732\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8076 - loss: 0.6475 - val_accuracy: 0.5739 - val_loss: 1.7756\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8080 - loss: 0.6474 - val_accuracy: 0.5740 - val_loss: 1.7711\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8076 - loss: 0.6474 - val_accuracy: 0.5738 - val_loss: 1.7746\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8087 - loss: 0.6473 - val_accuracy: 0.5739 - val_loss: 1.7726\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8082 - loss: 0.6473 - val_accuracy: 0.5739 - val_loss: 1.7746\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8080 - loss: 0.6472 - val_accuracy: 0.5739 - val_loss: 1.7745\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8076 - loss: 0.6472 - val_accuracy: 0.5739 - val_loss: 1.7813\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8089 - loss: 0.6471 - val_accuracy: 0.5741 - val_loss: 1.7701\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8076 - loss: 0.6471 - val_accuracy: 0.5739 - val_loss: 1.7712\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8080 - loss: 0.6470 - val_accuracy: 0.5740 - val_loss: 1.7750\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8082 - loss: 0.6470 - val_accuracy: 0.5740 - val_loss: 1.7763\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8078 - loss: 0.6469 - val_accuracy: 0.5741 - val_loss: 1.7694\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8084 - loss: 0.6469 - val_accuracy: 0.5740 - val_loss: 1.7733\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8092 - loss: 0.6468 - val_accuracy: 0.5739 - val_loss: 1.7767\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8078 - loss: 0.6468 - val_accuracy: 0.5739 - val_loss: 1.7777\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8081 - loss: 0.6468 - val_accuracy: 0.5739 - val_loss: 1.7743\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8086 - loss: 0.6467 - val_accuracy: 0.5739 - val_loss: 1.7773\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8086 - loss: 0.6467 - val_accuracy: 0.5739 - val_loss: 1.7763\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8087 - loss: 0.6466 - val_accuracy: 0.5740 - val_loss: 1.7754\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8092 - loss: 0.6466 - val_accuracy: 0.5739 - val_loss: 1.7810\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8081 - loss: 0.6465 - val_accuracy: 0.5740 - val_loss: 1.7758\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8093 - loss: 0.6465 - val_accuracy: 0.5739 - val_loss: 1.7789\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8091 - loss: 0.6464 - val_accuracy: 0.5740 - val_loss: 1.7786\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8091 - loss: 0.6464 - val_accuracy: 0.5740 - val_loss: 1.7774\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8091 - loss: 0.6463 - val_accuracy: 0.5740 - val_loss: 1.7777\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8096 - loss: 0.6463 - val_accuracy: 0.5739 - val_loss: 1.7794\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8097 - loss: 0.6463 - val_accuracy: 0.5740 - val_loss: 1.7796\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8089 - loss: 0.6462 - val_accuracy: 0.5741 - val_loss: 1.7777\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8098 - loss: 0.6462 - val_accuracy: 0.5741 - val_loss: 1.7768\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8091 - loss: 0.6461 - val_accuracy: 0.5742 - val_loss: 1.7790\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8093 - loss: 0.6461 - val_accuracy: 0.5739 - val_loss: 1.7804\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8095 - loss: 0.6460 - val_accuracy: 0.5741 - val_loss: 1.7774\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8093 - loss: 0.6460 - val_accuracy: 0.5739 - val_loss: 1.7826\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8099 - loss: 0.6459 - val_accuracy: 0.5739 - val_loss: 1.7827\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8097 - loss: 0.6459 - val_accuracy: 0.5742 - val_loss: 1.7810\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8095 - loss: 0.6459 - val_accuracy: 0.5740 - val_loss: 1.7807\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8093 - loss: 0.6458 - val_accuracy: 0.5739 - val_loss: 1.7813\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8097 - loss: 0.6458 - val_accuracy: 0.5740 - val_loss: 1.7808\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8101 - loss: 0.6457 - val_accuracy: 0.5742 - val_loss: 1.7801\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8100 - loss: 0.6457 - val_accuracy: 0.5741 - val_loss: 1.7780\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8096 - loss: 0.6457 - val_accuracy: 0.5740 - val_loss: 1.7800\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8097 - loss: 0.6456 - val_accuracy: 0.5742 - val_loss: 1.7801\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6456 - val_accuracy: 0.5740 - val_loss: 1.7825\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6455 - val_accuracy: 0.5741 - val_loss: 1.7855\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6455 - val_accuracy: 0.5742 - val_loss: 1.7806\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6454 - val_accuracy: 0.5742 - val_loss: 1.7798\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8100 - loss: 0.6454 - val_accuracy: 0.5740 - val_loss: 1.7818\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8095 - loss: 0.6454 - val_accuracy: 0.5741 - val_loss: 1.7816\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8099 - loss: 0.6453 - val_accuracy: 0.5742 - val_loss: 1.7822\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8098 - loss: 0.6453 - val_accuracy: 0.5686 - val_loss: 1.7867\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8100 - loss: 0.6452 - val_accuracy: 0.5741 - val_loss: 1.7793\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6452 - val_accuracy: 0.5743 - val_loss: 1.7751\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8102 - loss: 0.6452 - val_accuracy: 0.5741 - val_loss: 1.7836\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6451 - val_accuracy: 0.5741 - val_loss: 1.7863\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8103 - loss: 0.6451 - val_accuracy: 0.5741 - val_loss: 1.7847\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6450 - val_accuracy: 0.5741 - val_loss: 1.7859\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8102 - loss: 0.6450 - val_accuracy: 0.5686 - val_loss: 1.7852\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8102 - loss: 0.6450 - val_accuracy: 0.5741 - val_loss: 1.7884\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6449 - val_accuracy: 0.5741 - val_loss: 1.7827\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8103 - loss: 0.6449 - val_accuracy: 0.5741 - val_loss: 1.7839\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8104 - loss: 0.6449 - val_accuracy: 0.5741 - val_loss: 1.7826\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8101 - loss: 0.6448 - val_accuracy: 0.5741 - val_loss: 1.7874\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8103 - loss: 0.6448 - val_accuracy: 0.5742 - val_loss: 1.7879\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8103 - loss: 0.6447 - val_accuracy: 0.5741 - val_loss: 1.7877\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8104 - loss: 0.6447 - val_accuracy: 0.5742 - val_loss: 1.7862\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6447 - val_accuracy: 0.5744 - val_loss: 1.7870\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8104 - loss: 0.6446 - val_accuracy: 0.5742 - val_loss: 1.7856\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8102 - loss: 0.6446 - val_accuracy: 0.5687 - val_loss: 1.7880\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8104 - loss: 0.6446 - val_accuracy: 0.5742 - val_loss: 1.7898\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6445 - val_accuracy: 0.5742 - val_loss: 1.7881\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8104 - loss: 0.6445 - val_accuracy: 0.5745 - val_loss: 1.7867\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6444 - val_accuracy: 0.5687 - val_loss: 1.7896\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8104 - loss: 0.6444 - val_accuracy: 0.5687 - val_loss: 1.7935\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6444 - val_accuracy: 0.5690 - val_loss: 1.7913\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8103 - loss: 0.6443 - val_accuracy: 0.5744 - val_loss: 1.7884\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6443 - val_accuracy: 0.5747 - val_loss: 1.7855\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6443 - val_accuracy: 0.5689 - val_loss: 1.7909\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6442 - val_accuracy: 0.5692 - val_loss: 1.7868\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6442 - val_accuracy: 0.5747 - val_loss: 1.7872\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6442 - val_accuracy: 0.5747 - val_loss: 1.7876\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6441 - val_accuracy: 0.5747 - val_loss: 1.7905\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6441 - val_accuracy: 0.5747 - val_loss: 1.7877\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6441 - val_accuracy: 0.5692 - val_loss: 1.7919\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6440 - val_accuracy: 0.5747 - val_loss: 1.7906\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6440 - val_accuracy: 0.5692 - val_loss: 1.7947\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8107 - loss: 0.6440 - val_accuracy: 0.5747 - val_loss: 1.7881\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6439 - val_accuracy: 0.5747 - val_loss: 1.7896\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6439 - val_accuracy: 0.5689 - val_loss: 1.7949\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6439 - val_accuracy: 0.5691 - val_loss: 1.7922\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6438 - val_accuracy: 0.5689 - val_loss: 1.7942\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6438 - val_accuracy: 0.5747 - val_loss: 1.7864\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6438 - val_accuracy: 0.5746 - val_loss: 1.7899\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8105 - loss: 0.6437 - val_accuracy: 0.5746 - val_loss: 1.7877\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8107 - loss: 0.6437 - val_accuracy: 0.5691 - val_loss: 1.7942\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6437 - val_accuracy: 0.5691 - val_loss: 1.7936\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6436 - val_accuracy: 0.5691 - val_loss: 1.7951\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8107 - loss: 0.6436 - val_accuracy: 0.5691 - val_loss: 1.7944\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6436 - val_accuracy: 0.5691 - val_loss: 1.7888\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8106 - loss: 0.6435 - val_accuracy: 0.5746 - val_loss: 1.7910\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.58805\n726/726 - 5s - 6ms/step - accuracy: 0.8107 - loss: 0.6435 - val_accuracy: 0.5691 - val_loss: 1.7946\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.58805\n726/726 - 5s - 7ms/step - accuracy: 0.8107 - loss: 0.6435 - val_accuracy: 0.5691 - val_loss: 1.7966\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8107 - loss: 0.6434 - val_accuracy: 0.5691 - val_loss: 1.7936\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6434 - val_accuracy: 0.5691 - val_loss: 1.7971\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6434 - val_accuracy: 0.5691 - val_loss: 1.7931\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6433 - val_accuracy: 0.5690 - val_loss: 1.7972\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6433 - val_accuracy: 0.5691 - val_loss: 1.7959\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6433 - val_accuracy: 0.5691 - val_loss: 1.7954\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6432 - val_accuracy: 0.5691 - val_loss: 1.7964\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6432 - val_accuracy: 0.5691 - val_loss: 1.7981\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6432 - val_accuracy: 0.5691 - val_loss: 1.7970\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6431 - val_accuracy: 0.5691 - val_loss: 1.7918\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6431 - val_accuracy: 0.5691 - val_loss: 1.7944\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6431 - val_accuracy: 0.5745 - val_loss: 1.7978\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8106 - loss: 0.6430 - val_accuracy: 0.5691 - val_loss: 1.7940\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6430 - val_accuracy: 0.5690 - val_loss: 1.7990\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8106 - loss: 0.6430 - val_accuracy: 0.5690 - val_loss: 1.7969\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6430 - val_accuracy: 0.5690 - val_loss: 1.7965\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6429 - val_accuracy: 0.5690 - val_loss: 1.7996\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6429 - val_accuracy: 0.5691 - val_loss: 1.7956\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6429 - val_accuracy: 0.5690 - val_loss: 1.7969\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6428 - val_accuracy: 0.5690 - val_loss: 1.7989\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6428 - val_accuracy: 0.5697 - val_loss: 1.7934\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6428 - val_accuracy: 0.5691 - val_loss: 1.7985\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6427 - val_accuracy: 0.5696 - val_loss: 1.8001\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6427 - val_accuracy: 0.5697 - val_loss: 1.7973\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6427 - val_accuracy: 0.5697 - val_loss: 1.7983\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6427 - val_accuracy: 0.5697 - val_loss: 1.7996\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6426 - val_accuracy: 0.5699 - val_loss: 1.7972\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6426 - val_accuracy: 0.5697 - val_loss: 1.8013\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6426 - val_accuracy: 0.5699 - val_loss: 1.8011\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6425 - val_accuracy: 0.5699 - val_loss: 1.7959\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6425 - val_accuracy: 0.5697 - val_loss: 1.8045\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6425 - val_accuracy: 0.5698 - val_loss: 1.8009\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6424 - val_accuracy: 0.5699 - val_loss: 1.7973\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6424 - val_accuracy: 0.5699 - val_loss: 1.8013\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6424 - val_accuracy: 0.5699 - val_loss: 1.7973\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6424 - val_accuracy: 0.5699 - val_loss: 1.8015\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6423 - val_accuracy: 0.5699 - val_loss: 1.7994\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6423 - val_accuracy: 0.5699 - val_loss: 1.8039\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6423 - val_accuracy: 0.5699 - val_loss: 1.8016\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6423 - val_accuracy: 0.5699 - val_loss: 1.8022\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6422 - val_accuracy: 0.5699 - val_loss: 1.8017\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6422 - val_accuracy: 0.5699 - val_loss: 1.8014\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8115 - loss: 0.6422 - val_accuracy: 0.5699 - val_loss: 1.8037\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8107 - loss: 0.6421 - val_accuracy: 0.5699 - val_loss: 1.8031\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8108 - loss: 0.6421 - val_accuracy: 0.5699 - val_loss: 1.8035\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8118 - loss: 0.6421 - val_accuracy: 0.5699 - val_loss: 1.8015\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8111 - loss: 0.6421 - val_accuracy: 0.5699 - val_loss: 1.8008\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8111 - loss: 0.6420 - val_accuracy: 0.5699 - val_loss: 1.8031\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8115 - loss: 0.6420 - val_accuracy: 0.5699 - val_loss: 1.8042\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8118 - loss: 0.6420 - val_accuracy: 0.5699 - val_loss: 1.8084\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8116 - loss: 0.6420 - val_accuracy: 0.5699 - val_loss: 1.8036\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8119 - loss: 0.6419 - val_accuracy: 0.5699 - val_loss: 1.8002\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8119 - loss: 0.6419 - val_accuracy: 0.5699 - val_loss: 1.8049\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8111 - loss: 0.6419 - val_accuracy: 0.5699 - val_loss: 1.8049\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8117 - loss: 0.6418 - val_accuracy: 0.5699 - val_loss: 1.8053\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8116 - loss: 0.6418 - val_accuracy: 0.5699 - val_loss: 1.8074\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8113 - loss: 0.6418 - val_accuracy: 0.5699 - val_loss: 1.8114\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8113 - loss: 0.6418 - val_accuracy: 0.5699 - val_loss: 1.8051\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8111 - loss: 0.6417 - val_accuracy: 0.5699 - val_loss: 1.8056\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8111 - loss: 0.6417 - val_accuracy: 0.5699 - val_loss: 1.8036\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8112 - loss: 0.6417 - val_accuracy: 0.5699 - val_loss: 1.8096\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6417 - val_accuracy: 0.5699 - val_loss: 1.8095\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8111 - loss: 0.6416 - val_accuracy: 0.5699 - val_loss: 1.8048\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6416 - val_accuracy: 0.5699 - val_loss: 1.8055\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6416 - val_accuracy: 0.5699 - val_loss: 1.8084\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6416 - val_accuracy: 0.5700 - val_loss: 1.8037\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6415 - val_accuracy: 0.5699 - val_loss: 1.8058\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6415 - val_accuracy: 0.5699 - val_loss: 1.8059\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6415 - val_accuracy: 0.5701 - val_loss: 1.8063\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8109 - loss: 0.6415 - val_accuracy: 0.5700 - val_loss: 1.8059\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6414 - val_accuracy: 0.5700 - val_loss: 1.8038\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6414 - val_accuracy: 0.5700 - val_loss: 1.8074\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8108 - loss: 0.6414 - val_accuracy: 0.5700 - val_loss: 1.8076\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6413 - val_accuracy: 0.5701 - val_loss: 1.8057\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6413 - val_accuracy: 0.5700 - val_loss: 1.8067\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6413 - val_accuracy: 0.5700 - val_loss: 1.8089\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8108 - loss: 0.6413 - val_accuracy: 0.5701 - val_loss: 1.8057\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6412 - val_accuracy: 0.5701 - val_loss: 1.8070\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8108 - loss: 0.6412 - val_accuracy: 0.5698 - val_loss: 1.8103\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6412 - val_accuracy: 0.5701 - val_loss: 1.8092\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6412 - val_accuracy: 0.5701 - val_loss: 1.8086\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8114 - loss: 0.6411 - val_accuracy: 0.5698 - val_loss: 1.8127\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6411 - val_accuracy: 0.5698 - val_loss: 1.8118\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6411 - val_accuracy: 0.5691 - val_loss: 1.8105\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6411 - val_accuracy: 0.5701 - val_loss: 1.8102\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8111 - loss: 0.6411 - val_accuracy: 0.5701 - val_loss: 1.8064\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6410 - val_accuracy: 0.5701 - val_loss: 1.8097\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6410 - val_accuracy: 0.5698 - val_loss: 1.8129\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8109 - loss: 0.6410 - val_accuracy: 0.5698 - val_loss: 1.8065\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6410 - val_accuracy: 0.5698 - val_loss: 1.8096\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8110 - loss: 0.6409 - val_accuracy: 0.5698 - val_loss: 1.8108\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8114 - loss: 0.6409 - val_accuracy: 0.5698 - val_loss: 1.8144\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8119 - loss: 0.6409 - val_accuracy: 0.5699 - val_loss: 1.8083\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8112 - loss: 0.6409 - val_accuracy: 0.5698 - val_loss: 1.8116\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8120 - loss: 0.6408 - val_accuracy: 0.5698 - val_loss: 1.8094\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8112 - loss: 0.6408 - val_accuracy: 0.5698 - val_loss: 1.8090\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8116 - loss: 0.6408 - val_accuracy: 0.5698 - val_loss: 1.8124\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8115 - loss: 0.6408 - val_accuracy: 0.5698 - val_loss: 1.8114\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8123 - loss: 0.6407 - val_accuracy: 0.5698 - val_loss: 1.8120\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8119 - loss: 0.6407 - val_accuracy: 0.5729 - val_loss: 1.8122\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8117 - loss: 0.6407 - val_accuracy: 0.5729 - val_loss: 1.8118\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8125 - loss: 0.6407 - val_accuracy: 0.5730 - val_loss: 1.8089\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8133 - loss: 0.6406 - val_accuracy: 0.5730 - val_loss: 1.8103\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8128 - loss: 0.6406 - val_accuracy: 0.5698 - val_loss: 1.8138\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8121 - loss: 0.6406 - val_accuracy: 0.5729 - val_loss: 1.8194\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6406 - val_accuracy: 0.5729 - val_loss: 1.8141\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6406 - val_accuracy: 0.5698 - val_loss: 1.8147\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8117 - loss: 0.6405 - val_accuracy: 0.5729 - val_loss: 1.8153\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8135 - loss: 0.6405 - val_accuracy: 0.5729 - val_loss: 1.8137\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6405 - val_accuracy: 0.5698 - val_loss: 1.8125\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8136 - loss: 0.6405 - val_accuracy: 0.5729 - val_loss: 1.8142\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6404 - val_accuracy: 0.5698 - val_loss: 1.8162\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8120 - loss: 0.6404 - val_accuracy: 0.5729 - val_loss: 1.8134\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6404 - val_accuracy: 0.5729 - val_loss: 1.8165\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8128 - loss: 0.6404 - val_accuracy: 0.5729 - val_loss: 1.8153\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8137 - loss: 0.6403 - val_accuracy: 0.5729 - val_loss: 1.8170\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6403 - val_accuracy: 0.5697 - val_loss: 1.8187\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8131 - loss: 0.6403 - val_accuracy: 0.5729 - val_loss: 1.8160\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6403 - val_accuracy: 0.5729 - val_loss: 1.8138\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8138 - loss: 0.6403 - val_accuracy: 0.5729 - val_loss: 1.8115\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8138 - loss: 0.6402 - val_accuracy: 0.5729 - val_loss: 1.8149\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8136 - loss: 0.6402 - val_accuracy: 0.5729 - val_loss: 1.8160\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8138 - loss: 0.6402 - val_accuracy: 0.5729 - val_loss: 1.8123\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8139 - loss: 0.6402 - val_accuracy: 0.5729 - val_loss: 1.8166\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8137 - loss: 0.6402 - val_accuracy: 0.5729 - val_loss: 1.8183\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8137 - loss: 0.6401 - val_accuracy: 0.5725 - val_loss: 1.8182\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8141 - loss: 0.6401 - val_accuracy: 0.5729 - val_loss: 1.8139\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8139 - loss: 0.6401 - val_accuracy: 0.5729 - val_loss: 1.8174\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8142 - loss: 0.6401 - val_accuracy: 0.5725 - val_loss: 1.8170\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8140 - loss: 0.6400 - val_accuracy: 0.5725 - val_loss: 1.8151\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8142 - loss: 0.6400 - val_accuracy: 0.5725 - val_loss: 1.8177\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8142 - loss: 0.6400 - val_accuracy: 0.5725 - val_loss: 1.8179\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8141 - loss: 0.6400 - val_accuracy: 0.5725 - val_loss: 1.8189\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6400 - val_accuracy: 0.5724 - val_loss: 1.8187\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6399 - val_accuracy: 0.5725 - val_loss: 1.8224\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8142 - loss: 0.6399 - val_accuracy: 0.5724 - val_loss: 1.8180\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6399 - val_accuracy: 0.5725 - val_loss: 1.8176\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6399 - val_accuracy: 0.5724 - val_loss: 1.8183\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6398 - val_accuracy: 0.5738 - val_loss: 1.8198\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8147 - loss: 0.6398 - val_accuracy: 0.5724 - val_loss: 1.8207\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6398 - val_accuracy: 0.5725 - val_loss: 1.8218\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6398 - val_accuracy: 0.5725 - val_loss: 1.8155\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6398 - val_accuracy: 0.5725 - val_loss: 1.8198\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6397 - val_accuracy: 0.5725 - val_loss: 1.8228\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6397 - val_accuracy: 0.5724 - val_loss: 1.8224\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6397 - val_accuracy: 0.5725 - val_loss: 1.8215\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6397 - val_accuracy: 0.5724 - val_loss: 1.8214\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6397 - val_accuracy: 0.5716 - val_loss: 1.8243\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6396 - val_accuracy: 0.5738 - val_loss: 1.8172\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6396 - val_accuracy: 0.5724 - val_loss: 1.8218\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6396 - val_accuracy: 0.5725 - val_loss: 1.8241\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8143 - loss: 0.6396 - val_accuracy: 0.5739 - val_loss: 1.8198\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6395 - val_accuracy: 0.5715 - val_loss: 1.8272\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6395 - val_accuracy: 0.5725 - val_loss: 1.8255\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6395 - val_accuracy: 0.5738 - val_loss: 1.8233\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6395 - val_accuracy: 0.5725 - val_loss: 1.8239\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6395 - val_accuracy: 0.5738 - val_loss: 1.8234\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8143 - loss: 0.6394 - val_accuracy: 0.5725 - val_loss: 1.8239\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.58805\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6394 - val_accuracy: 0.5739 - val_loss: 1.8220\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6394 - val_accuracy: 0.5739 - val_loss: 1.8232\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8143 - loss: 0.6394 - val_accuracy: 0.5725 - val_loss: 1.8262\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6394 - val_accuracy: 0.5739 - val_loss: 1.8180\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6394 - val_accuracy: 0.5739 - val_loss: 1.8229\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6393 - val_accuracy: 0.5725 - val_loss: 1.8271\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6393 - val_accuracy: 0.5738 - val_loss: 1.8248\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6393 - val_accuracy: 0.5724 - val_loss: 1.8281\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8143 - loss: 0.6393 - val_accuracy: 0.5738 - val_loss: 1.8244\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6392 - val_accuracy: 0.5738 - val_loss: 1.8257\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6392 - val_accuracy: 0.5739 - val_loss: 1.8226\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6392 - val_accuracy: 0.5725 - val_loss: 1.8292\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8144 - loss: 0.6392 - val_accuracy: 0.5738 - val_loss: 1.8251\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8145 - loss: 0.6392 - val_accuracy: 0.5730 - val_loss: 1.8215\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8143 - loss: 0.6392 - val_accuracy: 0.5739 - val_loss: 1.8239\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.58805\n726/726 - 3s - 5ms/step - accuracy: 0.8146 - loss: 0.6391 - val_accuracy: 0.5738 - val_loss: 1.8270\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8142 - loss: 0.6391 - val_accuracy: 0.5738 - val_loss: 1.8225\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.58805\n726/726 - 4s - 5ms/step - accuracy: 0.8146 - loss: 0.6391 - val_accuracy: 0.5738 - val_loss: 1.8276\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_25, X_test_25, y_train_25, y_test_25 = train_test_split(\n    X, y, test_size=0.3, random_state=67, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_25, X_val_25, y_train_25, y_val_25 = train_test_split(\n    X_train_25, y_train_25, test_size=0.2, random_state=67, stratify=y_train_25\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_25:\", np.max(X_train_25))\nprint(\"Min value in X_train_25:\", np.min(X_train_25))\n\nX_train_25_scaled = scaler.fit_transform(X_train_25)\n\n# Get the original class distribution\nclass_counts_25 = Counter(y_train_25)\nprint(\"Original class distribution:\", class_counts_25)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_25 = class_counts_25[min(class_counts_25, key=class_counts_25.get)]\ndesired_majority_size_25 = minority_class_size_25 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_25 = {0: desired_majority_size_25, 1: minority_class_size_25}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_25 = RandomUnderSampler(sampling_strategy=sampling_strategy_25, random_state=42)\nX_resampled_25, y_resampled_25 = undersampler_25.fit_resample(X_train_25, y_train_25)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_25))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_25, y_train_resampled_25 = smote.fit_resample(X_resampled_25, y_resampled_25)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_25))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_25))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T00:51:00.794708Z","iopub.execute_input":"2025-03-08T00:51:00.795160Z","iopub.status.idle":"2025-03-08T00:51:30.213288Z","shell.execute_reply.started":"2025-03-08T00:51:00.795124Z","shell.execute_reply":"2025-03-08T00:51:30.212244Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_25: 2071000000.0\nMin value in X_train_25: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_25 = X_train_resampled_25.reshape(X_train_resampled_25.shape[0], 1, 56)\nX_val_25 = X_val_25.reshape(X_val_25.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_25,  # Features from CICIDS2017\n    y_train_resampled_25,  # Labels from CICIDS2017\n    validation_data=(X_val_25, y_val_25),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T00:51:30.214412Z","iopub.execute_input":"2025-03-08T00:51:30.214666Z","iopub.status.idle":"2025-03-08T01:27:10.257884Z","shell.execute_reply.started":"2025-03-08T00:51:30.214638Z","shell.execute_reply":"2025-03-08T01:27:10.256493Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy improved from -inf to 0.58494, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 7s - 10ms/step - accuracy: 0.7974 - loss: 0.7182 - val_accuracy: 0.5849 - val_loss: 1.6307\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.7962 - loss: 0.7092 - val_accuracy: 0.5840 - val_loss: 1.6387\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.7967 - loss: 0.7042 - val_accuracy: 0.5838 - val_loss: 1.6479\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.7964 - loss: 0.7008 - val_accuracy: 0.5837 - val_loss: 1.6544\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6982 - val_accuracy: 0.5842 - val_loss: 1.6620\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8055 - loss: 0.6962 - val_accuracy: 0.5843 - val_loss: 1.6619\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8059 - loss: 0.6946 - val_accuracy: 0.5841 - val_loss: 1.6691\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8058 - loss: 0.6932 - val_accuracy: 0.5833 - val_loss: 1.6777\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6921 - val_accuracy: 0.5831 - val_loss: 1.6801\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6910 - val_accuracy: 0.5834 - val_loss: 1.6808\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8059 - loss: 0.6901 - val_accuracy: 0.5817 - val_loss: 1.6828\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6893 - val_accuracy: 0.5815 - val_loss: 1.6858\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8059 - loss: 0.6885 - val_accuracy: 0.5815 - val_loss: 1.6891\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6878 - val_accuracy: 0.5815 - val_loss: 1.6955\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8058 - loss: 0.6871 - val_accuracy: 0.5815 - val_loss: 1.6925\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6864 - val_accuracy: 0.5814 - val_loss: 1.6966\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6858 - val_accuracy: 0.5814 - val_loss: 1.6943\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6852 - val_accuracy: 0.5816 - val_loss: 1.6979\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6847 - val_accuracy: 0.5816 - val_loss: 1.6978\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6841 - val_accuracy: 0.5815 - val_loss: 1.6989\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6836 - val_accuracy: 0.5815 - val_loss: 1.7011\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6831 - val_accuracy: 0.5815 - val_loss: 1.7022\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8059 - loss: 0.6826 - val_accuracy: 0.5816 - val_loss: 1.7013\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8067 - loss: 0.6821 - val_accuracy: 0.5816 - val_loss: 1.7052\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8073 - loss: 0.6817 - val_accuracy: 0.5816 - val_loss: 1.7036\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8073 - loss: 0.6812 - val_accuracy: 0.5816 - val_loss: 1.7066\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6808 - val_accuracy: 0.5809 - val_loss: 1.7082\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6804 - val_accuracy: 0.5809 - val_loss: 1.7089\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6800 - val_accuracy: 0.5809 - val_loss: 1.7069\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8073 - loss: 0.6796 - val_accuracy: 0.5812 - val_loss: 1.7057\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8073 - loss: 0.6792 - val_accuracy: 0.5799 - val_loss: 1.7068\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6788 - val_accuracy: 0.5795 - val_loss: 1.7075\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6784 - val_accuracy: 0.5794 - val_loss: 1.7102\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6780 - val_accuracy: 0.5792 - val_loss: 1.7081\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6777 - val_accuracy: 0.5795 - val_loss: 1.7069\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6773 - val_accuracy: 0.5792 - val_loss: 1.7089\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6770 - val_accuracy: 0.5792 - val_loss: 1.7099\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8076 - loss: 0.6766 - val_accuracy: 0.5793 - val_loss: 1.7078\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6763 - val_accuracy: 0.5793 - val_loss: 1.7094\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6760 - val_accuracy: 0.5793 - val_loss: 1.7106\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6756 - val_accuracy: 0.5791 - val_loss: 1.7124\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6753 - val_accuracy: 0.5790 - val_loss: 1.7091\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6750 - val_accuracy: 0.5790 - val_loss: 1.7109\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8078 - loss: 0.6747 - val_accuracy: 0.5796 - val_loss: 1.7126\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8083 - loss: 0.6744 - val_accuracy: 0.5796 - val_loss: 1.7144\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8084 - loss: 0.6741 - val_accuracy: 0.5792 - val_loss: 1.7149\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6738 - val_accuracy: 0.5792 - val_loss: 1.7136\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6735 - val_accuracy: 0.5792 - val_loss: 1.7123\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6732 - val_accuracy: 0.5792 - val_loss: 1.7111\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6730 - val_accuracy: 0.5792 - val_loss: 1.7101\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6727 - val_accuracy: 0.5792 - val_loss: 1.7141\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6724 - val_accuracy: 0.5794 - val_loss: 1.7156\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6722 - val_accuracy: 0.5794 - val_loss: 1.7151\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6719 - val_accuracy: 0.5794 - val_loss: 1.7159\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6716 - val_accuracy: 0.5794 - val_loss: 1.7130\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8085 - loss: 0.6714 - val_accuracy: 0.5795 - val_loss: 1.7090\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8084 - loss: 0.6712 - val_accuracy: 0.5787 - val_loss: 1.7175\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8088 - loss: 0.6709 - val_accuracy: 0.5792 - val_loss: 1.7119\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8119 - loss: 0.6707 - val_accuracy: 0.5792 - val_loss: 1.7162\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8140 - loss: 0.6704 - val_accuracy: 0.5790 - val_loss: 1.7141\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6702 - val_accuracy: 0.5789 - val_loss: 1.7139\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6700 - val_accuracy: 0.5789 - val_loss: 1.7129\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8150 - loss: 0.6697 - val_accuracy: 0.5789 - val_loss: 1.7120\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6695 - val_accuracy: 0.5789 - val_loss: 1.7160\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8150 - loss: 0.6693 - val_accuracy: 0.5789 - val_loss: 1.7149\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6691 - val_accuracy: 0.5789 - val_loss: 1.7131\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6688 - val_accuracy: 0.5784 - val_loss: 1.7170\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8143 - loss: 0.6686 - val_accuracy: 0.5789 - val_loss: 1.7150\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6684 - val_accuracy: 0.5789 - val_loss: 1.7150\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6682 - val_accuracy: 0.5789 - val_loss: 1.7118\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8139 - loss: 0.6680 - val_accuracy: 0.5779 - val_loss: 1.7180\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6678 - val_accuracy: 0.5784 - val_loss: 1.7158\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6676 - val_accuracy: 0.5789 - val_loss: 1.7168\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6674 - val_accuracy: 0.5789 - val_loss: 1.7149\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6672 - val_accuracy: 0.5784 - val_loss: 1.7178\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6670 - val_accuracy: 0.5789 - val_loss: 1.7165\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6668 - val_accuracy: 0.5789 - val_loss: 1.7195\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6666 - val_accuracy: 0.5779 - val_loss: 1.7162\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8136 - loss: 0.6664 - val_accuracy: 0.5784 - val_loss: 1.7188\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6662 - val_accuracy: 0.5784 - val_loss: 1.7178\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6660 - val_accuracy: 0.5784 - val_loss: 1.7193\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8136 - loss: 0.6658 - val_accuracy: 0.5784 - val_loss: 1.7181\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8136 - loss: 0.6657 - val_accuracy: 0.5788 - val_loss: 1.7178\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6655 - val_accuracy: 0.5779 - val_loss: 1.7152\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6653 - val_accuracy: 0.5785 - val_loss: 1.7110\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6651 - val_accuracy: 0.5780 - val_loss: 1.7154\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8136 - loss: 0.6649 - val_accuracy: 0.5779 - val_loss: 1.7191\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6648 - val_accuracy: 0.5790 - val_loss: 1.7160\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8136 - loss: 0.6646 - val_accuracy: 0.5785 - val_loss: 1.7134\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6644 - val_accuracy: 0.5784 - val_loss: 1.7180\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6643 - val_accuracy: 0.5785 - val_loss: 1.7187\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8134 - loss: 0.6641 - val_accuracy: 0.5779 - val_loss: 1.7187\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8134 - loss: 0.6639 - val_accuracy: 0.5779 - val_loss: 1.7191\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6638 - val_accuracy: 0.5780 - val_loss: 1.7158\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8134 - loss: 0.6636 - val_accuracy: 0.5785 - val_loss: 1.7149\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8134 - loss: 0.6634 - val_accuracy: 0.5780 - val_loss: 1.7193\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6633 - val_accuracy: 0.5780 - val_loss: 1.7200\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6631 - val_accuracy: 0.5779 - val_loss: 1.7179\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6630 - val_accuracy: 0.5780 - val_loss: 1.7161\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8133 - loss: 0.6628 - val_accuracy: 0.5779 - val_loss: 1.7171\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8131 - loss: 0.6627 - val_accuracy: 0.5781 - val_loss: 1.7172\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6625 - val_accuracy: 0.5781 - val_loss: 1.7173\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8131 - loss: 0.6624 - val_accuracy: 0.5781 - val_loss: 1.7165\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8132 - loss: 0.6622 - val_accuracy: 0.5781 - val_loss: 1.7133\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8131 - loss: 0.6621 - val_accuracy: 0.5776 - val_loss: 1.7184\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8134 - loss: 0.6619 - val_accuracy: 0.5776 - val_loss: 1.7192\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8134 - loss: 0.6618 - val_accuracy: 0.5779 - val_loss: 1.7190\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8136 - loss: 0.6616 - val_accuracy: 0.5779 - val_loss: 1.7192\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8135 - loss: 0.6615 - val_accuracy: 0.5779 - val_loss: 1.7152\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6613 - val_accuracy: 0.5776 - val_loss: 1.7167\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8135 - loss: 0.6612 - val_accuracy: 0.5816 - val_loss: 1.7178\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6610 - val_accuracy: 0.5775 - val_loss: 1.7204\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6609 - val_accuracy: 0.5776 - val_loss: 1.7215\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8140 - loss: 0.6608 - val_accuracy: 0.5792 - val_loss: 1.7155\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6606 - val_accuracy: 0.5791 - val_loss: 1.7184\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6605 - val_accuracy: 0.5831 - val_loss: 1.7188\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6604 - val_accuracy: 0.5830 - val_loss: 1.7221\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6602 - val_accuracy: 0.5830 - val_loss: 1.7205\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6601 - val_accuracy: 0.5790 - val_loss: 1.7201\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6600 - val_accuracy: 0.5790 - val_loss: 1.7203\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8148 - loss: 0.6598 - val_accuracy: 0.5830 - val_loss: 1.7211\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8146 - loss: 0.6597 - val_accuracy: 0.5830 - val_loss: 1.7243\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8149 - loss: 0.6596 - val_accuracy: 0.5790 - val_loss: 1.7244\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6595 - val_accuracy: 0.5830 - val_loss: 1.7183\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6593 - val_accuracy: 0.5791 - val_loss: 1.7190\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6592 - val_accuracy: 0.5830 - val_loss: 1.7240\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6591 - val_accuracy: 0.5830 - val_loss: 1.7167\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8144 - loss: 0.6590 - val_accuracy: 0.5830 - val_loss: 1.7201\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8145 - loss: 0.6588 - val_accuracy: 0.5830 - val_loss: 1.7218\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6587 - val_accuracy: 0.5791 - val_loss: 1.7213\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6586 - val_accuracy: 0.5791 - val_loss: 1.7221\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8144 - loss: 0.6585 - val_accuracy: 0.5830 - val_loss: 1.7170\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6584 - val_accuracy: 0.5830 - val_loss: 1.7183\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6582 - val_accuracy: 0.5821 - val_loss: 1.7200\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8144 - loss: 0.6581 - val_accuracy: 0.5821 - val_loss: 1.7213\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8152 - loss: 0.6580 - val_accuracy: 0.5821 - val_loss: 1.7231\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6579 - val_accuracy: 0.5821 - val_loss: 1.7196\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6578 - val_accuracy: 0.5821 - val_loss: 1.7223\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6577 - val_accuracy: 0.5821 - val_loss: 1.7228\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6576 - val_accuracy: 0.5821 - val_loss: 1.7191\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6574 - val_accuracy: 0.5821 - val_loss: 1.7215\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6573 - val_accuracy: 0.5821 - val_loss: 1.7227\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6572 - val_accuracy: 0.5821 - val_loss: 1.7219\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6571 - val_accuracy: 0.5821 - val_loss: 1.7238\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6570 - val_accuracy: 0.5815 - val_loss: 1.7212\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6569 - val_accuracy: 0.5815 - val_loss: 1.7204\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6568 - val_accuracy: 0.5821 - val_loss: 1.7214\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6567 - val_accuracy: 0.5776 - val_loss: 1.7260\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6566 - val_accuracy: 0.5815 - val_loss: 1.7234\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6565 - val_accuracy: 0.5815 - val_loss: 1.7219\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6564 - val_accuracy: 0.5817 - val_loss: 1.7239\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8144 - loss: 0.6563 - val_accuracy: 0.5818 - val_loss: 1.7210\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8141 - loss: 0.6562 - val_accuracy: 0.5814 - val_loss: 1.7227\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6561 - val_accuracy: 0.5775 - val_loss: 1.7249\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6560 - val_accuracy: 0.5775 - val_loss: 1.7283\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8154 - loss: 0.6559 - val_accuracy: 0.5814 - val_loss: 1.7232\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6558 - val_accuracy: 0.5819 - val_loss: 1.7251\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6557 - val_accuracy: 0.5817 - val_loss: 1.7260\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6556 - val_accuracy: 0.5817 - val_loss: 1.7206\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6555 - val_accuracy: 0.5817 - val_loss: 1.7261\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6554 - val_accuracy: 0.5819 - val_loss: 1.7248\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6553 - val_accuracy: 0.5814 - val_loss: 1.7240\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6552 - val_accuracy: 0.5817 - val_loss: 1.7248\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6551 - val_accuracy: 0.5817 - val_loss: 1.7254\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6550 - val_accuracy: 0.5819 - val_loss: 1.7250\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8162 - loss: 0.6549 - val_accuracy: 0.5778 - val_loss: 1.7266\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8153 - loss: 0.6548 - val_accuracy: 0.5817 - val_loss: 1.7210\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8160 - loss: 0.6547 - val_accuracy: 0.5778 - val_loss: 1.7263\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6546 - val_accuracy: 0.5819 - val_loss: 1.7270\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8153 - loss: 0.6545 - val_accuracy: 0.5815 - val_loss: 1.7232\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8156 - loss: 0.6544 - val_accuracy: 0.5819 - val_loss: 1.7219\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6544 - val_accuracy: 0.5817 - val_loss: 1.7247\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6543 - val_accuracy: 0.5774 - val_loss: 1.7264\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8157 - loss: 0.6542 - val_accuracy: 0.5774 - val_loss: 1.7258\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6541 - val_accuracy: 0.5778 - val_loss: 1.7230\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6540 - val_accuracy: 0.5776 - val_loss: 1.7264\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6539 - val_accuracy: 0.5774 - val_loss: 1.7279\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6538 - val_accuracy: 0.5818 - val_loss: 1.7236\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6537 - val_accuracy: 0.5815 - val_loss: 1.7263\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6537 - val_accuracy: 0.5816 - val_loss: 1.7274\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8160 - loss: 0.6536 - val_accuracy: 0.5814 - val_loss: 1.7296\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6535 - val_accuracy: 0.5814 - val_loss: 1.7246\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6534 - val_accuracy: 0.5771 - val_loss: 1.7305\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6533 - val_accuracy: 0.5813 - val_loss: 1.7267\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8162 - loss: 0.6532 - val_accuracy: 0.5774 - val_loss: 1.7272\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6532 - val_accuracy: 0.5771 - val_loss: 1.7272\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8171 - loss: 0.6531 - val_accuracy: 0.5770 - val_loss: 1.7289\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8164 - loss: 0.6530 - val_accuracy: 0.5771 - val_loss: 1.7294\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6529 - val_accuracy: 0.5770 - val_loss: 1.7250\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6528 - val_accuracy: 0.5811 - val_loss: 1.7261\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8169 - loss: 0.6527 - val_accuracy: 0.5770 - val_loss: 1.7287\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6527 - val_accuracy: 0.5811 - val_loss: 1.7269\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6526 - val_accuracy: 0.5773 - val_loss: 1.7267\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8163 - loss: 0.6525 - val_accuracy: 0.5770 - val_loss: 1.7291\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8175 - loss: 0.6524 - val_accuracy: 0.5770 - val_loss: 1.7294\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8171 - loss: 0.6524 - val_accuracy: 0.5770 - val_loss: 1.7272\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6523 - val_accuracy: 0.5770 - val_loss: 1.7288\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8171 - loss: 0.6522 - val_accuracy: 0.5770 - val_loss: 1.7280\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6521 - val_accuracy: 0.5773 - val_loss: 1.7272\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8170 - loss: 0.6520 - val_accuracy: 0.5770 - val_loss: 1.7265\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8170 - loss: 0.6520 - val_accuracy: 0.5812 - val_loss: 1.7272\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6519 - val_accuracy: 0.5770 - val_loss: 1.7308\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6518 - val_accuracy: 0.5769 - val_loss: 1.7307\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8174 - loss: 0.6518 - val_accuracy: 0.5770 - val_loss: 1.7296\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6517 - val_accuracy: 0.5770 - val_loss: 1.7319\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8170 - loss: 0.6516 - val_accuracy: 0.5770 - val_loss: 1.7292\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8179 - loss: 0.6515 - val_accuracy: 0.5770 - val_loss: 1.7297\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6515 - val_accuracy: 0.5770 - val_loss: 1.7293\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8173 - loss: 0.6514 - val_accuracy: 0.5771 - val_loss: 1.7325\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6513 - val_accuracy: 0.5773 - val_loss: 1.7269\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6512 - val_accuracy: 0.5770 - val_loss: 1.7312\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6512 - val_accuracy: 0.5770 - val_loss: 1.7356\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6511 - val_accuracy: 0.5770 - val_loss: 1.7282\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8178 - loss: 0.6510 - val_accuracy: 0.5769 - val_loss: 1.7322\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8177 - loss: 0.6510 - val_accuracy: 0.5769 - val_loss: 1.7318\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6509 - val_accuracy: 0.5769 - val_loss: 1.7310\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8179 - loss: 0.6508 - val_accuracy: 0.5771 - val_loss: 1.7325\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6507 - val_accuracy: 0.5769 - val_loss: 1.7349\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6507 - val_accuracy: 0.5773 - val_loss: 1.7330\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6506 - val_accuracy: 0.5768 - val_loss: 1.7359\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8185 - loss: 0.6505 - val_accuracy: 0.5770 - val_loss: 1.7322\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8175 - loss: 0.6505 - val_accuracy: 0.5770 - val_loss: 1.7346\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6504 - val_accuracy: 0.5773 - val_loss: 1.7276\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8185 - loss: 0.6503 - val_accuracy: 0.5770 - val_loss: 1.7312\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8181 - loss: 0.6503 - val_accuracy: 0.5773 - val_loss: 1.7313\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8174 - loss: 0.6502 - val_accuracy: 0.5770 - val_loss: 1.7334\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8184 - loss: 0.6501 - val_accuracy: 0.5769 - val_loss: 1.7357\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6501 - val_accuracy: 0.5773 - val_loss: 1.7346\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6500 - val_accuracy: 0.5773 - val_loss: 1.7322\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6499 - val_accuracy: 0.5730 - val_loss: 1.7326\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8173 - loss: 0.6499 - val_accuracy: 0.5770 - val_loss: 1.7332\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8177 - loss: 0.6498 - val_accuracy: 0.5770 - val_loss: 1.7296\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8185 - loss: 0.6498 - val_accuracy: 0.5771 - val_loss: 1.7310\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6497 - val_accuracy: 0.5771 - val_loss: 1.7326\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8180 - loss: 0.6496 - val_accuracy: 0.5768 - val_loss: 1.7340\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6496 - val_accuracy: 0.5768 - val_loss: 1.7343\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6495 - val_accuracy: 0.5766 - val_loss: 1.7354\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6494 - val_accuracy: 0.5767 - val_loss: 1.7325\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6494 - val_accuracy: 0.5769 - val_loss: 1.7326\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6493 - val_accuracy: 0.5726 - val_loss: 1.7332\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6492 - val_accuracy: 0.5726 - val_loss: 1.7347\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8178 - loss: 0.6492 - val_accuracy: 0.5767 - val_loss: 1.7356\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6491 - val_accuracy: 0.5767 - val_loss: 1.7362\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6491 - val_accuracy: 0.5766 - val_loss: 1.7385\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8180 - loss: 0.6490 - val_accuracy: 0.5767 - val_loss: 1.7317\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8171 - loss: 0.6490 - val_accuracy: 0.5766 - val_loss: 1.7333\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8169 - loss: 0.6489 - val_accuracy: 0.5766 - val_loss: 1.7370\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8179 - loss: 0.6488 - val_accuracy: 0.5767 - val_loss: 1.7374\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6488 - val_accuracy: 0.5767 - val_loss: 1.7364\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8178 - loss: 0.6487 - val_accuracy: 0.5770 - val_loss: 1.7367\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8180 - loss: 0.6487 - val_accuracy: 0.5770 - val_loss: 1.7298\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8183 - loss: 0.6486 - val_accuracy: 0.5767 - val_loss: 1.7357\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6485 - val_accuracy: 0.5767 - val_loss: 1.7348\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8180 - loss: 0.6485 - val_accuracy: 0.5770 - val_loss: 1.7323\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6484 - val_accuracy: 0.5767 - val_loss: 1.7354\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8180 - loss: 0.6484 - val_accuracy: 0.5770 - val_loss: 1.7327\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8185 - loss: 0.6483 - val_accuracy: 0.5768 - val_loss: 1.7334\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8162 - loss: 0.6482 - val_accuracy: 0.5767 - val_loss: 1.7370\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8186 - loss: 0.6482 - val_accuracy: 0.5767 - val_loss: 1.7349\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8179 - loss: 0.6481 - val_accuracy: 0.5728 - val_loss: 1.7362\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.58494\n726/726 - 4s - 5ms/step - accuracy: 0.8181 - loss: 0.6481 - val_accuracy: 0.5730 - val_loss: 1.7325\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6480 - val_accuracy: 0.5728 - val_loss: 1.7351\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6480 - val_accuracy: 0.5767 - val_loss: 1.7363\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8185 - loss: 0.6479 - val_accuracy: 0.5767 - val_loss: 1.7358\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8189 - loss: 0.6479 - val_accuracy: 0.5767 - val_loss: 1.7375\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6478 - val_accuracy: 0.5725 - val_loss: 1.7380\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8179 - loss: 0.6478 - val_accuracy: 0.5767 - val_loss: 1.7375\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6477 - val_accuracy: 0.5767 - val_loss: 1.7391\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8181 - loss: 0.6476 - val_accuracy: 0.5767 - val_loss: 1.7378\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6476 - val_accuracy: 0.5767 - val_loss: 1.7392\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8189 - loss: 0.6475 - val_accuracy: 0.5767 - val_loss: 1.7374\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8189 - loss: 0.6475 - val_accuracy: 0.5767 - val_loss: 1.7377\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6474 - val_accuracy: 0.5767 - val_loss: 1.7363\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8185 - loss: 0.6474 - val_accuracy: 0.5767 - val_loss: 1.7400\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6473 - val_accuracy: 0.5767 - val_loss: 1.7381\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6473 - val_accuracy: 0.5767 - val_loss: 1.7394\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6472 - val_accuracy: 0.5767 - val_loss: 1.7380\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6472 - val_accuracy: 0.5766 - val_loss: 1.7414\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8188 - loss: 0.6471 - val_accuracy: 0.5724 - val_loss: 1.7391\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6471 - val_accuracy: 0.5767 - val_loss: 1.7409\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6470 - val_accuracy: 0.5766 - val_loss: 1.7403\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8174 - loss: 0.6470 - val_accuracy: 0.5767 - val_loss: 1.7381\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8174 - loss: 0.6469 - val_accuracy: 0.5766 - val_loss: 1.7387\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6469 - val_accuracy: 0.5767 - val_loss: 1.7357\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8190 - loss: 0.6468 - val_accuracy: 0.5724 - val_loss: 1.7391\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8189 - loss: 0.6468 - val_accuracy: 0.5767 - val_loss: 1.7414\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6467 - val_accuracy: 0.5767 - val_loss: 1.7425\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6467 - val_accuracy: 0.5773 - val_loss: 1.7399\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6466 - val_accuracy: 0.5767 - val_loss: 1.7386\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8180 - loss: 0.6466 - val_accuracy: 0.5724 - val_loss: 1.7405\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6465 - val_accuracy: 0.5767 - val_loss: 1.7415\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8186 - loss: 0.6465 - val_accuracy: 0.5724 - val_loss: 1.7409\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6464 - val_accuracy: 0.5730 - val_loss: 1.7388\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8174 - loss: 0.6464 - val_accuracy: 0.5767 - val_loss: 1.7384\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8187 - loss: 0.6463 - val_accuracy: 0.5767 - val_loss: 1.7407\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6463 - val_accuracy: 0.5730 - val_loss: 1.7399\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8179 - loss: 0.6462 - val_accuracy: 0.5773 - val_loss: 1.7421\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6462 - val_accuracy: 0.5767 - val_loss: 1.7435\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6461 - val_accuracy: 0.5730 - val_loss: 1.7396\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6461 - val_accuracy: 0.5730 - val_loss: 1.7405\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6460 - val_accuracy: 0.5730 - val_loss: 1.7436\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8177 - loss: 0.6460 - val_accuracy: 0.5773 - val_loss: 1.7385\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6459 - val_accuracy: 0.5773 - val_loss: 1.7400\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8175 - loss: 0.6459 - val_accuracy: 0.5773 - val_loss: 1.7427\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6458 - val_accuracy: 0.5773 - val_loss: 1.7406\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6458 - val_accuracy: 0.5773 - val_loss: 1.7434\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8185 - loss: 0.6457 - val_accuracy: 0.5773 - val_loss: 1.7416\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8191 - loss: 0.6457 - val_accuracy: 0.5730 - val_loss: 1.7404\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8182 - loss: 0.6457 - val_accuracy: 0.5730 - val_loss: 1.7427\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6456 - val_accuracy: 0.5730 - val_loss: 1.7410\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8180 - loss: 0.6456 - val_accuracy: 0.5773 - val_loss: 1.7415\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8185 - loss: 0.6455 - val_accuracy: 0.5773 - val_loss: 1.7479\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8193 - loss: 0.6455 - val_accuracy: 0.5773 - val_loss: 1.7428\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8184 - loss: 0.6454 - val_accuracy: 0.5730 - val_loss: 1.7437\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8176 - loss: 0.6454 - val_accuracy: 0.5730 - val_loss: 1.7422\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8188 - loss: 0.6453 - val_accuracy: 0.5772 - val_loss: 1.7451\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6453 - val_accuracy: 0.5730 - val_loss: 1.7454\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8183 - loss: 0.6453 - val_accuracy: 0.5730 - val_loss: 1.7459\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8173 - loss: 0.6452 - val_accuracy: 0.5773 - val_loss: 1.7427\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8180 - loss: 0.6452 - val_accuracy: 0.5730 - val_loss: 1.7407\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8171 - loss: 0.6451 - val_accuracy: 0.5773 - val_loss: 1.7457\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8164 - loss: 0.6451 - val_accuracy: 0.5730 - val_loss: 1.7491\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8174 - loss: 0.6450 - val_accuracy: 0.5730 - val_loss: 1.7431\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8174 - loss: 0.6450 - val_accuracy: 0.5772 - val_loss: 1.7446\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8164 - loss: 0.6449 - val_accuracy: 0.5730 - val_loss: 1.7418\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8159 - loss: 0.6449 - val_accuracy: 0.5773 - val_loss: 1.7474\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8178 - loss: 0.6449 - val_accuracy: 0.5773 - val_loss: 1.7445\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8189 - loss: 0.6448 - val_accuracy: 0.5730 - val_loss: 1.7401\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8142 - loss: 0.6448 - val_accuracy: 0.5735 - val_loss: 1.7403\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8174 - loss: 0.6447 - val_accuracy: 0.5730 - val_loss: 1.7414\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6447 - val_accuracy: 0.5702 - val_loss: 1.7433\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8133 - loss: 0.6446 - val_accuracy: 0.5772 - val_loss: 1.7435\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8174 - loss: 0.6446 - val_accuracy: 0.5702 - val_loss: 1.7449\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8139 - loss: 0.6446 - val_accuracy: 0.5744 - val_loss: 1.7433\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8162 - loss: 0.6445 - val_accuracy: 0.5749 - val_loss: 1.7404\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8176 - loss: 0.6445 - val_accuracy: 0.5701 - val_loss: 1.7477\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8140 - loss: 0.6444 - val_accuracy: 0.5701 - val_loss: 1.7465\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6444 - val_accuracy: 0.5744 - val_loss: 1.7437\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6444 - val_accuracy: 0.5702 - val_loss: 1.7461\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8159 - loss: 0.6443 - val_accuracy: 0.5702 - val_loss: 1.7435\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6443 - val_accuracy: 0.5701 - val_loss: 1.7492\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6442 - val_accuracy: 0.5701 - val_loss: 1.7476\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6442 - val_accuracy: 0.5700 - val_loss: 1.7442\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8140 - loss: 0.6441 - val_accuracy: 0.5661 - val_loss: 1.7471\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8149 - loss: 0.6441 - val_accuracy: 0.5701 - val_loss: 1.7435\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6441 - val_accuracy: 0.5697 - val_loss: 1.7448\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8144 - loss: 0.6440 - val_accuracy: 0.5657 - val_loss: 1.7476\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8137 - loss: 0.6440 - val_accuracy: 0.5697 - val_loss: 1.7466\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6439 - val_accuracy: 0.5699 - val_loss: 1.7481\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8144 - loss: 0.6439 - val_accuracy: 0.5658 - val_loss: 1.7448\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6439 - val_accuracy: 0.5657 - val_loss: 1.7491\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6438 - val_accuracy: 0.5700 - val_loss: 1.7482\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6438 - val_accuracy: 0.5657 - val_loss: 1.7523\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8132 - loss: 0.6437 - val_accuracy: 0.5700 - val_loss: 1.7469\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8150 - loss: 0.6437 - val_accuracy: 0.5657 - val_loss: 1.7490\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6437 - val_accuracy: 0.5700 - val_loss: 1.7458\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6436 - val_accuracy: 0.5700 - val_loss: 1.7474\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8140 - loss: 0.6436 - val_accuracy: 0.5700 - val_loss: 1.7487\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6436 - val_accuracy: 0.5657 - val_loss: 1.7495\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8138 - loss: 0.6435 - val_accuracy: 0.5657 - val_loss: 1.7486\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8149 - loss: 0.6435 - val_accuracy: 0.5658 - val_loss: 1.7461\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8142 - loss: 0.6434 - val_accuracy: 0.5700 - val_loss: 1.7503\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6434 - val_accuracy: 0.5657 - val_loss: 1.7468\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6434 - val_accuracy: 0.5700 - val_loss: 1.7464\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6433 - val_accuracy: 0.5657 - val_loss: 1.7487\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6433 - val_accuracy: 0.5657 - val_loss: 1.7482\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8153 - loss: 0.6432 - val_accuracy: 0.5657 - val_loss: 1.7506\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8167 - loss: 0.6432 - val_accuracy: 0.5657 - val_loss: 1.7489\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8153 - loss: 0.6432 - val_accuracy: 0.5657 - val_loss: 1.7481\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6431 - val_accuracy: 0.5657 - val_loss: 1.7491\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8161 - loss: 0.6431 - val_accuracy: 0.5657 - val_loss: 1.7523\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8150 - loss: 0.6431 - val_accuracy: 0.5657 - val_loss: 1.7522\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6430 - val_accuracy: 0.5657 - val_loss: 1.7493\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8156 - loss: 0.6430 - val_accuracy: 0.5657 - val_loss: 1.7504\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8150 - loss: 0.6429 - val_accuracy: 0.5657 - val_loss: 1.7507\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8154 - loss: 0.6429 - val_accuracy: 0.5705 - val_loss: 1.7466\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6429 - val_accuracy: 0.5657 - val_loss: 1.7512\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6428 - val_accuracy: 0.5657 - val_loss: 1.7488\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6428 - val_accuracy: 0.5657 - val_loss: 1.7492\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6428 - val_accuracy: 0.5657 - val_loss: 1.7480\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6427 - val_accuracy: 0.5662 - val_loss: 1.7466\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8154 - loss: 0.6427 - val_accuracy: 0.5699 - val_loss: 1.7521\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8155 - loss: 0.6427 - val_accuracy: 0.5699 - val_loss: 1.7507\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8152 - loss: 0.6426 - val_accuracy: 0.5657 - val_loss: 1.7468\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6426 - val_accuracy: 0.5700 - val_loss: 1.7490\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6426 - val_accuracy: 0.5699 - val_loss: 1.7507\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6425 - val_accuracy: 0.5657 - val_loss: 1.7519\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6425 - val_accuracy: 0.5699 - val_loss: 1.7533\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6424 - val_accuracy: 0.5700 - val_loss: 1.7515\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6424 - val_accuracy: 0.5701 - val_loss: 1.7534\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8157 - loss: 0.6424 - val_accuracy: 0.5700 - val_loss: 1.7498\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6423 - val_accuracy: 0.5664 - val_loss: 1.7491\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8158 - loss: 0.6423 - val_accuracy: 0.5658 - val_loss: 1.7555\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8153 - loss: 0.6423 - val_accuracy: 0.5657 - val_loss: 1.7544\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8157 - loss: 0.6422 - val_accuracy: 0.5658 - val_loss: 1.7502\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6422 - val_accuracy: 0.5700 - val_loss: 1.7534\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6422 - val_accuracy: 0.5657 - val_loss: 1.7553\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6421 - val_accuracy: 0.5658 - val_loss: 1.7510\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6421 - val_accuracy: 0.5658 - val_loss: 1.7514\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8146 - loss: 0.6421 - val_accuracy: 0.5658 - val_loss: 1.7518\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8157 - loss: 0.6420 - val_accuracy: 0.5701 - val_loss: 1.7587\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6420 - val_accuracy: 0.5658 - val_loss: 1.7544\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6420 - val_accuracy: 0.5657 - val_loss: 1.7537\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6419 - val_accuracy: 0.5658 - val_loss: 1.7529\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6419 - val_accuracy: 0.5700 - val_loss: 1.7530\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8152 - loss: 0.6419 - val_accuracy: 0.5701 - val_loss: 1.7505\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8164 - loss: 0.6418 - val_accuracy: 0.5657 - val_loss: 1.7545\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8170 - loss: 0.6418 - val_accuracy: 0.5658 - val_loss: 1.7534\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8144 - loss: 0.6418 - val_accuracy: 0.5701 - val_loss: 1.7532\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8162 - loss: 0.6417 - val_accuracy: 0.5658 - val_loss: 1.7560\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8162 - loss: 0.6417 - val_accuracy: 0.5657 - val_loss: 1.7538\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8148 - loss: 0.6417 - val_accuracy: 0.5701 - val_loss: 1.7524\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8155 - loss: 0.6416 - val_accuracy: 0.5658 - val_loss: 1.7554\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8160 - loss: 0.6416 - val_accuracy: 0.5657 - val_loss: 1.7582\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6416 - val_accuracy: 0.5706 - val_loss: 1.7526\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6415 - val_accuracy: 0.5657 - val_loss: 1.7540\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8160 - loss: 0.6415 - val_accuracy: 0.5657 - val_loss: 1.7567\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8143 - loss: 0.6415 - val_accuracy: 0.5658 - val_loss: 1.7550\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6414 - val_accuracy: 0.5663 - val_loss: 1.7531\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8150 - loss: 0.6414 - val_accuracy: 0.5700 - val_loss: 1.7538\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6414 - val_accuracy: 0.5658 - val_loss: 1.7558\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8154 - loss: 0.6413 - val_accuracy: 0.5657 - val_loss: 1.7598\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8150 - loss: 0.6413 - val_accuracy: 0.5701 - val_loss: 1.7538\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6413 - val_accuracy: 0.5658 - val_loss: 1.7572\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8145 - loss: 0.6412 - val_accuracy: 0.5706 - val_loss: 1.7516\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8156 - loss: 0.6412 - val_accuracy: 0.5657 - val_loss: 1.7570\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8161 - loss: 0.6412 - val_accuracy: 0.5705 - val_loss: 1.7535\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6411 - val_accuracy: 0.5658 - val_loss: 1.7562\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6411 - val_accuracy: 0.5658 - val_loss: 1.7557\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8151 - loss: 0.6411 - val_accuracy: 0.5705 - val_loss: 1.7543\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6411 - val_accuracy: 0.5701 - val_loss: 1.7558\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6410 - val_accuracy: 0.5658 - val_loss: 1.7567\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6410 - val_accuracy: 0.5657 - val_loss: 1.7571\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6410 - val_accuracy: 0.5657 - val_loss: 1.7558\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8154 - loss: 0.6409 - val_accuracy: 0.5655 - val_loss: 1.7589\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6409 - val_accuracy: 0.5698 - val_loss: 1.7579\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8152 - loss: 0.6409 - val_accuracy: 0.5703 - val_loss: 1.7523\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8153 - loss: 0.6408 - val_accuracy: 0.5698 - val_loss: 1.7608\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6408 - val_accuracy: 0.5703 - val_loss: 1.7571\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6408 - val_accuracy: 0.5704 - val_loss: 1.7549\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6407 - val_accuracy: 0.5655 - val_loss: 1.7572\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6407 - val_accuracy: 0.5661 - val_loss: 1.7570\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8142 - loss: 0.6407 - val_accuracy: 0.5656 - val_loss: 1.7563\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6407 - val_accuracy: 0.5703 - val_loss: 1.7564\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8152 - loss: 0.6406 - val_accuracy: 0.5704 - val_loss: 1.7550\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6406 - val_accuracy: 0.5698 - val_loss: 1.7588\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6406 - val_accuracy: 0.5655 - val_loss: 1.7554\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6405 - val_accuracy: 0.5703 - val_loss: 1.7582\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8163 - loss: 0.6405 - val_accuracy: 0.5703 - val_loss: 1.7568\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6405 - val_accuracy: 0.5698 - val_loss: 1.7587\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8160 - loss: 0.6404 - val_accuracy: 0.5698 - val_loss: 1.7573\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8147 - loss: 0.6404 - val_accuracy: 0.5703 - val_loss: 1.7567\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8164 - loss: 0.6404 - val_accuracy: 0.5703 - val_loss: 1.7558\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8156 - loss: 0.6404 - val_accuracy: 0.5705 - val_loss: 1.7545\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8164 - loss: 0.6403 - val_accuracy: 0.5702 - val_loss: 1.7596\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8159 - loss: 0.6403 - val_accuracy: 0.5704 - val_loss: 1.7542\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6403 - val_accuracy: 0.5697 - val_loss: 1.7634\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8175 - loss: 0.6402 - val_accuracy: 0.5699 - val_loss: 1.7595\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8155 - loss: 0.6402 - val_accuracy: 0.5704 - val_loss: 1.7571\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6402 - val_accuracy: 0.5697 - val_loss: 1.7602\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8169 - loss: 0.6402 - val_accuracy: 0.5697 - val_loss: 1.7608\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6401 - val_accuracy: 0.5661 - val_loss: 1.7587\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6401 - val_accuracy: 0.5662 - val_loss: 1.7543\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8152 - loss: 0.6401 - val_accuracy: 0.5704 - val_loss: 1.7600\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6400 - val_accuracy: 0.5698 - val_loss: 1.7583\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8168 - loss: 0.6400 - val_accuracy: 0.5697 - val_loss: 1.7620\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6400 - val_accuracy: 0.5697 - val_loss: 1.7586\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8173 - loss: 0.6400 - val_accuracy: 0.5697 - val_loss: 1.7600\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6399 - val_accuracy: 0.5702 - val_loss: 1.7592\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8170 - loss: 0.6399 - val_accuracy: 0.5702 - val_loss: 1.7574\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8159 - loss: 0.6399 - val_accuracy: 0.5662 - val_loss: 1.7560\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8168 - loss: 0.6398 - val_accuracy: 0.5702 - val_loss: 1.7568\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8160 - loss: 0.6398 - val_accuracy: 0.5655 - val_loss: 1.7594\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8160 - loss: 0.6398 - val_accuracy: 0.5702 - val_loss: 1.7572\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8178 - loss: 0.6398 - val_accuracy: 0.5660 - val_loss: 1.7591\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8149 - loss: 0.6397 - val_accuracy: 0.5698 - val_loss: 1.7608\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8152 - loss: 0.6397 - val_accuracy: 0.5697 - val_loss: 1.7641\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8167 - loss: 0.6397 - val_accuracy: 0.5703 - val_loss: 1.7575\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8178 - loss: 0.6396 - val_accuracy: 0.5698 - val_loss: 1.7616\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8171 - loss: 0.6396 - val_accuracy: 0.5697 - val_loss: 1.7588\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8167 - loss: 0.6396 - val_accuracy: 0.5702 - val_loss: 1.7603\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8160 - loss: 0.6396 - val_accuracy: 0.5702 - val_loss: 1.7623\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8173 - loss: 0.6395 - val_accuracy: 0.5697 - val_loss: 1.7613\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8172 - loss: 0.6395 - val_accuracy: 0.5697 - val_loss: 1.7605\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8157 - loss: 0.6395 - val_accuracy: 0.5697 - val_loss: 1.7591\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6395 - val_accuracy: 0.5702 - val_loss: 1.7612\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.58494\n726/726 - 5s - 7ms/step - accuracy: 0.8177 - loss: 0.6394 - val_accuracy: 0.5702 - val_loss: 1.7625\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8173 - loss: 0.6394 - val_accuracy: 0.5702 - val_loss: 1.7597\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8176 - loss: 0.6394 - val_accuracy: 0.5702 - val_loss: 1.7577\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8170 - loss: 0.6393 - val_accuracy: 0.5697 - val_loss: 1.7644\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8173 - loss: 0.6393 - val_accuracy: 0.5702 - val_loss: 1.7612\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8169 - loss: 0.6393 - val_accuracy: 0.5697 - val_loss: 1.7662\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6393 - val_accuracy: 0.5660 - val_loss: 1.7612\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8159 - loss: 0.6392 - val_accuracy: 0.5697 - val_loss: 1.7633\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8175 - loss: 0.6392 - val_accuracy: 0.5702 - val_loss: 1.7601\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8178 - loss: 0.6392 - val_accuracy: 0.5702 - val_loss: 1.7630\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8168 - loss: 0.6392 - val_accuracy: 0.5697 - val_loss: 1.7667\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8165 - loss: 0.6391 - val_accuracy: 0.5654 - val_loss: 1.7673\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8161 - loss: 0.6391 - val_accuracy: 0.5702 - val_loss: 1.7595\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8166 - loss: 0.6391 - val_accuracy: 0.5704 - val_loss: 1.7617\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_26, X_test_26, y_train_26, y_test_26 = train_test_split(\n    X, y, test_size=0.3, random_state=68, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_26, X_val_26, y_train_26, y_val_26 = train_test_split(\n    X_train_26, y_train_26, test_size=0.2, random_state=68, stratify=y_train_26\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_26:\", np.max(X_train_26))\nprint(\"Min value in X_train_26:\", np.min(X_train_26))\n\nX_train_26_scaled = scaler.fit_transform(X_train_26)\n\n# Get the original class distribution\nclass_counts_26 = Counter(y_train_26)\nprint(\"Original class distribution:\", class_counts_26)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_26 = class_counts_26[min(class_counts_26, key=class_counts_26.get)]\ndesired_majority_size_26 = minority_class_size_26 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_26 = {0: desired_majority_size_26, 1: minority_class_size_26}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_26 = RandomUnderSampler(sampling_strategy=sampling_strategy_26, random_state=42)\nX_resampled_26, y_resampled_26 = undersampler_26.fit_resample(X_train_26, y_train_26)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_26))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_26, y_train_resampled_26 = smote.fit_resample(X_resampled_26, y_resampled_26)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_26))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_26))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T01:27:10.260195Z","iopub.execute_input":"2025-03-08T01:27:10.260614Z","iopub.status.idle":"2025-03-08T01:27:40.047463Z","shell.execute_reply.started":"2025-03-08T01:27:10.260551Z","shell.execute_reply":"2025-03-08T01:27:40.046289Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_26: 2071000000.0\nMin value in X_train_26: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_26 = X_train_resampled_26.reshape(X_train_resampled_26.shape[0], 1, 56)\nX_val_26 = X_val_26.reshape(X_val_26.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_26,  # Features from CICIDS2017\n    y_train_resampled_26,  # Labels from CICIDS2017\n    validation_data=(X_val_26, y_val_26),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T01:27:40.049125Z","iopub.execute_input":"2025-03-08T01:27:40.049607Z","iopub.status.idle":"2025-03-08T02:03:53.965434Z","shell.execute_reply.started":"2025-03-08T01:27:40.049578Z","shell.execute_reply":"2025-03-08T02:03:53.964088Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.7480 - val_accuracy: 0.5698 - val_loss: 1.7170\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.7434 - val_accuracy: 0.5708 - val_loss: 1.7142\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.7411 - val_accuracy: 0.5754 - val_loss: 1.7106\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8056 - loss: 0.7392 - val_accuracy: 0.5754 - val_loss: 1.7018\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8056 - loss: 0.7376 - val_accuracy: 0.5797 - val_loss: 1.6990\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8056 - loss: 0.7361 - val_accuracy: 0.5798 - val_loss: 1.6978\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7347 - val_accuracy: 0.5799 - val_loss: 1.6928\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7334 - val_accuracy: 0.5801 - val_loss: 1.6897\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7322 - val_accuracy: 0.5803 - val_loss: 1.6864\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.7310 - val_accuracy: 0.5803 - val_loss: 1.6810\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.7299 - val_accuracy: 0.5806 - val_loss: 1.6747\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.7288 - val_accuracy: 0.5807 - val_loss: 1.6742\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7278 - val_accuracy: 0.5808 - val_loss: 1.6738\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7268 - val_accuracy: 0.5810 - val_loss: 1.6686\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7259 - val_accuracy: 0.5810 - val_loss: 1.6668\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8055 - loss: 0.7249 - val_accuracy: 0.5811 - val_loss: 1.6630\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8056 - loss: 0.7241 - val_accuracy: 0.5814 - val_loss: 1.6634\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8055 - loss: 0.7232 - val_accuracy: 0.5816 - val_loss: 1.6605\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8054 - loss: 0.7224 - val_accuracy: 0.5816 - val_loss: 1.6579\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.7216 - val_accuracy: 0.5816 - val_loss: 1.6546\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.7208 - val_accuracy: 0.5823 - val_loss: 1.6541\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.7201 - val_accuracy: 0.5806 - val_loss: 1.6544\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.7193 - val_accuracy: 0.5806 - val_loss: 1.6513\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.7186 - val_accuracy: 0.5806 - val_loss: 1.6536\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.58494\n726/726 - 5s - 6ms/step - accuracy: 0.8054 - loss: 0.7179 - val_accuracy: 0.5827 - val_loss: 1.6501\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8055 - loss: 0.7173 - val_accuracy: 0.5832 - val_loss: 1.6461\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.58494\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7166 - val_accuracy: 0.5833 - val_loss: 1.6465\nEpoch 28/500\n\nEpoch 28: val_accuracy improved from 0.58494 to 0.58646, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.7160 - val_accuracy: 0.5865 - val_loss: 1.6453\nEpoch 29/500\n\nEpoch 29: val_accuracy improved from 0.58646 to 0.58729, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.7154 - val_accuracy: 0.5873 - val_loss: 1.6440\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.58729\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.7148 - val_accuracy: 0.5873 - val_loss: 1.6425\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.58729\n726/726 - 4s - 6ms/step - accuracy: 0.8056 - loss: 0.7142 - val_accuracy: 0.5873 - val_loss: 1.6443\nEpoch 32/500\n\nEpoch 32: val_accuracy improved from 0.58729 to 0.58742, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 6ms/step - accuracy: 0.8056 - loss: 0.7136 - val_accuracy: 0.5874 - val_loss: 1.6443\nEpoch 33/500\n\nEpoch 33: val_accuracy improved from 0.58742 to 0.58748, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8054 - loss: 0.7131 - val_accuracy: 0.5875 - val_loss: 1.6407\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8053 - loss: 0.7125 - val_accuracy: 0.5813 - val_loss: 1.6415\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8038 - loss: 0.7120 - val_accuracy: 0.5836 - val_loss: 1.6410\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8035 - loss: 0.7115 - val_accuracy: 0.5814 - val_loss: 1.6377\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.7110 - val_accuracy: 0.5815 - val_loss: 1.6390\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7105 - val_accuracy: 0.5814 - val_loss: 1.6383\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.58748\n726/726 - 5s - 7ms/step - accuracy: 0.8034 - loss: 0.7100 - val_accuracy: 0.5814 - val_loss: 1.6359\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7095 - val_accuracy: 0.5814 - val_loss: 1.6372\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7090 - val_accuracy: 0.5814 - val_loss: 1.6403\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7086 - val_accuracy: 0.5814 - val_loss: 1.6370\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.7081 - val_accuracy: 0.5815 - val_loss: 1.6364\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.7077 - val_accuracy: 0.5814 - val_loss: 1.6404\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.7072 - val_accuracy: 0.5815 - val_loss: 1.6345\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.7068 - val_accuracy: 0.5815 - val_loss: 1.6377\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.7064 - val_accuracy: 0.5816 - val_loss: 1.6389\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7060 - val_accuracy: 0.5815 - val_loss: 1.6375\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7056 - val_accuracy: 0.5817 - val_loss: 1.6315\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.7052 - val_accuracy: 0.5817 - val_loss: 1.6353\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7048 - val_accuracy: 0.5816 - val_loss: 1.6362\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.7044 - val_accuracy: 0.5816 - val_loss: 1.6368\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.7041 - val_accuracy: 0.5817 - val_loss: 1.6349\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8034 - loss: 0.7037 - val_accuracy: 0.5817 - val_loss: 1.6325\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.7033 - val_accuracy: 0.5817 - val_loss: 1.6331\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.7030 - val_accuracy: 0.5818 - val_loss: 1.6299\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.7026 - val_accuracy: 0.5820 - val_loss: 1.6277\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.7023 - val_accuracy: 0.5828 - val_loss: 1.6280\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.7019 - val_accuracy: 0.5819 - val_loss: 1.6330\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.7016 - val_accuracy: 0.5819 - val_loss: 1.6338\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.58748\n726/726 - 5s - 7ms/step - accuracy: 0.8043 - loss: 0.7013 - val_accuracy: 0.5820 - val_loss: 1.6294\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.7010 - val_accuracy: 0.5829 - val_loss: 1.6285\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.7006 - val_accuracy: 0.5829 - val_loss: 1.6311\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.7003 - val_accuracy: 0.5820 - val_loss: 1.6314\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.7000 - val_accuracy: 0.5829 - val_loss: 1.6283\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6997 - val_accuracy: 0.5829 - val_loss: 1.6297\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6994 - val_accuracy: 0.5829 - val_loss: 1.6271\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8050 - loss: 0.6991 - val_accuracy: 0.5829 - val_loss: 1.6288\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6988 - val_accuracy: 0.5829 - val_loss: 1.6284\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8050 - loss: 0.6985 - val_accuracy: 0.5829 - val_loss: 1.6274\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6983 - val_accuracy: 0.5828 - val_loss: 1.6284\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6980 - val_accuracy: 0.5828 - val_loss: 1.6305\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6977 - val_accuracy: 0.5834 - val_loss: 1.6251\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6974 - val_accuracy: 0.5830 - val_loss: 1.6289\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6972 - val_accuracy: 0.5833 - val_loss: 1.6310\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8048 - loss: 0.6969 - val_accuracy: 0.5834 - val_loss: 1.6279\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6967 - val_accuracy: 0.5833 - val_loss: 1.6306\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6964 - val_accuracy: 0.5834 - val_loss: 1.6300\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6962 - val_accuracy: 0.5835 - val_loss: 1.6256\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6959 - val_accuracy: 0.5834 - val_loss: 1.6291\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6957 - val_accuracy: 0.5835 - val_loss: 1.6262\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6954 - val_accuracy: 0.5837 - val_loss: 1.6243\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8049 - loss: 0.6952 - val_accuracy: 0.5836 - val_loss: 1.6264\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6950 - val_accuracy: 0.5837 - val_loss: 1.6255\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6947 - val_accuracy: 0.5837 - val_loss: 1.6230\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6945 - val_accuracy: 0.5838 - val_loss: 1.6271\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6943 - val_accuracy: 0.5838 - val_loss: 1.6262\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6940 - val_accuracy: 0.5838 - val_loss: 1.6286\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6938 - val_accuracy: 0.5838 - val_loss: 1.6276\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6936 - val_accuracy: 0.5838 - val_loss: 1.6272\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6934 - val_accuracy: 0.5839 - val_loss: 1.6278\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6932 - val_accuracy: 0.5838 - val_loss: 1.6309\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6930 - val_accuracy: 0.5838 - val_loss: 1.6314\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6928 - val_accuracy: 0.5839 - val_loss: 1.6333\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6926 - val_accuracy: 0.5839 - val_loss: 1.6282\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6924 - val_accuracy: 0.5840 - val_loss: 1.6263\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6922 - val_accuracy: 0.5839 - val_loss: 1.6274\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6920 - val_accuracy: 0.5840 - val_loss: 1.6266\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6918 - val_accuracy: 0.5840 - val_loss: 1.6286\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6916 - val_accuracy: 0.5840 - val_loss: 1.6283\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6914 - val_accuracy: 0.5840 - val_loss: 1.6267\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8051 - loss: 0.6912 - val_accuracy: 0.5840 - val_loss: 1.6278\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8065 - loss: 0.6910 - val_accuracy: 0.5840 - val_loss: 1.6276\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6908 - val_accuracy: 0.5840 - val_loss: 1.6278\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6906 - val_accuracy: 0.5840 - val_loss: 1.6274\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8070 - loss: 0.6905 - val_accuracy: 0.5840 - val_loss: 1.6285\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6903 - val_accuracy: 0.5840 - val_loss: 1.6271\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6901 - val_accuracy: 0.5840 - val_loss: 1.6312\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6899 - val_accuracy: 0.5840 - val_loss: 1.6273\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6897 - val_accuracy: 0.5840 - val_loss: 1.6288\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6896 - val_accuracy: 0.5839 - val_loss: 1.6308\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6894 - val_accuracy: 0.5840 - val_loss: 1.6260\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6892 - val_accuracy: 0.5838 - val_loss: 1.6287\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6891 - val_accuracy: 0.5845 - val_loss: 1.6253\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6889 - val_accuracy: 0.5839 - val_loss: 1.6276\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6887 - val_accuracy: 0.5844 - val_loss: 1.6305\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8070 - loss: 0.6886 - val_accuracy: 0.5846 - val_loss: 1.6290\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6884 - val_accuracy: 0.5845 - val_loss: 1.6255\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8071 - loss: 0.6883 - val_accuracy: 0.5844 - val_loss: 1.6293\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8071 - loss: 0.6881 - val_accuracy: 0.5845 - val_loss: 1.6287\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8070 - loss: 0.6879 - val_accuracy: 0.5846 - val_loss: 1.6256\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8071 - loss: 0.6878 - val_accuracy: 0.5846 - val_loss: 1.6300\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6876 - val_accuracy: 0.5846 - val_loss: 1.6309\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6875 - val_accuracy: 0.5846 - val_loss: 1.6291\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8073 - loss: 0.6873 - val_accuracy: 0.5846 - val_loss: 1.6310\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8073 - loss: 0.6872 - val_accuracy: 0.5846 - val_loss: 1.6301\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6871 - val_accuracy: 0.5846 - val_loss: 1.6323\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8074 - loss: 0.6869 - val_accuracy: 0.5846 - val_loss: 1.6324\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6868 - val_accuracy: 0.5846 - val_loss: 1.6281\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6866 - val_accuracy: 0.5845 - val_loss: 1.6338\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6865 - val_accuracy: 0.5845 - val_loss: 1.6330\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6863 - val_accuracy: 0.5846 - val_loss: 1.6292\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6862 - val_accuracy: 0.5846 - val_loss: 1.6328\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6861 - val_accuracy: 0.5846 - val_loss: 1.6311\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8073 - loss: 0.6859 - val_accuracy: 0.5846 - val_loss: 1.6313\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6858 - val_accuracy: 0.5847 - val_loss: 1.6321\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6856 - val_accuracy: 0.5847 - val_loss: 1.6268\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6855 - val_accuracy: 0.5846 - val_loss: 1.6331\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6854 - val_accuracy: 0.5847 - val_loss: 1.6315\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6853 - val_accuracy: 0.5847 - val_loss: 1.6255\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6851 - val_accuracy: 0.5847 - val_loss: 1.6295\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8076 - loss: 0.6850 - val_accuracy: 0.5847 - val_loss: 1.6292\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6849 - val_accuracy: 0.5846 - val_loss: 1.6309\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6847 - val_accuracy: 0.5847 - val_loss: 1.6279\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6846 - val_accuracy: 0.5846 - val_loss: 1.6353\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6845 - val_accuracy: 0.5846 - val_loss: 1.6327\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6844 - val_accuracy: 0.5846 - val_loss: 1.6314\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6843 - val_accuracy: 0.5846 - val_loss: 1.6275\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.58748\n726/726 - 5s - 7ms/step - accuracy: 0.8077 - loss: 0.6841 - val_accuracy: 0.5846 - val_loss: 1.6330\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6840 - val_accuracy: 0.5846 - val_loss: 1.6310\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6839 - val_accuracy: 0.5846 - val_loss: 1.6304\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6838 - val_accuracy: 0.5847 - val_loss: 1.6313\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6837 - val_accuracy: 0.5847 - val_loss: 1.6298\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6835 - val_accuracy: 0.5846 - val_loss: 1.6339\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8076 - loss: 0.6834 - val_accuracy: 0.5846 - val_loss: 1.6355\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6833 - val_accuracy: 0.5846 - val_loss: 1.6321\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8075 - loss: 0.6832 - val_accuracy: 0.5846 - val_loss: 1.6357\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8075 - loss: 0.6831 - val_accuracy: 0.5847 - val_loss: 1.6330\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8075 - loss: 0.6830 - val_accuracy: 0.5846 - val_loss: 1.6327\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6829 - val_accuracy: 0.5846 - val_loss: 1.6350\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6828 - val_accuracy: 0.5849 - val_loss: 1.6309\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8077 - loss: 0.6826 - val_accuracy: 0.5849 - val_loss: 1.6356\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8075 - loss: 0.6825 - val_accuracy: 0.5847 - val_loss: 1.6362\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8072 - loss: 0.6824 - val_accuracy: 0.5849 - val_loss: 1.6333\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6823 - val_accuracy: 0.5845 - val_loss: 1.6387\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6822 - val_accuracy: 0.5845 - val_loss: 1.6366\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6821 - val_accuracy: 0.5846 - val_loss: 1.6335\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6820 - val_accuracy: 0.5845 - val_loss: 1.6345\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8075 - loss: 0.6819 - val_accuracy: 0.5846 - val_loss: 1.6338\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8074 - loss: 0.6818 - val_accuracy: 0.5845 - val_loss: 1.6363\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.58748\n726/726 - 5s - 7ms/step - accuracy: 0.8072 - loss: 0.6817 - val_accuracy: 0.5846 - val_loss: 1.6357\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6816 - val_accuracy: 0.5846 - val_loss: 1.6352\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8072 - loss: 0.6815 - val_accuracy: 0.5850 - val_loss: 1.6368\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8070 - loss: 0.6814 - val_accuracy: 0.5850 - val_loss: 1.6348\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8067 - loss: 0.6813 - val_accuracy: 0.5850 - val_loss: 1.6344\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8068 - loss: 0.6812 - val_accuracy: 0.5850 - val_loss: 1.6381\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8069 - loss: 0.6811 - val_accuracy: 0.5850 - val_loss: 1.6364\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8061 - loss: 0.6810 - val_accuracy: 0.5850 - val_loss: 1.6353\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8068 - loss: 0.6809 - val_accuracy: 0.5849 - val_loss: 1.6371\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8062 - loss: 0.6808 - val_accuracy: 0.5850 - val_loss: 1.6378\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8066 - loss: 0.6807 - val_accuracy: 0.5850 - val_loss: 1.6395\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8068 - loss: 0.6806 - val_accuracy: 0.5849 - val_loss: 1.6377\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8063 - loss: 0.6805 - val_accuracy: 0.5821 - val_loss: 1.6417\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8063 - loss: 0.6804 - val_accuracy: 0.5821 - val_loss: 1.6402\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8062 - loss: 0.6803 - val_accuracy: 0.5821 - val_loss: 1.6415\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8055 - loss: 0.6802 - val_accuracy: 0.5850 - val_loss: 1.6355\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8068 - loss: 0.6802 - val_accuracy: 0.5821 - val_loss: 1.6367\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8065 - loss: 0.6801 - val_accuracy: 0.5821 - val_loss: 1.6412\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8059 - loss: 0.6800 - val_accuracy: 0.5821 - val_loss: 1.6383\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8065 - loss: 0.6799 - val_accuracy: 0.5820 - val_loss: 1.6422\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8066 - loss: 0.6798 - val_accuracy: 0.5820 - val_loss: 1.6413\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8067 - loss: 0.6797 - val_accuracy: 0.5820 - val_loss: 1.6411\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8063 - loss: 0.6796 - val_accuracy: 0.5820 - val_loss: 1.6353\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8063 - loss: 0.6795 - val_accuracy: 0.5820 - val_loss: 1.6372\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8063 - loss: 0.6794 - val_accuracy: 0.5820 - val_loss: 1.6403\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6794 - val_accuracy: 0.5819 - val_loss: 1.6414\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6793 - val_accuracy: 0.5820 - val_loss: 1.6452\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8057 - loss: 0.6792 - val_accuracy: 0.5820 - val_loss: 1.6405\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8059 - loss: 0.6791 - val_accuracy: 0.5821 - val_loss: 1.6387\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8061 - loss: 0.6790 - val_accuracy: 0.5819 - val_loss: 1.6413\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8055 - loss: 0.6789 - val_accuracy: 0.5839 - val_loss: 1.6387\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6788 - val_accuracy: 0.5841 - val_loss: 1.6395\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6788 - val_accuracy: 0.5841 - val_loss: 1.6417\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8054 - loss: 0.6787 - val_accuracy: 0.5840 - val_loss: 1.6456\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8061 - loss: 0.6786 - val_accuracy: 0.5840 - val_loss: 1.6397\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8051 - loss: 0.6785 - val_accuracy: 0.5841 - val_loss: 1.6406\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8054 - loss: 0.6784 - val_accuracy: 0.5841 - val_loss: 1.6429\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8058 - loss: 0.6784 - val_accuracy: 0.5841 - val_loss: 1.6425\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8061 - loss: 0.6783 - val_accuracy: 0.5844 - val_loss: 1.6365\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6782 - val_accuracy: 0.5839 - val_loss: 1.6444\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8056 - loss: 0.6781 - val_accuracy: 0.5843 - val_loss: 1.6428\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8051 - loss: 0.6780 - val_accuracy: 0.5843 - val_loss: 1.6414\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8046 - loss: 0.6780 - val_accuracy: 0.5843 - val_loss: 1.6444\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8048 - loss: 0.6779 - val_accuracy: 0.5844 - val_loss: 1.6451\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6778 - val_accuracy: 0.5844 - val_loss: 1.6445\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8053 - loss: 0.6777 - val_accuracy: 0.5844 - val_loss: 1.6439\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8058 - loss: 0.6777 - val_accuracy: 0.5842 - val_loss: 1.6448\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8047 - loss: 0.6776 - val_accuracy: 0.5842 - val_loss: 1.6486\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8046 - loss: 0.6775 - val_accuracy: 0.5842 - val_loss: 1.6420\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6774 - val_accuracy: 0.5843 - val_loss: 1.6447\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8053 - loss: 0.6774 - val_accuracy: 0.5842 - val_loss: 1.6436\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.58748\n726/726 - 4s - 5ms/step - accuracy: 0.8044 - loss: 0.6773 - val_accuracy: 0.5842 - val_loss: 1.6435\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6772 - val_accuracy: 0.5842 - val_loss: 1.6454\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6771 - val_accuracy: 0.5844 - val_loss: 1.6453\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6771 - val_accuracy: 0.5842 - val_loss: 1.6455\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6770 - val_accuracy: 0.5842 - val_loss: 1.6481\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6769 - val_accuracy: 0.5844 - val_loss: 1.6456\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6769 - val_accuracy: 0.5842 - val_loss: 1.6455\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6768 - val_accuracy: 0.5843 - val_loss: 1.6448\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6767 - val_accuracy: 0.5842 - val_loss: 1.6456\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8043 - loss: 0.6767 - val_accuracy: 0.5842 - val_loss: 1.6473\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6766 - val_accuracy: 0.5842 - val_loss: 1.6463\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6765 - val_accuracy: 0.5842 - val_loss: 1.6460\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6764 - val_accuracy: 0.5840 - val_loss: 1.6481\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6764 - val_accuracy: 0.5840 - val_loss: 1.6502\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6763 - val_accuracy: 0.5843 - val_loss: 1.6473\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6762 - val_accuracy: 0.5842 - val_loss: 1.6492\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8039 - loss: 0.6762 - val_accuracy: 0.5841 - val_loss: 1.6504\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6761 - val_accuracy: 0.5842 - val_loss: 1.6460\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6760 - val_accuracy: 0.5842 - val_loss: 1.6471\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6760 - val_accuracy: 0.5840 - val_loss: 1.6504\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6759 - val_accuracy: 0.5841 - val_loss: 1.6499\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6758 - val_accuracy: 0.5840 - val_loss: 1.6526\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6758 - val_accuracy: 0.5842 - val_loss: 1.6535\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6757 - val_accuracy: 0.5840 - val_loss: 1.6537\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6757 - val_accuracy: 0.5840 - val_loss: 1.6511\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6756 - val_accuracy: 0.5842 - val_loss: 1.6440\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6755 - val_accuracy: 0.5842 - val_loss: 1.6460\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6755 - val_accuracy: 0.5843 - val_loss: 1.6471\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6754 - val_accuracy: 0.5842 - val_loss: 1.6478\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6753 - val_accuracy: 0.5841 - val_loss: 1.6527\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6753 - val_accuracy: 0.5841 - val_loss: 1.6508\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8039 - loss: 0.6752 - val_accuracy: 0.5841 - val_loss: 1.6513\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6752 - val_accuracy: 0.5841 - val_loss: 1.6479\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6751 - val_accuracy: 0.5841 - val_loss: 1.6541\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6750 - val_accuracy: 0.5841 - val_loss: 1.6497\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6750 - val_accuracy: 0.5842 - val_loss: 1.6525\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6749 - val_accuracy: 0.5841 - val_loss: 1.6504\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6749 - val_accuracy: 0.5841 - val_loss: 1.6481\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6748 - val_accuracy: 0.5841 - val_loss: 1.6519\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6747 - val_accuracy: 0.5839 - val_loss: 1.6550\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6747 - val_accuracy: 0.5841 - val_loss: 1.6507\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6746 - val_accuracy: 0.5839 - val_loss: 1.6542\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6746 - val_accuracy: 0.5839 - val_loss: 1.6538\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6745 - val_accuracy: 0.5841 - val_loss: 1.6516\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6745 - val_accuracy: 0.5841 - val_loss: 1.6525\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6744 - val_accuracy: 0.5839 - val_loss: 1.6557\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.6743 - val_accuracy: 0.5839 - val_loss: 1.6579\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6743 - val_accuracy: 0.5839 - val_loss: 1.6564\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6742 - val_accuracy: 0.5839 - val_loss: 1.6576\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6742 - val_accuracy: 0.5840 - val_loss: 1.6532\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6741 - val_accuracy: 0.5840 - val_loss: 1.6564\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6741 - val_accuracy: 0.5839 - val_loss: 1.6533\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6740 - val_accuracy: 0.5839 - val_loss: 1.6549\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8033 - loss: 0.6739 - val_accuracy: 0.5839 - val_loss: 1.6558\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6739 - val_accuracy: 0.5839 - val_loss: 1.6551\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6738 - val_accuracy: 0.5839 - val_loss: 1.6599\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6738 - val_accuracy: 0.5839 - val_loss: 1.6578\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6737 - val_accuracy: 0.5839 - val_loss: 1.6544\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6737 - val_accuracy: 0.5839 - val_loss: 1.6553\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6736 - val_accuracy: 0.5839 - val_loss: 1.6548\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8034 - loss: 0.6736 - val_accuracy: 0.5839 - val_loss: 1.6564\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6735 - val_accuracy: 0.5843 - val_loss: 1.6535\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6735 - val_accuracy: 0.5844 - val_loss: 1.6565\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6734 - val_accuracy: 0.5839 - val_loss: 1.6583\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6734 - val_accuracy: 0.5839 - val_loss: 1.6540\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6733 - val_accuracy: 0.5839 - val_loss: 1.6580\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6733 - val_accuracy: 0.5844 - val_loss: 1.6574\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6732 - val_accuracy: 0.5839 - val_loss: 1.6568\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.6732 - val_accuracy: 0.5843 - val_loss: 1.6571\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6731 - val_accuracy: 0.5843 - val_loss: 1.6611\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6731 - val_accuracy: 0.5843 - val_loss: 1.6625\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6730 - val_accuracy: 0.5843 - val_loss: 1.6593\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6730 - val_accuracy: 0.5843 - val_loss: 1.6626\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6729 - val_accuracy: 0.5843 - val_loss: 1.6571\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8030 - loss: 0.6729 - val_accuracy: 0.5839 - val_loss: 1.6585\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8032 - loss: 0.6728 - val_accuracy: 0.5843 - val_loss: 1.6582\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6728 - val_accuracy: 0.5843 - val_loss: 1.6603\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6727 - val_accuracy: 0.5844 - val_loss: 1.6622\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6727 - val_accuracy: 0.5843 - val_loss: 1.6580\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6726 - val_accuracy: 0.5843 - val_loss: 1.6625\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6726 - val_accuracy: 0.5843 - val_loss: 1.6590\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6725 - val_accuracy: 0.5843 - val_loss: 1.6612\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8030 - loss: 0.6725 - val_accuracy: 0.5843 - val_loss: 1.6589\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6724 - val_accuracy: 0.5843 - val_loss: 1.6615\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6724 - val_accuracy: 0.5843 - val_loss: 1.6625\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6723 - val_accuracy: 0.5843 - val_loss: 1.6627\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6723 - val_accuracy: 0.5843 - val_loss: 1.6617\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6723 - val_accuracy: 0.5843 - val_loss: 1.6606\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6722 - val_accuracy: 0.5842 - val_loss: 1.6611\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8029 - loss: 0.6722 - val_accuracy: 0.5843 - val_loss: 1.6615\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6721 - val_accuracy: 0.5842 - val_loss: 1.6611\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6721 - val_accuracy: 0.5844 - val_loss: 1.6661\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6720 - val_accuracy: 0.5844 - val_loss: 1.6625\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6720 - val_accuracy: 0.5842 - val_loss: 1.6658\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6719 - val_accuracy: 0.5842 - val_loss: 1.6602\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6719 - val_accuracy: 0.5842 - val_loss: 1.6664\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6718 - val_accuracy: 0.5844 - val_loss: 1.6610\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8029 - loss: 0.6718 - val_accuracy: 0.5844 - val_loss: 1.6648\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6718 - val_accuracy: 0.5844 - val_loss: 1.6624\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6717 - val_accuracy: 0.5844 - val_loss: 1.6694\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6717 - val_accuracy: 0.5844 - val_loss: 1.6645\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6716 - val_accuracy: 0.5844 - val_loss: 1.6632\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6716 - val_accuracy: 0.5844 - val_loss: 1.6655\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6715 - val_accuracy: 0.5844 - val_loss: 1.6645\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8028 - loss: 0.6715 - val_accuracy: 0.5844 - val_loss: 1.6650\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6715 - val_accuracy: 0.5844 - val_loss: 1.6671\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6714 - val_accuracy: 0.5844 - val_loss: 1.6684\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6714 - val_accuracy: 0.5844 - val_loss: 1.6683\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6713 - val_accuracy: 0.5844 - val_loss: 1.6664\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6713 - val_accuracy: 0.5844 - val_loss: 1.6665\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6713 - val_accuracy: 0.5844 - val_loss: 1.6681\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6712 - val_accuracy: 0.5844 - val_loss: 1.6658\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6712 - val_accuracy: 0.5844 - val_loss: 1.6665\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6711 - val_accuracy: 0.5844 - val_loss: 1.6691\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6711 - val_accuracy: 0.5827 - val_loss: 1.6670\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6711 - val_accuracy: 0.5826 - val_loss: 1.6712\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6710 - val_accuracy: 0.5827 - val_loss: 1.6681\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6710 - val_accuracy: 0.5844 - val_loss: 1.6668\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6709 - val_accuracy: 0.5844 - val_loss: 1.6671\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8029 - loss: 0.6709 - val_accuracy: 0.5844 - val_loss: 1.6637\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6709 - val_accuracy: 0.5844 - val_loss: 1.6702\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6708 - val_accuracy: 0.5844 - val_loss: 1.6688\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6708 - val_accuracy: 0.5826 - val_loss: 1.6708\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6707 - val_accuracy: 0.5844 - val_loss: 1.6675\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6707 - val_accuracy: 0.5826 - val_loss: 1.6700\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6707 - val_accuracy: 0.5844 - val_loss: 1.6706\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8028 - loss: 0.6706 - val_accuracy: 0.5828 - val_loss: 1.6705\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6706 - val_accuracy: 0.5828 - val_loss: 1.6698\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6705 - val_accuracy: 0.5828 - val_loss: 1.6687\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6705 - val_accuracy: 0.5828 - val_loss: 1.6709\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6705 - val_accuracy: 0.5845 - val_loss: 1.6717\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6704 - val_accuracy: 0.5829 - val_loss: 1.6708\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6704 - val_accuracy: 0.5846 - val_loss: 1.6698\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6704 - val_accuracy: 0.5828 - val_loss: 1.6697\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6703 - val_accuracy: 0.5845 - val_loss: 1.6750\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6703 - val_accuracy: 0.5827 - val_loss: 1.6722\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6702 - val_accuracy: 0.5827 - val_loss: 1.6724\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6702 - val_accuracy: 0.5846 - val_loss: 1.6717\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6702 - val_accuracy: 0.5846 - val_loss: 1.6707\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6701 - val_accuracy: 0.5846 - val_loss: 1.6737\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6701 - val_accuracy: 0.5846 - val_loss: 1.6698\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8024 - loss: 0.6701 - val_accuracy: 0.5828 - val_loss: 1.6728\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6700 - val_accuracy: 0.5845 - val_loss: 1.6732\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6700 - val_accuracy: 0.5831 - val_loss: 1.6722\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6700 - val_accuracy: 0.5845 - val_loss: 1.6737\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6699 - val_accuracy: 0.5827 - val_loss: 1.6756\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6699 - val_accuracy: 0.5860 - val_loss: 1.6739\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6699 - val_accuracy: 0.5860 - val_loss: 1.6735\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.58748\n726/726 - 5s - 7ms/step - accuracy: 0.8024 - loss: 0.6698 - val_accuracy: 0.5860 - val_loss: 1.6725\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6698 - val_accuracy: 0.5847 - val_loss: 1.6745\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6698 - val_accuracy: 0.5842 - val_loss: 1.6744\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6697 - val_accuracy: 0.5861 - val_loss: 1.6736\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6697 - val_accuracy: 0.5832 - val_loss: 1.6764\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6697 - val_accuracy: 0.5860 - val_loss: 1.6744\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6696 - val_accuracy: 0.5832 - val_loss: 1.6746\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6696 - val_accuracy: 0.5860 - val_loss: 1.6735\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8024 - loss: 0.6696 - val_accuracy: 0.5860 - val_loss: 1.6758\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6695 - val_accuracy: 0.5843 - val_loss: 1.6755\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6695 - val_accuracy: 0.5831 - val_loss: 1.6774\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6695 - val_accuracy: 0.5831 - val_loss: 1.6774\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6694 - val_accuracy: 0.5842 - val_loss: 1.6738\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6694 - val_accuracy: 0.5862 - val_loss: 1.6771\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.58748\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6694 - val_accuracy: 0.5831 - val_loss: 1.6828\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.58748\n726/726 - 5s - 6ms/step - accuracy: 0.8034 - loss: 0.6693 - val_accuracy: 0.5843 - val_loss: 1.6765\nEpoch 386/500\n\nEpoch 386: val_accuracy improved from 0.58748 to 0.58759, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6693 - val_accuracy: 0.5876 - val_loss: 1.6733\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.58759\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6693 - val_accuracy: 0.5876 - val_loss: 1.6774\nEpoch 388/500\n\nEpoch 388: val_accuracy improved from 0.58759 to 0.58935, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6692 - val_accuracy: 0.5893 - val_loss: 1.6750\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.58935\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6692 - val_accuracy: 0.5875 - val_loss: 1.6782\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.58935\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6692 - val_accuracy: 0.5876 - val_loss: 1.6762\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.58935\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6691 - val_accuracy: 0.5877 - val_loss: 1.6793\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.58935\n726/726 - 5s - 6ms/step - accuracy: 0.8040 - loss: 0.6691 - val_accuracy: 0.5892 - val_loss: 1.6778\nEpoch 393/500\n\nEpoch 393: val_accuracy improved from 0.58935 to 0.58941, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6691 - val_accuracy: 0.5894 - val_loss: 1.6780\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6690 - val_accuracy: 0.5877 - val_loss: 1.6786\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6690 - val_accuracy: 0.5877 - val_loss: 1.6770\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6690 - val_accuracy: 0.5877 - val_loss: 1.6769\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6689 - val_accuracy: 0.5877 - val_loss: 1.6794\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6689 - val_accuracy: 0.5877 - val_loss: 1.6812\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6689 - val_accuracy: 0.5877 - val_loss: 1.6805\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6688 - val_accuracy: 0.5876 - val_loss: 1.6821\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6688 - val_accuracy: 0.5877 - val_loss: 1.6802\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6688 - val_accuracy: 0.5877 - val_loss: 1.6812\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6688 - val_accuracy: 0.5876 - val_loss: 1.6810\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6687 - val_accuracy: 0.5876 - val_loss: 1.6799\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6687 - val_accuracy: 0.5877 - val_loss: 1.6836\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6687 - val_accuracy: 0.5877 - val_loss: 1.6863\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.58941\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6686 - val_accuracy: 0.5877 - val_loss: 1.6781\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.58941\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6686 - val_accuracy: 0.5877 - val_loss: 1.6816\nEpoch 409/500\n\nEpoch 409: val_accuracy improved from 0.58941 to 0.58944, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6686 - val_accuracy: 0.5894 - val_loss: 1.6794\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6686 - val_accuracy: 0.5877 - val_loss: 1.6798\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6685 - val_accuracy: 0.5877 - val_loss: 1.6848\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6685 - val_accuracy: 0.5877 - val_loss: 1.6796\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6685 - val_accuracy: 0.5877 - val_loss: 1.6813\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.58944\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6684 - val_accuracy: 0.5877 - val_loss: 1.6829\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6684 - val_accuracy: 0.5894 - val_loss: 1.6806\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6684 - val_accuracy: 0.5894 - val_loss: 1.6786\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6683 - val_accuracy: 0.5877 - val_loss: 1.6829\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.58944\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6683 - val_accuracy: 0.5877 - val_loss: 1.6843\nEpoch 419/500\n\nEpoch 419: val_accuracy improved from 0.58944 to 0.58946, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6683 - val_accuracy: 0.5895 - val_loss: 1.6815\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.58946\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6683 - val_accuracy: 0.5877 - val_loss: 1.6835\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.58946\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6682 - val_accuracy: 0.5877 - val_loss: 1.6832\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.58946\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6682 - val_accuracy: 0.5877 - val_loss: 1.6853\nEpoch 423/500\n\nEpoch 423: val_accuracy improved from 0.58946 to 0.58947, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6682 - val_accuracy: 0.5895 - val_loss: 1.6801\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6681 - val_accuracy: 0.5877 - val_loss: 1.6835\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6681 - val_accuracy: 0.5877 - val_loss: 1.6826\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6681 - val_accuracy: 0.5877 - val_loss: 1.6843\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6681 - val_accuracy: 0.5877 - val_loss: 1.6873\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6680 - val_accuracy: 0.5877 - val_loss: 1.6858\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.58947\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6680 - val_accuracy: 0.5877 - val_loss: 1.6818\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6680 - val_accuracy: 0.5877 - val_loss: 1.6814\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6680 - val_accuracy: 0.5877 - val_loss: 1.6881\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6679 - val_accuracy: 0.5877 - val_loss: 1.6877\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.58947\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6679 - val_accuracy: 0.5877 - val_loss: 1.6848\nEpoch 434/500\n\nEpoch 434: val_accuracy improved from 0.58947 to 0.58948, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6679 - val_accuracy: 0.5895 - val_loss: 1.6834\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6678 - val_accuracy: 0.5877 - val_loss: 1.6857\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6678 - val_accuracy: 0.5877 - val_loss: 1.6873\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6678 - val_accuracy: 0.5878 - val_loss: 1.6820\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6678 - val_accuracy: 0.5877 - val_loss: 1.6870\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6677 - val_accuracy: 0.5877 - val_loss: 1.6878\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6677 - val_accuracy: 0.5877 - val_loss: 1.6896\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6677 - val_accuracy: 0.5877 - val_loss: 1.6847\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6677 - val_accuracy: 0.5877 - val_loss: 1.6859\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6676 - val_accuracy: 0.5878 - val_loss: 1.6849\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.58948\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6676 - val_accuracy: 0.5877 - val_loss: 1.6870\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6676 - val_accuracy: 0.5878 - val_loss: 1.6862\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6676 - val_accuracy: 0.5878 - val_loss: 1.6846\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6675 - val_accuracy: 0.5878 - val_loss: 1.6849\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6675 - val_accuracy: 0.5878 - val_loss: 1.6853\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.58948\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6675 - val_accuracy: 0.5877 - val_loss: 1.6925\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.58948\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6675 - val_accuracy: 0.5877 - val_loss: 1.6881\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.58948\n726/726 - 5s - 7ms/step - accuracy: 0.8041 - loss: 0.6674 - val_accuracy: 0.5877 - val_loss: 1.6892\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.58948\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6674 - val_accuracy: 0.5877 - val_loss: 1.6887\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.58948\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6674 - val_accuracy: 0.5889 - val_loss: 1.6855\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.58948\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6674 - val_accuracy: 0.5889 - val_loss: 1.6863\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6673 - val_accuracy: 0.5889 - val_loss: 1.6873\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6673 - val_accuracy: 0.5877 - val_loss: 1.6907\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.58948\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6673 - val_accuracy: 0.5889 - val_loss: 1.6870\nEpoch 458/500\n\nEpoch 458: val_accuracy improved from 0.58948 to 0.59065, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6673 - val_accuracy: 0.5907 - val_loss: 1.6870\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6672 - val_accuracy: 0.5889 - val_loss: 1.6876\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6672 - val_accuracy: 0.5889 - val_loss: 1.6916\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6672 - val_accuracy: 0.5889 - val_loss: 1.6894\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6672 - val_accuracy: 0.5906 - val_loss: 1.6860\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6671 - val_accuracy: 0.5889 - val_loss: 1.6921\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6671 - val_accuracy: 0.5889 - val_loss: 1.6869\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6671 - val_accuracy: 0.5889 - val_loss: 1.6882\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6671 - val_accuracy: 0.5889 - val_loss: 1.6895\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6670 - val_accuracy: 0.5889 - val_loss: 1.6937\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6670 - val_accuracy: 0.5889 - val_loss: 1.6879\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6670 - val_accuracy: 0.5889 - val_loss: 1.6922\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6670 - val_accuracy: 0.5889 - val_loss: 1.6878\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6669 - val_accuracy: 0.5889 - val_loss: 1.6923\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6669 - val_accuracy: 0.5889 - val_loss: 1.6884\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6669 - val_accuracy: 0.5889 - val_loss: 1.6882\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6669 - val_accuracy: 0.5889 - val_loss: 1.6935\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6669 - val_accuracy: 0.5889 - val_loss: 1.6925\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6668 - val_accuracy: 0.5889 - val_loss: 1.6961\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6668 - val_accuracy: 0.5889 - val_loss: 1.6928\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6668 - val_accuracy: 0.5889 - val_loss: 1.6881\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6668 - val_accuracy: 0.5889 - val_loss: 1.6883\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6667 - val_accuracy: 0.5889 - val_loss: 1.6932\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6667 - val_accuracy: 0.5889 - val_loss: 1.6914\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6667 - val_accuracy: 0.5906 - val_loss: 1.6879\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6667 - val_accuracy: 0.5889 - val_loss: 1.6922\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6666 - val_accuracy: 0.5889 - val_loss: 1.6943\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6666 - val_accuracy: 0.5906 - val_loss: 1.6927\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6666 - val_accuracy: 0.5889 - val_loss: 1.6948\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6666 - val_accuracy: 0.5889 - val_loss: 1.6961\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6666 - val_accuracy: 0.5889 - val_loss: 1.6902\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6665 - val_accuracy: 0.5889 - val_loss: 1.6939\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6665 - val_accuracy: 0.5889 - val_loss: 1.6919\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6665 - val_accuracy: 0.5889 - val_loss: 1.6955\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6665 - val_accuracy: 0.5889 - val_loss: 1.6938\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6664 - val_accuracy: 0.5889 - val_loss: 1.6937\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6664 - val_accuracy: 0.5889 - val_loss: 1.6944\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6664 - val_accuracy: 0.5889 - val_loss: 1.6969\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6664 - val_accuracy: 0.5889 - val_loss: 1.6963\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6664 - val_accuracy: 0.5889 - val_loss: 1.6925\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6663 - val_accuracy: 0.5889 - val_loss: 1.6991\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6663 - val_accuracy: 0.5889 - val_loss: 1.6976\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6663 - val_accuracy: 0.5889 - val_loss: 1.6952\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_27, X_test_27, y_train_27, y_test_27 = train_test_split(\n    X, y, test_size=0.3, random_state=69, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_27, X_val_27, y_train_27, y_val_27 = train_test_split(\n    X_train_27, y_train_27, test_size=0.2, random_state=69, stratify=y_train_27\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_27:\", np.max(X_train_27))\nprint(\"Min value in X_train_27:\", np.min(X_train_27))\n\nX_train_27_scaled = scaler.fit_transform(X_train_27)\n\n# Get the original class distribution\nclass_counts_27 = Counter(y_train_27)\nprint(\"Original class distribution:\", class_counts_27)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_27 = class_counts_27[min(class_counts_27, key=class_counts_27.get)]\ndesired_majority_size_27 = minority_class_size_27 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_27 = {0: desired_majority_size_27, 1: minority_class_size_27}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_27 = RandomUnderSampler(sampling_strategy=sampling_strategy_27, random_state=42)\nX_resampled_27, y_resampled_27 = undersampler_27.fit_resample(X_train_27, y_train_27)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_27))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_27, y_train_resampled_27 = smote.fit_resample(X_resampled_27, y_resampled_27)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_27))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_27))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T02:03:53.967193Z","iopub.execute_input":"2025-03-08T02:03:53.967612Z","iopub.status.idle":"2025-03-08T02:04:23.383331Z","shell.execute_reply.started":"2025-03-08T02:03:53.967568Z","shell.execute_reply":"2025-03-08T02:04:23.382432Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_27: 2071000000.0\nMin value in X_train_27: -32212234632.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_27 = X_train_resampled_27.reshape(X_train_resampled_27.shape[0], 1, 56)\nX_val_27 = X_val_27.reshape(X_val_27.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_27,  # Features from CICIDS2017\n    y_train_resampled_27,  # Labels from CICIDS2017\n    validation_data=(X_val_27, y_val_27),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T02:04:23.384237Z","iopub.execute_input":"2025-03-08T02:04:23.384591Z","iopub.status.idle":"2025-03-08T02:39:21.296158Z","shell.execute_reply.started":"2025-03-08T02:04:23.384555Z","shell.execute_reply":"2025-03-08T02:39:21.294803Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7727 - loss: 0.8589 - val_accuracy: 0.5885 - val_loss: 1.7199\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7733 - loss: 0.8458 - val_accuracy: 0.5834 - val_loss: 1.7220\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7746 - loss: 0.8388 - val_accuracy: 0.5833 - val_loss: 1.7298\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7810 - loss: 0.8328 - val_accuracy: 0.5832 - val_loss: 1.7346\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7810 - loss: 0.8274 - val_accuracy: 0.5833 - val_loss: 1.7428\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7801 - loss: 0.8224 - val_accuracy: 0.5799 - val_loss: 1.7515\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7796 - loss: 0.8177 - val_accuracy: 0.5787 - val_loss: 1.7613\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7795 - loss: 0.8133 - val_accuracy: 0.5785 - val_loss: 1.7690\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7778 - loss: 0.8091 - val_accuracy: 0.5786 - val_loss: 1.7721\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7779 - loss: 0.8050 - val_accuracy: 0.5780 - val_loss: 1.7792\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7774 - loss: 0.8012 - val_accuracy: 0.5768 - val_loss: 1.7907\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7769 - loss: 0.7976 - val_accuracy: 0.5766 - val_loss: 1.7962\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7769 - loss: 0.7941 - val_accuracy: 0.5765 - val_loss: 1.8031\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7769 - loss: 0.7907 - val_accuracy: 0.5757 - val_loss: 1.8105\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7770 - loss: 0.7875 - val_accuracy: 0.5757 - val_loss: 1.8141\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7771 - loss: 0.7844 - val_accuracy: 0.5757 - val_loss: 1.8218\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7771 - loss: 0.7815 - val_accuracy: 0.5751 - val_loss: 1.8281\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7771 - loss: 0.7788 - val_accuracy: 0.5751 - val_loss: 1.8355\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7771 - loss: 0.7761 - val_accuracy: 0.5750 - val_loss: 1.8355\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7771 - loss: 0.7736 - val_accuracy: 0.5747 - val_loss: 1.8441\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7863 - loss: 0.7712 - val_accuracy: 0.5747 - val_loss: 1.8463\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7865 - loss: 0.7690 - val_accuracy: 0.5746 - val_loss: 1.8556\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7865 - loss: 0.7669 - val_accuracy: 0.5746 - val_loss: 1.8549\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7865 - loss: 0.7649 - val_accuracy: 0.5746 - val_loss: 1.8618\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7865 - loss: 0.7631 - val_accuracy: 0.5741 - val_loss: 1.8641\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7866 - loss: 0.7613 - val_accuracy: 0.5747 - val_loss: 1.8681\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7867 - loss: 0.7597 - val_accuracy: 0.5741 - val_loss: 1.8747\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7867 - loss: 0.7581 - val_accuracy: 0.5725 - val_loss: 1.8843\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7866 - loss: 0.7566 - val_accuracy: 0.5726 - val_loss: 1.8813\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7869 - loss: 0.7553 - val_accuracy: 0.5717 - val_loss: 1.8849\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7870 - loss: 0.7540 - val_accuracy: 0.5717 - val_loss: 1.8886\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7889 - loss: 0.7528 - val_accuracy: 0.5717 - val_loss: 1.8922\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7895 - loss: 0.7516 - val_accuracy: 0.5717 - val_loss: 1.8936\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7895 - loss: 0.7506 - val_accuracy: 0.5715 - val_loss: 1.8950\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7895 - loss: 0.7495 - val_accuracy: 0.5715 - val_loss: 1.9001\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7895 - loss: 0.7486 - val_accuracy: 0.5715 - val_loss: 1.9018\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7895 - loss: 0.7477 - val_accuracy: 0.5715 - val_loss: 1.8967\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7895 - loss: 0.7468 - val_accuracy: 0.5715 - val_loss: 1.9012\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7897 - loss: 0.7460 - val_accuracy: 0.5715 - val_loss: 1.9091\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7898 - loss: 0.7452 - val_accuracy: 0.5724 - val_loss: 1.9051\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7445 - val_accuracy: 0.5721 - val_loss: 1.9122\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7438 - val_accuracy: 0.5721 - val_loss: 1.9167\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7431 - val_accuracy: 0.5721 - val_loss: 1.9180\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7425 - val_accuracy: 0.5721 - val_loss: 1.9163\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7419 - val_accuracy: 0.5721 - val_loss: 1.9191\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7907 - loss: 0.7414 - val_accuracy: 0.5721 - val_loss: 1.9219\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7408 - val_accuracy: 0.5721 - val_loss: 1.9244\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7907 - loss: 0.7403 - val_accuracy: 0.5721 - val_loss: 1.9214\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7906 - loss: 0.7398 - val_accuracy: 0.5721 - val_loss: 1.9224\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7906 - loss: 0.7393 - val_accuracy: 0.5721 - val_loss: 1.9199\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7906 - loss: 0.7389 - val_accuracy: 0.5720 - val_loss: 1.9288\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7384 - val_accuracy: 0.5720 - val_loss: 1.9276\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7928 - loss: 0.7380 - val_accuracy: 0.5720 - val_loss: 1.9303\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7929 - loss: 0.7376 - val_accuracy: 0.5720 - val_loss: 1.9274\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7929 - loss: 0.7372 - val_accuracy: 0.5720 - val_loss: 1.9274\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7929 - loss: 0.7369 - val_accuracy: 0.5720 - val_loss: 1.9313\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7929 - loss: 0.7365 - val_accuracy: 0.5720 - val_loss: 1.9328\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7929 - loss: 0.7362 - val_accuracy: 0.5720 - val_loss: 1.9327\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7929 - loss: 0.7359 - val_accuracy: 0.5720 - val_loss: 1.9315\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7927 - loss: 0.7356 - val_accuracy: 0.5720 - val_loss: 1.9336\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7926 - loss: 0.7353 - val_accuracy: 0.5720 - val_loss: 1.9354\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7924 - loss: 0.7350 - val_accuracy: 0.5720 - val_loss: 1.9379\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7924 - loss: 0.7347 - val_accuracy: 0.5720 - val_loss: 1.9333\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7925 - loss: 0.7344 - val_accuracy: 0.5687 - val_loss: 1.9370\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7342 - val_accuracy: 0.5718 - val_loss: 1.9346\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7339 - val_accuracy: 0.5718 - val_loss: 1.9328\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7337 - val_accuracy: 0.5718 - val_loss: 1.9346\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7334 - val_accuracy: 0.5715 - val_loss: 1.9372\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7332 - val_accuracy: 0.5724 - val_loss: 1.9380\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7330 - val_accuracy: 0.5721 - val_loss: 1.9359\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7328 - val_accuracy: 0.5706 - val_loss: 1.9412\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7326 - val_accuracy: 0.5703 - val_loss: 1.9401\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7324 - val_accuracy: 0.5703 - val_loss: 1.9392\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7322 - val_accuracy: 0.5703 - val_loss: 1.9409\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7320 - val_accuracy: 0.5703 - val_loss: 1.9416\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7318 - val_accuracy: 0.5704 - val_loss: 1.9392\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7316 - val_accuracy: 0.5700 - val_loss: 1.9406\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7314 - val_accuracy: 0.5704 - val_loss: 1.9368\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7313 - val_accuracy: 0.5700 - val_loss: 1.9415\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7311 - val_accuracy: 0.5700 - val_loss: 1.9382\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7309 - val_accuracy: 0.5700 - val_loss: 1.9404\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7308 - val_accuracy: 0.5700 - val_loss: 1.9434\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7937 - loss: 0.7306 - val_accuracy: 0.5700 - val_loss: 1.9403\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7305 - val_accuracy: 0.5700 - val_loss: 1.9405\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7303 - val_accuracy: 0.5700 - val_loss: 1.9391\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7302 - val_accuracy: 0.5700 - val_loss: 1.9384\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7301 - val_accuracy: 0.5700 - val_loss: 1.9398\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7299 - val_accuracy: 0.5695 - val_loss: 1.9439\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7298 - val_accuracy: 0.5695 - val_loss: 1.9442\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7296 - val_accuracy: 0.5695 - val_loss: 1.9476\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7938 - loss: 0.7295 - val_accuracy: 0.5695 - val_loss: 1.9428\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7294 - val_accuracy: 0.5695 - val_loss: 1.9434\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7292 - val_accuracy: 0.5695 - val_loss: 1.9419\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7291 - val_accuracy: 0.5695 - val_loss: 1.9441\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7290 - val_accuracy: 0.5695 - val_loss: 1.9447\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7289 - val_accuracy: 0.5695 - val_loss: 1.9443\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7288 - val_accuracy: 0.5695 - val_loss: 1.9421\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7938 - loss: 0.7286 - val_accuracy: 0.5695 - val_loss: 1.9461\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7285 - val_accuracy: 0.5695 - val_loss: 1.9437\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7938 - loss: 0.7284 - val_accuracy: 0.5695 - val_loss: 1.9459\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7939 - loss: 0.7283 - val_accuracy: 0.5695 - val_loss: 1.9438\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7282 - val_accuracy: 0.5695 - val_loss: 1.9443\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7939 - loss: 0.7281 - val_accuracy: 0.5695 - val_loss: 1.9450\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7941 - loss: 0.7280 - val_accuracy: 0.5695 - val_loss: 1.9463\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7941 - loss: 0.7279 - val_accuracy: 0.5695 - val_loss: 1.9438\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7941 - loss: 0.7277 - val_accuracy: 0.5694 - val_loss: 1.9439\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7940 - loss: 0.7276 - val_accuracy: 0.5694 - val_loss: 1.9461\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7940 - loss: 0.7275 - val_accuracy: 0.5695 - val_loss: 1.9424\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7926 - loss: 0.7274 - val_accuracy: 0.5695 - val_loss: 1.9421\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7932 - loss: 0.7273 - val_accuracy: 0.5696 - val_loss: 1.9429\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7940 - loss: 0.7272 - val_accuracy: 0.5666 - val_loss: 1.9437\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7916 - loss: 0.7271 - val_accuracy: 0.5665 - val_loss: 1.9465\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7913 - loss: 0.7270 - val_accuracy: 0.5666 - val_loss: 1.9436\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7915 - loss: 0.7269 - val_accuracy: 0.5665 - val_loss: 1.9469\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7268 - val_accuracy: 0.5666 - val_loss: 1.9469\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7913 - loss: 0.7267 - val_accuracy: 0.5666 - val_loss: 1.9452\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7915 - loss: 0.7266 - val_accuracy: 0.5666 - val_loss: 1.9415\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7266 - val_accuracy: 0.5666 - val_loss: 1.9432\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7913 - loss: 0.7265 - val_accuracy: 0.5666 - val_loss: 1.9452\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7912 - loss: 0.7264 - val_accuracy: 0.5666 - val_loss: 1.9452\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7263 - val_accuracy: 0.5665 - val_loss: 1.9499\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7262 - val_accuracy: 0.5665 - val_loss: 1.9486\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7261 - val_accuracy: 0.5666 - val_loss: 1.9472\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7260 - val_accuracy: 0.5666 - val_loss: 1.9453\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7259 - val_accuracy: 0.5666 - val_loss: 1.9417\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7258 - val_accuracy: 0.5664 - val_loss: 1.9491\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7911 - loss: 0.7258 - val_accuracy: 0.5664 - val_loss: 1.9486\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7257 - val_accuracy: 0.5671 - val_loss: 1.9426\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7256 - val_accuracy: 0.5664 - val_loss: 1.9448\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7255 - val_accuracy: 0.5665 - val_loss: 1.9442\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7254 - val_accuracy: 0.5645 - val_loss: 1.9459\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7253 - val_accuracy: 0.5651 - val_loss: 1.9423\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7252 - val_accuracy: 0.5645 - val_loss: 1.9461\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7252 - val_accuracy: 0.5651 - val_loss: 1.9415\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7910 - loss: 0.7251 - val_accuracy: 0.5645 - val_loss: 1.9472\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7250 - val_accuracy: 0.5645 - val_loss: 1.9465\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7249 - val_accuracy: 0.5645 - val_loss: 1.9470\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7248 - val_accuracy: 0.5645 - val_loss: 1.9446\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7248 - val_accuracy: 0.5645 - val_loss: 1.9462\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7247 - val_accuracy: 0.5651 - val_loss: 1.9468\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7246 - val_accuracy: 0.5651 - val_loss: 1.9478\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7245 - val_accuracy: 0.5651 - val_loss: 1.9447\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7245 - val_accuracy: 0.5645 - val_loss: 1.9500\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7244 - val_accuracy: 0.5645 - val_loss: 1.9487\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7243 - val_accuracy: 0.5646 - val_loss: 1.9499\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7242 - val_accuracy: 0.5646 - val_loss: 1.9482\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7242 - val_accuracy: 0.5651 - val_loss: 1.9446\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7241 - val_accuracy: 0.5646 - val_loss: 1.9497\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7240 - val_accuracy: 0.5646 - val_loss: 1.9464\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7909 - loss: 0.7239 - val_accuracy: 0.5645 - val_loss: 1.9505\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7239 - val_accuracy: 0.5645 - val_loss: 1.9467\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7238 - val_accuracy: 0.5650 - val_loss: 1.9482\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7237 - val_accuracy: 0.5644 - val_loss: 1.9545\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7237 - val_accuracy: 0.5650 - val_loss: 1.9496\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7236 - val_accuracy: 0.5645 - val_loss: 1.9492\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7235 - val_accuracy: 0.5651 - val_loss: 1.9456\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7235 - val_accuracy: 0.5651 - val_loss: 1.9433\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7234 - val_accuracy: 0.5645 - val_loss: 1.9508\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7233 - val_accuracy: 0.5645 - val_loss: 1.9541\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7232 - val_accuracy: 0.5651 - val_loss: 1.9444\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7232 - val_accuracy: 0.5645 - val_loss: 1.9519\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7909 - loss: 0.7231 - val_accuracy: 0.5650 - val_loss: 1.9522\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7910 - loss: 0.7230 - val_accuracy: 0.5651 - val_loss: 1.9480\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7230 - val_accuracy: 0.5645 - val_loss: 1.9516\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7229 - val_accuracy: 0.5650 - val_loss: 1.9530\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7228 - val_accuracy: 0.5651 - val_loss: 1.9496\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7228 - val_accuracy: 0.5650 - val_loss: 1.9483\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7227 - val_accuracy: 0.5651 - val_loss: 1.9491\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7226 - val_accuracy: 0.5650 - val_loss: 1.9480\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7226 - val_accuracy: 0.5650 - val_loss: 1.9529\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7225 - val_accuracy: 0.5651 - val_loss: 1.9489\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7225 - val_accuracy: 0.5644 - val_loss: 1.9557\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7224 - val_accuracy: 0.5645 - val_loss: 1.9524\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7910 - loss: 0.7223 - val_accuracy: 0.5651 - val_loss: 1.9456\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7223 - val_accuracy: 0.5651 - val_loss: 1.9491\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7222 - val_accuracy: 0.5651 - val_loss: 1.9538\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7221 - val_accuracy: 0.5651 - val_loss: 1.9535\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7910 - loss: 0.7221 - val_accuracy: 0.5651 - val_loss: 1.9509\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7220 - val_accuracy: 0.5653 - val_loss: 1.9501\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7220 - val_accuracy: 0.5651 - val_loss: 1.9550\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7219 - val_accuracy: 0.5653 - val_loss: 1.9495\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7910 - loss: 0.7218 - val_accuracy: 0.5653 - val_loss: 1.9507\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7910 - loss: 0.7218 - val_accuracy: 0.5653 - val_loss: 1.9518\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7910 - loss: 0.7217 - val_accuracy: 0.5654 - val_loss: 1.9494\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7911 - loss: 0.7217 - val_accuracy: 0.5653 - val_loss: 1.9501\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7216 - val_accuracy: 0.5653 - val_loss: 1.9489\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7215 - val_accuracy: 0.5648 - val_loss: 1.9525\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7215 - val_accuracy: 0.5654 - val_loss: 1.9497\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7214 - val_accuracy: 0.5653 - val_loss: 1.9544\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7214 - val_accuracy: 0.5653 - val_loss: 1.9545\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7213 - val_accuracy: 0.5653 - val_loss: 1.9520\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7213 - val_accuracy: 0.5653 - val_loss: 1.9516\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7212 - val_accuracy: 0.5653 - val_loss: 1.9498\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7911 - loss: 0.7211 - val_accuracy: 0.5653 - val_loss: 1.9483\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7911 - loss: 0.7211 - val_accuracy: 0.5653 - val_loss: 1.9534\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7210 - val_accuracy: 0.5652 - val_loss: 1.9545\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7210 - val_accuracy: 0.5653 - val_loss: 1.9541\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7911 - loss: 0.7209 - val_accuracy: 0.5653 - val_loss: 1.9546\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7209 - val_accuracy: 0.5653 - val_loss: 1.9557\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7912 - loss: 0.7208 - val_accuracy: 0.5653 - val_loss: 1.9547\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7912 - loss: 0.7208 - val_accuracy: 0.5653 - val_loss: 1.9501\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7207 - val_accuracy: 0.5653 - val_loss: 1.9512\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7207 - val_accuracy: 0.5653 - val_loss: 1.9529\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7206 - val_accuracy: 0.5653 - val_loss: 1.9554\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7912 - loss: 0.7205 - val_accuracy: 0.5653 - val_loss: 1.9568\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7912 - loss: 0.7205 - val_accuracy: 0.5653 - val_loss: 1.9540\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7912 - loss: 0.7204 - val_accuracy: 0.5647 - val_loss: 1.9583\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7912 - loss: 0.7204 - val_accuracy: 0.5653 - val_loss: 1.9544\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7913 - loss: 0.7203 - val_accuracy: 0.5653 - val_loss: 1.9530\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7911 - loss: 0.7203 - val_accuracy: 0.5653 - val_loss: 1.9510\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7202 - val_accuracy: 0.5647 - val_loss: 1.9541\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7914 - loss: 0.7202 - val_accuracy: 0.5655 - val_loss: 1.9545\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7201 - val_accuracy: 0.5647 - val_loss: 1.9578\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7201 - val_accuracy: 0.5647 - val_loss: 1.9582\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7200 - val_accuracy: 0.5655 - val_loss: 1.9543\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7200 - val_accuracy: 0.5655 - val_loss: 1.9586\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7199 - val_accuracy: 0.5655 - val_loss: 1.9620\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7199 - val_accuracy: 0.5655 - val_loss: 1.9570\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7198 - val_accuracy: 0.5655 - val_loss: 1.9559\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7198 - val_accuracy: 0.5655 - val_loss: 1.9524\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7197 - val_accuracy: 0.5655 - val_loss: 1.9561\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7197 - val_accuracy: 0.5655 - val_loss: 1.9592\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7196 - val_accuracy: 0.5655 - val_loss: 1.9586\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7196 - val_accuracy: 0.5655 - val_loss: 1.9607\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7195 - val_accuracy: 0.5655 - val_loss: 1.9543\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7195 - val_accuracy: 0.5655 - val_loss: 1.9525\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7194 - val_accuracy: 0.5655 - val_loss: 1.9530\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7194 - val_accuracy: 0.5655 - val_loss: 1.9583\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7193 - val_accuracy: 0.5655 - val_loss: 1.9604\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7193 - val_accuracy: 0.5655 - val_loss: 1.9598\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7192 - val_accuracy: 0.5655 - val_loss: 1.9613\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7192 - val_accuracy: 0.5655 - val_loss: 1.9589\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7191 - val_accuracy: 0.5655 - val_loss: 1.9590\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7191 - val_accuracy: 0.5655 - val_loss: 1.9612\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7191 - val_accuracy: 0.5655 - val_loss: 1.9559\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7190 - val_accuracy: 0.5655 - val_loss: 1.9576\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7190 - val_accuracy: 0.5653 - val_loss: 1.9629\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7189 - val_accuracy: 0.5655 - val_loss: 1.9589\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7189 - val_accuracy: 0.5655 - val_loss: 1.9576\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7188 - val_accuracy: 0.5654 - val_loss: 1.9601\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7188 - val_accuracy: 0.5656 - val_loss: 1.9584\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7187 - val_accuracy: 0.5653 - val_loss: 1.9622\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7187 - val_accuracy: 0.5655 - val_loss: 1.9591\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7186 - val_accuracy: 0.5654 - val_loss: 1.9601\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7186 - val_accuracy: 0.5655 - val_loss: 1.9612\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7185 - val_accuracy: 0.5654 - val_loss: 1.9589\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7185 - val_accuracy: 0.5654 - val_loss: 1.9585\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7185 - val_accuracy: 0.5654 - val_loss: 1.9574\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7184 - val_accuracy: 0.5654 - val_loss: 1.9613\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7184 - val_accuracy: 0.5655 - val_loss: 1.9573\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7183 - val_accuracy: 0.5654 - val_loss: 1.9624\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7183 - val_accuracy: 0.5655 - val_loss: 1.9587\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7182 - val_accuracy: 0.5654 - val_loss: 1.9639\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7182 - val_accuracy: 0.5654 - val_loss: 1.9648\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7181 - val_accuracy: 0.5654 - val_loss: 1.9609\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7181 - val_accuracy: 0.5654 - val_loss: 1.9587\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7181 - val_accuracy: 0.5655 - val_loss: 1.9579\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7180 - val_accuracy: 0.5654 - val_loss: 1.9614\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7180 - val_accuracy: 0.5654 - val_loss: 1.9620\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7179 - val_accuracy: 0.5654 - val_loss: 1.9611\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7179 - val_accuracy: 0.5654 - val_loss: 1.9647\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7179 - val_accuracy: 0.5654 - val_loss: 1.9656\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7178 - val_accuracy: 0.5655 - val_loss: 1.9627\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7178 - val_accuracy: 0.5654 - val_loss: 1.9657\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7177 - val_accuracy: 0.5654 - val_loss: 1.9602\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7177 - val_accuracy: 0.5654 - val_loss: 1.9679\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7176 - val_accuracy: 0.5655 - val_loss: 1.9610\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7176 - val_accuracy: 0.5654 - val_loss: 1.9631\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7176 - val_accuracy: 0.5655 - val_loss: 1.9584\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7175 - val_accuracy: 0.5654 - val_loss: 1.9651\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7175 - val_accuracy: 0.5654 - val_loss: 1.9642\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7174 - val_accuracy: 0.5655 - val_loss: 1.9628\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7174 - val_accuracy: 0.5654 - val_loss: 1.9657\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7174 - val_accuracy: 0.5688 - val_loss: 1.9608\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7173 - val_accuracy: 0.5655 - val_loss: 1.9604\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7173 - val_accuracy: 0.5655 - val_loss: 1.9579\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7172 - val_accuracy: 0.5654 - val_loss: 1.9669\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7172 - val_accuracy: 0.5655 - val_loss: 1.9655\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7172 - val_accuracy: 0.5655 - val_loss: 1.9663\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7171 - val_accuracy: 0.5687 - val_loss: 1.9614\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7171 - val_accuracy: 0.5654 - val_loss: 1.9672\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7170 - val_accuracy: 0.5654 - val_loss: 1.9623\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7170 - val_accuracy: 0.5654 - val_loss: 1.9690\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7170 - val_accuracy: 0.5655 - val_loss: 1.9667\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7169 - val_accuracy: 0.5655 - val_loss: 1.9638\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7169 - val_accuracy: 0.5654 - val_loss: 1.9670\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7169 - val_accuracy: 0.5655 - val_loss: 1.9660\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7168 - val_accuracy: 0.5654 - val_loss: 1.9697\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7168 - val_accuracy: 0.5655 - val_loss: 1.9632\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7167 - val_accuracy: 0.5654 - val_loss: 1.9701\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7167 - val_accuracy: 0.5655 - val_loss: 1.9687\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7167 - val_accuracy: 0.5655 - val_loss: 1.9648\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7166 - val_accuracy: 0.5655 - val_loss: 1.9647\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7166 - val_accuracy: 0.5655 - val_loss: 1.9666\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7165 - val_accuracy: 0.5655 - val_loss: 1.9646\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7165 - val_accuracy: 0.5655 - val_loss: 1.9697\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7165 - val_accuracy: 0.5655 - val_loss: 1.9695\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7164 - val_accuracy: 0.5655 - val_loss: 1.9661\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7164 - val_accuracy: 0.5654 - val_loss: 1.9691\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7164 - val_accuracy: 0.5655 - val_loss: 1.9649\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7163 - val_accuracy: 0.5687 - val_loss: 1.9644\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7163 - val_accuracy: 0.5654 - val_loss: 1.9670\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7163 - val_accuracy: 0.5655 - val_loss: 1.9682\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7162 - val_accuracy: 0.5655 - val_loss: 1.9670\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7162 - val_accuracy: 0.5655 - val_loss: 1.9703\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7161 - val_accuracy: 0.5655 - val_loss: 1.9687\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7161 - val_accuracy: 0.5655 - val_loss: 1.9661\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7161 - val_accuracy: 0.5687 - val_loss: 1.9647\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7160 - val_accuracy: 0.5655 - val_loss: 1.9732\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7160 - val_accuracy: 0.5655 - val_loss: 1.9680\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7160 - val_accuracy: 0.5654 - val_loss: 1.9711\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7918 - loss: 0.7159 - val_accuracy: 0.5655 - val_loss: 1.9704\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7159 - val_accuracy: 0.5655 - val_loss: 1.9689\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7159 - val_accuracy: 0.5654 - val_loss: 1.9703\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7158 - val_accuracy: 0.5654 - val_loss: 1.9715\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7158 - val_accuracy: 0.5654 - val_loss: 1.9710\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7158 - val_accuracy: 0.5654 - val_loss: 1.9734\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7157 - val_accuracy: 0.5654 - val_loss: 1.9719\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7157 - val_accuracy: 0.5654 - val_loss: 1.9729\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7157 - val_accuracy: 0.5654 - val_loss: 1.9685\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7156 - val_accuracy: 0.5654 - val_loss: 1.9726\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7156 - val_accuracy: 0.5658 - val_loss: 1.9677\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7156 - val_accuracy: 0.5656 - val_loss: 1.9724\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7155 - val_accuracy: 0.5655 - val_loss: 1.9713\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7155 - val_accuracy: 0.5655 - val_loss: 1.9744\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7155 - val_accuracy: 0.5656 - val_loss: 1.9749\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7154 - val_accuracy: 0.5655 - val_loss: 1.9749\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7154 - val_accuracy: 0.5691 - val_loss: 1.9686\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7154 - val_accuracy: 0.5655 - val_loss: 1.9712\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7153 - val_accuracy: 0.5656 - val_loss: 1.9729\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7153 - val_accuracy: 0.5658 - val_loss: 1.9726\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7153 - val_accuracy: 0.5655 - val_loss: 1.9756\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7152 - val_accuracy: 0.5655 - val_loss: 1.9755\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7152 - val_accuracy: 0.5659 - val_loss: 1.9681\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7152 - val_accuracy: 0.5658 - val_loss: 1.9701\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7151 - val_accuracy: 0.5658 - val_loss: 1.9712\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7151 - val_accuracy: 0.5656 - val_loss: 1.9747\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7920 - loss: 0.7151 - val_accuracy: 0.5658 - val_loss: 1.9749\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7150 - val_accuracy: 0.5658 - val_loss: 1.9749\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7150 - val_accuracy: 0.5658 - val_loss: 1.9704\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7150 - val_accuracy: 0.5655 - val_loss: 1.9766\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7149 - val_accuracy: 0.5654 - val_loss: 1.9761\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7919 - loss: 0.7149 - val_accuracy: 0.5659 - val_loss: 1.9709\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7149 - val_accuracy: 0.5658 - val_loss: 1.9730\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7148 - val_accuracy: 0.5658 - val_loss: 1.9728\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7148 - val_accuracy: 0.5659 - val_loss: 1.9711\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7148 - val_accuracy: 0.5658 - val_loss: 1.9750\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7147 - val_accuracy: 0.5658 - val_loss: 1.9735\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7147 - val_accuracy: 0.5658 - val_loss: 1.9755\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7147 - val_accuracy: 0.5658 - val_loss: 1.9780\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7146 - val_accuracy: 0.5658 - val_loss: 1.9765\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7146 - val_accuracy: 0.5658 - val_loss: 1.9752\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7146 - val_accuracy: 0.5659 - val_loss: 1.9711\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7145 - val_accuracy: 0.5658 - val_loss: 1.9765\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7145 - val_accuracy: 0.5659 - val_loss: 1.9752\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7921 - loss: 0.7145 - val_accuracy: 0.5658 - val_loss: 1.9820\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7145 - val_accuracy: 0.5658 - val_loss: 1.9774\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7144 - val_accuracy: 0.5691 - val_loss: 1.9747\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7921 - loss: 0.7144 - val_accuracy: 0.5658 - val_loss: 1.9786\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7144 - val_accuracy: 0.5658 - val_loss: 1.9745\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7143 - val_accuracy: 0.5658 - val_loss: 1.9788\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7143 - val_accuracy: 0.5659 - val_loss: 1.9736\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7143 - val_accuracy: 0.5658 - val_loss: 1.9742\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7142 - val_accuracy: 0.5691 - val_loss: 1.9736\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7142 - val_accuracy: 0.5658 - val_loss: 1.9757\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7921 - loss: 0.7142 - val_accuracy: 0.5659 - val_loss: 1.9791\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7921 - loss: 0.7142 - val_accuracy: 0.5658 - val_loss: 1.9808\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7141 - val_accuracy: 0.5659 - val_loss: 1.9749\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7141 - val_accuracy: 0.5656 - val_loss: 1.9784\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7921 - loss: 0.7141 - val_accuracy: 0.5659 - val_loss: 1.9743\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7925 - loss: 0.7140 - val_accuracy: 0.5658 - val_loss: 1.9816\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7922 - loss: 0.7140 - val_accuracy: 0.5658 - val_loss: 1.9813\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7922 - loss: 0.7140 - val_accuracy: 0.5658 - val_loss: 1.9805\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7932 - loss: 0.7139 - val_accuracy: 0.5658 - val_loss: 1.9814\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7930 - loss: 0.7139 - val_accuracy: 0.5659 - val_loss: 1.9745\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7925 - loss: 0.7139 - val_accuracy: 0.5655 - val_loss: 1.9794\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7139 - val_accuracy: 0.5658 - val_loss: 1.9812\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7931 - loss: 0.7138 - val_accuracy: 0.5691 - val_loss: 1.9727\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7138 - val_accuracy: 0.5655 - val_loss: 1.9803\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7932 - loss: 0.7138 - val_accuracy: 0.5658 - val_loss: 1.9781\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7137 - val_accuracy: 0.5657 - val_loss: 1.9802\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7137 - val_accuracy: 0.5657 - val_loss: 1.9811\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7137 - val_accuracy: 0.5658 - val_loss: 1.9812\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7137 - val_accuracy: 0.5657 - val_loss: 1.9844\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7136 - val_accuracy: 0.5659 - val_loss: 1.9780\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7136 - val_accuracy: 0.5659 - val_loss: 1.9777\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7136 - val_accuracy: 0.5657 - val_loss: 1.9812\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7135 - val_accuracy: 0.5656 - val_loss: 1.9798\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7135 - val_accuracy: 0.5659 - val_loss: 1.9781\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7135 - val_accuracy: 0.5658 - val_loss: 1.9807\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7135 - val_accuracy: 0.5659 - val_loss: 1.9797\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7134 - val_accuracy: 0.5656 - val_loss: 1.9790\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7134 - val_accuracy: 0.5656 - val_loss: 1.9809\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7134 - val_accuracy: 0.5692 - val_loss: 1.9795\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7133 - val_accuracy: 0.5692 - val_loss: 1.9776\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7133 - val_accuracy: 0.5659 - val_loss: 1.9803\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7133 - val_accuracy: 0.5659 - val_loss: 1.9795\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7133 - val_accuracy: 0.5656 - val_loss: 1.9845\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7132 - val_accuracy: 0.5659 - val_loss: 1.9816\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7132 - val_accuracy: 0.5657 - val_loss: 1.9790\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7132 - val_accuracy: 0.5656 - val_loss: 1.9810\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7132 - val_accuracy: 0.5689 - val_loss: 1.9769\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7131 - val_accuracy: 0.5656 - val_loss: 1.9830\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7131 - val_accuracy: 0.5656 - val_loss: 1.9840\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7131 - val_accuracy: 0.5659 - val_loss: 1.9808\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7130 - val_accuracy: 0.5689 - val_loss: 1.9832\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7130 - val_accuracy: 0.5656 - val_loss: 1.9876\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7130 - val_accuracy: 0.5658 - val_loss: 1.9865\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7130 - val_accuracy: 0.5659 - val_loss: 1.9821\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7129 - val_accuracy: 0.5659 - val_loss: 1.9832\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7129 - val_accuracy: 0.5656 - val_loss: 1.9871\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7129 - val_accuracy: 0.5656 - val_loss: 1.9857\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7129 - val_accuracy: 0.5656 - val_loss: 1.9885\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7128 - val_accuracy: 0.5656 - val_loss: 1.9855\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7128 - val_accuracy: 0.5656 - val_loss: 1.9869\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7128 - val_accuracy: 0.5657 - val_loss: 1.9847\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7128 - val_accuracy: 0.5656 - val_loss: 1.9884\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7127 - val_accuracy: 0.5692 - val_loss: 1.9815\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7127 - val_accuracy: 0.5656 - val_loss: 1.9880\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7127 - val_accuracy: 0.5657 - val_loss: 1.9837\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7127 - val_accuracy: 0.5657 - val_loss: 1.9830\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7126 - val_accuracy: 0.5659 - val_loss: 1.9812\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7126 - val_accuracy: 0.5689 - val_loss: 1.9830\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7126 - val_accuracy: 0.5656 - val_loss: 1.9860\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7125 - val_accuracy: 0.5659 - val_loss: 1.9862\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7125 - val_accuracy: 0.5659 - val_loss: 1.9848\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7125 - val_accuracy: 0.5659 - val_loss: 1.9862\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7125 - val_accuracy: 0.5689 - val_loss: 1.9861\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7124 - val_accuracy: 0.5656 - val_loss: 1.9863\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7124 - val_accuracy: 0.5656 - val_loss: 1.9886\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7124 - val_accuracy: 0.5656 - val_loss: 1.9905\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7124 - val_accuracy: 0.5656 - val_loss: 1.9895\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7123 - val_accuracy: 0.5656 - val_loss: 1.9871\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7123 - val_accuracy: 0.5658 - val_loss: 1.9901\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7123 - val_accuracy: 0.5656 - val_loss: 1.9886\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7123 - val_accuracy: 0.5659 - val_loss: 1.9857\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7122 - val_accuracy: 0.5657 - val_loss: 1.9851\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7122 - val_accuracy: 0.5656 - val_loss: 1.9869\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7122 - val_accuracy: 0.5656 - val_loss: 1.9898\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7122 - val_accuracy: 0.5659 - val_loss: 1.9869\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7121 - val_accuracy: 0.5689 - val_loss: 1.9847\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7121 - val_accuracy: 0.5657 - val_loss: 1.9852\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7121 - val_accuracy: 0.5689 - val_loss: 1.9888\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7121 - val_accuracy: 0.5654 - val_loss: 1.9898\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7121 - val_accuracy: 0.5657 - val_loss: 1.9887\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7120 - val_accuracy: 0.5657 - val_loss: 1.9915\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7120 - val_accuracy: 0.5690 - val_loss: 1.9832\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7120 - val_accuracy: 0.5654 - val_loss: 1.9943\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7120 - val_accuracy: 0.5654 - val_loss: 1.9903\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7119 - val_accuracy: 0.5654 - val_loss: 1.9920\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7119 - val_accuracy: 0.5657 - val_loss: 1.9915\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7934 - loss: 0.7119 - val_accuracy: 0.5655 - val_loss: 1.9879\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7119 - val_accuracy: 0.5654 - val_loss: 1.9957\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7118 - val_accuracy: 0.5655 - val_loss: 1.9933\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7118 - val_accuracy: 0.5655 - val_loss: 1.9870\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7118 - val_accuracy: 0.5655 - val_loss: 1.9917\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7118 - val_accuracy: 0.5655 - val_loss: 1.9905\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7117 - val_accuracy: 0.5655 - val_loss: 1.9881\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7117 - val_accuracy: 0.5655 - val_loss: 1.9922\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7935 - loss: 0.7117 - val_accuracy: 0.5655 - val_loss: 1.9920\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7117 - val_accuracy: 0.5655 - val_loss: 1.9950\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7116 - val_accuracy: 0.5688 - val_loss: 1.9885\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7116 - val_accuracy: 0.5655 - val_loss: 1.9919\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7116 - val_accuracy: 0.5655 - val_loss: 1.9927\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7116 - val_accuracy: 0.5655 - val_loss: 1.9905\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7115 - val_accuracy: 0.5655 - val_loss: 1.9920\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7936 - loss: 0.7115 - val_accuracy: 0.5655 - val_loss: 1.9900\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7115 - val_accuracy: 0.5688 - val_loss: 1.9913\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7937 - loss: 0.7115 - val_accuracy: 0.5655 - val_loss: 1.9928\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7115 - val_accuracy: 0.5655 - val_loss: 1.9915\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7114 - val_accuracy: 0.5655 - val_loss: 1.9933\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7114 - val_accuracy: 0.5655 - val_loss: 1.9957\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7114 - val_accuracy: 0.5655 - val_loss: 1.9932\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7114 - val_accuracy: 0.5690 - val_loss: 1.9912\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7936 - loss: 0.7113 - val_accuracy: 0.5657 - val_loss: 1.9914\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7113 - val_accuracy: 0.5688 - val_loss: 1.9925\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7113 - val_accuracy: 0.5655 - val_loss: 1.9965\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7113 - val_accuracy: 0.5655 - val_loss: 1.9954\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7113 - val_accuracy: 0.5658 - val_loss: 1.9918\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7112 - val_accuracy: 0.5655 - val_loss: 1.9920\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7112 - val_accuracy: 0.5688 - val_loss: 1.9902\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.59065\n726/726 - 5s - 6ms/step - accuracy: 0.7936 - loss: 0.7112 - val_accuracy: 0.5655 - val_loss: 1.9937\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7112 - val_accuracy: 0.5655 - val_loss: 1.9936\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7111 - val_accuracy: 0.5688 - val_loss: 1.9920\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7111 - val_accuracy: 0.5655 - val_loss: 1.9921\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7111 - val_accuracy: 0.5688 - val_loss: 1.9929\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7111 - val_accuracy: 0.5655 - val_loss: 1.9965\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7111 - val_accuracy: 0.5655 - val_loss: 1.9979\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7110 - val_accuracy: 0.5655 - val_loss: 1.9978\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7110 - val_accuracy: 0.5655 - val_loss: 1.9973\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7110 - val_accuracy: 0.5655 - val_loss: 1.9933\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7110 - val_accuracy: 0.5690 - val_loss: 1.9883\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7109 - val_accuracy: 0.5655 - val_loss: 1.9942\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7109 - val_accuracy: 0.5655 - val_loss: 1.9972\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7109 - val_accuracy: 0.5688 - val_loss: 1.9945\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7109 - val_accuracy: 0.5658 - val_loss: 1.9937\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7936 - loss: 0.7109 - val_accuracy: 0.5654 - val_loss: 1.9986\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7934 - loss: 0.7108 - val_accuracy: 0.5688 - val_loss: 1.9946\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7108 - val_accuracy: 0.5655 - val_loss: 1.9964\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7935 - loss: 0.7108 - val_accuracy: 0.5655 - val_loss: 1.9959\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_28, X_test_28, y_train_28, y_test_28 = train_test_split(\n    X, y, test_size=0.3, random_state=70, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_28, X_val_28, y_train_28, y_val_28 = train_test_split(\n    X_train_28, y_train_28, test_size=0.2, random_state=70, stratify=y_train_28\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_28:\", np.max(X_train_28))\nprint(\"Min value in X_train_28:\", np.min(X_train_28))\n\nX_train_28_scaled = scaler.fit_transform(X_train_28)\n\n# Get the original class distribution\nclass_counts_28 = Counter(y_train_28)\nprint(\"Original class distribution:\", class_counts_28)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_28 = class_counts_28[min(class_counts_28, key=class_counts_28.get)]\ndesired_majority_size_28 = minority_class_size_28 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_28 = {0: desired_majority_size_28, 1: minority_class_size_28}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_28 = RandomUnderSampler(sampling_strategy=sampling_strategy_28, random_state=42)\nX_resampled_28, y_resampled_28 = undersampler_28.fit_resample(X_train_28, y_train_28)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_28))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_28, y_train_resampled_28 = smote.fit_resample(X_resampled_28, y_resampled_28)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_28))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_28))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T02:39:21.298192Z","iopub.execute_input":"2025-03-08T02:39:21.298577Z","iopub.status.idle":"2025-03-08T02:39:52.113158Z","shell.execute_reply.started":"2025-03-08T02:39:21.298545Z","shell.execute_reply":"2025-03-08T02:39:52.112093Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_28: 2071000000.0\nMin value in X_train_28: -6442447920.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_28 = X_train_resampled_28.reshape(X_train_resampled_28.shape[0], 1, 56)\nX_val_28 = X_val_28.reshape(X_val_28.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_28,  # Features from CICIDS2017\n    y_train_resampled_28,  # Labels from CICIDS2017\n    validation_data=(X_val_28, y_val_28),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T02:39:52.115821Z","iopub.execute_input":"2025-03-08T02:39:52.116112Z","iopub.status.idle":"2025-03-08T03:14:46.247418Z","shell.execute_reply.started":"2025-03-08T02:39:52.116086Z","shell.execute_reply":"2025-03-08T03:14:46.246237Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7886 - loss: 0.7428 - val_accuracy: 0.5745 - val_loss: 1.9618\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7891 - loss: 0.7388 - val_accuracy: 0.5748 - val_loss: 1.9489\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7892 - loss: 0.7366 - val_accuracy: 0.5732 - val_loss: 1.9321\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7892 - loss: 0.7347 - val_accuracy: 0.5732 - val_loss: 1.9182\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7891 - loss: 0.7331 - val_accuracy: 0.5733 - val_loss: 1.9020\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7894 - loss: 0.7316 - val_accuracy: 0.5739 - val_loss: 1.8855\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7918 - loss: 0.7303 - val_accuracy: 0.5756 - val_loss: 1.8770\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7919 - loss: 0.7291 - val_accuracy: 0.5755 - val_loss: 1.8631\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7927 - loss: 0.7279 - val_accuracy: 0.5757 - val_loss: 1.8488\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7920 - loss: 0.7269 - val_accuracy: 0.5751 - val_loss: 1.8396\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7921 - loss: 0.7259 - val_accuracy: 0.5753 - val_loss: 1.8333\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7926 - loss: 0.7250 - val_accuracy: 0.5756 - val_loss: 1.8235\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7922 - loss: 0.7242 - val_accuracy: 0.5758 - val_loss: 1.8176\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7932 - loss: 0.7234 - val_accuracy: 0.5761 - val_loss: 1.8111\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7922 - loss: 0.7227 - val_accuracy: 0.5763 - val_loss: 1.8063\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7926 - loss: 0.7220 - val_accuracy: 0.5763 - val_loss: 1.8029\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7926 - loss: 0.7213 - val_accuracy: 0.5771 - val_loss: 1.7906\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7938 - loss: 0.7207 - val_accuracy: 0.5773 - val_loss: 1.7899\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7940 - loss: 0.7201 - val_accuracy: 0.5779 - val_loss: 1.7868\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7951 - loss: 0.7195 - val_accuracy: 0.5813 - val_loss: 1.7867\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7963 - loss: 0.7190 - val_accuracy: 0.5815 - val_loss: 1.7821\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7965 - loss: 0.7185 - val_accuracy: 0.5815 - val_loss: 1.7779\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7962 - loss: 0.7180 - val_accuracy: 0.5813 - val_loss: 1.7819\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7965 - loss: 0.7175 - val_accuracy: 0.5814 - val_loss: 1.7766\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7970 - loss: 0.7171 - val_accuracy: 0.5816 - val_loss: 1.7710\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7972 - loss: 0.7167 - val_accuracy: 0.5817 - val_loss: 1.7719\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7972 - loss: 0.7162 - val_accuracy: 0.5819 - val_loss: 1.7695\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7975 - loss: 0.7158 - val_accuracy: 0.5819 - val_loss: 1.7658\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7976 - loss: 0.7154 - val_accuracy: 0.5823 - val_loss: 1.7628\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7971 - loss: 0.7151 - val_accuracy: 0.5821 - val_loss: 1.7642\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7975 - loss: 0.7147 - val_accuracy: 0.5823 - val_loss: 1.7642\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7973 - loss: 0.7143 - val_accuracy: 0.5823 - val_loss: 1.7607\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.7140 - val_accuracy: 0.5823 - val_loss: 1.7624\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7973 - loss: 0.7136 - val_accuracy: 0.5823 - val_loss: 1.7625\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7980 - loss: 0.7133 - val_accuracy: 0.5823 - val_loss: 1.7635\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7982 - loss: 0.7130 - val_accuracy: 0.5830 - val_loss: 1.7623\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.7127 - val_accuracy: 0.5831 - val_loss: 1.7595\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.7124 - val_accuracy: 0.5830 - val_loss: 1.7607\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7985 - loss: 0.7121 - val_accuracy: 0.5831 - val_loss: 1.7603\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7984 - loss: 0.7118 - val_accuracy: 0.5831 - val_loss: 1.7596\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7981 - loss: 0.7115 - val_accuracy: 0.5835 - val_loss: 1.7557\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.7112 - val_accuracy: 0.5832 - val_loss: 1.7600\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7987 - loss: 0.7109 - val_accuracy: 0.5833 - val_loss: 1.7578\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.7107 - val_accuracy: 0.5835 - val_loss: 1.7579\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7981 - loss: 0.7104 - val_accuracy: 0.5835 - val_loss: 1.7593\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7988 - loss: 0.7102 - val_accuracy: 0.5837 - val_loss: 1.7569\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7988 - loss: 0.7099 - val_accuracy: 0.5837 - val_loss: 1.7543\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7988 - loss: 0.7097 - val_accuracy: 0.5837 - val_loss: 1.7538\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7978 - loss: 0.7094 - val_accuracy: 0.5835 - val_loss: 1.7537\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7988 - loss: 0.7092 - val_accuracy: 0.5835 - val_loss: 1.7565\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7988 - loss: 0.7090 - val_accuracy: 0.5839 - val_loss: 1.7546\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7992 - loss: 0.7088 - val_accuracy: 0.5839 - val_loss: 1.7544\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.7085 - val_accuracy: 0.5882 - val_loss: 1.7547\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.7083 - val_accuracy: 0.5882 - val_loss: 1.7597\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.7081 - val_accuracy: 0.5883 - val_loss: 1.7538\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.7079 - val_accuracy: 0.5883 - val_loss: 1.7503\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.7077 - val_accuracy: 0.5883 - val_loss: 1.7566\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.7999 - loss: 0.7075 - val_accuracy: 0.5883 - val_loss: 1.7553\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.7073 - val_accuracy: 0.5882 - val_loss: 1.7526\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.7071 - val_accuracy: 0.5882 - val_loss: 1.7545\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.7069 - val_accuracy: 0.5883 - val_loss: 1.7594\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.59065\n726/726 - 4s - 6ms/step - accuracy: 0.7990 - loss: 0.7067 - val_accuracy: 0.5883 - val_loss: 1.7579\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.8000 - loss: 0.7065 - val_accuracy: 0.5883 - val_loss: 1.7528\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.59065\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.7063 - val_accuracy: 0.5883 - val_loss: 1.7556\nEpoch 65/500\n\nEpoch 65: val_accuracy improved from 0.59065 to 0.59116, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.7062 - val_accuracy: 0.5912 - val_loss: 1.7522\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.59116\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7060 - val_accuracy: 0.5887 - val_loss: 1.7522\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.59116\n726/726 - 4s - 5ms/step - accuracy: 0.8000 - loss: 0.7058 - val_accuracy: 0.5888 - val_loss: 1.7519\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.59116\n726/726 - 4s - 5ms/step - accuracy: 0.8005 - loss: 0.7056 - val_accuracy: 0.5888 - val_loss: 1.7542\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.59116\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7055 - val_accuracy: 0.5888 - val_loss: 1.7536\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.59116\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.7053 - val_accuracy: 0.5888 - val_loss: 1.7532\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.59116\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7051 - val_accuracy: 0.5888 - val_loss: 1.7560\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.59116\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7050 - val_accuracy: 0.5888 - val_loss: 1.7540\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.59116\n726/726 - 4s - 5ms/step - accuracy: 0.7998 - loss: 0.7048 - val_accuracy: 0.5889 - val_loss: 1.7516\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.59116\n726/726 - 4s - 5ms/step - accuracy: 0.8004 - loss: 0.7047 - val_accuracy: 0.5887 - val_loss: 1.7566\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.59116\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.7045 - val_accuracy: 0.5887 - val_loss: 1.7579\nEpoch 76/500\n\nEpoch 76: val_accuracy improved from 0.59116 to 0.59148, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.7044 - val_accuracy: 0.5915 - val_loss: 1.7489\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.59148\n726/726 - 5s - 6ms/step - accuracy: 0.8006 - loss: 0.7042 - val_accuracy: 0.5890 - val_loss: 1.7500\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7041 - val_accuracy: 0.5886 - val_loss: 1.7551\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7039 - val_accuracy: 0.5890 - val_loss: 1.7575\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7038 - val_accuracy: 0.5886 - val_loss: 1.7546\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7036 - val_accuracy: 0.5913 - val_loss: 1.7525\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7035 - val_accuracy: 0.5894 - val_loss: 1.7507\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.7033 - val_accuracy: 0.5913 - val_loss: 1.7533\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.7032 - val_accuracy: 0.5889 - val_loss: 1.7574\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.7031 - val_accuracy: 0.5890 - val_loss: 1.7576\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.7029 - val_accuracy: 0.5891 - val_loss: 1.7600\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.7028 - val_accuracy: 0.5915 - val_loss: 1.7538\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.59148\n726/726 - 4s - 5ms/step - accuracy: 0.8005 - loss: 0.7027 - val_accuracy: 0.5895 - val_loss: 1.7549\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.59148\n726/726 - 4s - 5ms/step - accuracy: 0.8006 - loss: 0.7025 - val_accuracy: 0.5891 - val_loss: 1.7583\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.59148\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7024 - val_accuracy: 0.5897 - val_loss: 1.7550\nEpoch 91/500\n\nEpoch 91: val_accuracy improved from 0.59148 to 0.59212, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7023 - val_accuracy: 0.5921 - val_loss: 1.7521\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7022 - val_accuracy: 0.5894 - val_loss: 1.7560\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7020 - val_accuracy: 0.5897 - val_loss: 1.7535\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7019 - val_accuracy: 0.5897 - val_loss: 1.7557\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7018 - val_accuracy: 0.5892 - val_loss: 1.7580\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.7017 - val_accuracy: 0.5893 - val_loss: 1.7576\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.7015 - val_accuracy: 0.5897 - val_loss: 1.7559\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.7014 - val_accuracy: 0.5920 - val_loss: 1.7541\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.7013 - val_accuracy: 0.5892 - val_loss: 1.7579\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.7012 - val_accuracy: 0.5893 - val_loss: 1.7590\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7011 - val_accuracy: 0.5892 - val_loss: 1.7576\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7010 - val_accuracy: 0.5921 - val_loss: 1.7540\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.7009 - val_accuracy: 0.5920 - val_loss: 1.7541\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.7007 - val_accuracy: 0.5920 - val_loss: 1.7531\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.7006 - val_accuracy: 0.5897 - val_loss: 1.7524\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.59212\n726/726 - 4s - 5ms/step - accuracy: 0.8004 - loss: 0.7005 - val_accuracy: 0.5920 - val_loss: 1.7561\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.59212\n726/726 - 4s - 5ms/step - accuracy: 0.8005 - loss: 0.7004 - val_accuracy: 0.5920 - val_loss: 1.7535\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.7003 - val_accuracy: 0.5916 - val_loss: 1.7575\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.7002 - val_accuracy: 0.5918 - val_loss: 1.7564\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.7001 - val_accuracy: 0.5920 - val_loss: 1.7556\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.7000 - val_accuracy: 0.5920 - val_loss: 1.7579\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6999 - val_accuracy: 0.5920 - val_loss: 1.7572\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6998 - val_accuracy: 0.5920 - val_loss: 1.7528\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6997 - val_accuracy: 0.5920 - val_loss: 1.7555\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6996 - val_accuracy: 0.5920 - val_loss: 1.7529\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6995 - val_accuracy: 0.5896 - val_loss: 1.7567\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.59212\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6994 - val_accuracy: 0.5920 - val_loss: 1.7547\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6993 - val_accuracy: 0.5896 - val_loss: 1.7575\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6992 - val_accuracy: 0.5920 - val_loss: 1.7571\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6991 - val_accuracy: 0.5897 - val_loss: 1.7579\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6990 - val_accuracy: 0.5896 - val_loss: 1.7557\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.59212\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.6989 - val_accuracy: 0.5897 - val_loss: 1.7599\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6988 - val_accuracy: 0.5893 - val_loss: 1.7616\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6987 - val_accuracy: 0.5920 - val_loss: 1.7539\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6987 - val_accuracy: 0.5920 - val_loss: 1.7548\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6986 - val_accuracy: 0.5893 - val_loss: 1.7588\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6985 - val_accuracy: 0.5897 - val_loss: 1.7566\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6984 - val_accuracy: 0.5921 - val_loss: 1.7558\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6983 - val_accuracy: 0.5897 - val_loss: 1.7570\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6982 - val_accuracy: 0.5897 - val_loss: 1.7560\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6981 - val_accuracy: 0.5921 - val_loss: 1.7590\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6980 - val_accuracy: 0.5897 - val_loss: 1.7587\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6980 - val_accuracy: 0.5896 - val_loss: 1.7581\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6979 - val_accuracy: 0.5921 - val_loss: 1.7563\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6978 - val_accuracy: 0.5920 - val_loss: 1.7588\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6977 - val_accuracy: 0.5920 - val_loss: 1.7596\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6976 - val_accuracy: 0.5897 - val_loss: 1.7577\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6975 - val_accuracy: 0.5921 - val_loss: 1.7554\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.59212\n726/726 - 5s - 6ms/step - accuracy: 0.8000 - loss: 0.6975 - val_accuracy: 0.5897 - val_loss: 1.7571\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6974 - val_accuracy: 0.5920 - val_loss: 1.7593\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.59212\n726/726 - 4s - 6ms/step - accuracy: 0.8012 - loss: 0.6973 - val_accuracy: 0.5921 - val_loss: 1.7559\nEpoch 142/500\n\nEpoch 142: val_accuracy improved from 0.59212 to 0.59240, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6972 - val_accuracy: 0.5924 - val_loss: 1.7586\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.59240\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6971 - val_accuracy: 0.5901 - val_loss: 1.7544\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.59240\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6971 - val_accuracy: 0.5900 - val_loss: 1.7610\nEpoch 145/500\n\nEpoch 145: val_accuracy improved from 0.59240 to 0.59241, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6970 - val_accuracy: 0.5924 - val_loss: 1.7589\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.59241\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6969 - val_accuracy: 0.5900 - val_loss: 1.7599\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.59241\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6968 - val_accuracy: 0.5896 - val_loss: 1.7628\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.59241\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6968 - val_accuracy: 0.5924 - val_loss: 1.7608\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.59241\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6967 - val_accuracy: 0.5901 - val_loss: 1.7573\nEpoch 150/500\n\nEpoch 150: val_accuracy improved from 0.59241 to 0.59324, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6966 - val_accuracy: 0.5932 - val_loss: 1.7546\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6965 - val_accuracy: 0.5900 - val_loss: 1.7646\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6965 - val_accuracy: 0.5908 - val_loss: 1.7601\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6964 - val_accuracy: 0.5909 - val_loss: 1.7600\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8015 - loss: 0.6963 - val_accuracy: 0.5909 - val_loss: 1.7587\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8013 - loss: 0.6963 - val_accuracy: 0.5932 - val_loss: 1.7609\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6962 - val_accuracy: 0.5932 - val_loss: 1.7567\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6961 - val_accuracy: 0.5908 - val_loss: 1.7598\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6961 - val_accuracy: 0.5909 - val_loss: 1.7608\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8012 - loss: 0.6960 - val_accuracy: 0.5909 - val_loss: 1.7571\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6959 - val_accuracy: 0.5932 - val_loss: 1.7590\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6958 - val_accuracy: 0.5909 - val_loss: 1.7587\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8010 - loss: 0.6958 - val_accuracy: 0.5909 - val_loss: 1.7597\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8012 - loss: 0.6957 - val_accuracy: 0.5909 - val_loss: 1.7535\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6956 - val_accuracy: 0.5932 - val_loss: 1.7569\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6956 - val_accuracy: 0.5908 - val_loss: 1.7594\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6955 - val_accuracy: 0.5909 - val_loss: 1.7568\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6954 - val_accuracy: 0.5932 - val_loss: 1.7622\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6954 - val_accuracy: 0.5908 - val_loss: 1.7604\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6953 - val_accuracy: 0.5932 - val_loss: 1.7601\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6953 - val_accuracy: 0.5932 - val_loss: 1.7592\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6952 - val_accuracy: 0.5908 - val_loss: 1.7606\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6951 - val_accuracy: 0.5932 - val_loss: 1.7589\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6951 - val_accuracy: 0.5907 - val_loss: 1.7650\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6950 - val_accuracy: 0.5930 - val_loss: 1.7575\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6949 - val_accuracy: 0.5906 - val_loss: 1.7604\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6949 - val_accuracy: 0.5905 - val_loss: 1.7625\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6948 - val_accuracy: 0.5929 - val_loss: 1.7570\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6948 - val_accuracy: 0.5929 - val_loss: 1.7603\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6947 - val_accuracy: 0.5905 - val_loss: 1.7621\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6946 - val_accuracy: 0.5905 - val_loss: 1.7599\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6946 - val_accuracy: 0.5905 - val_loss: 1.7560\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6945 - val_accuracy: 0.5904 - val_loss: 1.7608\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6945 - val_accuracy: 0.5905 - val_loss: 1.7565\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6944 - val_accuracy: 0.5906 - val_loss: 1.7604\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.6943 - val_accuracy: 0.5905 - val_loss: 1.7619\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6943 - val_accuracy: 0.5906 - val_loss: 1.7603\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6942 - val_accuracy: 0.5904 - val_loss: 1.7633\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6942 - val_accuracy: 0.5907 - val_loss: 1.7587\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6941 - val_accuracy: 0.5906 - val_loss: 1.7605\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6941 - val_accuracy: 0.5907 - val_loss: 1.7624\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6940 - val_accuracy: 0.5907 - val_loss: 1.7629\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8039 - loss: 0.6939 - val_accuracy: 0.5907 - val_loss: 1.7645\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6939 - val_accuracy: 0.5907 - val_loss: 1.7625\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6938 - val_accuracy: 0.5907 - val_loss: 1.7602\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6938 - val_accuracy: 0.5907 - val_loss: 1.7654\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6937 - val_accuracy: 0.5907 - val_loss: 1.7605\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6937 - val_accuracy: 0.5907 - val_loss: 1.7599\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6936 - val_accuracy: 0.5907 - val_loss: 1.7630\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6936 - val_accuracy: 0.5930 - val_loss: 1.7602\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6935 - val_accuracy: 0.5907 - val_loss: 1.7637\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6935 - val_accuracy: 0.5907 - val_loss: 1.7602\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6934 - val_accuracy: 0.5907 - val_loss: 1.7619\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6934 - val_accuracy: 0.5932 - val_loss: 1.7605\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6933 - val_accuracy: 0.5906 - val_loss: 1.7648\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6933 - val_accuracy: 0.5907 - val_loss: 1.7588\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6932 - val_accuracy: 0.5908 - val_loss: 1.7601\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6932 - val_accuracy: 0.5906 - val_loss: 1.7608\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6931 - val_accuracy: 0.5907 - val_loss: 1.7642\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6931 - val_accuracy: 0.5907 - val_loss: 1.7611\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6930 - val_accuracy: 0.5908 - val_loss: 1.7584\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6930 - val_accuracy: 0.5908 - val_loss: 1.7584\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6929 - val_accuracy: 0.5907 - val_loss: 1.7600\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6929 - val_accuracy: 0.5907 - val_loss: 1.7651\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6928 - val_accuracy: 0.5907 - val_loss: 1.7620\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6928 - val_accuracy: 0.5907 - val_loss: 1.7642\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6927 - val_accuracy: 0.5907 - val_loss: 1.7644\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6927 - val_accuracy: 0.5908 - val_loss: 1.7647\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6926 - val_accuracy: 0.5907 - val_loss: 1.7616\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6926 - val_accuracy: 0.5906 - val_loss: 1.7584\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6925 - val_accuracy: 0.5906 - val_loss: 1.7639\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6925 - val_accuracy: 0.5907 - val_loss: 1.7642\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8040 - loss: 0.6924 - val_accuracy: 0.5907 - val_loss: 1.7631\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6924 - val_accuracy: 0.5906 - val_loss: 1.7619\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6923 - val_accuracy: 0.5906 - val_loss: 1.7667\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6923 - val_accuracy: 0.5907 - val_loss: 1.7630\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6922 - val_accuracy: 0.5906 - val_loss: 1.7625\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6922 - val_accuracy: 0.5907 - val_loss: 1.7639\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6921 - val_accuracy: 0.5901 - val_loss: 1.7646\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6921 - val_accuracy: 0.5903 - val_loss: 1.7641\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6921 - val_accuracy: 0.5902 - val_loss: 1.7653\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8040 - loss: 0.6920 - val_accuracy: 0.5904 - val_loss: 1.7601\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6920 - val_accuracy: 0.5902 - val_loss: 1.7643\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6919 - val_accuracy: 0.5902 - val_loss: 1.7645\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6919 - val_accuracy: 0.5902 - val_loss: 1.7638\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6918 - val_accuracy: 0.5902 - val_loss: 1.7617\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6918 - val_accuracy: 0.5902 - val_loss: 1.7652\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6917 - val_accuracy: 0.5902 - val_loss: 1.7637\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6917 - val_accuracy: 0.5861 - val_loss: 1.7677\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6917 - val_accuracy: 0.5861 - val_loss: 1.7662\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6916 - val_accuracy: 0.5862 - val_loss: 1.7649\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6916 - val_accuracy: 0.5863 - val_loss: 1.7632\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6915 - val_accuracy: 0.5865 - val_loss: 1.7607\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6915 - val_accuracy: 0.5862 - val_loss: 1.7647\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6914 - val_accuracy: 0.5863 - val_loss: 1.7666\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6914 - val_accuracy: 0.5863 - val_loss: 1.7627\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6914 - val_accuracy: 0.5863 - val_loss: 1.7651\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6913 - val_accuracy: 0.5863 - val_loss: 1.7612\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6913 - val_accuracy: 0.5861 - val_loss: 1.7652\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6912 - val_accuracy: 0.5863 - val_loss: 1.7668\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6912 - val_accuracy: 0.5863 - val_loss: 1.7675\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6912 - val_accuracy: 0.5861 - val_loss: 1.7639\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6911 - val_accuracy: 0.5863 - val_loss: 1.7678\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6911 - val_accuracy: 0.5863 - val_loss: 1.7625\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6910 - val_accuracy: 0.5863 - val_loss: 1.7666\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6910 - val_accuracy: 0.5863 - val_loss: 1.7648\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6910 - val_accuracy: 0.5863 - val_loss: 1.7665\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6909 - val_accuracy: 0.5862 - val_loss: 1.7667\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6909 - val_accuracy: 0.5864 - val_loss: 1.7671\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6908 - val_accuracy: 0.5862 - val_loss: 1.7683\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8028 - loss: 0.6908 - val_accuracy: 0.5861 - val_loss: 1.7681\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6908 - val_accuracy: 0.5860 - val_loss: 1.7698\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6907 - val_accuracy: 0.5863 - val_loss: 1.7689\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6907 - val_accuracy: 0.5865 - val_loss: 1.7635\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6906 - val_accuracy: 0.5867 - val_loss: 1.7645\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6906 - val_accuracy: 0.5861 - val_loss: 1.7707\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6906 - val_accuracy: 0.5863 - val_loss: 1.7668\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6905 - val_accuracy: 0.5865 - val_loss: 1.7681\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8039 - loss: 0.6905 - val_accuracy: 0.5863 - val_loss: 1.7681\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6905 - val_accuracy: 0.5865 - val_loss: 1.7689\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6904 - val_accuracy: 0.5863 - val_loss: 1.7664\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6904 - val_accuracy: 0.5869 - val_loss: 1.7649\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6903 - val_accuracy: 0.5867 - val_loss: 1.7673\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6903 - val_accuracy: 0.5867 - val_loss: 1.7683\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6903 - val_accuracy: 0.5867 - val_loss: 1.7640\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.6902 - val_accuracy: 0.5867 - val_loss: 1.7691\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6902 - val_accuracy: 0.5869 - val_loss: 1.7639\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6902 - val_accuracy: 0.5867 - val_loss: 1.7662\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6901 - val_accuracy: 0.5867 - val_loss: 1.7686\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6901 - val_accuracy: 0.5867 - val_loss: 1.7682\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6901 - val_accuracy: 0.5869 - val_loss: 1.7658\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6900 - val_accuracy: 0.5865 - val_loss: 1.7744\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6900 - val_accuracy: 0.5865 - val_loss: 1.7714\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8032 - loss: 0.6899 - val_accuracy: 0.5868 - val_loss: 1.7662\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6899 - val_accuracy: 0.5867 - val_loss: 1.7671\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6899 - val_accuracy: 0.5869 - val_loss: 1.7676\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6898 - val_accuracy: 0.5869 - val_loss: 1.7657\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6898 - val_accuracy: 0.5867 - val_loss: 1.7647\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6898 - val_accuracy: 0.5867 - val_loss: 1.7678\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6897 - val_accuracy: 0.5869 - val_loss: 1.7628\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8036 - loss: 0.6897 - val_accuracy: 0.5867 - val_loss: 1.7674\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6897 - val_accuracy: 0.5869 - val_loss: 1.7650\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6896 - val_accuracy: 0.5868 - val_loss: 1.7705\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8043 - loss: 0.6896 - val_accuracy: 0.5866 - val_loss: 1.7686\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6896 - val_accuracy: 0.5867 - val_loss: 1.7657\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6895 - val_accuracy: 0.5867 - val_loss: 1.7701\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6895 - val_accuracy: 0.5869 - val_loss: 1.7658\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8037 - loss: 0.6895 - val_accuracy: 0.5869 - val_loss: 1.7668\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6894 - val_accuracy: 0.5867 - val_loss: 1.7673\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6894 - val_accuracy: 0.5869 - val_loss: 1.7697\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6894 - val_accuracy: 0.5867 - val_loss: 1.7692\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6893 - val_accuracy: 0.5868 - val_loss: 1.7695\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6893 - val_accuracy: 0.5866 - val_loss: 1.7712\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6893 - val_accuracy: 0.5866 - val_loss: 1.7708\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6892 - val_accuracy: 0.5868 - val_loss: 1.7639\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8032 - loss: 0.6892 - val_accuracy: 0.5869 - val_loss: 1.7688\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6892 - val_accuracy: 0.5868 - val_loss: 1.7697\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6891 - val_accuracy: 0.5869 - val_loss: 1.7681\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6891 - val_accuracy: 0.5867 - val_loss: 1.7671\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6891 - val_accuracy: 0.5869 - val_loss: 1.7712\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6890 - val_accuracy: 0.5870 - val_loss: 1.7686\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6890 - val_accuracy: 0.5870 - val_loss: 1.7689\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8040 - loss: 0.6890 - val_accuracy: 0.5870 - val_loss: 1.7723\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6889 - val_accuracy: 0.5870 - val_loss: 1.7673\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6889 - val_accuracy: 0.5869 - val_loss: 1.7667\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6889 - val_accuracy: 0.5868 - val_loss: 1.7687\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6888 - val_accuracy: 0.5868 - val_loss: 1.7703\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6888 - val_accuracy: 0.5870 - val_loss: 1.7703\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6888 - val_accuracy: 0.5870 - val_loss: 1.7670\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6888 - val_accuracy: 0.5869 - val_loss: 1.7662\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6887 - val_accuracy: 0.5870 - val_loss: 1.7724\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6887 - val_accuracy: 0.5870 - val_loss: 1.7676\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6887 - val_accuracy: 0.5870 - val_loss: 1.7701\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6886 - val_accuracy: 0.5869 - val_loss: 1.7677\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6886 - val_accuracy: 0.5868 - val_loss: 1.7685\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6886 - val_accuracy: 0.5868 - val_loss: 1.7695\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6885 - val_accuracy: 0.5868 - val_loss: 1.7713\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6885 - val_accuracy: 0.5869 - val_loss: 1.7651\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6885 - val_accuracy: 0.5870 - val_loss: 1.7695\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6885 - val_accuracy: 0.5869 - val_loss: 1.7651\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6884 - val_accuracy: 0.5868 - val_loss: 1.7694\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6884 - val_accuracy: 0.5870 - val_loss: 1.7696\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6884 - val_accuracy: 0.5870 - val_loss: 1.7665\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6883 - val_accuracy: 0.5870 - val_loss: 1.7702\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8040 - loss: 0.6883 - val_accuracy: 0.5868 - val_loss: 1.7698\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6883 - val_accuracy: 0.5868 - val_loss: 1.7685\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6883 - val_accuracy: 0.5870 - val_loss: 1.7691\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6882 - val_accuracy: 0.5868 - val_loss: 1.7735\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6882 - val_accuracy: 0.5870 - val_loss: 1.7690\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6882 - val_accuracy: 0.5870 - val_loss: 1.7679\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6881 - val_accuracy: 0.5868 - val_loss: 1.7716\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6881 - val_accuracy: 0.5870 - val_loss: 1.7683\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6881 - val_accuracy: 0.5870 - val_loss: 1.7709\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6880 - val_accuracy: 0.5870 - val_loss: 1.7724\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6880 - val_accuracy: 0.5870 - val_loss: 1.7707\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6880 - val_accuracy: 0.5867 - val_loss: 1.7689\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6880 - val_accuracy: 0.5868 - val_loss: 1.7693\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6879 - val_accuracy: 0.5868 - val_loss: 1.7717\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6879 - val_accuracy: 0.5869 - val_loss: 1.7731\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6879 - val_accuracy: 0.5867 - val_loss: 1.7682\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6879 - val_accuracy: 0.5867 - val_loss: 1.7707\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6878 - val_accuracy: 0.5867 - val_loss: 1.7716\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6878 - val_accuracy: 0.5869 - val_loss: 1.7690\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6878 - val_accuracy: 0.5869 - val_loss: 1.7732\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6877 - val_accuracy: 0.5867 - val_loss: 1.7694\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.6877 - val_accuracy: 0.5869 - val_loss: 1.7673\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6877 - val_accuracy: 0.5867 - val_loss: 1.7713\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6877 - val_accuracy: 0.5867 - val_loss: 1.7719\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6876 - val_accuracy: 0.5868 - val_loss: 1.7709\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6876 - val_accuracy: 0.5869 - val_loss: 1.7684\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8033 - loss: 0.6876 - val_accuracy: 0.5868 - val_loss: 1.7700\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6876 - val_accuracy: 0.5867 - val_loss: 1.7750\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6875 - val_accuracy: 0.5869 - val_loss: 1.7694\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6875 - val_accuracy: 0.5867 - val_loss: 1.7738\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6875 - val_accuracy: 0.5869 - val_loss: 1.7674\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6874 - val_accuracy: 0.5868 - val_loss: 1.7714\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6874 - val_accuracy: 0.5867 - val_loss: 1.7773\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8038 - loss: 0.6874 - val_accuracy: 0.5868 - val_loss: 1.7729\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6874 - val_accuracy: 0.5868 - val_loss: 1.7704\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8022 - loss: 0.6873 - val_accuracy: 0.5869 - val_loss: 1.7723\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6873 - val_accuracy: 0.5868 - val_loss: 1.7743\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6873 - val_accuracy: 0.5868 - val_loss: 1.7710\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6873 - val_accuracy: 0.5869 - val_loss: 1.7697\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6872 - val_accuracy: 0.5869 - val_loss: 1.7754\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6872 - val_accuracy: 0.5869 - val_loss: 1.7782\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6872 - val_accuracy: 0.5868 - val_loss: 1.7760\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6872 - val_accuracy: 0.5868 - val_loss: 1.7760\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6871 - val_accuracy: 0.5884 - val_loss: 1.7681\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6871 - val_accuracy: 0.5869 - val_loss: 1.7719\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6871 - val_accuracy: 0.5871 - val_loss: 1.7743\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6871 - val_accuracy: 0.5871 - val_loss: 1.7737\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6870 - val_accuracy: 0.5878 - val_loss: 1.7722\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6870 - val_accuracy: 0.5879 - val_loss: 1.7739\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6870 - val_accuracy: 0.5878 - val_loss: 1.7719\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6870 - val_accuracy: 0.5876 - val_loss: 1.7734\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6869 - val_accuracy: 0.5879 - val_loss: 1.7725\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6869 - val_accuracy: 0.5879 - val_loss: 1.7720\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6869 - val_accuracy: 0.5875 - val_loss: 1.7726\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6869 - val_accuracy: 0.5879 - val_loss: 1.7705\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6868 - val_accuracy: 0.5875 - val_loss: 1.7753\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6868 - val_accuracy: 0.5879 - val_loss: 1.7715\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6868 - val_accuracy: 0.5884 - val_loss: 1.7722\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6868 - val_accuracy: 0.5876 - val_loss: 1.7730\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8032 - loss: 0.6867 - val_accuracy: 0.5878 - val_loss: 1.7738\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.6867 - val_accuracy: 0.5879 - val_loss: 1.7785\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8032 - loss: 0.6867 - val_accuracy: 0.5875 - val_loss: 1.7742\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8021 - loss: 0.6867 - val_accuracy: 0.5876 - val_loss: 1.7724\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8035 - loss: 0.6866 - val_accuracy: 0.5875 - val_loss: 1.7728\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8017 - loss: 0.6866 - val_accuracy: 0.5876 - val_loss: 1.7764\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.6866 - val_accuracy: 0.5881 - val_loss: 1.7713\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8033 - loss: 0.6866 - val_accuracy: 0.5875 - val_loss: 1.7754\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8028 - loss: 0.6865 - val_accuracy: 0.5875 - val_loss: 1.7714\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8030 - loss: 0.6865 - val_accuracy: 0.5881 - val_loss: 1.7729\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8032 - loss: 0.6865 - val_accuracy: 0.5874 - val_loss: 1.7771\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6865 - val_accuracy: 0.5875 - val_loss: 1.7730\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8021 - loss: 0.6865 - val_accuracy: 0.5875 - val_loss: 1.7732\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6864 - val_accuracy: 0.5876 - val_loss: 1.7717\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6864 - val_accuracy: 0.5876 - val_loss: 1.7760\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6864 - val_accuracy: 0.5881 - val_loss: 1.7742\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8028 - loss: 0.6864 - val_accuracy: 0.5880 - val_loss: 1.7706\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6863 - val_accuracy: 0.5881 - val_loss: 1.7737\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6863 - val_accuracy: 0.5876 - val_loss: 1.7771\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6863 - val_accuracy: 0.5875 - val_loss: 1.7751\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6863 - val_accuracy: 0.5881 - val_loss: 1.7731\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6862 - val_accuracy: 0.5880 - val_loss: 1.7717\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6862 - val_accuracy: 0.5881 - val_loss: 1.7742\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6862 - val_accuracy: 0.5876 - val_loss: 1.7762\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6862 - val_accuracy: 0.5873 - val_loss: 1.7766\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6862 - val_accuracy: 0.5873 - val_loss: 1.7755\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6861 - val_accuracy: 0.5876 - val_loss: 1.7758\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6861 - val_accuracy: 0.5876 - val_loss: 1.7718\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6861 - val_accuracy: 0.5877 - val_loss: 1.7769\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6861 - val_accuracy: 0.5876 - val_loss: 1.7778\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8013 - loss: 0.6860 - val_accuracy: 0.5873 - val_loss: 1.7731\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8029 - loss: 0.6860 - val_accuracy: 0.5878 - val_loss: 1.7715\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6860 - val_accuracy: 0.5871 - val_loss: 1.7749\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6860 - val_accuracy: 0.5876 - val_loss: 1.7724\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6860 - val_accuracy: 0.5871 - val_loss: 1.7725\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8013 - loss: 0.6859 - val_accuracy: 0.5873 - val_loss: 1.7779\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6859 - val_accuracy: 0.5871 - val_loss: 1.7799\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6859 - val_accuracy: 0.5878 - val_loss: 1.7738\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8028 - loss: 0.6859 - val_accuracy: 0.5871 - val_loss: 1.7765\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6858 - val_accuracy: 0.5879 - val_loss: 1.7736\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6858 - val_accuracy: 0.5871 - val_loss: 1.7781\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6858 - val_accuracy: 0.5878 - val_loss: 1.7739\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6858 - val_accuracy: 0.5879 - val_loss: 1.7733\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6858 - val_accuracy: 0.5877 - val_loss: 1.7772\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6857 - val_accuracy: 0.5877 - val_loss: 1.7729\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6857 - val_accuracy: 0.5872 - val_loss: 1.7782\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8023 - loss: 0.6857 - val_accuracy: 0.5874 - val_loss: 1.7788\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6857 - val_accuracy: 0.5871 - val_loss: 1.7786\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8018 - loss: 0.6856 - val_accuracy: 0.5872 - val_loss: 1.7753\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6856 - val_accuracy: 0.5872 - val_loss: 1.7792\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6856 - val_accuracy: 0.5872 - val_loss: 1.7817\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6856 - val_accuracy: 0.5878 - val_loss: 1.7723\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6856 - val_accuracy: 0.5874 - val_loss: 1.7800\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6855 - val_accuracy: 0.5874 - val_loss: 1.7799\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6855 - val_accuracy: 0.5872 - val_loss: 1.7809\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6855 - val_accuracy: 0.5879 - val_loss: 1.7770\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6855 - val_accuracy: 0.5879 - val_loss: 1.7771\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6855 - val_accuracy: 0.5878 - val_loss: 1.7780\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6854 - val_accuracy: 0.5872 - val_loss: 1.7813\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6854 - val_accuracy: 0.5878 - val_loss: 1.7710\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8012 - loss: 0.6854 - val_accuracy: 0.5879 - val_loss: 1.7788\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6854 - val_accuracy: 0.5878 - val_loss: 1.7755\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6854 - val_accuracy: 0.5878 - val_loss: 1.7773\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6853 - val_accuracy: 0.5878 - val_loss: 1.7779\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6853 - val_accuracy: 0.5878 - val_loss: 1.7769\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8006 - loss: 0.6853 - val_accuracy: 0.5879 - val_loss: 1.7788\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6853 - val_accuracy: 0.5879 - val_loss: 1.7765\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6853 - val_accuracy: 0.5879 - val_loss: 1.7789\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6852 - val_accuracy: 0.5878 - val_loss: 1.7770\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8012 - loss: 0.6852 - val_accuracy: 0.5878 - val_loss: 1.7776\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8015 - loss: 0.6852 - val_accuracy: 0.5878 - val_loss: 1.7780\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.6852 - val_accuracy: 0.5878 - val_loss: 1.7782\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6852 - val_accuracy: 0.5878 - val_loss: 1.7765\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8016 - loss: 0.6851 - val_accuracy: 0.5878 - val_loss: 1.7741\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6851 - val_accuracy: 0.5878 - val_loss: 1.7782\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8016 - loss: 0.6851 - val_accuracy: 0.5878 - val_loss: 1.7747\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8017 - loss: 0.6851 - val_accuracy: 0.5878 - val_loss: 1.7773\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6850 - val_accuracy: 0.5877 - val_loss: 1.7762\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8019 - loss: 0.6850 - val_accuracy: 0.5879 - val_loss: 1.7739\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6850 - val_accuracy: 0.5874 - val_loss: 1.7782\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8021 - loss: 0.6850 - val_accuracy: 0.5874 - val_loss: 1.7813\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8024 - loss: 0.6850 - val_accuracy: 0.5873 - val_loss: 1.7781\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8023 - loss: 0.6850 - val_accuracy: 0.5879 - val_loss: 1.7748\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6849 - val_accuracy: 0.5879 - val_loss: 1.7749\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6849 - val_accuracy: 0.5873 - val_loss: 1.7789\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6849 - val_accuracy: 0.5878 - val_loss: 1.7751\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8020 - loss: 0.6849 - val_accuracy: 0.5873 - val_loss: 1.7798\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6849 - val_accuracy: 0.5871 - val_loss: 1.7840\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6848 - val_accuracy: 0.5880 - val_loss: 1.7787\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6848 - val_accuracy: 0.5878 - val_loss: 1.7793\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6848 - val_accuracy: 0.5878 - val_loss: 1.7798\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8023 - loss: 0.6848 - val_accuracy: 0.5878 - val_loss: 1.7801\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8033 - loss: 0.6848 - val_accuracy: 0.5878 - val_loss: 1.7804\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6847 - val_accuracy: 0.5878 - val_loss: 1.7792\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6847 - val_accuracy: 0.5876 - val_loss: 1.7824\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8041 - loss: 0.6847 - val_accuracy: 0.5878 - val_loss: 1.7771\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.6847 - val_accuracy: 0.5873 - val_loss: 1.7817\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6847 - val_accuracy: 0.5876 - val_loss: 1.7817\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6846 - val_accuracy: 0.5878 - val_loss: 1.7790\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6846 - val_accuracy: 0.5879 - val_loss: 1.7799\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8042 - loss: 0.6846 - val_accuracy: 0.5876 - val_loss: 1.7807\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6846 - val_accuracy: 0.5878 - val_loss: 1.7827\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6846 - val_accuracy: 0.5877 - val_loss: 1.7802\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6845 - val_accuracy: 0.5879 - val_loss: 1.7814\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6845 - val_accuracy: 0.5878 - val_loss: 1.7799\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6845 - val_accuracy: 0.5877 - val_loss: 1.7800\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6845 - val_accuracy: 0.5878 - val_loss: 1.7753\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8024 - loss: 0.6845 - val_accuracy: 0.5877 - val_loss: 1.7808\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_29, X_test_29, y_train_29, y_test_29 = train_test_split(\n    X, y, test_size=0.3, random_state=71, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_29, X_val_29, y_train_29, y_val_29 = train_test_split(\n    X_train_29, y_train_29, test_size=0.2, random_state=71, stratify=y_train_29\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_29:\", np.max(X_train_29))\nprint(\"Min value in X_train_29:\", np.min(X_train_29))\n\nX_train_29_scaled = scaler.fit_transform(X_train_29)\n\n# Get the original class distribution\nclass_counts_29 = Counter(y_train_29)\nprint(\"Original class distribution:\", class_counts_29)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_29 = class_counts_29[min(class_counts_29, key=class_counts_29.get)]\ndesired_majority_size_29 = minority_class_size_29 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_29 = {0: desired_majority_size_29, 1: minority_class_size_29}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_29 = RandomUnderSampler(sampling_strategy=sampling_strategy_29, random_state=42)\nX_resampled_29, y_resampled_29 = undersampler_29.fit_resample(X_train_29, y_train_29)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_29))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_29, y_train_resampled_29 = smote.fit_resample(X_resampled_29, y_resampled_29)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_29))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_29))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T03:14:46.249667Z","iopub.execute_input":"2025-03-08T03:14:46.249952Z","iopub.status.idle":"2025-03-08T03:15:18.816477Z","shell.execute_reply.started":"2025-03-08T03:14:46.249923Z","shell.execute_reply":"2025-03-08T03:15:18.815467Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_29: 2071000000.0\nMin value in X_train_29: -9663668122.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_29 = X_train_resampled_29.reshape(X_train_resampled_29.shape[0], 1, 56)\nX_val_29 = X_val_29.reshape(X_val_29.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_29,  # Features from CICIDS2017\n    y_train_resampled_29,  # Labels from CICIDS2017\n    validation_data=(X_val_29, y_val_29),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T03:15:18.817673Z","iopub.execute_input":"2025-03-08T03:15:18.818068Z","iopub.status.idle":"2025-03-08T03:49:11.832592Z","shell.execute_reply.started":"2025-03-08T03:15:18.818030Z","shell.execute_reply":"2025-03-08T03:49:11.831586Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7909 - loss: 0.7324 - val_accuracy: 0.5781 - val_loss: 1.7518\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7972 - loss: 0.7275 - val_accuracy: 0.5785 - val_loss: 1.7439\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7998 - loss: 0.7252 - val_accuracy: 0.5784 - val_loss: 1.7351\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.7235 - val_accuracy: 0.5813 - val_loss: 1.7264\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8035 - loss: 0.7222 - val_accuracy: 0.5814 - val_loss: 1.7205\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.7210 - val_accuracy: 0.5816 - val_loss: 1.7208\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.7199 - val_accuracy: 0.5817 - val_loss: 1.7110\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.7189 - val_accuracy: 0.5828 - val_loss: 1.7047\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.7180 - val_accuracy: 0.5828 - val_loss: 1.7043\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.7171 - val_accuracy: 0.5828 - val_loss: 1.7020\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.7163 - val_accuracy: 0.5828 - val_loss: 1.6975\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.7155 - val_accuracy: 0.5829 - val_loss: 1.6914\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.7147 - val_accuracy: 0.5827 - val_loss: 1.6901\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.7140 - val_accuracy: 0.5829 - val_loss: 1.6869\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.7134 - val_accuracy: 0.5829 - val_loss: 1.6820\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.7127 - val_accuracy: 0.5829 - val_loss: 1.6818\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.7121 - val_accuracy: 0.5829 - val_loss: 1.6815\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.7115 - val_accuracy: 0.5828 - val_loss: 1.6762\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.7109 - val_accuracy: 0.5829 - val_loss: 1.6768\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.7103 - val_accuracy: 0.5825 - val_loss: 1.6755\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.7098 - val_accuracy: 0.5826 - val_loss: 1.6708\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.7093 - val_accuracy: 0.5825 - val_loss: 1.6692\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.7087 - val_accuracy: 0.5840 - val_loss: 1.6660\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.7083 - val_accuracy: 0.5837 - val_loss: 1.6633\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.7078 - val_accuracy: 0.5836 - val_loss: 1.6644\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.7073 - val_accuracy: 0.5840 - val_loss: 1.6619\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.7068 - val_accuracy: 0.5839 - val_loss: 1.6603\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.7064 - val_accuracy: 0.5838 - val_loss: 1.6620\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.7059 - val_accuracy: 0.5839 - val_loss: 1.6591\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.7055 - val_accuracy: 0.5839 - val_loss: 1.6568\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.7051 - val_accuracy: 0.5839 - val_loss: 1.6539\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.7047 - val_accuracy: 0.5839 - val_loss: 1.6583\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8031 - loss: 0.7043 - val_accuracy: 0.5839 - val_loss: 1.6507\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8031 - loss: 0.7039 - val_accuracy: 0.5839 - val_loss: 1.6554\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.7035 - val_accuracy: 0.5839 - val_loss: 1.6522\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8031 - loss: 0.7031 - val_accuracy: 0.5839 - val_loss: 1.6449\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.59324\n726/726 - 5s - 7ms/step - accuracy: 0.8030 - loss: 0.7027 - val_accuracy: 0.5839 - val_loss: 1.6460\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.7024 - val_accuracy: 0.5839 - val_loss: 1.6481\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.7020 - val_accuracy: 0.5840 - val_loss: 1.6496\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.8031 - loss: 0.7017 - val_accuracy: 0.5841 - val_loss: 1.6422\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.7013 - val_accuracy: 0.5841 - val_loss: 1.6463\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.7010 - val_accuracy: 0.5842 - val_loss: 1.6435\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.7006 - val_accuracy: 0.5828 - val_loss: 1.6442\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.7003 - val_accuracy: 0.5828 - val_loss: 1.6423\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.7000 - val_accuracy: 0.5868 - val_loss: 1.6417\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7987 - loss: 0.6997 - val_accuracy: 0.5868 - val_loss: 1.6445\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6994 - val_accuracy: 0.5868 - val_loss: 1.6416\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7981 - loss: 0.6990 - val_accuracy: 0.5868 - val_loss: 1.6410\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7979 - loss: 0.6987 - val_accuracy: 0.5868 - val_loss: 1.6409\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.6984 - val_accuracy: 0.5867 - val_loss: 1.6437\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.6982 - val_accuracy: 0.5867 - val_loss: 1.6368\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.6979 - val_accuracy: 0.5868 - val_loss: 1.6363\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.6976 - val_accuracy: 0.5862 - val_loss: 1.6388\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7978 - loss: 0.6973 - val_accuracy: 0.5863 - val_loss: 1.6388\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7978 - loss: 0.6970 - val_accuracy: 0.5862 - val_loss: 1.6335\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.6968 - val_accuracy: 0.5863 - val_loss: 1.6343\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7977 - loss: 0.6965 - val_accuracy: 0.5862 - val_loss: 1.6396\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7977 - loss: 0.6962 - val_accuracy: 0.5862 - val_loss: 1.6357\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7977 - loss: 0.6960 - val_accuracy: 0.5862 - val_loss: 1.6348\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7977 - loss: 0.6957 - val_accuracy: 0.5863 - val_loss: 1.6351\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7977 - loss: 0.6954 - val_accuracy: 0.5863 - val_loss: 1.6331\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7977 - loss: 0.6952 - val_accuracy: 0.5863 - val_loss: 1.6336\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.59324\n726/726 - 5s - 6ms/step - accuracy: 0.7978 - loss: 0.6949 - val_accuracy: 0.5863 - val_loss: 1.6328\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7978 - loss: 0.6947 - val_accuracy: 0.5862 - val_loss: 1.6321\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7978 - loss: 0.6945 - val_accuracy: 0.5862 - val_loss: 1.6352\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7978 - loss: 0.6942 - val_accuracy: 0.5864 - val_loss: 1.6336\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7979 - loss: 0.6940 - val_accuracy: 0.5863 - val_loss: 1.6357\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7979 - loss: 0.6938 - val_accuracy: 0.5863 - val_loss: 1.6343\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7979 - loss: 0.6935 - val_accuracy: 0.5864 - val_loss: 1.6301\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7980 - loss: 0.6933 - val_accuracy: 0.5864 - val_loss: 1.6321\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7981 - loss: 0.6931 - val_accuracy: 0.5864 - val_loss: 1.6332\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7982 - loss: 0.6929 - val_accuracy: 0.5864 - val_loss: 1.6318\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7982 - loss: 0.6926 - val_accuracy: 0.5864 - val_loss: 1.6319\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7982 - loss: 0.6924 - val_accuracy: 0.5864 - val_loss: 1.6321\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7982 - loss: 0.6922 - val_accuracy: 0.5860 - val_loss: 1.6347\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6920 - val_accuracy: 0.5860 - val_loss: 1.6324\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6918 - val_accuracy: 0.5860 - val_loss: 1.6293\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6916 - val_accuracy: 0.5860 - val_loss: 1.6322\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6914 - val_accuracy: 0.5860 - val_loss: 1.6329\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6912 - val_accuracy: 0.5861 - val_loss: 1.6306\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6910 - val_accuracy: 0.5862 - val_loss: 1.6333\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7984 - loss: 0.6908 - val_accuracy: 0.5861 - val_loss: 1.6294\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7984 - loss: 0.6906 - val_accuracy: 0.5861 - val_loss: 1.6297\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6904 - val_accuracy: 0.5861 - val_loss: 1.6307\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6902 - val_accuracy: 0.5861 - val_loss: 1.6322\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6900 - val_accuracy: 0.5861 - val_loss: 1.6311\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6898 - val_accuracy: 0.5861 - val_loss: 1.6279\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7984 - loss: 0.6897 - val_accuracy: 0.5861 - val_loss: 1.6307\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7984 - loss: 0.6895 - val_accuracy: 0.5861 - val_loss: 1.6332\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6893 - val_accuracy: 0.5902 - val_loss: 1.6327\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6891 - val_accuracy: 0.5904 - val_loss: 1.6283\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7982 - loss: 0.6890 - val_accuracy: 0.5902 - val_loss: 1.6336\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6888 - val_accuracy: 0.5902 - val_loss: 1.6325\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6886 - val_accuracy: 0.5903 - val_loss: 1.6292\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6884 - val_accuracy: 0.5896 - val_loss: 1.6331\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6883 - val_accuracy: 0.5893 - val_loss: 1.6336\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6881 - val_accuracy: 0.5893 - val_loss: 1.6294\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6879 - val_accuracy: 0.5893 - val_loss: 1.6325\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6878 - val_accuracy: 0.5894 - val_loss: 1.6291\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6876 - val_accuracy: 0.5894 - val_loss: 1.6295\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7985 - loss: 0.6875 - val_accuracy: 0.5893 - val_loss: 1.6331\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6873 - val_accuracy: 0.5893 - val_loss: 1.6319\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6871 - val_accuracy: 0.5892 - val_loss: 1.6301\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7983 - loss: 0.6870 - val_accuracy: 0.5893 - val_loss: 1.6297\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6868 - val_accuracy: 0.5893 - val_loss: 1.6336\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6867 - val_accuracy: 0.5892 - val_loss: 1.6299\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6865 - val_accuracy: 0.5892 - val_loss: 1.6318\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7984 - loss: 0.6864 - val_accuracy: 0.5892 - val_loss: 1.6294\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.59324\n726/726 - 4s - 5ms/step - accuracy: 0.7987 - loss: 0.6862 - val_accuracy: 0.5892 - val_loss: 1.6332\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7987 - loss: 0.6861 - val_accuracy: 0.5892 - val_loss: 1.6340\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.59324\n726/726 - 4s - 6ms/step - accuracy: 0.7986 - loss: 0.6859 - val_accuracy: 0.5892 - val_loss: 1.6332\nEpoch 112/500\n\nEpoch 112: val_accuracy improved from 0.59324 to 0.59474, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.7986 - loss: 0.6858 - val_accuracy: 0.5947 - val_loss: 1.6276\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7987 - loss: 0.6857 - val_accuracy: 0.5947 - val_loss: 1.6298\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7988 - loss: 0.6855 - val_accuracy: 0.5944 - val_loss: 1.6351\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7989 - loss: 0.6854 - val_accuracy: 0.5893 - val_loss: 1.6316\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7986 - loss: 0.6852 - val_accuracy: 0.5889 - val_loss: 1.6334\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7987 - loss: 0.6851 - val_accuracy: 0.5945 - val_loss: 1.6309\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.59474\n726/726 - 5s - 6ms/step - accuracy: 0.7992 - loss: 0.6850 - val_accuracy: 0.5889 - val_loss: 1.6307\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6848 - val_accuracy: 0.5888 - val_loss: 1.6344\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7989 - loss: 0.6847 - val_accuracy: 0.5945 - val_loss: 1.6288\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6846 - val_accuracy: 0.5945 - val_loss: 1.6305\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6844 - val_accuracy: 0.5885 - val_loss: 1.6318\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7992 - loss: 0.6843 - val_accuracy: 0.5938 - val_loss: 1.6344\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7993 - loss: 0.6842 - val_accuracy: 0.5941 - val_loss: 1.6323\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6840 - val_accuracy: 0.5883 - val_loss: 1.6344\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7992 - loss: 0.6839 - val_accuracy: 0.5885 - val_loss: 1.6315\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7993 - loss: 0.6838 - val_accuracy: 0.5943 - val_loss: 1.6314\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6837 - val_accuracy: 0.5937 - val_loss: 1.6361\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6835 - val_accuracy: 0.5883 - val_loss: 1.6354\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6834 - val_accuracy: 0.5882 - val_loss: 1.6382\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6833 - val_accuracy: 0.5942 - val_loss: 1.6345\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6832 - val_accuracy: 0.5945 - val_loss: 1.6325\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6830 - val_accuracy: 0.5943 - val_loss: 1.6316\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.59474\n726/726 - 4s - 5ms/step - accuracy: 0.7996 - loss: 0.6829 - val_accuracy: 0.5945 - val_loss: 1.6330\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.59474\n726/726 - 4s - 5ms/step - accuracy: 0.7999 - loss: 0.6828 - val_accuracy: 0.5945 - val_loss: 1.6331\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.59474\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6827 - val_accuracy: 0.5946 - val_loss: 1.6326\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6826 - val_accuracy: 0.5946 - val_loss: 1.6330\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.59474\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.6825 - val_accuracy: 0.5945 - val_loss: 1.6309\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.59474\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6824 - val_accuracy: 0.5944 - val_loss: 1.6317\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.59474\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6822 - val_accuracy: 0.5946 - val_loss: 1.6332\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6821 - val_accuracy: 0.5946 - val_loss: 1.6343\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6820 - val_accuracy: 0.5945 - val_loss: 1.6358\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.59474\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6819 - val_accuracy: 0.5943 - val_loss: 1.6385\nEpoch 144/500\n\nEpoch 144: val_accuracy improved from 0.59474 to 0.59497, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6818 - val_accuracy: 0.5950 - val_loss: 1.6376\nEpoch 145/500\n\nEpoch 145: val_accuracy improved from 0.59497 to 0.59535, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.6817 - val_accuracy: 0.5953 - val_loss: 1.6351\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.59535\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6816 - val_accuracy: 0.5949 - val_loss: 1.6361\nEpoch 147/500\n\nEpoch 147: val_accuracy improved from 0.59535 to 0.59542, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.6815 - val_accuracy: 0.5954 - val_loss: 1.6349\nEpoch 148/500\n\nEpoch 148: val_accuracy improved from 0.59542 to 0.59542, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6814 - val_accuracy: 0.5954 - val_loss: 1.6336\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.59542\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6813 - val_accuracy: 0.5954 - val_loss: 1.6351\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.59542\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6812 - val_accuracy: 0.5952 - val_loss: 1.6356\nEpoch 151/500\n\nEpoch 151: val_accuracy improved from 0.59542 to 0.59563, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6811 - val_accuracy: 0.5956 - val_loss: 1.6354\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.59563\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6809 - val_accuracy: 0.5954 - val_loss: 1.6394\nEpoch 153/500\n\nEpoch 153: val_accuracy improved from 0.59563 to 0.59568, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6808 - val_accuracy: 0.5957 - val_loss: 1.6334\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.59568\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6807 - val_accuracy: 0.5956 - val_loss: 1.6343\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.59568\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6806 - val_accuracy: 0.5956 - val_loss: 1.6345\nEpoch 156/500\n\nEpoch 156: val_accuracy improved from 0.59568 to 0.59570, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6805 - val_accuracy: 0.5957 - val_loss: 1.6345\nEpoch 157/500\n\nEpoch 157: val_accuracy improved from 0.59570 to 0.59571, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6804 - val_accuracy: 0.5957 - val_loss: 1.6373\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.59571\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6803 - val_accuracy: 0.5955 - val_loss: 1.6401\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.59571\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6802 - val_accuracy: 0.5955 - val_loss: 1.6401\nEpoch 160/500\n\nEpoch 160: val_accuracy improved from 0.59571 to 0.59572, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8003 - loss: 0.6801 - val_accuracy: 0.5957 - val_loss: 1.6358\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.59572\n726/726 - 4s - 5ms/step - accuracy: 0.8004 - loss: 0.6800 - val_accuracy: 0.5957 - val_loss: 1.6340\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.59572\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6799 - val_accuracy: 0.5956 - val_loss: 1.6371\nEpoch 163/500\n\nEpoch 163: val_accuracy improved from 0.59572 to 0.59581, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6798 - val_accuracy: 0.5958 - val_loss: 1.6353\nEpoch 164/500\n\nEpoch 164: val_accuracy improved from 0.59581 to 0.59586, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8006 - loss: 0.6797 - val_accuracy: 0.5959 - val_loss: 1.6375\nEpoch 165/500\n\nEpoch 165: val_accuracy improved from 0.59586 to 0.59586, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6796 - val_accuracy: 0.5959 - val_loss: 1.6388\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.59586\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.6796 - val_accuracy: 0.5958 - val_loss: 1.6382\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.59586\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6795 - val_accuracy: 0.5956 - val_loss: 1.6409\nEpoch 168/500\n\nEpoch 168: val_accuracy improved from 0.59586 to 0.59645, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6794 - val_accuracy: 0.5965 - val_loss: 1.6389\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.59645\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6793 - val_accuracy: 0.5963 - val_loss: 1.6372\nEpoch 170/500\n\nEpoch 170: val_accuracy improved from 0.59645 to 0.59647, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6792 - val_accuracy: 0.5965 - val_loss: 1.6373\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.59647\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6791 - val_accuracy: 0.5965 - val_loss: 1.6396\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.59647\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6790 - val_accuracy: 0.5962 - val_loss: 1.6415\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.59647\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6789 - val_accuracy: 0.5963 - val_loss: 1.6403\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.59647\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6788 - val_accuracy: 0.5965 - val_loss: 1.6390\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.59647\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6787 - val_accuracy: 0.5963 - val_loss: 1.6398\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.59647\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6786 - val_accuracy: 0.5963 - val_loss: 1.6408\nEpoch 177/500\n\nEpoch 177: val_accuracy improved from 0.59647 to 0.59654, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6785 - val_accuracy: 0.5965 - val_loss: 1.6367\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6785 - val_accuracy: 0.5963 - val_loss: 1.6404\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8009 - loss: 0.6784 - val_accuracy: 0.5963 - val_loss: 1.6374\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8009 - loss: 0.6783 - val_accuracy: 0.5965 - val_loss: 1.6406\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6782 - val_accuracy: 0.5962 - val_loss: 1.6415\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6781 - val_accuracy: 0.5962 - val_loss: 1.6419\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8010 - loss: 0.6780 - val_accuracy: 0.5964 - val_loss: 1.6437\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8009 - loss: 0.6779 - val_accuracy: 0.5947 - val_loss: 1.6412\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6779 - val_accuracy: 0.5947 - val_loss: 1.6467\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6778 - val_accuracy: 0.5949 - val_loss: 1.6433\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6777 - val_accuracy: 0.5951 - val_loss: 1.6408\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8010 - loss: 0.6776 - val_accuracy: 0.5951 - val_loss: 1.6412\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6775 - val_accuracy: 0.5949 - val_loss: 1.6452\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6774 - val_accuracy: 0.5951 - val_loss: 1.6436\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8009 - loss: 0.6774 - val_accuracy: 0.5949 - val_loss: 1.6434\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6773 - val_accuracy: 0.5949 - val_loss: 1.6450\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8010 - loss: 0.6772 - val_accuracy: 0.5949 - val_loss: 1.6425\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6771 - val_accuracy: 0.5951 - val_loss: 1.6432\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6770 - val_accuracy: 0.5955 - val_loss: 1.6395\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6770 - val_accuracy: 0.5951 - val_loss: 1.6461\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6769 - val_accuracy: 0.5952 - val_loss: 1.6438\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6768 - val_accuracy: 0.5954 - val_loss: 1.6411\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6767 - val_accuracy: 0.5953 - val_loss: 1.6446\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6766 - val_accuracy: 0.5957 - val_loss: 1.6425\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.59654\n726/726 - 5s - 6ms/step - accuracy: 0.8010 - loss: 0.6766 - val_accuracy: 0.5954 - val_loss: 1.6446\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.59654\n726/726 - 5s - 6ms/step - accuracy: 0.8010 - loss: 0.6765 - val_accuracy: 0.5956 - val_loss: 1.6437\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.59654\n726/726 - 5s - 6ms/step - accuracy: 0.8010 - loss: 0.6764 - val_accuracy: 0.5958 - val_loss: 1.6429\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.59654\n726/726 - 5s - 7ms/step - accuracy: 0.8009 - loss: 0.6763 - val_accuracy: 0.5952 - val_loss: 1.6448\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6763 - val_accuracy: 0.5954 - val_loss: 1.6447\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6762 - val_accuracy: 0.5957 - val_loss: 1.6453\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6761 - val_accuracy: 0.5959 - val_loss: 1.6400\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6760 - val_accuracy: 0.5957 - val_loss: 1.6462\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6760 - val_accuracy: 0.5957 - val_loss: 1.6457\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6759 - val_accuracy: 0.5956 - val_loss: 1.6465\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6758 - val_accuracy: 0.5958 - val_loss: 1.6429\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6757 - val_accuracy: 0.5958 - val_loss: 1.6405\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6757 - val_accuracy: 0.5956 - val_loss: 1.6478\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8007 - loss: 0.6756 - val_accuracy: 0.5956 - val_loss: 1.6472\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6755 - val_accuracy: 0.5956 - val_loss: 1.6433\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6755 - val_accuracy: 0.5956 - val_loss: 1.6445\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6754 - val_accuracy: 0.5956 - val_loss: 1.6481\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6753 - val_accuracy: 0.5956 - val_loss: 1.6467\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6752 - val_accuracy: 0.5959 - val_loss: 1.6466\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6752 - val_accuracy: 0.5960 - val_loss: 1.6448\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6751 - val_accuracy: 0.5959 - val_loss: 1.6464\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6750 - val_accuracy: 0.5959 - val_loss: 1.6464\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6750 - val_accuracy: 0.5960 - val_loss: 1.6454\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6749 - val_accuracy: 0.5959 - val_loss: 1.6453\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8008 - loss: 0.6748 - val_accuracy: 0.5959 - val_loss: 1.6440\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8009 - loss: 0.6748 - val_accuracy: 0.5957 - val_loss: 1.6521\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6747 - val_accuracy: 0.5958 - val_loss: 1.6497\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6746 - val_accuracy: 0.5958 - val_loss: 1.6484\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6746 - val_accuracy: 0.5959 - val_loss: 1.6460\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6745 - val_accuracy: 0.5957 - val_loss: 1.6504\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6744 - val_accuracy: 0.5948 - val_loss: 1.6491\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6744 - val_accuracy: 0.5960 - val_loss: 1.6474\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6743 - val_accuracy: 0.5953 - val_loss: 1.6456\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.8006 - loss: 0.6742 - val_accuracy: 0.5948 - val_loss: 1.6484\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6742 - val_accuracy: 0.5949 - val_loss: 1.6499\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7993 - loss: 0.6741 - val_accuracy: 0.5955 - val_loss: 1.6486\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7988 - loss: 0.6740 - val_accuracy: 0.5957 - val_loss: 1.6456\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6740 - val_accuracy: 0.5956 - val_loss: 1.6483\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.7985 - loss: 0.6739 - val_accuracy: 0.5956 - val_loss: 1.6471\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6738 - val_accuracy: 0.5955 - val_loss: 1.6490\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6738 - val_accuracy: 0.5956 - val_loss: 1.6508\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.7985 - loss: 0.6737 - val_accuracy: 0.5957 - val_loss: 1.6491\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6737 - val_accuracy: 0.5956 - val_loss: 1.6495\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6736 - val_accuracy: 0.5959 - val_loss: 1.6455\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7984 - loss: 0.6735 - val_accuracy: 0.5957 - val_loss: 1.6481\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.7985 - loss: 0.6735 - val_accuracy: 0.5957 - val_loss: 1.6485\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6734 - val_accuracy: 0.5957 - val_loss: 1.6479\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6734 - val_accuracy: 0.5957 - val_loss: 1.6526\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6733 - val_accuracy: 0.5957 - val_loss: 1.6500\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6732 - val_accuracy: 0.5958 - val_loss: 1.6544\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6732 - val_accuracy: 0.5957 - val_loss: 1.6507\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6731 - val_accuracy: 0.5957 - val_loss: 1.6500\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6731 - val_accuracy: 0.5957 - val_loss: 1.6486\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6730 - val_accuracy: 0.5957 - val_loss: 1.6516\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6729 - val_accuracy: 0.5957 - val_loss: 1.6541\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.7985 - loss: 0.6729 - val_accuracy: 0.5958 - val_loss: 1.6476\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6728 - val_accuracy: 0.5958 - val_loss: 1.6503\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.59654\n726/726 - 4s - 5ms/step - accuracy: 0.7991 - loss: 0.6728 - val_accuracy: 0.5958 - val_loss: 1.6476\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7986 - loss: 0.6727 - val_accuracy: 0.5957 - val_loss: 1.6496\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7985 - loss: 0.6726 - val_accuracy: 0.5959 - val_loss: 1.6517\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7988 - loss: 0.6726 - val_accuracy: 0.5957 - val_loss: 1.6480\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7986 - loss: 0.6725 - val_accuracy: 0.5957 - val_loss: 1.6518\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6725 - val_accuracy: 0.5957 - val_loss: 1.6539\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6724 - val_accuracy: 0.5958 - val_loss: 1.6532\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6724 - val_accuracy: 0.5958 - val_loss: 1.6533\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6723 - val_accuracy: 0.5962 - val_loss: 1.6519\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.59654\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6722 - val_accuracy: 0.5957 - val_loss: 1.6550\nEpoch 268/500\n\nEpoch 268: val_accuracy improved from 0.59654 to 0.59727, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8012 - loss: 0.6722 - val_accuracy: 0.5973 - val_loss: 1.6535\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.59727\n726/726 - 4s - 5ms/step - accuracy: 0.8017 - loss: 0.6721 - val_accuracy: 0.5969 - val_loss: 1.6546\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.59727\n726/726 - 4s - 5ms/step - accuracy: 0.8016 - loss: 0.6721 - val_accuracy: 0.5970 - val_loss: 1.6519\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.59727\n726/726 - 4s - 5ms/step - accuracy: 0.8017 - loss: 0.6720 - val_accuracy: 0.5969 - val_loss: 1.6555\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.59727\n726/726 - 4s - 6ms/step - accuracy: 0.8017 - loss: 0.6720 - val_accuracy: 0.5969 - val_loss: 1.6536\nEpoch 273/500\n\nEpoch 273: val_accuracy improved from 0.59727 to 0.59759, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8017 - loss: 0.6719 - val_accuracy: 0.5976 - val_loss: 1.6496\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.59759\n726/726 - 4s - 5ms/step - accuracy: 0.8020 - loss: 0.6719 - val_accuracy: 0.5970 - val_loss: 1.6538\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.59759\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6718 - val_accuracy: 0.5969 - val_loss: 1.6559\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.59759\n726/726 - 4s - 5ms/step - accuracy: 0.8017 - loss: 0.6717 - val_accuracy: 0.5974 - val_loss: 1.6506\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.59759\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6717 - val_accuracy: 0.5972 - val_loss: 1.6522\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.59759\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6716 - val_accuracy: 0.5968 - val_loss: 1.6561\nEpoch 279/500\n\nEpoch 279: val_accuracy improved from 0.59759 to 0.59807, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8022 - loss: 0.6716 - val_accuracy: 0.5981 - val_loss: 1.6519\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8022 - loss: 0.6715 - val_accuracy: 0.5980 - val_loss: 1.6506\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8024 - loss: 0.6715 - val_accuracy: 0.5980 - val_loss: 1.6509\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6714 - val_accuracy: 0.5981 - val_loss: 1.6519\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6714 - val_accuracy: 0.5974 - val_loss: 1.6578\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6713 - val_accuracy: 0.5980 - val_loss: 1.6533\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6713 - val_accuracy: 0.5980 - val_loss: 1.6507\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8023 - loss: 0.6712 - val_accuracy: 0.5980 - val_loss: 1.6518\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6712 - val_accuracy: 0.5980 - val_loss: 1.6538\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6711 - val_accuracy: 0.5979 - val_loss: 1.6519\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6711 - val_accuracy: 0.5978 - val_loss: 1.6555\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6710 - val_accuracy: 0.5978 - val_loss: 1.6560\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6710 - val_accuracy: 0.5978 - val_loss: 1.6550\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6709 - val_accuracy: 0.5978 - val_loss: 1.6537\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6709 - val_accuracy: 0.5978 - val_loss: 1.6568\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6708 - val_accuracy: 0.5980 - val_loss: 1.6522\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6708 - val_accuracy: 0.5978 - val_loss: 1.6535\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6707 - val_accuracy: 0.5979 - val_loss: 1.6526\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6707 - val_accuracy: 0.5978 - val_loss: 1.6574\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6706 - val_accuracy: 0.5979 - val_loss: 1.6556\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6706 - val_accuracy: 0.5978 - val_loss: 1.6540\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6705 - val_accuracy: 0.5979 - val_loss: 1.6534\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6705 - val_accuracy: 0.5978 - val_loss: 1.6598\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6704 - val_accuracy: 0.5979 - val_loss: 1.6580\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6704 - val_accuracy: 0.5979 - val_loss: 1.6554\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6703 - val_accuracy: 0.5979 - val_loss: 1.6489\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6703 - val_accuracy: 0.5979 - val_loss: 1.6569\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6702 - val_accuracy: 0.5979 - val_loss: 1.6593\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6702 - val_accuracy: 0.5979 - val_loss: 1.6534\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6701 - val_accuracy: 0.5979 - val_loss: 1.6537\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6701 - val_accuracy: 0.5979 - val_loss: 1.6552\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6700 - val_accuracy: 0.5979 - val_loss: 1.6530\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6700 - val_accuracy: 0.5979 - val_loss: 1.6563\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6699 - val_accuracy: 0.5979 - val_loss: 1.6551\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6699 - val_accuracy: 0.5979 - val_loss: 1.6587\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6698 - val_accuracy: 0.5979 - val_loss: 1.6573\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6698 - val_accuracy: 0.5979 - val_loss: 1.6551\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6697 - val_accuracy: 0.5979 - val_loss: 1.6546\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6697 - val_accuracy: 0.5979 - val_loss: 1.6581\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6697 - val_accuracy: 0.5979 - val_loss: 1.6563\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6696 - val_accuracy: 0.5979 - val_loss: 1.6571\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6696 - val_accuracy: 0.5979 - val_loss: 1.6574\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6695 - val_accuracy: 0.5979 - val_loss: 1.6569\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6695 - val_accuracy: 0.5979 - val_loss: 1.6569\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6694 - val_accuracy: 0.5979 - val_loss: 1.6537\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6694 - val_accuracy: 0.5979 - val_loss: 1.6577\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6693 - val_accuracy: 0.5978 - val_loss: 1.6619\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6693 - val_accuracy: 0.5979 - val_loss: 1.6587\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6692 - val_accuracy: 0.5979 - val_loss: 1.6559\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6692 - val_accuracy: 0.5979 - val_loss: 1.6563\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6692 - val_accuracy: 0.5979 - val_loss: 1.6589\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6691 - val_accuracy: 0.5978 - val_loss: 1.6624\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6691 - val_accuracy: 0.5978 - val_loss: 1.6592\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6690 - val_accuracy: 0.5978 - val_loss: 1.6583\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6690 - val_accuracy: 0.5978 - val_loss: 1.6574\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6689 - val_accuracy: 0.5979 - val_loss: 1.6583\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6689 - val_accuracy: 0.5979 - val_loss: 1.6576\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6689 - val_accuracy: 0.5979 - val_loss: 1.6564\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6688 - val_accuracy: 0.5978 - val_loss: 1.6624\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6688 - val_accuracy: 0.5979 - val_loss: 1.6571\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6687 - val_accuracy: 0.5978 - val_loss: 1.6613\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6687 - val_accuracy: 0.5978 - val_loss: 1.6594\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6686 - val_accuracy: 0.5978 - val_loss: 1.6586\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6686 - val_accuracy: 0.5978 - val_loss: 1.6566\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6686 - val_accuracy: 0.5978 - val_loss: 1.6620\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6685 - val_accuracy: 0.5978 - val_loss: 1.6598\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6685 - val_accuracy: 0.5978 - val_loss: 1.6611\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6684 - val_accuracy: 0.5978 - val_loss: 1.6614\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6684 - val_accuracy: 0.5978 - val_loss: 1.6625\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6683 - val_accuracy: 0.5978 - val_loss: 1.6631\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6683 - val_accuracy: 0.5978 - val_loss: 1.6632\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6683 - val_accuracy: 0.5978 - val_loss: 1.6625\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6682 - val_accuracy: 0.5978 - val_loss: 1.6609\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6682 - val_accuracy: 0.5978 - val_loss: 1.6593\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6681 - val_accuracy: 0.5978 - val_loss: 1.6630\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6681 - val_accuracy: 0.5978 - val_loss: 1.6629\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6681 - val_accuracy: 0.5978 - val_loss: 1.6623\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6680 - val_accuracy: 0.5978 - val_loss: 1.6590\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6680 - val_accuracy: 0.5978 - val_loss: 1.6583\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6679 - val_accuracy: 0.5978 - val_loss: 1.6598\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6679 - val_accuracy: 0.5978 - val_loss: 1.6585\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6679 - val_accuracy: 0.5978 - val_loss: 1.6609\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6678 - val_accuracy: 0.5978 - val_loss: 1.6635\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6678 - val_accuracy: 0.5978 - val_loss: 1.6627\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6677 - val_accuracy: 0.5978 - val_loss: 1.6605\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6677 - val_accuracy: 0.5979 - val_loss: 1.6593\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6677 - val_accuracy: 0.5979 - val_loss: 1.6578\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6676 - val_accuracy: 0.5978 - val_loss: 1.6595\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6676 - val_accuracy: 0.5976 - val_loss: 1.6617\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6675 - val_accuracy: 0.5979 - val_loss: 1.6631\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6675 - val_accuracy: 0.5976 - val_loss: 1.6630\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6675 - val_accuracy: 0.5978 - val_loss: 1.6616\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6674 - val_accuracy: 0.5978 - val_loss: 1.6631\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6674 - val_accuracy: 0.5979 - val_loss: 1.6611\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6674 - val_accuracy: 0.5978 - val_loss: 1.6618\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6673 - val_accuracy: 0.5978 - val_loss: 1.6607\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6673 - val_accuracy: 0.5976 - val_loss: 1.6625\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6672 - val_accuracy: 0.5979 - val_loss: 1.6621\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6672 - val_accuracy: 0.5976 - val_loss: 1.6663\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6672 - val_accuracy: 0.5976 - val_loss: 1.6639\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6671 - val_accuracy: 0.5976 - val_loss: 1.6680\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6671 - val_accuracy: 0.5976 - val_loss: 1.6662\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6671 - val_accuracy: 0.5976 - val_loss: 1.6605\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6670 - val_accuracy: 0.5976 - val_loss: 1.6653\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6670 - val_accuracy: 0.5979 - val_loss: 1.6591\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6669 - val_accuracy: 0.5976 - val_loss: 1.6662\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6669 - val_accuracy: 0.5976 - val_loss: 1.6646\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6669 - val_accuracy: 0.5976 - val_loss: 1.6653\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6668 - val_accuracy: 0.5976 - val_loss: 1.6640\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.6668 - val_accuracy: 0.5976 - val_loss: 1.6661\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6668 - val_accuracy: 0.5976 - val_loss: 1.6634\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6667 - val_accuracy: 0.5976 - val_loss: 1.6657\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6667 - val_accuracy: 0.5976 - val_loss: 1.6674\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6666 - val_accuracy: 0.5976 - val_loss: 1.6644\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6666 - val_accuracy: 0.5976 - val_loss: 1.6627\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6666 - val_accuracy: 0.5976 - val_loss: 1.6613\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6665 - val_accuracy: 0.5976 - val_loss: 1.6667\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6665 - val_accuracy: 0.5976 - val_loss: 1.6637\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6665 - val_accuracy: 0.5976 - val_loss: 1.6669\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6664 - val_accuracy: 0.5976 - val_loss: 1.6669\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6664 - val_accuracy: 0.5976 - val_loss: 1.6666\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6664 - val_accuracy: 0.5976 - val_loss: 1.6646\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6663 - val_accuracy: 0.5976 - val_loss: 1.6668\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6663 - val_accuracy: 0.5976 - val_loss: 1.6674\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6663 - val_accuracy: 0.5976 - val_loss: 1.6613\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6662 - val_accuracy: 0.5976 - val_loss: 1.6621\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6662 - val_accuracy: 0.5976 - val_loss: 1.6633\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6662 - val_accuracy: 0.5976 - val_loss: 1.6673\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6661 - val_accuracy: 0.5976 - val_loss: 1.6638\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6661 - val_accuracy: 0.5976 - val_loss: 1.6630\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6660 - val_accuracy: 0.5976 - val_loss: 1.6650\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6660 - val_accuracy: 0.5949 - val_loss: 1.6627\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6660 - val_accuracy: 0.5976 - val_loss: 1.6688\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6659 - val_accuracy: 0.5977 - val_loss: 1.6663\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6659 - val_accuracy: 0.5949 - val_loss: 1.6699\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6659 - val_accuracy: 0.5949 - val_loss: 1.6661\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6658 - val_accuracy: 0.5949 - val_loss: 1.6689\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6658 - val_accuracy: 0.5949 - val_loss: 1.6683\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6658 - val_accuracy: 0.5949 - val_loss: 1.6651\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6657 - val_accuracy: 0.5949 - val_loss: 1.6646\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6657 - val_accuracy: 0.5949 - val_loss: 1.6657\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6657 - val_accuracy: 0.5949 - val_loss: 1.6671\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6656 - val_accuracy: 0.5949 - val_loss: 1.6649\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6656 - val_accuracy: 0.5949 - val_loss: 1.6660\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6656 - val_accuracy: 0.5977 - val_loss: 1.6644\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6655 - val_accuracy: 0.5948 - val_loss: 1.6690\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6655 - val_accuracy: 0.5948 - val_loss: 1.6673\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6655 - val_accuracy: 0.5949 - val_loss: 1.6651\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6654 - val_accuracy: 0.5950 - val_loss: 1.6641\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6654 - val_accuracy: 0.5949 - val_loss: 1.6702\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6654 - val_accuracy: 0.5949 - val_loss: 1.6652\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6654 - val_accuracy: 0.5949 - val_loss: 1.6670\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6653 - val_accuracy: 0.5948 - val_loss: 1.6692\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6653 - val_accuracy: 0.5948 - val_loss: 1.6677\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6653 - val_accuracy: 0.5948 - val_loss: 1.6695\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6652 - val_accuracy: 0.5948 - val_loss: 1.6693\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6652 - val_accuracy: 0.5948 - val_loss: 1.6662\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6652 - val_accuracy: 0.5948 - val_loss: 1.6712\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6651 - val_accuracy: 0.5948 - val_loss: 1.6692\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6651 - val_accuracy: 0.5948 - val_loss: 1.6703\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6651 - val_accuracy: 0.5949 - val_loss: 1.6656\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6650 - val_accuracy: 0.5948 - val_loss: 1.6686\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6650 - val_accuracy: 0.5949 - val_loss: 1.6642\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6650 - val_accuracy: 0.5949 - val_loss: 1.6663\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6649 - val_accuracy: 0.5948 - val_loss: 1.6697\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6649 - val_accuracy: 0.5948 - val_loss: 1.6724\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6649 - val_accuracy: 0.5949 - val_loss: 1.6641\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6648 - val_accuracy: 0.5950 - val_loss: 1.6656\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6648 - val_accuracy: 0.5949 - val_loss: 1.6685\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6648 - val_accuracy: 0.5949 - val_loss: 1.6693\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6648 - val_accuracy: 0.5947 - val_loss: 1.6704\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6647 - val_accuracy: 0.5947 - val_loss: 1.6726\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6647 - val_accuracy: 0.5948 - val_loss: 1.6677\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6647 - val_accuracy: 0.5947 - val_loss: 1.6688\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6646 - val_accuracy: 0.5947 - val_loss: 1.6718\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6646 - val_accuracy: 0.5948 - val_loss: 1.6686\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8028 - loss: 0.6646 - val_accuracy: 0.5947 - val_loss: 1.6710\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6645 - val_accuracy: 0.5947 - val_loss: 1.6690\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6645 - val_accuracy: 0.5947 - val_loss: 1.6683\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6645 - val_accuracy: 0.5948 - val_loss: 1.6661\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6645 - val_accuracy: 0.5947 - val_loss: 1.6708\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6644 - val_accuracy: 0.5949 - val_loss: 1.6661\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.59807\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6644 - val_accuracy: 0.5947 - val_loss: 1.6718\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8026 - loss: 0.6644 - val_accuracy: 0.5949 - val_loss: 1.6659\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6643 - val_accuracy: 0.5947 - val_loss: 1.6743\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.59807\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6643 - val_accuracy: 0.5948 - val_loss: 1.6707\nEpoch 465/500\n\nEpoch 465: val_accuracy improved from 0.59807 to 0.60470, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6643 - val_accuracy: 0.6047 - val_loss: 1.6653\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6642 - val_accuracy: 0.5948 - val_loss: 1.6682\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6642 - val_accuracy: 0.5948 - val_loss: 1.6690\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6642 - val_accuracy: 0.5947 - val_loss: 1.6716\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60470\n726/726 - 4s - 5ms/step - accuracy: 0.8027 - loss: 0.6642 - val_accuracy: 0.6046 - val_loss: 1.6663\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60470\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6641 - val_accuracy: 0.6045 - val_loss: 1.6713\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6641 - val_accuracy: 0.6045 - val_loss: 1.6705\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6641 - val_accuracy: 0.6046 - val_loss: 1.6666\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6640 - val_accuracy: 0.6046 - val_loss: 1.6688\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6640 - val_accuracy: 0.6045 - val_loss: 1.6696\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6640 - val_accuracy: 0.6045 - val_loss: 1.6704\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60470\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6640 - val_accuracy: 0.6045 - val_loss: 1.6707\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60470\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6639 - val_accuracy: 0.6045 - val_loss: 1.6707\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60470\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6639 - val_accuracy: 0.6046 - val_loss: 1.6690\nEpoch 479/500\n\nEpoch 479: val_accuracy improved from 0.60470 to 0.60471, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6639 - val_accuracy: 0.6047 - val_loss: 1.6677\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60471\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6638 - val_accuracy: 0.6046 - val_loss: 1.6705\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60471\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6638 - val_accuracy: 0.6046 - val_loss: 1.6683\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60471\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6638 - val_accuracy: 0.6046 - val_loss: 1.6740\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60471\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6638 - val_accuracy: 0.6045 - val_loss: 1.6708\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60471\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6637 - val_accuracy: 0.6047 - val_loss: 1.6692\nEpoch 485/500\n\nEpoch 485: val_accuracy improved from 0.60471 to 0.60485, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6637 - val_accuracy: 0.6048 - val_loss: 1.6662\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6637 - val_accuracy: 0.6048 - val_loss: 1.6722\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6636 - val_accuracy: 0.6045 - val_loss: 1.6737\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6636 - val_accuracy: 0.6047 - val_loss: 1.6713\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6636 - val_accuracy: 0.6046 - val_loss: 1.6693\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6636 - val_accuracy: 0.6047 - val_loss: 1.6734\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6635 - val_accuracy: 0.6047 - val_loss: 1.6724\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6635 - val_accuracy: 0.6048 - val_loss: 1.6713\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6635 - val_accuracy: 0.6047 - val_loss: 1.6731\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6634 - val_accuracy: 0.6046 - val_loss: 1.6719\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6634 - val_accuracy: 0.6047 - val_loss: 1.6738\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6634 - val_accuracy: 0.6047 - val_loss: 1.6728\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6634 - val_accuracy: 0.6047 - val_loss: 1.6706\nEpoch 498/500\n\nEpoch 498: val_accuracy improved from 0.60485 to 0.60485, saving model to /kaggle/working/checkpoint_model_lstm.keras\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6633 - val_accuracy: 0.6049 - val_loss: 1.6698\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6633 - val_accuracy: 0.6048 - val_loss: 1.6719\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6633 - val_accuracy: 0.6047 - val_loss: 1.6748\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Initial split into training and test sets\nX_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(\n    X, y, test_size=0.3, random_state=72, stratify=y\n)\n\n# Further split the training set into training and validation sets\nX_train_30, X_val_30, y_train_30, y_val_30 = train_test_split(\n    X_train_30, y_train_30, test_size=0.2, random_state=72, stratify=y_train_30\n)\n\n# Check for extremely large values\nprint(\"Max value in X_train_30:\", np.max(X_train_30))\nprint(\"Min value in X_train_30:\", np.min(X_train_30))\n\nX_train_30_scaled = scaler.fit_transform(X_train_30)\n\n# Get the original class distribution\nclass_counts_30 = Counter(y_train_30)\nprint(\"Original class distribution:\", class_counts_30)\n\n# Set the desired ratio: majority class = 5 times the minority class\nminority_class_size_30 = class_counts_30[min(class_counts_30, key=class_counts_30.get)]\ndesired_majority_size_30 = minority_class_size_30 * 5\n\n# Create the sampling strategy dictionary\nsampling_strategy_30 = {0: desired_majority_size_30, 1: minority_class_size_30}  # Adjust class labels accordingly\n\n# Apply RandomUnderSampler with the dictionary\nundersampler_30 = RandomUnderSampler(sampling_strategy=sampling_strategy_30, random_state=42)\nX_resampled_30, y_resampled_30 = undersampler_30.fit_resample(X_train_30, y_train_30)\n\n# Check the new class distribution\nprint(\"Class distribution after undersampling:\", Counter(y_resampled_30))\n\n# Apply SMOTE on the smaller subset\nX_train_resampled_30, y_train_resampled_30 = smote.fit_resample(X_resampled_30, y_resampled_30)\n\n\n#Verify the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class Distribution Before SMOTE:\", Counter(y_resampled_30))\nprint(\"Class Distribution After SMOTE:\", Counter(y_train_resampled_30))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T03:49:11.834088Z","iopub.execute_input":"2025-03-08T03:49:11.834392Z","iopub.status.idle":"2025-03-08T03:49:43.577840Z","shell.execute_reply.started":"2025-03-08T03:49:11.834345Z","shell.execute_reply":"2025-03-08T03:49:43.576803Z"}},"outputs":[{"name":"stdout","text":"Max value in X_train_30: 2071000000.0\nMin value in X_train_30: -9663668122.0\nOriginal class distribution: Counter({0: 1173231, 4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 1: 1091, 12: 823, 14: 365, 9: 20, 13: 12, 8: 6})\nClass distribution after undersampling: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution Before SMOTE: Counter({4: 96794, 2: 71688, 10: 50789, 3: 5760, 7: 3322, 6: 3015, 5: 2928, 11: 1802, 12: 823, 14: 365, 0: 30, 9: 20, 13: 12, 1: 6, 8: 6})\nClass Distribution After SMOTE: Counter({0: 96794, 1: 96794, 2: 96794, 3: 96794, 4: 96794, 5: 96794, 6: 96794, 7: 96794, 8: 96794, 9: 96794, 10: 96794, 11: 96794, 12: 96794, 13: 96794, 14: 96794})\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Reshape the training and validation data to (samples, time_steps, features)\nX_train_resampled_30 = X_train_resampled_30.reshape(X_train_resampled_30.shape[0], 1, 56)\nX_val_30 = X_val_30.reshape(X_val_30.shape[0], 1, 56)\n\n# Train the fine-tuned model\nhistory = fine_tuned_model.fit(\n    X_train_resampled_30,  # Features from CICIDS2017\n    y_train_resampled_30,  # Labels from CICIDS2017\n    validation_data=(X_val_30, y_val_30),  # Validation set\n    epochs=500,  # Adjust based on the dataset size\n    batch_size=2000,  # Adjust batch size as needed\n    verbose=2,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T03:49:43.578997Z","iopub.execute_input":"2025-03-08T03:49:43.579397Z","iopub.status.idle":"2025-03-08T04:24:46.251782Z","shell.execute_reply.started":"2025-03-08T03:49:43.579341Z","shell.execute_reply":"2025-03-08T04:24:46.250719Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\nEpoch 1: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7946 - loss: 0.6980 - val_accuracy: 0.6013 - val_loss: 1.7457\nEpoch 2/500\n\nEpoch 2: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7959 - loss: 0.6940 - val_accuracy: 0.5998 - val_loss: 1.7551\nEpoch 3/500\n\nEpoch 3: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7970 - loss: 0.6922 - val_accuracy: 0.6006 - val_loss: 1.7589\nEpoch 4/500\n\nEpoch 4: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7978 - loss: 0.6908 - val_accuracy: 0.6000 - val_loss: 1.7627\nEpoch 5/500\n\nEpoch 5: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7979 - loss: 0.6897 - val_accuracy: 0.5999 - val_loss: 1.7696\nEpoch 6/500\n\nEpoch 6: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7983 - loss: 0.6887 - val_accuracy: 0.5996 - val_loss: 1.7701\nEpoch 7/500\n\nEpoch 7: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6879 - val_accuracy: 0.5990 - val_loss: 1.7728\nEpoch 8/500\n\nEpoch 8: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6872 - val_accuracy: 0.6016 - val_loss: 1.7758\nEpoch 9/500\n\nEpoch 9: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8012 - loss: 0.6865 - val_accuracy: 0.6016 - val_loss: 1.7808\nEpoch 10/500\n\nEpoch 10: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6859 - val_accuracy: 0.6011 - val_loss: 1.7806\nEpoch 11/500\n\nEpoch 11: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6854 - val_accuracy: 0.6011 - val_loss: 1.7796\nEpoch 12/500\n\nEpoch 12: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6848 - val_accuracy: 0.6012 - val_loss: 1.7777\nEpoch 13/500\n\nEpoch 13: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6843 - val_accuracy: 0.6013 - val_loss: 1.7834\nEpoch 14/500\n\nEpoch 14: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8015 - loss: 0.6838 - val_accuracy: 0.5981 - val_loss: 1.7817\nEpoch 15/500\n\nEpoch 15: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6834 - val_accuracy: 0.5981 - val_loss: 1.7875\nEpoch 16/500\n\nEpoch 16: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6830 - val_accuracy: 0.5981 - val_loss: 1.7877\nEpoch 17/500\n\nEpoch 17: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6826 - val_accuracy: 0.5981 - val_loss: 1.7884\nEpoch 18/500\n\nEpoch 18: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6822 - val_accuracy: 0.5980 - val_loss: 1.7892\nEpoch 19/500\n\nEpoch 19: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8017 - loss: 0.6818 - val_accuracy: 0.5980 - val_loss: 1.7868\nEpoch 20/500\n\nEpoch 20: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6815 - val_accuracy: 0.5978 - val_loss: 1.7829\nEpoch 21/500\n\nEpoch 21: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6811 - val_accuracy: 0.5979 - val_loss: 1.7869\nEpoch 22/500\n\nEpoch 22: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8002 - loss: 0.6808 - val_accuracy: 0.5977 - val_loss: 1.7894\nEpoch 23/500\n\nEpoch 23: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6805 - val_accuracy: 0.5978 - val_loss: 1.7865\nEpoch 24/500\n\nEpoch 24: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6802 - val_accuracy: 0.5978 - val_loss: 1.7888\nEpoch 25/500\n\nEpoch 25: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6799 - val_accuracy: 0.5982 - val_loss: 1.7893\nEpoch 26/500\n\nEpoch 26: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6796 - val_accuracy: 0.5940 - val_loss: 1.7870\nEpoch 27/500\n\nEpoch 27: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8000 - loss: 0.6793 - val_accuracy: 0.5939 - val_loss: 1.7917\nEpoch 28/500\n\nEpoch 28: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6790 - val_accuracy: 0.5939 - val_loss: 1.7942\nEpoch 29/500\n\nEpoch 29: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6788 - val_accuracy: 0.5941 - val_loss: 1.7875\nEpoch 30/500\n\nEpoch 30: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7994 - loss: 0.6785 - val_accuracy: 0.5938 - val_loss: 1.7895\nEpoch 31/500\n\nEpoch 31: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8001 - loss: 0.6783 - val_accuracy: 0.5938 - val_loss: 1.7916\nEpoch 32/500\n\nEpoch 32: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6781 - val_accuracy: 0.5938 - val_loss: 1.7930\nEpoch 33/500\n\nEpoch 33: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7992 - loss: 0.6778 - val_accuracy: 0.5938 - val_loss: 1.7956\nEpoch 34/500\n\nEpoch 34: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7996 - loss: 0.6776 - val_accuracy: 0.5944 - val_loss: 1.7912\nEpoch 35/500\n\nEpoch 35: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6774 - val_accuracy: 0.5953 - val_loss: 1.7925\nEpoch 36/500\n\nEpoch 36: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6772 - val_accuracy: 0.5961 - val_loss: 1.7971\nEpoch 37/500\n\nEpoch 37: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7994 - loss: 0.6770 - val_accuracy: 0.5961 - val_loss: 1.7937\nEpoch 38/500\n\nEpoch 38: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7994 - loss: 0.6768 - val_accuracy: 0.5961 - val_loss: 1.7965\nEpoch 39/500\n\nEpoch 39: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6766 - val_accuracy: 0.5970 - val_loss: 1.7925\nEpoch 40/500\n\nEpoch 40: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7993 - loss: 0.6764 - val_accuracy: 0.5947 - val_loss: 1.7996\nEpoch 41/500\n\nEpoch 41: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6762 - val_accuracy: 0.5946 - val_loss: 1.8002\nEpoch 42/500\n\nEpoch 42: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7994 - loss: 0.6761 - val_accuracy: 0.5956 - val_loss: 1.7976\nEpoch 43/500\n\nEpoch 43: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7996 - loss: 0.6759 - val_accuracy: 0.5954 - val_loss: 1.7986\nEpoch 44/500\n\nEpoch 44: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6757 - val_accuracy: 0.5944 - val_loss: 1.8030\nEpoch 45/500\n\nEpoch 45: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6755 - val_accuracy: 0.5954 - val_loss: 1.7975\nEpoch 46/500\n\nEpoch 46: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6754 - val_accuracy: 0.5954 - val_loss: 1.8013\nEpoch 47/500\n\nEpoch 47: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7995 - loss: 0.6752 - val_accuracy: 0.5954 - val_loss: 1.8023\nEpoch 48/500\n\nEpoch 48: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7994 - loss: 0.6751 - val_accuracy: 0.5955 - val_loss: 1.8021\nEpoch 49/500\n\nEpoch 49: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6749 - val_accuracy: 0.5956 - val_loss: 1.7989\nEpoch 50/500\n\nEpoch 50: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6748 - val_accuracy: 0.5956 - val_loss: 1.8009\nEpoch 51/500\n\nEpoch 51: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6746 - val_accuracy: 0.5956 - val_loss: 1.8014\nEpoch 52/500\n\nEpoch 52: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6745 - val_accuracy: 0.5954 - val_loss: 1.8021\nEpoch 53/500\n\nEpoch 53: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6743 - val_accuracy: 0.5954 - val_loss: 1.8030\nEpoch 54/500\n\nEpoch 54: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6742 - val_accuracy: 0.5954 - val_loss: 1.8035\nEpoch 55/500\n\nEpoch 55: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6740 - val_accuracy: 0.5954 - val_loss: 1.8005\nEpoch 56/500\n\nEpoch 56: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6739 - val_accuracy: 0.5951 - val_loss: 1.7995\nEpoch 57/500\n\nEpoch 57: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6738 - val_accuracy: 0.5951 - val_loss: 1.8044\nEpoch 58/500\n\nEpoch 58: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6736 - val_accuracy: 0.5951 - val_loss: 1.8000\nEpoch 59/500\n\nEpoch 59: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6735 - val_accuracy: 0.5951 - val_loss: 1.8036\nEpoch 60/500\n\nEpoch 60: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6734 - val_accuracy: 0.5951 - val_loss: 1.8059\nEpoch 61/500\n\nEpoch 61: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6733 - val_accuracy: 0.5951 - val_loss: 1.8042\nEpoch 62/500\n\nEpoch 62: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6731 - val_accuracy: 0.5951 - val_loss: 1.8081\nEpoch 63/500\n\nEpoch 63: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6730 - val_accuracy: 0.5951 - val_loss: 1.8036\nEpoch 64/500\n\nEpoch 64: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6729 - val_accuracy: 0.5951 - val_loss: 1.8049\nEpoch 65/500\n\nEpoch 65: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6728 - val_accuracy: 0.5950 - val_loss: 1.8094\nEpoch 66/500\n\nEpoch 66: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7994 - loss: 0.6727 - val_accuracy: 0.5951 - val_loss: 1.8060\nEpoch 67/500\n\nEpoch 67: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.7995 - loss: 0.6725 - val_accuracy: 0.5951 - val_loss: 1.8094\nEpoch 68/500\n\nEpoch 68: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6724 - val_accuracy: 0.5950 - val_loss: 1.8094\nEpoch 69/500\n\nEpoch 69: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6723 - val_accuracy: 0.5950 - val_loss: 1.8073\nEpoch 70/500\n\nEpoch 70: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6722 - val_accuracy: 0.5951 - val_loss: 1.8028\nEpoch 71/500\n\nEpoch 71: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6721 - val_accuracy: 0.5950 - val_loss: 1.8063\nEpoch 72/500\n\nEpoch 72: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6720 - val_accuracy: 0.5950 - val_loss: 1.8097\nEpoch 73/500\n\nEpoch 73: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6719 - val_accuracy: 0.5951 - val_loss: 1.8111\nEpoch 74/500\n\nEpoch 74: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6718 - val_accuracy: 0.5949 - val_loss: 1.8107\nEpoch 75/500\n\nEpoch 75: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6717 - val_accuracy: 0.5951 - val_loss: 1.8087\nEpoch 76/500\n\nEpoch 76: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6716 - val_accuracy: 0.5951 - val_loss: 1.8103\nEpoch 77/500\n\nEpoch 77: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6715 - val_accuracy: 0.5953 - val_loss: 1.8055\nEpoch 78/500\n\nEpoch 78: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6714 - val_accuracy: 0.5952 - val_loss: 1.8130\nEpoch 79/500\n\nEpoch 79: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6713 - val_accuracy: 0.5953 - val_loss: 1.8066\nEpoch 80/500\n\nEpoch 80: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6712 - val_accuracy: 0.5951 - val_loss: 1.8091\nEpoch 81/500\n\nEpoch 81: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6711 - val_accuracy: 0.5952 - val_loss: 1.8114\nEpoch 82/500\n\nEpoch 82: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6710 - val_accuracy: 0.5953 - val_loss: 1.8121\nEpoch 83/500\n\nEpoch 83: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7996 - loss: 0.6709 - val_accuracy: 0.5952 - val_loss: 1.8146\nEpoch 84/500\n\nEpoch 84: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6708 - val_accuracy: 0.5953 - val_loss: 1.8076\nEpoch 85/500\n\nEpoch 85: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6707 - val_accuracy: 0.5953 - val_loss: 1.8142\nEpoch 86/500\n\nEpoch 86: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6706 - val_accuracy: 0.5953 - val_loss: 1.8132\nEpoch 87/500\n\nEpoch 87: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6705 - val_accuracy: 0.5953 - val_loss: 1.8117\nEpoch 88/500\n\nEpoch 88: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7998 - loss: 0.6704 - val_accuracy: 0.5953 - val_loss: 1.8111\nEpoch 89/500\n\nEpoch 89: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6703 - val_accuracy: 0.5952 - val_loss: 1.8130\nEpoch 90/500\n\nEpoch 90: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6702 - val_accuracy: 0.5952 - val_loss: 1.8109\nEpoch 91/500\n\nEpoch 91: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6701 - val_accuracy: 0.5949 - val_loss: 1.8187\nEpoch 92/500\n\nEpoch 92: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7996 - loss: 0.6700 - val_accuracy: 0.5952 - val_loss: 1.8117\nEpoch 93/500\n\nEpoch 93: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6699 - val_accuracy: 0.5951 - val_loss: 1.8102\nEpoch 94/500\n\nEpoch 94: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6699 - val_accuracy: 0.5951 - val_loss: 1.8123\nEpoch 95/500\n\nEpoch 95: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.7997 - loss: 0.6698 - val_accuracy: 0.5949 - val_loss: 1.8158\nEpoch 96/500\n\nEpoch 96: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6697 - val_accuracy: 0.5950 - val_loss: 1.8104\nEpoch 97/500\n\nEpoch 97: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6696 - val_accuracy: 0.5949 - val_loss: 1.8141\nEpoch 98/500\n\nEpoch 98: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6695 - val_accuracy: 0.5949 - val_loss: 1.8139\nEpoch 99/500\n\nEpoch 99: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6694 - val_accuracy: 0.5949 - val_loss: 1.8149\nEpoch 100/500\n\nEpoch 100: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6694 - val_accuracy: 0.5949 - val_loss: 1.8175\nEpoch 101/500\n\nEpoch 101: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6693 - val_accuracy: 0.5949 - val_loss: 1.8148\nEpoch 102/500\n\nEpoch 102: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6692 - val_accuracy: 0.5949 - val_loss: 1.8166\nEpoch 103/500\n\nEpoch 103: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6691 - val_accuracy: 0.5949 - val_loss: 1.8170\nEpoch 104/500\n\nEpoch 104: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6690 - val_accuracy: 0.5949 - val_loss: 1.8127\nEpoch 105/500\n\nEpoch 105: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6690 - val_accuracy: 0.5948 - val_loss: 1.8195\nEpoch 106/500\n\nEpoch 106: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6689 - val_accuracy: 0.5949 - val_loss: 1.8195\nEpoch 107/500\n\nEpoch 107: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6688 - val_accuracy: 0.5949 - val_loss: 1.8160\nEpoch 108/500\n\nEpoch 108: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6687 - val_accuracy: 0.5950 - val_loss: 1.8155\nEpoch 109/500\n\nEpoch 109: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6686 - val_accuracy: 0.5950 - val_loss: 1.8176\nEpoch 110/500\n\nEpoch 110: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6686 - val_accuracy: 0.5950 - val_loss: 1.8172\nEpoch 111/500\n\nEpoch 111: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6685 - val_accuracy: 0.5950 - val_loss: 1.8162\nEpoch 112/500\n\nEpoch 112: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6684 - val_accuracy: 0.5949 - val_loss: 1.8231\nEpoch 113/500\n\nEpoch 113: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6683 - val_accuracy: 0.5950 - val_loss: 1.8170\nEpoch 114/500\n\nEpoch 114: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6683 - val_accuracy: 0.5950 - val_loss: 1.8159\nEpoch 115/500\n\nEpoch 115: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6682 - val_accuracy: 0.5953 - val_loss: 1.8153\nEpoch 116/500\n\nEpoch 116: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6681 - val_accuracy: 0.5953 - val_loss: 1.8173\nEpoch 117/500\n\nEpoch 117: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6680 - val_accuracy: 0.5953 - val_loss: 1.8173\nEpoch 118/500\n\nEpoch 118: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6680 - val_accuracy: 0.5953 - val_loss: 1.8184\nEpoch 119/500\n\nEpoch 119: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6679 - val_accuracy: 0.5953 - val_loss: 1.8207\nEpoch 120/500\n\nEpoch 120: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6678 - val_accuracy: 0.5953 - val_loss: 1.8216\nEpoch 121/500\n\nEpoch 121: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.7998 - loss: 0.6678 - val_accuracy: 0.5953 - val_loss: 1.8204\nEpoch 122/500\n\nEpoch 122: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6677 - val_accuracy: 0.5953 - val_loss: 1.8230\nEpoch 123/500\n\nEpoch 123: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6676 - val_accuracy: 0.5953 - val_loss: 1.8176\nEpoch 124/500\n\nEpoch 124: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6676 - val_accuracy: 0.5953 - val_loss: 1.8208\nEpoch 125/500\n\nEpoch 125: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6675 - val_accuracy: 0.5952 - val_loss: 1.8208\nEpoch 126/500\n\nEpoch 126: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6674 - val_accuracy: 0.5953 - val_loss: 1.8190\nEpoch 127/500\n\nEpoch 127: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6673 - val_accuracy: 0.5953 - val_loss: 1.8218\nEpoch 128/500\n\nEpoch 128: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.7998 - loss: 0.6673 - val_accuracy: 0.5952 - val_loss: 1.8256\nEpoch 129/500\n\nEpoch 129: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6672 - val_accuracy: 0.5952 - val_loss: 1.8200\nEpoch 130/500\n\nEpoch 130: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6671 - val_accuracy: 0.5952 - val_loss: 1.8210\nEpoch 131/500\n\nEpoch 131: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6671 - val_accuracy: 0.5955 - val_loss: 1.8207\nEpoch 132/500\n\nEpoch 132: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6670 - val_accuracy: 0.5954 - val_loss: 1.8238\nEpoch 133/500\n\nEpoch 133: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6669 - val_accuracy: 0.5954 - val_loss: 1.8259\nEpoch 134/500\n\nEpoch 134: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6669 - val_accuracy: 0.5955 - val_loss: 1.8177\nEpoch 135/500\n\nEpoch 135: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6668 - val_accuracy: 0.5955 - val_loss: 1.8204\nEpoch 136/500\n\nEpoch 136: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6668 - val_accuracy: 0.5955 - val_loss: 1.8204\nEpoch 137/500\n\nEpoch 137: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6667 - val_accuracy: 0.5955 - val_loss: 1.8240\nEpoch 138/500\n\nEpoch 138: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6666 - val_accuracy: 0.5953 - val_loss: 1.8256\nEpoch 139/500\n\nEpoch 139: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6666 - val_accuracy: 0.5953 - val_loss: 1.8260\nEpoch 140/500\n\nEpoch 140: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6665 - val_accuracy: 0.5953 - val_loss: 1.8240\nEpoch 141/500\n\nEpoch 141: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6664 - val_accuracy: 0.5953 - val_loss: 1.8219\nEpoch 142/500\n\nEpoch 142: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6664 - val_accuracy: 0.5953 - val_loss: 1.8252\nEpoch 143/500\n\nEpoch 143: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6663 - val_accuracy: 0.5953 - val_loss: 1.8266\nEpoch 144/500\n\nEpoch 144: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6662 - val_accuracy: 0.5954 - val_loss: 1.8250\nEpoch 145/500\n\nEpoch 145: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6662 - val_accuracy: 0.5951 - val_loss: 1.8254\nEpoch 146/500\n\nEpoch 146: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6661 - val_accuracy: 0.5953 - val_loss: 1.8232\nEpoch 147/500\n\nEpoch 147: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6661 - val_accuracy: 0.5941 - val_loss: 1.8280\nEpoch 148/500\n\nEpoch 148: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6660 - val_accuracy: 0.5951 - val_loss: 1.8279\nEpoch 149/500\n\nEpoch 149: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6659 - val_accuracy: 0.5950 - val_loss: 1.8266\nEpoch 150/500\n\nEpoch 150: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8001 - loss: 0.6659 - val_accuracy: 0.5941 - val_loss: 1.8274\nEpoch 151/500\n\nEpoch 151: val_accuracy did not improve from 0.60485\n726/726 - 5s - 7ms/step - accuracy: 0.8002 - loss: 0.6658 - val_accuracy: 0.5951 - val_loss: 1.8264\nEpoch 152/500\n\nEpoch 152: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6658 - val_accuracy: 0.5949 - val_loss: 1.8259\nEpoch 153/500\n\nEpoch 153: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6657 - val_accuracy: 0.5952 - val_loss: 1.8241\nEpoch 154/500\n\nEpoch 154: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6657 - val_accuracy: 0.5952 - val_loss: 1.8259\nEpoch 155/500\n\nEpoch 155: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6656 - val_accuracy: 0.5949 - val_loss: 1.8273\nEpoch 156/500\n\nEpoch 156: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6655 - val_accuracy: 0.5949 - val_loss: 1.8273\nEpoch 157/500\n\nEpoch 157: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6655 - val_accuracy: 0.5949 - val_loss: 1.8277\nEpoch 158/500\n\nEpoch 158: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8007 - loss: 0.6654 - val_accuracy: 0.5949 - val_loss: 1.8275\nEpoch 159/500\n\nEpoch 159: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6654 - val_accuracy: 0.5949 - val_loss: 1.8261\nEpoch 160/500\n\nEpoch 160: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6653 - val_accuracy: 0.5949 - val_loss: 1.8280\nEpoch 161/500\n\nEpoch 161: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6653 - val_accuracy: 0.5949 - val_loss: 1.8255\nEpoch 162/500\n\nEpoch 162: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6652 - val_accuracy: 0.5939 - val_loss: 1.8294\nEpoch 163/500\n\nEpoch 163: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6651 - val_accuracy: 0.5949 - val_loss: 1.8265\nEpoch 164/500\n\nEpoch 164: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6651 - val_accuracy: 0.5948 - val_loss: 1.8281\nEpoch 165/500\n\nEpoch 165: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6650 - val_accuracy: 0.5941 - val_loss: 1.8308\nEpoch 166/500\n\nEpoch 166: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6650 - val_accuracy: 0.5949 - val_loss: 1.8269\nEpoch 167/500\n\nEpoch 167: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6649 - val_accuracy: 0.5937 - val_loss: 1.8304\nEpoch 168/500\n\nEpoch 168: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6649 - val_accuracy: 0.5938 - val_loss: 1.8294\nEpoch 169/500\n\nEpoch 169: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6648 - val_accuracy: 0.5947 - val_loss: 1.8292\nEpoch 170/500\n\nEpoch 170: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6648 - val_accuracy: 0.5947 - val_loss: 1.8277\nEpoch 171/500\n\nEpoch 171: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6647 - val_accuracy: 0.5937 - val_loss: 1.8307\nEpoch 172/500\n\nEpoch 172: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6646 - val_accuracy: 0.5938 - val_loss: 1.8328\nEpoch 173/500\n\nEpoch 173: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6646 - val_accuracy: 0.5938 - val_loss: 1.8305\nEpoch 174/500\n\nEpoch 174: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6645 - val_accuracy: 0.5940 - val_loss: 1.8289\nEpoch 175/500\n\nEpoch 175: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6645 - val_accuracy: 0.5938 - val_loss: 1.8295\nEpoch 176/500\n\nEpoch 176: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6644 - val_accuracy: 0.5936 - val_loss: 1.8311\nEpoch 177/500\n\nEpoch 177: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6644 - val_accuracy: 0.5936 - val_loss: 1.8333\nEpoch 178/500\n\nEpoch 178: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6643 - val_accuracy: 0.5943 - val_loss: 1.8335\nEpoch 179/500\n\nEpoch 179: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6643 - val_accuracy: 0.5939 - val_loss: 1.8286\nEpoch 180/500\n\nEpoch 180: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6642 - val_accuracy: 0.5948 - val_loss: 1.8275\nEpoch 181/500\n\nEpoch 181: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8000 - loss: 0.6642 - val_accuracy: 0.5938 - val_loss: 1.8321\nEpoch 182/500\n\nEpoch 182: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6641 - val_accuracy: 0.5938 - val_loss: 1.8322\nEpoch 183/500\n\nEpoch 183: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6641 - val_accuracy: 0.5938 - val_loss: 1.8330\nEpoch 184/500\n\nEpoch 184: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6640 - val_accuracy: 0.5936 - val_loss: 1.8350\nEpoch 185/500\n\nEpoch 185: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6640 - val_accuracy: 0.5936 - val_loss: 1.8335\nEpoch 186/500\n\nEpoch 186: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6639 - val_accuracy: 0.5936 - val_loss: 1.8348\nEpoch 187/500\n\nEpoch 187: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6639 - val_accuracy: 0.5936 - val_loss: 1.8350\nEpoch 188/500\n\nEpoch 188: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8004 - loss: 0.6638 - val_accuracy: 0.5938 - val_loss: 1.8339\nEpoch 189/500\n\nEpoch 189: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7999 - loss: 0.6638 - val_accuracy: 0.5938 - val_loss: 1.8333\nEpoch 190/500\n\nEpoch 190: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6637 - val_accuracy: 0.5943 - val_loss: 1.8320\nEpoch 191/500\n\nEpoch 191: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6637 - val_accuracy: 0.5938 - val_loss: 1.8362\nEpoch 192/500\n\nEpoch 192: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7995 - loss: 0.6636 - val_accuracy: 0.5938 - val_loss: 1.8350\nEpoch 193/500\n\nEpoch 193: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8011 - loss: 0.6636 - val_accuracy: 0.5938 - val_loss: 1.8342\nEpoch 194/500\n\nEpoch 194: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7998 - loss: 0.6635 - val_accuracy: 0.5939 - val_loss: 1.8367\nEpoch 195/500\n\nEpoch 195: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8010 - loss: 0.6635 - val_accuracy: 0.5938 - val_loss: 1.8349\nEpoch 196/500\n\nEpoch 196: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6634 - val_accuracy: 0.5938 - val_loss: 1.8338\nEpoch 197/500\n\nEpoch 197: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6634 - val_accuracy: 0.5938 - val_loss: 1.8339\nEpoch 198/500\n\nEpoch 198: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.7997 - loss: 0.6633 - val_accuracy: 0.5943 - val_loss: 1.8365\nEpoch 199/500\n\nEpoch 199: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6633 - val_accuracy: 0.5943 - val_loss: 1.8370\nEpoch 200/500\n\nEpoch 200: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6632 - val_accuracy: 0.5938 - val_loss: 1.8348\nEpoch 201/500\n\nEpoch 201: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6632 - val_accuracy: 0.5938 - val_loss: 1.8375\nEpoch 202/500\n\nEpoch 202: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8003 - loss: 0.6631 - val_accuracy: 0.5938 - val_loss: 1.8389\nEpoch 203/500\n\nEpoch 203: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8007 - loss: 0.6631 - val_accuracy: 0.5888 - val_loss: 1.8379\nEpoch 204/500\n\nEpoch 204: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6630 - val_accuracy: 0.5938 - val_loss: 1.8376\nEpoch 205/500\n\nEpoch 205: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8001 - loss: 0.6630 - val_accuracy: 0.5888 - val_loss: 1.8410\nEpoch 206/500\n\nEpoch 206: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6630 - val_accuracy: 0.5948 - val_loss: 1.8411\nEpoch 207/500\n\nEpoch 207: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8006 - loss: 0.6629 - val_accuracy: 0.5947 - val_loss: 1.8382\nEpoch 208/500\n\nEpoch 208: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6629 - val_accuracy: 0.5942 - val_loss: 1.8338\nEpoch 209/500\n\nEpoch 209: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6628 - val_accuracy: 0.5947 - val_loss: 1.8371\nEpoch 210/500\n\nEpoch 210: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8012 - loss: 0.6628 - val_accuracy: 0.5941 - val_loss: 1.8353\nEpoch 211/500\n\nEpoch 211: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6627 - val_accuracy: 0.5892 - val_loss: 1.8368\nEpoch 212/500\n\nEpoch 212: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6627 - val_accuracy: 0.5941 - val_loss: 1.8329\nEpoch 213/500\n\nEpoch 213: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8010 - loss: 0.6626 - val_accuracy: 0.5947 - val_loss: 1.8398\nEpoch 214/500\n\nEpoch 214: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8004 - loss: 0.6626 - val_accuracy: 0.5947 - val_loss: 1.8373\nEpoch 215/500\n\nEpoch 215: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6625 - val_accuracy: 0.5947 - val_loss: 1.8385\nEpoch 216/500\n\nEpoch 216: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6625 - val_accuracy: 0.5892 - val_loss: 1.8429\nEpoch 217/500\n\nEpoch 217: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8002 - loss: 0.6625 - val_accuracy: 0.5948 - val_loss: 1.8403\nEpoch 218/500\n\nEpoch 218: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8008 - loss: 0.6624 - val_accuracy: 0.5948 - val_loss: 1.8384\nEpoch 219/500\n\nEpoch 219: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6624 - val_accuracy: 0.5892 - val_loss: 1.8409\nEpoch 220/500\n\nEpoch 220: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8007 - loss: 0.6623 - val_accuracy: 0.5892 - val_loss: 1.8387\nEpoch 221/500\n\nEpoch 221: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8009 - loss: 0.6623 - val_accuracy: 0.5947 - val_loss: 1.8388\nEpoch 222/500\n\nEpoch 222: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8005 - loss: 0.6622 - val_accuracy: 0.5948 - val_loss: 1.8405\nEpoch 223/500\n\nEpoch 223: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6622 - val_accuracy: 0.5947 - val_loss: 1.8408\nEpoch 224/500\n\nEpoch 224: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8014 - loss: 0.6622 - val_accuracy: 0.5920 - val_loss: 1.8422\nEpoch 225/500\n\nEpoch 225: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6621 - val_accuracy: 0.5969 - val_loss: 1.8368\nEpoch 226/500\n\nEpoch 226: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6621 - val_accuracy: 0.5920 - val_loss: 1.8423\nEpoch 227/500\n\nEpoch 227: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6620 - val_accuracy: 0.5920 - val_loss: 1.8434\nEpoch 228/500\n\nEpoch 228: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6620 - val_accuracy: 0.5919 - val_loss: 1.8435\nEpoch 229/500\n\nEpoch 229: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6619 - val_accuracy: 0.5919 - val_loss: 1.8426\nEpoch 230/500\n\nEpoch 230: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8017 - loss: 0.6619 - val_accuracy: 0.5920 - val_loss: 1.8436\nEpoch 231/500\n\nEpoch 231: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6618 - val_accuracy: 0.5919 - val_loss: 1.8406\nEpoch 232/500\n\nEpoch 232: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6618 - val_accuracy: 0.5919 - val_loss: 1.8419\nEpoch 233/500\n\nEpoch 233: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8022 - loss: 0.6618 - val_accuracy: 0.5920 - val_loss: 1.8412\nEpoch 234/500\n\nEpoch 234: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8016 - loss: 0.6617 - val_accuracy: 0.5919 - val_loss: 1.8431\nEpoch 235/500\n\nEpoch 235: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6617 - val_accuracy: 0.5976 - val_loss: 1.8468\nEpoch 236/500\n\nEpoch 236: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6616 - val_accuracy: 0.5920 - val_loss: 1.8427\nEpoch 237/500\n\nEpoch 237: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6616 - val_accuracy: 0.5921 - val_loss: 1.8437\nEpoch 238/500\n\nEpoch 238: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6616 - val_accuracy: 0.5920 - val_loss: 1.8437\nEpoch 239/500\n\nEpoch 239: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6615 - val_accuracy: 0.5919 - val_loss: 1.8458\nEpoch 240/500\n\nEpoch 240: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6615 - val_accuracy: 0.5921 - val_loss: 1.8465\nEpoch 241/500\n\nEpoch 241: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6614 - val_accuracy: 0.5919 - val_loss: 1.8447\nEpoch 242/500\n\nEpoch 242: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6614 - val_accuracy: 0.5919 - val_loss: 1.8474\nEpoch 243/500\n\nEpoch 243: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8020 - loss: 0.6614 - val_accuracy: 0.5976 - val_loss: 1.8390\nEpoch 244/500\n\nEpoch 244: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6613 - val_accuracy: 0.5975 - val_loss: 1.8428\nEpoch 245/500\n\nEpoch 245: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6613 - val_accuracy: 0.5920 - val_loss: 1.8421\nEpoch 246/500\n\nEpoch 246: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6612 - val_accuracy: 0.5921 - val_loss: 1.8463\nEpoch 247/500\n\nEpoch 247: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6612 - val_accuracy: 0.5919 - val_loss: 1.8450\nEpoch 248/500\n\nEpoch 248: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8019 - loss: 0.6612 - val_accuracy: 0.5919 - val_loss: 1.8467\nEpoch 249/500\n\nEpoch 249: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8024 - loss: 0.6611 - val_accuracy: 0.5919 - val_loss: 1.8470\nEpoch 250/500\n\nEpoch 250: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6611 - val_accuracy: 0.5919 - val_loss: 1.8446\nEpoch 251/500\n\nEpoch 251: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6610 - val_accuracy: 0.5919 - val_loss: 1.8427\nEpoch 252/500\n\nEpoch 252: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6610 - val_accuracy: 0.5976 - val_loss: 1.8427\nEpoch 253/500\n\nEpoch 253: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6610 - val_accuracy: 0.5920 - val_loss: 1.8442\nEpoch 254/500\n\nEpoch 254: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6609 - val_accuracy: 0.5920 - val_loss: 1.8431\nEpoch 255/500\n\nEpoch 255: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6609 - val_accuracy: 0.5920 - val_loss: 1.8462\nEpoch 256/500\n\nEpoch 256: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6608 - val_accuracy: 0.5919 - val_loss: 1.8473\nEpoch 257/500\n\nEpoch 257: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6608 - val_accuracy: 0.5919 - val_loss: 1.8467\nEpoch 258/500\n\nEpoch 258: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8021 - loss: 0.6608 - val_accuracy: 0.5919 - val_loss: 1.8484\nEpoch 259/500\n\nEpoch 259: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6607 - val_accuracy: 0.5975 - val_loss: 1.8415\nEpoch 260/500\n\nEpoch 260: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6607 - val_accuracy: 0.5920 - val_loss: 1.8456\nEpoch 261/500\n\nEpoch 261: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8022 - loss: 0.6606 - val_accuracy: 0.5919 - val_loss: 1.8445\nEpoch 262/500\n\nEpoch 262: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8018 - loss: 0.6606 - val_accuracy: 0.5919 - val_loss: 1.8432\nEpoch 263/500\n\nEpoch 263: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8026 - loss: 0.6606 - val_accuracy: 0.5918 - val_loss: 1.8491\nEpoch 264/500\n\nEpoch 264: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6605 - val_accuracy: 0.5920 - val_loss: 1.8445\nEpoch 265/500\n\nEpoch 265: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6605 - val_accuracy: 0.5975 - val_loss: 1.8444\nEpoch 266/500\n\nEpoch 266: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6604 - val_accuracy: 0.5918 - val_loss: 1.8508\nEpoch 267/500\n\nEpoch 267: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6604 - val_accuracy: 0.5919 - val_loss: 1.8452\nEpoch 268/500\n\nEpoch 268: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6604 - val_accuracy: 0.5919 - val_loss: 1.8464\nEpoch 269/500\n\nEpoch 269: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6603 - val_accuracy: 0.5919 - val_loss: 1.8469\nEpoch 270/500\n\nEpoch 270: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8024 - loss: 0.6603 - val_accuracy: 0.5918 - val_loss: 1.8506\nEpoch 271/500\n\nEpoch 271: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6603 - val_accuracy: 0.5918 - val_loss: 1.8478\nEpoch 272/500\n\nEpoch 272: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8019 - loss: 0.6602 - val_accuracy: 0.5920 - val_loss: 1.8500\nEpoch 273/500\n\nEpoch 273: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6602 - val_accuracy: 0.5918 - val_loss: 1.8530\nEpoch 274/500\n\nEpoch 274: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6602 - val_accuracy: 0.5976 - val_loss: 1.8469\nEpoch 275/500\n\nEpoch 275: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6601 - val_accuracy: 0.5919 - val_loss: 1.8497\nEpoch 276/500\n\nEpoch 276: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6601 - val_accuracy: 0.5920 - val_loss: 1.8501\nEpoch 277/500\n\nEpoch 277: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6600 - val_accuracy: 0.5920 - val_loss: 1.8477\nEpoch 278/500\n\nEpoch 278: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8034 - loss: 0.6600 - val_accuracy: 0.5917 - val_loss: 1.8476\nEpoch 279/500\n\nEpoch 279: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6600 - val_accuracy: 0.5917 - val_loss: 1.8507\nEpoch 280/500\n\nEpoch 280: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6599 - val_accuracy: 0.5917 - val_loss: 1.8481\nEpoch 281/500\n\nEpoch 281: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6599 - val_accuracy: 0.5918 - val_loss: 1.8477\nEpoch 282/500\n\nEpoch 282: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6599 - val_accuracy: 0.5917 - val_loss: 1.8491\nEpoch 283/500\n\nEpoch 283: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8023 - loss: 0.6598 - val_accuracy: 0.5917 - val_loss: 1.8516\nEpoch 284/500\n\nEpoch 284: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8026 - loss: 0.6598 - val_accuracy: 0.5919 - val_loss: 1.8493\nEpoch 285/500\n\nEpoch 285: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6597 - val_accuracy: 0.5917 - val_loss: 1.8512\nEpoch 286/500\n\nEpoch 286: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8025 - loss: 0.6597 - val_accuracy: 0.5917 - val_loss: 1.8519\nEpoch 287/500\n\nEpoch 287: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6597 - val_accuracy: 0.5917 - val_loss: 1.8505\nEpoch 288/500\n\nEpoch 288: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6596 - val_accuracy: 0.5919 - val_loss: 1.8525\nEpoch 289/500\n\nEpoch 289: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6596 - val_accuracy: 0.5917 - val_loss: 1.8473\nEpoch 290/500\n\nEpoch 290: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6596 - val_accuracy: 0.5917 - val_loss: 1.8530\nEpoch 291/500\n\nEpoch 291: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6595 - val_accuracy: 0.5917 - val_loss: 1.8536\nEpoch 292/500\n\nEpoch 292: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6595 - val_accuracy: 0.5917 - val_loss: 1.8516\nEpoch 293/500\n\nEpoch 293: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6595 - val_accuracy: 0.5917 - val_loss: 1.8505\nEpoch 294/500\n\nEpoch 294: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6594 - val_accuracy: 0.5917 - val_loss: 1.8538\nEpoch 295/500\n\nEpoch 295: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6594 - val_accuracy: 0.5917 - val_loss: 1.8546\nEpoch 296/500\n\nEpoch 296: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6594 - val_accuracy: 0.5917 - val_loss: 1.8523\nEpoch 297/500\n\nEpoch 297: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6593 - val_accuracy: 0.5918 - val_loss: 1.8563\nEpoch 298/500\n\nEpoch 298: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6593 - val_accuracy: 0.5918 - val_loss: 1.8555\nEpoch 299/500\n\nEpoch 299: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6593 - val_accuracy: 0.5917 - val_loss: 1.8543\nEpoch 300/500\n\nEpoch 300: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6592 - val_accuracy: 0.5916 - val_loss: 1.8543\nEpoch 301/500\n\nEpoch 301: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6592 - val_accuracy: 0.5918 - val_loss: 1.8556\nEpoch 302/500\n\nEpoch 302: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6591 - val_accuracy: 0.5916 - val_loss: 1.8566\nEpoch 303/500\n\nEpoch 303: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6591 - val_accuracy: 0.5916 - val_loss: 1.8537\nEpoch 304/500\n\nEpoch 304: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6591 - val_accuracy: 0.5918 - val_loss: 1.8529\nEpoch 305/500\n\nEpoch 305: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6590 - val_accuracy: 0.5917 - val_loss: 1.8555\nEpoch 306/500\n\nEpoch 306: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6590 - val_accuracy: 0.5918 - val_loss: 1.8537\nEpoch 307/500\n\nEpoch 307: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6590 - val_accuracy: 0.5912 - val_loss: 1.8562\nEpoch 308/500\n\nEpoch 308: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6589 - val_accuracy: 0.5918 - val_loss: 1.8547\nEpoch 309/500\n\nEpoch 309: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8029 - loss: 0.6589 - val_accuracy: 0.5918 - val_loss: 1.8524\nEpoch 310/500\n\nEpoch 310: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6589 - val_accuracy: 0.5911 - val_loss: 1.8582\nEpoch 311/500\n\nEpoch 311: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6588 - val_accuracy: 0.5912 - val_loss: 1.8531\nEpoch 312/500\n\nEpoch 312: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6588 - val_accuracy: 0.5918 - val_loss: 1.8521\nEpoch 313/500\n\nEpoch 313: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6588 - val_accuracy: 0.5916 - val_loss: 1.8561\nEpoch 314/500\n\nEpoch 314: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6587 - val_accuracy: 0.5917 - val_loss: 1.8563\nEpoch 315/500\n\nEpoch 315: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8030 - loss: 0.6587 - val_accuracy: 0.5911 - val_loss: 1.8584\nEpoch 316/500\n\nEpoch 316: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6587 - val_accuracy: 0.5912 - val_loss: 1.8567\nEpoch 317/500\n\nEpoch 317: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8024 - loss: 0.6586 - val_accuracy: 0.5913 - val_loss: 1.8572\nEpoch 318/500\n\nEpoch 318: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6586 - val_accuracy: 0.5912 - val_loss: 1.8554\nEpoch 319/500\n\nEpoch 319: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6586 - val_accuracy: 0.5916 - val_loss: 1.8567\nEpoch 320/500\n\nEpoch 320: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8029 - loss: 0.6585 - val_accuracy: 0.5912 - val_loss: 1.8610\nEpoch 321/500\n\nEpoch 321: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8036 - loss: 0.6585 - val_accuracy: 0.5917 - val_loss: 1.8543\nEpoch 322/500\n\nEpoch 322: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8036 - loss: 0.6585 - val_accuracy: 0.5911 - val_loss: 1.8578\nEpoch 323/500\n\nEpoch 323: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6584 - val_accuracy: 0.5911 - val_loss: 1.8566\nEpoch 324/500\n\nEpoch 324: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6584 - val_accuracy: 0.5912 - val_loss: 1.8574\nEpoch 325/500\n\nEpoch 325: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6584 - val_accuracy: 0.5913 - val_loss: 1.8571\nEpoch 326/500\n\nEpoch 326: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8038 - loss: 0.6584 - val_accuracy: 0.5913 - val_loss: 1.8571\nEpoch 327/500\n\nEpoch 327: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8025 - loss: 0.6583 - val_accuracy: 0.5912 - val_loss: 1.8601\nEpoch 328/500\n\nEpoch 328: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8038 - loss: 0.6583 - val_accuracy: 0.5911 - val_loss: 1.8601\nEpoch 329/500\n\nEpoch 329: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8047 - loss: 0.6583 - val_accuracy: 0.5912 - val_loss: 1.8575\nEpoch 330/500\n\nEpoch 330: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8031 - loss: 0.6582 - val_accuracy: 0.5913 - val_loss: 1.8553\nEpoch 331/500\n\nEpoch 331: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6582 - val_accuracy: 0.5911 - val_loss: 1.8604\nEpoch 332/500\n\nEpoch 332: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6582 - val_accuracy: 0.5911 - val_loss: 1.8620\nEpoch 333/500\n\nEpoch 333: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8034 - loss: 0.6581 - val_accuracy: 0.5911 - val_loss: 1.8582\nEpoch 334/500\n\nEpoch 334: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8030 - loss: 0.6581 - val_accuracy: 0.5913 - val_loss: 1.8562\nEpoch 335/500\n\nEpoch 335: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6581 - val_accuracy: 0.5911 - val_loss: 1.8582\nEpoch 336/500\n\nEpoch 336: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6580 - val_accuracy: 0.5911 - val_loss: 1.8589\nEpoch 337/500\n\nEpoch 337: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6580 - val_accuracy: 0.5911 - val_loss: 1.8629\nEpoch 338/500\n\nEpoch 338: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6580 - val_accuracy: 0.5912 - val_loss: 1.8586\nEpoch 339/500\n\nEpoch 339: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6579 - val_accuracy: 0.5913 - val_loss: 1.8580\nEpoch 340/500\n\nEpoch 340: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6579 - val_accuracy: 0.5912 - val_loss: 1.8644\nEpoch 341/500\n\nEpoch 341: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8032 - loss: 0.6579 - val_accuracy: 0.5912 - val_loss: 1.8609\nEpoch 342/500\n\nEpoch 342: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6578 - val_accuracy: 0.5912 - val_loss: 1.8616\nEpoch 343/500\n\nEpoch 343: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8033 - loss: 0.6578 - val_accuracy: 0.5912 - val_loss: 1.8630\nEpoch 344/500\n\nEpoch 344: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8038 - loss: 0.6578 - val_accuracy: 0.5910 - val_loss: 1.8614\nEpoch 345/500\n\nEpoch 345: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8027 - loss: 0.6578 - val_accuracy: 0.5910 - val_loss: 1.8622\nEpoch 346/500\n\nEpoch 346: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6577 - val_accuracy: 0.5912 - val_loss: 1.8596\nEpoch 347/500\n\nEpoch 347: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6577 - val_accuracy: 0.5910 - val_loss: 1.8638\nEpoch 348/500\n\nEpoch 348: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6577 - val_accuracy: 0.5911 - val_loss: 1.8596\nEpoch 349/500\n\nEpoch 349: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8041 - loss: 0.6576 - val_accuracy: 0.5911 - val_loss: 1.8624\nEpoch 350/500\n\nEpoch 350: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8028 - loss: 0.6576 - val_accuracy: 0.5911 - val_loss: 1.8628\nEpoch 351/500\n\nEpoch 351: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8039 - loss: 0.6576 - val_accuracy: 0.5909 - val_loss: 1.8639\nEpoch 352/500\n\nEpoch 352: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6575 - val_accuracy: 0.5911 - val_loss: 1.8605\nEpoch 353/500\n\nEpoch 353: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6575 - val_accuracy: 0.5909 - val_loss: 1.8617\nEpoch 354/500\n\nEpoch 354: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8036 - loss: 0.6575 - val_accuracy: 0.5910 - val_loss: 1.8632\nEpoch 355/500\n\nEpoch 355: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6574 - val_accuracy: 0.5910 - val_loss: 1.8643\nEpoch 356/500\n\nEpoch 356: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6574 - val_accuracy: 0.5907 - val_loss: 1.8631\nEpoch 357/500\n\nEpoch 357: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6574 - val_accuracy: 0.5910 - val_loss: 1.8636\nEpoch 358/500\n\nEpoch 358: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6574 - val_accuracy: 0.5909 - val_loss: 1.8667\nEpoch 359/500\n\nEpoch 359: val_accuracy did not improve from 0.60485\n726/726 - 4s - 5ms/step - accuracy: 0.8046 - loss: 0.6573 - val_accuracy: 0.5910 - val_loss: 1.8631\nEpoch 360/500\n\nEpoch 360: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6573 - val_accuracy: 0.5910 - val_loss: 1.8613\nEpoch 361/500\n\nEpoch 361: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6573 - val_accuracy: 0.5908 - val_loss: 1.8634\nEpoch 362/500\n\nEpoch 362: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6572 - val_accuracy: 0.5908 - val_loss: 1.8615\nEpoch 363/500\n\nEpoch 363: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6572 - val_accuracy: 0.5907 - val_loss: 1.8653\nEpoch 364/500\n\nEpoch 364: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6572 - val_accuracy: 0.5908 - val_loss: 1.8644\nEpoch 365/500\n\nEpoch 365: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6571 - val_accuracy: 0.5908 - val_loss: 1.8617\nEpoch 366/500\n\nEpoch 366: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6571 - val_accuracy: 0.5909 - val_loss: 1.8629\nEpoch 367/500\n\nEpoch 367: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6571 - val_accuracy: 0.5908 - val_loss: 1.8626\nEpoch 368/500\n\nEpoch 368: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6571 - val_accuracy: 0.5908 - val_loss: 1.8644\nEpoch 369/500\n\nEpoch 369: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6570 - val_accuracy: 0.5907 - val_loss: 1.8620\nEpoch 370/500\n\nEpoch 370: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8032 - loss: 0.6570 - val_accuracy: 0.5910 - val_loss: 1.8638\nEpoch 371/500\n\nEpoch 371: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6570 - val_accuracy: 0.5908 - val_loss: 1.8705\nEpoch 372/500\n\nEpoch 372: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6569 - val_accuracy: 0.5907 - val_loss: 1.8641\nEpoch 373/500\n\nEpoch 373: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6569 - val_accuracy: 0.5907 - val_loss: 1.8655\nEpoch 374/500\n\nEpoch 374: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6569 - val_accuracy: 0.5908 - val_loss: 1.8669\nEpoch 375/500\n\nEpoch 375: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6569 - val_accuracy: 0.5908 - val_loss: 1.8664\nEpoch 376/500\n\nEpoch 376: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6568 - val_accuracy: 0.5908 - val_loss: 1.8655\nEpoch 377/500\n\nEpoch 377: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6568 - val_accuracy: 0.5907 - val_loss: 1.8672\nEpoch 378/500\n\nEpoch 378: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6568 - val_accuracy: 0.5908 - val_loss: 1.8655\nEpoch 379/500\n\nEpoch 379: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6567 - val_accuracy: 0.5908 - val_loss: 1.8682\nEpoch 380/500\n\nEpoch 380: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6567 - val_accuracy: 0.5906 - val_loss: 1.8677\nEpoch 381/500\n\nEpoch 381: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6567 - val_accuracy: 0.5907 - val_loss: 1.8629\nEpoch 382/500\n\nEpoch 382: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6567 - val_accuracy: 0.5908 - val_loss: 1.8659\nEpoch 383/500\n\nEpoch 383: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6566 - val_accuracy: 0.5908 - val_loss: 1.8676\nEpoch 384/500\n\nEpoch 384: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6566 - val_accuracy: 0.5903 - val_loss: 1.8730\nEpoch 385/500\n\nEpoch 385: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8037 - loss: 0.6566 - val_accuracy: 0.5908 - val_loss: 1.8673\nEpoch 386/500\n\nEpoch 386: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6565 - val_accuracy: 0.5908 - val_loss: 1.8664\nEpoch 387/500\n\nEpoch 387: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6565 - val_accuracy: 0.5907 - val_loss: 1.8674\nEpoch 388/500\n\nEpoch 388: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6565 - val_accuracy: 0.5907 - val_loss: 1.8689\nEpoch 389/500\n\nEpoch 389: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6565 - val_accuracy: 0.5908 - val_loss: 1.8679\nEpoch 390/500\n\nEpoch 390: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6564 - val_accuracy: 0.5908 - val_loss: 1.8664\nEpoch 391/500\n\nEpoch 391: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6564 - val_accuracy: 0.5908 - val_loss: 1.8691\nEpoch 392/500\n\nEpoch 392: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8051 - loss: 0.6564 - val_accuracy: 0.5906 - val_loss: 1.8683\nEpoch 393/500\n\nEpoch 393: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6563 - val_accuracy: 0.5906 - val_loss: 1.8692\nEpoch 394/500\n\nEpoch 394: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8049 - loss: 0.6563 - val_accuracy: 0.5908 - val_loss: 1.8681\nEpoch 395/500\n\nEpoch 395: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6563 - val_accuracy: 0.5906 - val_loss: 1.8671\nEpoch 396/500\n\nEpoch 396: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6563 - val_accuracy: 0.5905 - val_loss: 1.8732\nEpoch 397/500\n\nEpoch 397: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6562 - val_accuracy: 0.5905 - val_loss: 1.8724\nEpoch 398/500\n\nEpoch 398: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6562 - val_accuracy: 0.5909 - val_loss: 1.8673\nEpoch 399/500\n\nEpoch 399: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6562 - val_accuracy: 0.5905 - val_loss: 1.8691\nEpoch 400/500\n\nEpoch 400: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6562 - val_accuracy: 0.5909 - val_loss: 1.8672\nEpoch 401/500\n\nEpoch 401: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8048 - loss: 0.6561 - val_accuracy: 0.5905 - val_loss: 1.8690\nEpoch 402/500\n\nEpoch 402: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8034 - loss: 0.6561 - val_accuracy: 0.5907 - val_loss: 1.8710\nEpoch 403/500\n\nEpoch 403: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6561 - val_accuracy: 0.5905 - val_loss: 1.8727\nEpoch 404/500\n\nEpoch 404: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6560 - val_accuracy: 0.5907 - val_loss: 1.8709\nEpoch 405/500\n\nEpoch 405: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6560 - val_accuracy: 0.5906 - val_loss: 1.8682\nEpoch 406/500\n\nEpoch 406: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6560 - val_accuracy: 0.5904 - val_loss: 1.8719\nEpoch 407/500\n\nEpoch 407: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6560 - val_accuracy: 0.5905 - val_loss: 1.8729\nEpoch 408/500\n\nEpoch 408: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6559 - val_accuracy: 0.5906 - val_loss: 1.8715\nEpoch 409/500\n\nEpoch 409: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8041 - loss: 0.6559 - val_accuracy: 0.5906 - val_loss: 1.8730\nEpoch 410/500\n\nEpoch 410: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6559 - val_accuracy: 0.5907 - val_loss: 1.8677\nEpoch 411/500\n\nEpoch 411: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8051 - loss: 0.6559 - val_accuracy: 0.5905 - val_loss: 1.8704\nEpoch 412/500\n\nEpoch 412: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8035 - loss: 0.6558 - val_accuracy: 0.5903 - val_loss: 1.8724\nEpoch 413/500\n\nEpoch 413: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6558 - val_accuracy: 0.5907 - val_loss: 1.8655\nEpoch 414/500\n\nEpoch 414: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6558 - val_accuracy: 0.5906 - val_loss: 1.8722\nEpoch 415/500\n\nEpoch 415: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6557 - val_accuracy: 0.5903 - val_loss: 1.8734\nEpoch 416/500\n\nEpoch 416: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8039 - loss: 0.6557 - val_accuracy: 0.5907 - val_loss: 1.8718\nEpoch 417/500\n\nEpoch 417: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6557 - val_accuracy: 0.5905 - val_loss: 1.8746\nEpoch 418/500\n\nEpoch 418: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8039 - loss: 0.6557 - val_accuracy: 0.5905 - val_loss: 1.8738\nEpoch 419/500\n\nEpoch 419: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6556 - val_accuracy: 0.5904 - val_loss: 1.8727\nEpoch 420/500\n\nEpoch 420: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6556 - val_accuracy: 0.5906 - val_loss: 1.8708\nEpoch 421/500\n\nEpoch 421: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6556 - val_accuracy: 0.5904 - val_loss: 1.8764\nEpoch 422/500\n\nEpoch 422: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6556 - val_accuracy: 0.5907 - val_loss: 1.8695\nEpoch 423/500\n\nEpoch 423: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6555 - val_accuracy: 0.5907 - val_loss: 1.8740\nEpoch 424/500\n\nEpoch 424: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6555 - val_accuracy: 0.5907 - val_loss: 1.8712\nEpoch 425/500\n\nEpoch 425: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6555 - val_accuracy: 0.5907 - val_loss: 1.8693\nEpoch 426/500\n\nEpoch 426: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6555 - val_accuracy: 0.5905 - val_loss: 1.8748\nEpoch 427/500\n\nEpoch 427: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6554 - val_accuracy: 0.5905 - val_loss: 1.8747\nEpoch 428/500\n\nEpoch 428: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6554 - val_accuracy: 0.5907 - val_loss: 1.8736\nEpoch 429/500\n\nEpoch 429: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6554 - val_accuracy: 0.5903 - val_loss: 1.8749\nEpoch 430/500\n\nEpoch 430: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8040 - loss: 0.6554 - val_accuracy: 0.5907 - val_loss: 1.8709\nEpoch 431/500\n\nEpoch 431: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8047 - loss: 0.6553 - val_accuracy: 0.5907 - val_loss: 1.8737\nEpoch 432/500\n\nEpoch 432: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6553 - val_accuracy: 0.5907 - val_loss: 1.8732\nEpoch 433/500\n\nEpoch 433: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6553 - val_accuracy: 0.5905 - val_loss: 1.8747\nEpoch 434/500\n\nEpoch 434: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6553 - val_accuracy: 0.5907 - val_loss: 1.8745\nEpoch 435/500\n\nEpoch 435: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6552 - val_accuracy: 0.5904 - val_loss: 1.8745\nEpoch 436/500\n\nEpoch 436: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6552 - val_accuracy: 0.5904 - val_loss: 1.8734\nEpoch 437/500\n\nEpoch 437: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8041 - loss: 0.6552 - val_accuracy: 0.5905 - val_loss: 1.8794\nEpoch 438/500\n\nEpoch 438: val_accuracy did not improve from 0.60485\n726/726 - 5s - 6ms/step - accuracy: 0.8045 - loss: 0.6551 - val_accuracy: 0.5905 - val_loss: 1.8763\nEpoch 439/500\n\nEpoch 439: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6551 - val_accuracy: 0.5906 - val_loss: 1.8730\nEpoch 440/500\n\nEpoch 440: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6551 - val_accuracy: 0.5904 - val_loss: 1.8770\nEpoch 441/500\n\nEpoch 441: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6551 - val_accuracy: 0.5904 - val_loss: 1.8767\nEpoch 442/500\n\nEpoch 442: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8038 - loss: 0.6550 - val_accuracy: 0.5908 - val_loss: 1.8773\nEpoch 443/500\n\nEpoch 443: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6550 - val_accuracy: 0.5905 - val_loss: 1.8815\nEpoch 444/500\n\nEpoch 444: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6550 - val_accuracy: 0.5905 - val_loss: 1.8769\nEpoch 445/500\n\nEpoch 445: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6550 - val_accuracy: 0.5904 - val_loss: 1.8786\nEpoch 446/500\n\nEpoch 446: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6549 - val_accuracy: 0.5906 - val_loss: 1.8749\nEpoch 447/500\n\nEpoch 447: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6549 - val_accuracy: 0.5906 - val_loss: 1.8801\nEpoch 448/500\n\nEpoch 448: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6549 - val_accuracy: 0.5908 - val_loss: 1.8739\nEpoch 449/500\n\nEpoch 449: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8042 - loss: 0.6549 - val_accuracy: 0.5905 - val_loss: 1.8789\nEpoch 450/500\n\nEpoch 450: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6548 - val_accuracy: 0.5907 - val_loss: 1.8767\nEpoch 451/500\n\nEpoch 451: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6548 - val_accuracy: 0.5905 - val_loss: 1.8782\nEpoch 452/500\n\nEpoch 452: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6548 - val_accuracy: 0.5906 - val_loss: 1.8743\nEpoch 453/500\n\nEpoch 453: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6548 - val_accuracy: 0.5906 - val_loss: 1.8790\nEpoch 454/500\n\nEpoch 454: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6547 - val_accuracy: 0.5906 - val_loss: 1.8771\nEpoch 455/500\n\nEpoch 455: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6547 - val_accuracy: 0.5907 - val_loss: 1.8787\nEpoch 456/500\n\nEpoch 456: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6547 - val_accuracy: 0.5908 - val_loss: 1.8744\nEpoch 457/500\n\nEpoch 457: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6547 - val_accuracy: 0.5905 - val_loss: 1.8774\nEpoch 458/500\n\nEpoch 458: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6546 - val_accuracy: 0.5904 - val_loss: 1.8792\nEpoch 459/500\n\nEpoch 459: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6546 - val_accuracy: 0.5905 - val_loss: 1.8788\nEpoch 460/500\n\nEpoch 460: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6546 - val_accuracy: 0.5905 - val_loss: 1.8767\nEpoch 461/500\n\nEpoch 461: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6546 - val_accuracy: 0.5904 - val_loss: 1.8801\nEpoch 462/500\n\nEpoch 462: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6545 - val_accuracy: 0.5906 - val_loss: 1.8763\nEpoch 463/500\n\nEpoch 463: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8031 - loss: 0.6545 - val_accuracy: 0.5903 - val_loss: 1.8802\nEpoch 464/500\n\nEpoch 464: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6545 - val_accuracy: 0.5903 - val_loss: 1.8813\nEpoch 465/500\n\nEpoch 465: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8054 - loss: 0.6545 - val_accuracy: 0.5904 - val_loss: 1.8812\nEpoch 466/500\n\nEpoch 466: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8036 - loss: 0.6544 - val_accuracy: 0.5903 - val_loss: 1.8796\nEpoch 467/500\n\nEpoch 467: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6544 - val_accuracy: 0.5905 - val_loss: 1.8797\nEpoch 468/500\n\nEpoch 468: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6544 - val_accuracy: 0.5903 - val_loss: 1.8806\nEpoch 469/500\n\nEpoch 469: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6544 - val_accuracy: 0.5904 - val_loss: 1.8772\nEpoch 470/500\n\nEpoch 470: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6544 - val_accuracy: 0.5902 - val_loss: 1.8805\nEpoch 471/500\n\nEpoch 471: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6543 - val_accuracy: 0.5902 - val_loss: 1.8792\nEpoch 472/500\n\nEpoch 472: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6543 - val_accuracy: 0.5902 - val_loss: 1.8827\nEpoch 473/500\n\nEpoch 473: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6543 - val_accuracy: 0.5904 - val_loss: 1.8797\nEpoch 474/500\n\nEpoch 474: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6543 - val_accuracy: 0.5902 - val_loss: 1.8781\nEpoch 475/500\n\nEpoch 475: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6542 - val_accuracy: 0.5902 - val_loss: 1.8845\nEpoch 476/500\n\nEpoch 476: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8045 - loss: 0.6542 - val_accuracy: 0.5904 - val_loss: 1.8810\nEpoch 477/500\n\nEpoch 477: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6542 - val_accuracy: 0.5904 - val_loss: 1.8801\nEpoch 478/500\n\nEpoch 478: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6542 - val_accuracy: 0.5904 - val_loss: 1.8780\nEpoch 479/500\n\nEpoch 479: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6541 - val_accuracy: 0.5904 - val_loss: 1.8821\nEpoch 480/500\n\nEpoch 480: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.6541 - val_accuracy: 0.5902 - val_loss: 1.8844\nEpoch 481/500\n\nEpoch 481: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6541 - val_accuracy: 0.5904 - val_loss: 1.8799\nEpoch 482/500\n\nEpoch 482: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6541 - val_accuracy: 0.5904 - val_loss: 1.8800\nEpoch 483/500\n\nEpoch 483: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6540 - val_accuracy: 0.5904 - val_loss: 1.8795\nEpoch 484/500\n\nEpoch 484: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8052 - loss: 0.6540 - val_accuracy: 0.5902 - val_loss: 1.8799\nEpoch 485/500\n\nEpoch 485: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6540 - val_accuracy: 0.5903 - val_loss: 1.8815\nEpoch 486/500\n\nEpoch 486: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6540 - val_accuracy: 0.5903 - val_loss: 1.8827\nEpoch 487/500\n\nEpoch 487: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8053 - loss: 0.6540 - val_accuracy: 0.5902 - val_loss: 1.8833\nEpoch 488/500\n\nEpoch 488: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6539 - val_accuracy: 0.5902 - val_loss: 1.8851\nEpoch 489/500\n\nEpoch 489: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8051 - loss: 0.6539 - val_accuracy: 0.5902 - val_loss: 1.8815\nEpoch 490/500\n\nEpoch 490: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8046 - loss: 0.6539 - val_accuracy: 0.5903 - val_loss: 1.8837\nEpoch 491/500\n\nEpoch 491: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6539 - val_accuracy: 0.5902 - val_loss: 1.8836\nEpoch 492/500\n\nEpoch 492: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6538 - val_accuracy: 0.5902 - val_loss: 1.8822\nEpoch 493/500\n\nEpoch 493: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8044 - loss: 0.6538 - val_accuracy: 0.5902 - val_loss: 1.8840\nEpoch 494/500\n\nEpoch 494: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8043 - loss: 0.6538 - val_accuracy: 0.5903 - val_loss: 1.8850\nEpoch 495/500\n\nEpoch 495: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8051 - loss: 0.6538 - val_accuracy: 0.5903 - val_loss: 1.8845\nEpoch 496/500\n\nEpoch 496: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8048 - loss: 0.6537 - val_accuracy: 0.5902 - val_loss: 1.8822\nEpoch 497/500\n\nEpoch 497: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8047 - loss: 0.6537 - val_accuracy: 0.5903 - val_loss: 1.8841\nEpoch 498/500\n\nEpoch 498: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8050 - loss: 0.6537 - val_accuracy: 0.5902 - val_loss: 1.8865\nEpoch 499/500\n\nEpoch 499: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8054 - loss: 0.6537 - val_accuracy: 0.5902 - val_loss: 1.8860\nEpoch 500/500\n\nEpoch 500: val_accuracy did not improve from 0.60485\n726/726 - 4s - 6ms/step - accuracy: 0.8049 - loss: 0.6536 - val_accuracy: 0.5903 - val_loss: 1.8831\n","output_type":"stream"}],"execution_count":19}]}